<!DOCTYPE html>
<!-- saved from url=(0071)https://arxiv.org/html/2502.14881?_immersive_translate_auto_translate=1 -->
<html lang="en" data-theme="light" imt-state="dual" imt-trans-position="after"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations</title>
<!--Generated on Fri Feb 14 08:23:59 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/bootstrap.bundle.min.js"></script>
<script src="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/html2canvas.min.js"></script>
<script src="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/addons_new.js"></script>
<script src="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/feedbackOverlay.js"></script>
<meta content="
Large Vision-Language Model,  Safety,  Attack,  Defense,  Evaluation
" lang="en" name="keywords">
<!--<base href="/html/2502.14881v1/">--><base href="."><link rel="stylesheet" href="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-modal {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style><style data-id="immersive-translate-default-injected-css">:root {
  --immersive-translate-theme-underline-borderColor: #72ece9;
  --immersive-translate-theme-nativeUnderline-borderColor: #72ece9;
  --immersive-translate-theme-nativeDashed-borderColor: #72ece9;
  --immersive-translate-theme-nativeDotted-borderColor: #72ece9;
  --immersive-translate-theme-highlight-backgroundColor: #ffff00;
  --immersive-translate-theme-dashed-borderColor: #59c1bd;
  --immersive-translate-theme-blockquote-borderColor: #cc3355;
  --immersive-translate-theme-thinDashed-borderColor: #ff374f;
  --immersive-translate-theme-dashedBorder-borderColor: #94a3b8;
  --immersive-translate-theme-dashedBorder-borderRadius: 0;
  --immersive-translate-theme-solidBorder-borderColor: #94a3b8;
  --immersive-translate-theme-solidBorder-borderRadius: 0;
  --immersive-translate-theme-dotted-borderColor: #94a3b8;
  --immersive-translate-theme-wavy-borderColor: #72ece9;
  --immersive-translate-theme-dividingLine-borderColor: #94a3b8;
  --immersive-translate-theme-grey-textColor: #2f4f4f;
  --immersive-translate-theme-marker-backgroundColor: #fbda41;
  --immersive-translate-theme-marker-backgroundColor-rgb: 251, 218, 65;
  --immersive-translate-theme-marker2-backgroundColor: #ffff00;
  --immersive-translate-theme-background-backgroundColor: #dbafaf;
  --immersive-translate-theme-background-backgroundColor-rgb: 219, 175, 175;
  --immersive-translate-theme-background-backgroundOpacity: 12;
  --immersive-translate-theme-opacity-opacity: 10;
}

[imt-state="dual"] .immersive-translate-target-translation-pre-whitespace {
  white-space: pre-wrap !important;
}

[imt-state="dual"] .immersive-translate-pdf-target-container {
  position: absolute;
  background-color: #fff;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica,
    sans-serif;
  top: 0;
  width: 600px;
  height: 100%;
  z-index: 2;
  line-height: 1.3;
  font-size: 16px;
}
[imt-state="dual"] .immersive-translate-target-wrapper[dir="rtl"] {
  text-align: right;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper {
  color: rgb(0, 0, 0);
  white-space: normal;
  position: absolute;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper
  font {
  color: inherit;
  white-space: inherit;
  position: unset;
}

[imt-state="translation"] .immersive-translate-target-wrapper > br {
  display: none;
}

[imt-state="translation"]
  .immersive-translate-target-translation-block-wrapper {
  margin: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-block-wrapper {
  margin: 8px 0 !important;
  display: inline-block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  display: block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  margin-top: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-pdf-block-wrapper {
  margin: 0 !important;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-grey-inner {
  color: var(--immersive-translate-theme-grey-textColor);
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-underline-inner {
  border-bottom: 1px solid
    var(--immersive-translate-theme-underline-borderColor) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeUnderline-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeUnderline-borderColor
  ) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDashed-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDashed-borderColor
  ) !important;
  text-decoration-style: dashed !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-thinDashed-inner {
  border-bottom: 1px dashed
    var(--immersive-translate-theme-thinDashed-borderColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dotted-inner {
  background-image: linear-gradient(
    to right,
    var(--immersive-translate-theme-dotted-borderColor) 30%,
    rgba(255, 255, 255, 0) 0%
  );
  background-position: bottom;
  background-size: 5px 1px;
  background-repeat: repeat-x;
  padding-bottom: 3px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDotted-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDotted-borderColor
  ) !important;
  text-decoration-style: dotted !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-wavy-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-wavy-borderColor
  ) !important;
  text-decoration-style: wavy !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dashed-inner {
  background: linear-gradient(
      to right,
      var(--immersive-translate-theme-dashed-borderColor) 0%,
      var(--immersive-translate-theme-dashed-borderColor) 50%,
      transparent 50%,
      transparent 100%
    )
    repeat-x left bottom;
  background-size: 8px 2px;
  padding-bottom: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {
  content: "";
  display: block;
  max-width: 80px;
  width: 10%;
  border-top: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  padding-top: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dividingLine::before {
  content: "";
  border-left: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  max-height: 16px;
  height: 16px;
  padding-left: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-highlight-inner {
  background: var(--immersive-translate-theme-highlight-backgroundColor);
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-marker {
  line-height: 1.5em;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker2-inner {
  font-weight: bold;
  text-shadow: 10px 0px 3px
      var(--immersive-translate-theme-marker2-backgroundColor),
    16px 3px 9px var(--immersive-translate-theme-marker2-backgroundColor),
    2px 0px 6px var(--immersive-translate-theme-marker2-backgroundColor),
    -12px 0px 12px var(--immersive-translate-theme-marker2-backgroundColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker-inner {
  /* TODO: add more texture */
  background: linear-gradient(
    to right,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.1),
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 3%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 35%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 70%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.8) 95%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.3)
  );
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-weakening {
  opacity: 0.618 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-italic {
  font-style: italic !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-bold {
  font-weight: bold !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-paper {
  margin: 8px 0;
  box-shadow: rgba(0, 0, 0, 0.24) 0px 3px 8px;
  padding: 16px 32px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-blockquote {
  border-left: 4px solid var(--immersive-translate-theme-blockquote-borderColor) !important;
  padding-left: 12px !important;
  margin-top: 4px;
  margin-bottom: 4px;
  padding-top: 4px;
  padding-bottom: 4px;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-mask-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-mask-inner {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

/* opacity theme start */

[imt-state="dual"] .immersive-translate-target-translation-theme-opacity-inner {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-opacity-inner {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner,
[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: none !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-mask-inner:hover {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

/* opacity theme end */

/* background theme start */
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-background {
  margin: 8px 0;
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  border-radius: 4px;
  box-shadow: unset !important;
  padding: 12px;
  display: inline-block;
}
[imt-state="dual"]
  .immersive-translate-target-translation-theme-background-inner {
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  padding-left: 6px;
  padding-right: 6px;
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper
  .immersive-translate-target-translation-theme-background-inner {
  background: unset;
  padding-left: unset;
  padding-right: unset;
}
/* background theme end */

/* vertical css , please remain it in the last one. */
.immersive-translate-target-translation-vertical-block-wrapper {
  margin: 0px 8px !important;
}

.immersive-translate-text {
  font-size: 15px !important;
}

.immersive-translate-error-toast {
  position: fixed;
  top: 5%;
  z-index: 99999999;
  left: 0;
  right: 0;
  margin: auto;
  max-width: 300px;
  padding: 16px;
  border-radius: 12px;
  background-color: rgba(0, 0, 0, 0.8);
  display: flex;
  flex-direction: row;
  justify-content: space-between;
}

@media all and (min-width: 750px) {
  .immersive-translate-error-toast {
    max-width: 400px;
  }
}

.immersive-translate-clickable-button {
  cursor: pointer;
}

.immersive-translate-help-button {
  cursor: pointer;
}

.immersive-translate-loading-text:before {
  content: "...";
}

/* dark mode for loading */

@media only screen and (prefers-color-scheme: dark) {
  .immersive-translate-loading {
    border: 2px rgba(255, 255, 255, 0.25) solid !important;
    border-top: 2px rgba(255, 255, 255, 1) solid !important;
  }
}

.immersive-translate-error-wrapper {
  position: relative;
  display: inline-flex;
  padding: 6px;
  margin: 0 12px;
  white-space: nowrap;
  font-size: 0.9em;
}
[lang="zh-CN"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}
[lang="zh-TW"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}

.immersive-translate-tooltip {
  position: relative;
  display: inline-flex;
  /* little indicater to indicate it's hoverable */
}

.immersive-translate-tooltip-content {
  /* here's the magic */
  position: absolute;
  z-index: 100000000000;

  left: 50%;
  bottom: 0;
  transform: translate(-50%, 110%);
  line-height: 1;
  /* and add a small left margin */

  /* basic styles */
  width: max-content;
  max-width: 250px;
  word-wrap: break-word;
  white-space: pre-line;
  padding: 10px;
  border-radius: 10px;
  background: #000c;
  color: #fff;
  text-align: center;
  font-size: 14px;
  display: none;
  /* hide by default */
}

.immersive-translate-tooltip:hover .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip:hover + .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip-content-table {
  left: unset !important;
  bottom: unset !important;
  transform: translate(-10%, 50%) !important;
}

.immersive-translate-tooltip:hover:before {
  display: inline-block;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5);
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--bg-2, #fff);
  font-size: 14px;
}
</style><style data-id="immersive-translate-user-custom-style">:root {

.immersive-translate-target-inner { font-family: inherit; }


.immersive-translate-target-inner { font-family: inherit; }
}
</style><style data-id="immersive-translate-dynamic-injected-css">.immersive-translate-target-wrapper[dir='rtl'] {text-align: right;display:block!important;}
[dir='rtl'] .immersive-translate-target-wrapper:not([dir]) {text-align:left;direction:ltr;}
.immersive-translate-target-wrapper {word-break:break-word; user-select:text;}
[imt-state=dual] .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {display:block;}
[imt-trans-position=before] .immersive-translate-target-translation-block-wrapper {display:block!important;}
</style></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2502.14881?_immersive_translate_auto_translate=1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2502.14881v1/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2502.14881v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2502.14881v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2502.14881?_immersive_translate_auto_translate=1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1" title="In A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1.SS1" title="In 1 Introduction ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span><span class="ltx_text ltx_font_italic">Prior Surveys</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1.SS2" title="In 1 Introduction ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span><span class="ltx_text ltx_font_italic">Contributions</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2" title="In A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span><span class="ltx_text ltx_font_smallcaps">Background</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS1" title="In 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span><span class="ltx_text ltx_font_italic">Large Vision-Language Models</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS2" title="In 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span><span class="ltx_text ltx_font_italic">Unique Vulnerabilities of LVLMs</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS3" title="In 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span><span class="ltx_text ltx_font_italic">Access Capabilities</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS4" title="In 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span><span class="ltx_text ltx_font_italic">Attack Objectives</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS5" title="In 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span><span class="ltx_text ltx_font_italic">Attack Strategies</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3" title="In A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_font_smallcaps">Attack</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1" title="In 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span><span class="ltx_text ltx_font_italic">Inference-Phase Attacks</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS1" title="In 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>White-Box Attacks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS2" title="In 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Gray-Box Attacks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS3" title="In 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Black-Box Attacks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2" title="In 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span><span class="ltx_text ltx_font_italic">Training-Phase Attacks</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2.SSS1" title="In 3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Label Poisoning Attacks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2.SSS2" title="In 3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Backdoor Trigger Attacks</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4" title="In A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span><span class="ltx_text ltx_font_smallcaps">Defense</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1" title="In 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span><span class="ltx_text ltx_font_italic">Inference-Phase Defenses</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS1" title="In 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Input Sanization Defenses</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS2" title="In 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Internal Optimization Defenses</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS3" title="In 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Output Validation Defenses</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS4" title="In 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.4 </span>Multi-Stage Integration Defenses</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2" title="In 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span><span class="ltx_text ltx_font_italic">Training-Phase Defenses</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2.SSS1" title="In 4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Data-Driven Refinement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2.SSS2" title="In 4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Strategy-Driven Optimization</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5" title="In A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span><span class="ltx_text ltx_font_smallcaps">Evaluation</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS1" title="In 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span><span class="ltx_text ltx_font_italic">Setup</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS1.SSS1" title="In 5.1 Setup ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS1.SSS2" title="In 5.1 Setup ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2" title="In 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span><span class="ltx_text ltx_font_italic">Benchmarks</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2.SSS1" title="In 5.2 Benchmarks ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Strategy Effectivity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2.SSS2" title="In 5.2 Benchmarks ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.2 </span>Safety Capability</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S6" title="In A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span><span class="ltx_text ltx_font_smallcaps">Safety Evaluation on Janus-Pro</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S6.SS1" title="In 6 Safety Evaluation on Janus-Pro ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span><span class="ltx_text ltx_font_italic">Details of Janus-Pro</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S6.SS2" title="In 6 Safety Evaluation on Janus-Pro ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span><span class="ltx_text ltx_font_italic">Experiments</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S6.SS2.SSS1" title="In 6.2 Experiments ‣ 6 Safety Evaluation on Janus-Pro ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.1 </span>Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S6.SS2.SSS2" title="In 6.2 Experiments ‣ 6 Safety Evaluation on Janus-Pro ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.2 </span>Results Analyse</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S7" title="In A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span><span class="ltx_text ltx_font_smallcaps">Outlook</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S7.SS1" title="In 7 Outlook ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span><span class="ltx_text ltx_font_italic">Future Trends</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S7.SS2" title="In 7 Outlook ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span><span class="ltx_text ltx_font_italic">Conclusion</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2502.14881?_immersive_translate_auto_translate=1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert" onclick="closePopup()">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: epic</li><li>failed: fontawesome</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: arXiv.org perpetual non-exclusive license<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">许可证：arXiv.org 永久非排他性许可</font></font></font></a><div id="watermark-tr" data-imt_insert_failed="1">arXiv:2502.14881v1 [cs.CR] 14 Feb 2025</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">《大型视觉语言模型安全综述：攻击、防御与评估》</font></font></font></h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Mang Ye,
Xuankun Rong, Wenke Huang, Bo Du, Nenghai Yu, Dacheng Tao,&nbsp;


</span><span class="ltx_author_notes">
M. Ye, X. Rong, W. Huang, and B. Du are with the School of Computer Science, Wuhan University, Wuhan, China. E-mail:{yemang, rongxuankun, wenkehuang, dubo}@whu.edu.cn
N. Yu is with the School of Cyber Science and Technology, University of Science and Technology of China, Hefei, China. E-mail: ynh@ustc.edu.cn D. Tao is with the College of Computing and Data Science,
Nanyang Technological University, Singapore. E-mail: dacheng.tao@gmail.com </span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">摘要</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id1.id1">With the rapid advancement of Large Vision-Language Models (LVLMs), ensuring their safety has emerged as a crucial area of research. This survey provides a comprehensive analysis of LVLM safety, covering key aspects such as attacks, defenses, and evaluation methods. We introduce a unified framework that integrates these interrelated components, offering a holistic perspective on the vulnerabilities of LVLMs and the corresponding mitigation strategies. Through an analysis of the LVLM lifecycle, we introduce a classification framework that distinguishes between inference and training phases, with further subcategories to provide deeper insights. Furthermore, we highlight limitations in existing research and outline future directions aimed at strengthening the robustness of LVLMs. As part of our research, we conduct a set of safety evaluations on the latest LVLM, Deepseek Janus-Pro, and provide a theoretical analysis of the results. Our findings provide strategic recommendations for advancing LVLM safety and ensuring their secure and reliable deployment in high-stakes, real-world applications. This survey aims to serve as a cornerstone for future research, facilitating the development of models that not only push the boundaries of multimodal intelligence but also adhere to the highest standards of security and ethical integrity.
Furthermore, to aid the growing research in this field, we have created a public repository to continuously compile and update the latest work on LVLM safety: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/XuankunRong/Awesome-LVLM-Safety" title="">https://github.com/XuankunRong/Awesome-LVLM-Safety</a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">随着大型视觉语言模型（LVLMs）的快速发展，确保其安全性已成为一个关键的研究领域。本综述全面分析了 LVLM 的安全性，涵盖了攻击、防御和评估方法等关键方面。我们介绍了一个统一框架，将这些相互关联的组成部分整合起来，为 LVLM 的漏洞以及相应的缓解策略提供了整体视角。通过分析 LVLM 的生命周期，我们引入了一个分类框架，区分了推理和训练阶段，并进一步细分为子类别以提供更深入的见解。此外，我们强调了现有研究的局限性，并概述了旨在增强 LVLM 鲁棒性的未来方向。作为我们研究的一部分，我们对最新的 LVLM Deepseek Janus-Pro 进行了一系列安全性评估，并对结果进行了理论分析。我们的研究为推进 LVLM 安全性提供了战略建议，并确保其在高风险、现实世界应用中的安全可靠部署。 这项调查旨在为未来研究奠定基础，促进开发不仅推动多模态智能边界，而且符合最高安全标准和道德完整性的模型。此外，为了帮助该领域日益增长的研究，我们创建了一个公共仓库，用于持续编译和更新 LVLM 安全方面的最新工作：https://github.com/XuankunRong/Awesome-LVLM-Safety。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
Large Vision-Language Model, Safety, Attack, Defense, Evaluation

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">索引词：大型视觉语言模型，安全，攻击，防御，评估</font></font></font></div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1 引言</font></font></font>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Nowadays Large Language Models (LLMs) have remarkably transformed the AI landscape, demonstrating unprecedented capabilities in natural language understanding and generation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib6" title="">6</a>]</cite>.
Their versatility and scalability have set new benchmarks across various domains, from conversational agents to complex problem-solving tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib11" title="">11</a>]</cite>.
To further enhance the applicability of LLMs, researchers have integrated visual modalities, giving rise to Large Vision-Language Models (LVLMs)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib17" title="">17</a>]</cite>.
This fusion has expanded the horizons of AI by enabling multimodal comprehension and interaction. LVLMs have rapidly evolved from early task-specific systems, such as image captioning and visual question answering, to sophisticated frameworks capable of complex reasoning and creative generation. Leveraging large-scale pretraining on diverse datasets, models like CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib12" title="">12</a>]</cite>, ALIGN&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib18" title="">18</a>]</cite>, GPT-4V&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib16" title="">16</a>]</cite>, and LLaVA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib15" title="">15</a>]</cite> have set new standards in zero-shot and few-shot learning. The advancements in LVLMs have unlocked their potential across a wide array of applications, including autonomous driving&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib19" title="">19</a>]</cite>, healthcare diagnostics&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib20" title="">20</a>]</cite>, and content creation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib22" title="">22</a>]</cite>.
As the field continues to advance, LVLMs are poised to become indispensable tools in critical industries, driving the development of highly adaptive and intelligent AI systems with comprehensive multimodal understanding.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">如今，大型语言模型（LLMs）已显著改变了人工智能领域，展现出在自然语言理解和生成方面的前所未有的能力[1, 2, 3, 4, 5, 6]。它们的通用性和可扩展性在从对话代理到复杂问题解决任务等多个领域树立了新的标杆[7, 8, 9, 10, 11]。为了进一步提升 LLMs 的适用性，研究人员将视觉模态整合进来，由此诞生了大型视觉语言模型（LVLMs）[12, 13, 14, 15, 16, 17]。这种融合通过实现多模态理解和交互扩展了人工智能的视野。LVLMs 已从早期的特定任务系统（如图像描述和视觉问答）迅速发展，成为能够进行复杂推理和创造性生成的先进框架。通过在多样化数据集上进行大规模预训练，像 CLIP[12]、ALIGN[18]、GPT-4V[16]和 LLaVA[15]等模型在零样本和少样本学习方面树立了新标准。LVLMs 的进步解锁了它们在自动驾驶[19]、医疗诊断[20]和内容创作[21, 22]等广泛应用中的潜力。 随着该领域的不断进步，LVLMs 正逐渐成为关键行业中不可或缺的工具，推动着具有全面多模态理解能力的高度适应性和智能 AI 系统的发展。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">While LVLMs offer immense benefits and have significantly enhanced user experiences across various applications, ensuring their safety and security is equally paramount.
The multimodal nature of LVLMs introduces unique vulnerabilities, as adversarial perturbations in one modality (for example, subtly altered images) can cascade through the system&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib25" title="">25</a>]</cite>, resulting in unsafe behaviors and potentially harmful outputs when combined with deceptive textual inputs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib27" title="">27</a>]</cite>.
Moreover, challenges like difficulties in model alignment&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib29" title="">29</a>]</cite>, and susceptibility to backdoor attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib32" title="">32</a>]</cite> further exacerbate the security concerns surrounding LVLMs. In practical scenarios, these vulnerabilities can have severe repercussions: for example, manipulated medical images may lead to incorrect diagnoses, adversarial alterations of financial data can distort risk assessments, and tampered navigation maps or traffic signs can mislead autonomous driving systems, resulting in hazardous outcomes. As LVLMs become increasingly integrated into critical sectors like healthcare, finance, and transportation, it is imperative to prioritize the robustness, reliability, and ethical alignment of these models. Addressing the security challenges of LVLMs is not only a technical necessity but also a crucial step towards the responsible and safe deployment of these advanced AI systems in real-world applications.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管大型视觉语言模型（LVLMs）带来了巨大的益处，并在各种应用中显著提升了用户体验，但确保其安全性和可靠性同样至关重要。LVLMs 的多模态特性带来了独特的脆弱性，因为一种模态（例如，微妙改变的图像）中的对抗性扰动会通过系统级联[ 23, 24, 25]，当与欺骗性文本输入结合时[ 26, 27]，可能导致不安全行为和潜在的有害输出。此外，模型对齐困难[ 28, 29]以及易受后门攻击[ 30, 31, 32]等挑战进一步加剧了围绕 LVLMs 的安全问题。在实际场景中，这些脆弱性可能带来严重后果：例如，被篡改的医疗图像可能导致误诊，对抗性修改的金融数据会扭曲风险评估，而篡改的导航地图或交通标志会误导自动驾驶系统，最终导致危险结果。 随着大型视觉语言模型（LVLMs）越来越多地融入医疗保健、金融和交通等关键领域，优先考虑这些模型的鲁棒性、可靠性和伦理一致性变得至关重要。解决 LVLMs 的安全挑战不仅是技术上的必要条件，也是负责任和安全地部署这些先进 AI 系统在实际应用中的关键步骤。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S1.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Overview of related surveys. See details in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1.SS1" title="1.1 Prior Surveys ‣ 1 Introduction ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">1.1</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 I：相关调查概述。详情见§ 1.1。</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S1.T1.1" style="width:867.2pt;height:449.9pt;vertical-align:-1.2pt;"><span class="ltx_transformed_inner" style="transform:translate(78.7pt,-40.7pt) scale(1.22185070499498,1.22185070499498) ;">
<table class="ltx_tabular ltx_align_middle" id="S1.T1.1.1">
<tbody><tr class="ltx_tr" id="S1.T1.1.1.1" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.1.1.1.1" style="padding:2.5pt 4.0pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span><span class="ltx_text" id="S1.T1.1.1.1.1.1" style="background-color:#D8D6C4;">
<span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.1.1.1">Surveys<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">调查</font></font></font></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.1.2" style="padding:2.5pt 4.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.2.1" style="background-color:#D8D6C4;">Attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">攻击</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.1.3" style="padding:2.5pt 4.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.3.1" style="background-color:#D8D6C4;">Defense<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">防御</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.1.4" style="padding:2.5pt 4.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.4.1" style="background-color:#D8D6C4;">Evaluation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">评估</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.1.5" style="padding:2.5pt 4.0pt;"><span class="ltx_text ltx_font_bold" id="S1.T1.1.1.1.5.1" style="background-color:#D8D6C4;">Contributions &amp; Limitations<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">贡献与局限性</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.2">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" id="S1.T1.1.1.2.1" style="padding:2.5pt 4.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S1.T1.1.1.2.1.1" style="color:#4D4D4D;">[IJCAI’24]</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib33" title="">33</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.2.2" style="padding:2.5pt 4.0pt;"><del class="ltx_del updiagonalstrike" id="S1.T1.1.1.2.2.1" style="color:#5DAD55;"><span class="ltx_text" id="S1.T1.1.1.2.2.1.1">✓</span></del></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.2.3" style="padding:2.5pt 4.0pt;"><del class="ltx_del updiagonalstrike" id="S1.T1.1.1.2.3.1" style="color:#5DAD55;"><span class="ltx_text" id="S1.T1.1.1.2.3.1.1">✓</span></del></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S1.T1.1.1.2.4" style="padding:2.5pt 4.0pt;"><del class="ltx_del updiagonalstrike" id="S1.T1.1.1.2.4.1" style="color:#5DAD55;"><span class="ltx_text" id="S1.T1.1.1.2.4.1.1">✓</span></del></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S1.T1.1.1.2.5" style="padding:2.5pt 4.0pt;">
<span class="ltx_text" id="S1.T1.1.1.2.5.1"></span><span class="ltx_text" id="S1.T1.1.1.2.5.2">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.1.1.2.5.2.1">
<span class="ltx_tr" id="S1.T1.1.1.2.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.2.5.2.1.1.1" style="padding:2.5pt 4.0pt;">Provides a concise overview and basic categorization, lacking in-depth analysis<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">提供简洁的概述和基本分类，缺乏深入分析</font></font></font></span></span>
<span class="ltx_tr" id="S1.T1.1.1.2.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.2.5.2.1.2.1" style="padding:2.5pt 4.0pt;">and comprehensive discussion of methods.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">以及方法的全 diện 讨论。</font></font></font></span></span>
</span></span><span class="ltx_text" id="S1.T1.1.1.2.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.3">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.1.1.3.1" style="padding:2.5pt 4.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S1.T1.1.1.3.1.1" style="color:#4D4D4D;">[arXiv’24]</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib34" title="">34</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.3.2" style="padding:2.5pt 4.0pt;"><del class="ltx_del updiagonalstrike" id="S1.T1.1.1.3.2.1" style="color:#5DAD55;"><span class="ltx_text" id="S1.T1.1.1.3.2.1.1">✓</span></del></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.3.3" style="padding:2.5pt 4.0pt;"><del class="ltx_del updiagonalstrike" id="S1.T1.1.1.3.3.1" style="color:#5DAD55;"><span class="ltx_text" id="S1.T1.1.1.3.3.1.1">✓</span></del></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.3.4" style="padding:2.5pt 4.0pt;">-</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.3.5" style="padding:2.5pt 4.0pt;">
<span class="ltx_text" id="S1.T1.1.1.3.5.1"></span><span class="ltx_text" id="S1.T1.1.1.3.5.2">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.1.1.3.5.2.1">
<span class="ltx_tr" id="S1.T1.1.1.3.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.3.5.2.1.1.1" style="padding:2.5pt 4.0pt;">Focuses primarily on vulnerabilities in image inputs of multimodal models,<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">主要关注多模态模型图像输入中的漏洞，</font></font></font></span></span>
<span class="ltx_tr" id="S1.T1.1.1.3.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.3.5.2.1.2.1" style="padding:2.5pt 4.0pt;">with limited attention to text-based attacks and cross-modal vulnerabilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对基于文本的攻击和跨模态漏洞关注有限。</font></font></font></span></span>
</span></span><span class="ltx_text" id="S1.T1.1.1.3.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.4">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.1.1.4.1" style="padding:2.5pt 4.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S1.T1.1.1.4.1.1" style="color:#4D4D4D;">[EMNLP’24]</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib35" title="">35</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.4.2" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.4.3" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.4.4" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.4.5" style="padding:2.5pt 4.0pt;">
<span class="ltx_text" id="S1.T1.1.1.4.5.1"></span><span class="ltx_text" id="S1.T1.1.1.4.5.2">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.1.1.4.5.2.1">
<span class="ltx_tr" id="S1.T1.1.1.4.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.4.5.2.1.1.1" style="padding:2.5pt 4.0pt;">Explores jailbreaks from LLMs to LVLMs, focusing narrowly on attacks while<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">探讨了从 LLMs 到 LVLMs 的越狱，但仅狭隘地关注攻击。</font></font></font></span></span>
<span class="ltx_tr" id="S1.T1.1.1.4.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.4.5.2.1.2.1" style="padding:2.5pt 4.0pt;">lacking broader analysis of robustness and safety frameworks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">缺乏对鲁棒性和安全框架的更广泛分析。</font></font></font></span></span>
</span></span><span class="ltx_text" id="S1.T1.1.1.4.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.5">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.1.1.5.1" style="padding:2.5pt 4.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S1.T1.1.1.5.1.1" style="color:#4D4D4D;">[arXiv’24]</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib36" title="">36</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.5.2" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.5.3" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.5.4" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.5.5" style="padding:2.5pt 4.0pt;">
<span class="ltx_text" id="S1.T1.1.1.5.5.1"></span><span class="ltx_text" id="S1.T1.1.1.5.5.2">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.1.1.5.5.2.1">
<span class="ltx_tr" id="S1.T1.1.1.5.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.5.5.2.1.1.1" style="padding:2.5pt 4.0pt;">Comprehensive survey of jailbreaking attacks in LLMs and LVLMs, but lacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对 LLMs 和 LVLMs 中的越狱攻击进行了全面调查，但缺乏</font></font></font></span></span>
<span class="ltx_tr" id="S1.T1.1.1.5.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.5.5.2.1.2.1" style="padding:2.5pt 4.0pt;">detailed coverage of non-jailbreaking attacks and defenses.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对非越狱攻击和防御的详细覆盖。</font></font></font></span></span>
</span></span><span class="ltx_text" id="S1.T1.1.1.5.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.6">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.1.1.6.1" style="padding:2.5pt 4.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S1.T1.1.1.6.1.1" style="color:#4D4D4D;">[arXiv’24]</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib37" title="">37</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.6.2" style="padding:2.5pt 4.0pt;"><span class="ltx_text" id="S1.T1.1.1.6.2.1" style="color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.6.3" style="padding:2.5pt 4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.6.4" style="padding:2.5pt 4.0pt;">-</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.6.5" style="padding:2.5pt 4.0pt;">
<span class="ltx_text" id="S1.T1.1.1.6.5.1"></span><span class="ltx_text" id="S1.T1.1.1.6.5.2">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.1.1.6.5.2.1">
<span class="ltx_tr" id="S1.T1.1.1.6.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.6.5.2.1.1.1" style="padding:2.5pt 4.0pt;">Surveys recent advances in attacks on LVLMs, focusing on methodologies,<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">综述了针对 LVLMs 的攻击的最新进展，重点关注了方法，</font></font></font></span></span>
<span class="ltx_tr" id="S1.T1.1.1.6.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.6.5.2.1.2.1" style="padding:2.5pt 4.0pt;">but lacks sufficient emphasis on defenses and evaluations<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">但缺乏对防御和评估的足够重视</font></font></font></span></span>
</span></span><span class="ltx_text" id="S1.T1.1.1.6.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.7">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.1.1.7.1" style="padding:2.5pt 4.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S1.T1.1.1.7.1.1" style="color:#4D4D4D;">[arXiv’24]</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib38" title="">38</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.7.2" style="padding:2.5pt 4.0pt;">Adversarial<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对抗性</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.7.3" style="padding:2.5pt 4.0pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.7.4" style="padding:2.5pt 4.0pt;">-</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.7.5" style="padding:2.5pt 4.0pt;">
<span class="ltx_text" id="S1.T1.1.1.7.5.1"></span><span class="ltx_text" id="S1.T1.1.1.7.5.2">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.1.1.7.5.2.1">
<span class="ltx_tr" id="S1.T1.1.1.7.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.7.5.2.1.1.1" style="padding:2.5pt 4.0pt;">Covers adversarial attacks on vision tasks but fails to address the unique<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">涵盖了对视觉任务中的对抗性攻击，但未能解决与 LVLMs 相关的独特</font></font></font></span></span>
<span class="ltx_tr" id="S1.T1.1.1.7.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.7.5.2.1.2.1" style="padding:2.5pt 4.0pt;">multimodal security challenges associated with LVLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多模态安全挑战。</font></font></font></span></span>
</span></span><span class="ltx_text" id="S1.T1.1.1.7.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.8">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.1.1.8.1" style="padding:2.5pt 4.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S1.T1.1.1.8.1.1" style="color:#4D4D4D;">[arXiv’24]</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib39" title="">39</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.8.2" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S1.T1.1.1.8.3" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S1.T1.1.1.8.4" style="padding:2.5pt 4.0pt;">Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱</font></font></font></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S1.T1.1.1.8.5" style="padding:2.5pt 4.0pt;">
<span class="ltx_text" id="S1.T1.1.1.8.5.1"></span><span class="ltx_text" id="S1.T1.1.1.8.5.2">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.1.1.8.5.2.1">
<span class="ltx_tr" id="S1.T1.1.1.8.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.8.5.2.1.1.1" style="padding:2.5pt 4.0pt;">Highlights jailbreaking attacks and defenses in multimodal generative models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">强调了对多模态生成模型中的越狱攻击和防御。</font></font></font></span></span>
<span class="ltx_tr" id="S1.T1.1.1.8.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.8.5.2.1.2.1" style="padding:2.5pt 4.0pt;">but excludes broader LVLM use cases and attack scenarios.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">但它排除了更广泛的 LVLM 使用案例和攻击场景。</font></font></font></span></span>
</span></span><span class="ltx_text" id="S1.T1.1.1.8.5.3"></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.9">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" id="S1.T1.1.1.9.1" style="background-color:#F5F5F0;padding:2.5pt 4.0pt;"><span class="ltx_text" id="S1.T1.1.1.9.1.1" style="background-color:#F5F5F0;" data-imt_insert_failed="1">Ours</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.9.2" style="background-color:#F5F5F0;padding:2.5pt 4.0pt;"><span class="ltx_text" id="S1.T1.1.1.9.2.1" style="background-color:#F5F5F0;"><span class="ltx_text" id="S1.T1.1.1.9.2.1.1" style="color:#5DAD55;">✓</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S1.T1.1.1.9.3" style="background-color:#F5F5F0;padding:2.5pt 4.0pt;"><span class="ltx_text" id="S1.T1.1.1.9.3.1" style="background-color:#F5F5F0;"><span class="ltx_text" id="S1.T1.1.1.9.3.1.1" style="color:#5DAD55;">✓</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S1.T1.1.1.9.4" style="background-color:#F5F5F0;padding:2.5pt 4.0pt;"><span class="ltx_text" id="S1.T1.1.1.9.4.1" style="background-color:#F5F5F0;"><span class="ltx_text" id="S1.T1.1.1.9.4.1.1" style="color:#5DAD55;">✓</span></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S1.T1.1.1.9.5" style="background-color:#F5F5F0;padding:2.5pt 4.0pt;"><span class="ltx_text" id="S1.T1.1.1.9.5.1" style="background-color:#F5F5F0;"><span class="ltx_text" id="S1.T1.1.1.9.5.1.1"></span><span class="ltx_text" id="S1.T1.1.1.9.5.1.2">
<span class="ltx_tabular ltx_align_middle" id="S1.T1.1.1.9.5.1.2.1">
<span class="ltx_tr" id="S1.T1.1.1.9.5.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.9.5.1.2.1.1.1" style="padding:2.5pt 4.0pt;">Presents a systematic analysis of LVLM safety, introducing a lifecycle-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">介绍基于生命周期的 LVLM 安全系统性分析</font></font></font></span></span>
<span class="ltx_tr" id="S1.T1.1.1.9.5.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S1.T1.1.1.9.5.1.2.1.2.1" style="padding:2.5pt 4.0pt;">classification and integrating perspectives on attacks, defenses, and evaluations.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">分类和整合关于攻击、防御和评估的视角。</font></font></font></span></span>
</span></span><span class="ltx_text" id="S1.T1.1.1.9.5.1.3"></span></span></td>
</tr>
<tr class="ltx_tr" id="S1.T1.1.1.10">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S1.T1.1.1.10.1" style="padding:2.5pt 4.0pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_t" id="S1.T1.1.1.10.2" style="padding:2.5pt 4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S1.T1.1.1.10.3" style="padding:2.5pt 4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S1.T1.1.1.10.4" style="padding:2.5pt 4.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S1.T1.1.1.10.5" style="padding:2.5pt 4.0pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Currently, safety-related research on LVLMs can be delineated into the following three categories:
<span class="ltx_text ltx_font_bold" id="S1.p3.1.1">i)&nbsp;Attacks</span>.
Investigating attacks on LVLMs is essential for uncovering and mitigating the vulnerabilities inherent in these sophisticated architectures. Unlike LLMs, LVLMs present more extensive security challenges due to the integration of visual and textual modalities&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib42" title="">42</a>]</cite>. Adversaries frequently exploit weaknesses in the visual processing components and inherent vulnerabilities in the training methodologies of LVLMs to induce the model to output unsafe responses.
<span class="ltx_text ltx_font_bold" id="S1.p3.1.2">ii)&nbsp;Defenses</span>.
Defense strategies are designed to enhance the resilience of LVLMs against a spectrum of adversarial threats. Based on the lifecycle of LVLM, these strategies are typically categorized into inference-phase and training-phase defenses. Inference-phase defenses incorporate techniques such as input sanization&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib44" title="">44</a>]</cite>, internal optimization&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib46" title="">46</a>]</cite> and output validation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib47" title="">47</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib48" title="">48</a>]</cite> to safeguard models during deployment, effectively preventing the exploitation of operational vulnerabilities. Conversely, training-phase defenses employ methodologies like adversarial fine-tuning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib50" title="">50</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib51" title="">51</a>]</cite> to fortify the models during their development, thereby augmenting their robustness against potential adversarial manipulations.
<span class="ltx_text ltx_font_bold" id="S1.p3.1.3">iii)&nbsp;Evaluations</span>.
Evaluation efforts focus on the creation of comprehensive benchmarks that assess the security capabilities of various LVLMs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib54" title="">54</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib55" title="">55</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib56" title="">56</a>]</cite>. These benchmarks provide standardized frameworks for researchers to evaluate and compare the efficacy of safety measures across different models. By systematically identifying security deficiencies, these evaluations facilitate the advancement of more secure and reliable LVLMs, ensuring their safe integration into critical applications.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">目前，关于 LVLMs 的安全相关研究可以划分为以下三个类别：i) 攻击。研究 LVLMs 的攻击对于揭示和缓解这些复杂架构中固有的漏洞至关重要。与 LLMs 不同，由于集成了视觉和文本模态，LVLMs 带来了更广泛的安全挑战[28, 23, 40, 41, 42]。攻击者经常利用 LVLMs 视觉处理组件中的弱点和训练方法中的固有漏洞，诱使模型输出不安全响应。ii) 防御。防御策略旨在增强 LVLMs 对各种对抗性威胁的鲁棒性。基于 LVLMs 的生命周期，这些策略通常分为推理阶段防御和训练阶段防御。推理阶段防御包括输入清理[43, 44]、内部优化[45, 46]和输出验证[47, 48]等技术，以在部署期间保护模型，有效防止操作漏洞的利用。 相反，训练阶段的防御采用对抗微调等方法[49, 50, 51]，在模型开发过程中增强其能力，从而提高其对抗潜在对抗性操控的鲁棒性。iii) 评估。评估工作重点在于创建综合基准，用于评估各种视觉语言模型的（安全）能力[52, 53, 54, 55, 56]。这些基准为研究人员提供了标准化的框架，用于评估和比较不同模型中安全措施的有效性。通过系统地识别安全缺陷，这些评估促进了更安全、更可靠的视觉语言模型的发展，确保它们能够安全地集成到关键应用中。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="352" id="S1.F1.g1" src="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/x1.png" width="830"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S1.F1.1"><svg height="175.11" overflow="visible" version="1.1" width="781.87"><g transform="translate(0,175.11) scale(1,-1)"><g transform="translate(-588.07,84.41)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="138.923481389235"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1" style="font-size:70%;" title="1 Introduction ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a></foreignobject></g></g><g transform="translate(-588.07,55.35)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="144.319911443199"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1.SS1" style="font-size:70%;" title="1.1 Prior Surveys ‣ 1 Introduction ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">1.1</span></a></foreignobject></g></g><g transform="translate(-594.99,19.37)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="145.150131451501"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1.SS2" style="font-size:70%;" title="1.2 Contributions ‣ 1 Introduction ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">1.2</span></a></foreignobject></g></g><g transform="translate(-339.01,81.64)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="135.74097135741"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2" style="font-size:70%;" title="2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a></foreignobject></g></g><g transform="translate(-359.76,53.96)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="217.65601217656"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS1" style="font-size:70%;" title="2.1 Large Vision-Language Models ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2.1</span></a></foreignobject></g></g><g transform="translate(-350.08,19.37)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="326.138093261381"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS2" style="font-size:70%;" title="2.2 Unique Vulnerabilities of LVLMs ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2.2</span></a></foreignobject></g></g><g transform="translate(-213.09,59.5)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="161.892901618929"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS3" style="font-size:70%;" title="2.3 Access Capabilities ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2.3</span></a></foreignobject></g></g><g transform="translate(-214.47,36.67)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="162.999861629999"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS4" style="font-size:70%;" title="2.4 Attack Objectives ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2.4</span></a></foreignobject></g></g><g transform="translate(-214.47,13.84)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="159.955721599557"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS5" style="font-size:70%;" title="2.5 Attack Strategies ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2.5</span></a></foreignobject></g></g><g transform="translate(-433.1,160.51)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="115.262211152622"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3" style="font-size:70%;" title="3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a></foreignobject></g></g><g transform="translate(-624.05,196.49)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="188.736681887367"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1" style="font-size:70%;" title="3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1</span></a></foreignobject></g></g><g transform="translate(-636.5,171.58)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="167.012591670126"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS1" style="font-size:70%;" title="3.1.1 White-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.1</span></a></foreignobject></g></g><g transform="translate(-642.04,150.82)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="161.892901618929"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS2" style="font-size:70%;" title="3.1.2 Gray-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a></foreignobject></g></g><g transform="translate(-642.04,130.07)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="164.383561643836"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS3" style="font-size:70%;" title="3.1.3 Black-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.3</span></a></foreignobject></g></g><g transform="translate(-503.67,196.49)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="186.24602186246"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2" style="font-size:70%;" title="3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2</span></a></foreignobject></g></g><g transform="translate(-511.97,166.04)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="189.843641898436"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2.SSS1" style="font-size:70%;" title="3.2.1 Label Poisoning Attacks ‣ 3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2.1</span></a></foreignobject></g></g><g transform="translate(-506.43,134.91)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="195.931921959319"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2.SSS2" style="font-size:70%;" title="3.2.2 Backdoor Trigger Attacks ‣ 3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2.2</span></a></foreignobject></g></g><g transform="translate(-348.69,239.38)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="119.274941192749"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4" style="font-size:70%;" title="4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a></foreignobject></g></g><g transform="translate(-532.72,283.66)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="192.61104192611"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1" style="font-size:70%;" title="4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1</span></a></foreignobject></g></g><g transform="translate(-601.91,261.52)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="197.038881970389"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS1" style="font-size:70%;" title="4.1.1 Input Sanization Defenses ‣ 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1.1</span></a></foreignobject></g></g><g transform="translate(-458,261.52)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="218.901342189013"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS2" style="font-size:70%;" title="4.1.2 Internal Optimization Defenses ‣ 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1.2</span></a></foreignobject></g></g><g transform="translate(-599.14,238)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="204.234122042341"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS3" style="font-size:70%;" title="4.1.3 Output Validation Defenses ‣ 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1.3</span></a></foreignobject></g></g><g transform="translate(-446.94,236.61)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="226.096582260966"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS4" style="font-size:70%;" title="4.1.4 Multi-Stage Integration Defenses ‣ 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1.4</span></a></foreignobject></g></g><g transform="translate(-128.68,282.27)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="190.258751902588"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2" style="font-size:70%;" title="4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.2</span></a></foreignobject></g></g><g transform="translate(-114.85,258.75)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="190.535491905355"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2.SSS1" style="font-size:70%;" title="4.2.1 Data-Driven Refinement ‣ 4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.2.1</span></a></foreignobject></g></g><g transform="translate(-92.71,237.3)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="213.366542133665"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2.SSS2" style="font-size:70%;" title="4.2.2 Strategy-Driven Optimization ‣ 4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.2.2</span></a></foreignobject></g></g><g transform="translate(-262.9,160.51)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="132.281721322817"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5" style="font-size:70%;" title="5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a></foreignobject></g></g><g transform="translate(-161.89,196.49)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="110.972741109727"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS1" style="font-size:70%;" title="5.1 Setup ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.1</span></a></foreignobject></g></g><g transform="translate(-166.04,167.43)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="123.42604123426"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS1.SSS1" style="font-size:70%;" title="5.1.1 Methods ‣ 5.1 Setup ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.1.1</span></a></foreignobject></g></g><g transform="translate(-168.81,136.99)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="118.306351183064"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS1.SSS2" style="font-size:70%;" title="5.1.2 Metrics ‣ 5.1 Setup ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.1.2</span></a></foreignobject></g></g><g transform="translate(-45.66,196.49)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="138.3700013837"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2" style="font-size:70%;" title="5.2 Benchmarks ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.2</span></a></foreignobject></g></g><g transform="translate(-33.21,167.43)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="169.7799916978"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2.SSS1" style="font-size:70%;" title="5.2.1 Strategy Effectivity ‣ 5.2 Benchmarks ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.2.1</span></a></foreignobject></g></g><g transform="translate(-40.13,136.99)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="160.232461602325"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2.SSS2" style="font-size:70%;" title="5.2.2 Safety Capability ‣ 5.2 Benchmarks ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.2.2</span></a></foreignobject></g></g><g transform="translate(-55.35,83.02)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="121.212121212121"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S7" style="font-size:70%;" title="7 Outlook ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">7</span></a></foreignobject></g></g><g transform="translate(-48.43,54.66)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="146.948941469489"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S7.SS1" style="font-size:70%;" title="7.1 Future Trends ‣ 7 Outlook ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">7.1</span></a></foreignobject></g></g><g transform="translate(-56.73,20.06)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="133.111941331119"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S7.SS2" style="font-size:70%;" title="7.2 Conclusion ‣ 7 Outlook ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">7.2</span></a></foreignobject></g></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the survey. Best viewed in color.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 1：调查概述。最佳效果为彩色查看。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span><span class="ltx_text ltx_font_italic" id="S1.SS1.1.1">Prior Surveys</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1.1 先前综述</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">Recent surveys on the safety and security of Large Vision-Language Models (LVLMs) have made significant contributions by highlighting the diverse attack methods, defense mechanisms, and vulnerabilities specific to multimodal systems.
However, despite these valuable insights, current surveys often fall short of providing a comprehensive and systematic view that integrates both attack and defense strategies across all modalities, leaving gaps in understanding the full spectrum of LVLM vulnerabilities.
Therefore, we discuss the main contributions and limitations of existing related surveys and highlight the unique contributions of our work in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1.T1" title="In 1 Introduction ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Tab.</span>&nbsp;<span class="ltx_text ltx_ref_tag">I</span></a>.
For instance, Liu <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.1">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib33" title="">33</a>]</cite> explore the general safety concerns in LVLMs, focusing on issues like unsafe outputs caused by inconsistencies between the image and text modalities. It provides a concise overview and basic categorization of the core safety challenges, but lacks in-depth exploration of advanced attack techniques and specific countermeasures tailored for LVLMs.
In contrast, Fan <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib34" title="">34</a>]</cite> emphasize the risks associated with image inputs in LVLMs, particularly in the context of adversarial image manipulations and their downstream effects on text generation. This survey provides valuable insights into the inherent vulnerabilities in LVLMs’ visual understanding but does not sufficiently address the broader spectrum of safety concerns, such as backdoor attacks or the interplay between different attack modalities (e.g., visual and textual).
Similarly, Wang <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.3">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib35" title="">35</a>]</cite> and Jin <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.4">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib36" title="">36</a>]</cite> concentrate on the emerging problem of jailbreaking attacks from LLMs to LVLMs, providing detailed analyses of attack methods and possible defensive strategies. While both surveys are highly focused on jailbreaking, they leave gaps in covering other attack types and the overall landscape of LVLM security.
Surveys such as Liu <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.5">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib37" title="">37</a>]</cite> and Zhang <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.6">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib38" title="">38</a>]</cite> offer more expansive overviews of adversarial and attack-based vulnerabilities in LVLMs. Liu <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.7">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib37" title="">37</a>]</cite> survey recent advances in LVLM attacks, offering a broad perspective on resources and trends, but it lacks a focused discussion on multimodal-specific attacks and fails to integrate defense strategies systematically. Zhang <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.8">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib38" title="">38</a>]</cite> present a historical overview of adversarial attacks on vision tasks and their relevance to LVLMs. However, its narrow focus on vision-specific tasks limits its applicability to the multimodal setting of modern LVLMs. Lastly, Liu <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.9">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib39" title="">39</a>]</cite> specifically address jailbreak attacks and defenses for generative multimodal models, providing a detailed account of this rapidly evolving threat. However, it limited scope to multimodal generative models, excluding broader LVLM use cases and attacks, such as prompt injection or backdoor poisoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">关于大型视觉语言模型（LVLMs）的安全性和安全性的最新综述通过强调针对多模态系统的多样化攻击方法、防御机制和特定漏洞做出了重要贡献。然而，尽管这些宝贵的见解，目前的综述往往未能提供全面且系统的视角，整合所有模态的攻击和防御策略，导致在理解 LVLM 漏洞全貌方面存在空白。因此，我们在表 I 中讨论了现有相关综述的主要贡献和局限性，并突出了我们工作的独特贡献。例如，Liu 等人[33]探讨了 LVLM 的一般安全问题，重点关注图像和文本模态之间不一致导致的不安全输出等问题。它提供了核心安全挑战的简要概述和基本分类，但在深入探讨高级攻击技术和针对 LVLM 的特定对策方面存在不足。 相比之下，Fan 等人[34]强调了 LVLMs 中图像输入相关的风险，特别是在对抗性图像操作及其对文本生成的影响方面。这项调查为 LVLMs 视觉理解中的固有漏洞提供了宝贵的见解，但并未充分涵盖更广泛的安全问题，例如后门攻击或不同攻击方式（例如视觉和文本）之间的相互作用。类似地，Wang 等人[35]和 Jin 等人[36]专注于 LLMs 到 LVLMs 的越狱攻击这一新兴问题，提供了对攻击方法和可能防御策略的详细分析。虽然这两项调查都高度关注越狱攻击，但它们在涵盖其他攻击类型和 LVLMs 整体安全状况方面存在空白。例如，Liu 等人[37]和张等人[38]的综述提供了更广泛的关于 LVLMs 中对抗性和基于攻击的漏洞的概述。 刘等人[37]综述了 LVLM 攻击的最新进展，从资源和趋势的角度提供了广泛的视角，但缺乏对多模态特定攻击的集中讨论，并且未能系统地整合防御策略。张等人[38]概述了针对视觉任务的对齐攻击及其与 LVLM 的相关性。然而，其仅关注视觉特定任务的狭窄焦点限制了其在现代 LVLM 多模态环境中的适用性。最后，刘等人[39]专门针对生成式多模态模型的越狱攻击和防御进行了探讨，详细记录了这一快速发展的威胁。 然而，其范围仅限于多模态生成模型，排除了更广泛的 LVLM 使用案例和攻击，例如提示注入或后门中毒。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span><span class="ltx_text ltx_font_italic" id="S1.SS2.1.1">Contributions</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1.2 贡献</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">In this paper, we introduce a comprehensive survey on safety of LVLM and mainly focus on attacks, defenses, and evaluations. Compared with existing surveys, this paper makes the following contributions:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本文中，我们介绍了关于大型视觉语言模型（LVLM）安全性的全面综述，主要关注攻击、防御和评估。与现有综述相比，本文做出了以下贡献：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We provide a comprehensive and systematic analysis of LVLM safety by integrating the interconnected aspects of attacks, defenses, and evaluations. Isolated examination of attacks or defenses alone does not fully capture the overall security landscape, whereas our approach combines these critical components to offer a more holistic understanding of the vulnerabilities and mitigation strategies inherent in LVLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 我们通过整合攻击、防御和评估的相互关联方面，对 LVLM 安全性进行了全面和系统的分析。单独考察攻击或防御无法全面捕捉整体安全态势，而我们的方法将这些关键组成部分结合起来，提供对 LVLM 中固有漏洞和缓解策略更全面的理解。</font></font></font>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">By analyzing the lifecycle of LVLMs, we propose a universal classification framework that categorizes security-related works based on the model’s inference and training phases. Further subcategories are identified to provide a more granular understanding. For each work, we present a thorough exploration of the methodologies and contributions, delivering a comprehensive and insightful analysis of the prevailing landscape of LVLM security.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 通过分析 LVLM 的生命周期，我们提出了一个通用分类框架，根据模型的推理和训练阶段对安全相关研究进行分类。进一步细分的子类别被识别出来，以提供更精细的理解。对于每项研究，我们深入探讨了其方法和贡献，为 LVLM 安全现状提供了全面而深刻的分析。</font></font></font>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We conduct safety evaluations on the latest LVLM, Deepseek Janus-Pro and delineate future research trajectories, presenting profound insights and strategic recommendations that empower the research community to enhance the safety and robustness of LVLMs. This guidance is instrumental in facilitating the safe and reliable deployment of these models within mission-critical applications.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 我们对最新的视觉语言模型（LVLM）Deepseek Janus-Pro 进行安全性评估，并阐明未来研究方向，为研究界提供深刻见解和战略建议，以提升 LVLM 的安全性和鲁棒性。这一指导对于促进这些模型在关键任务应用中的安全可靠部署至关重要。</font></font></font>
</li>
</ul>
<p class="ltx_p" id="S1.SS2.p1.2">The remainder of this paper is structured as follows: <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S1.F1" title="In 1 Introduction ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Fig.</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a> delineates the overall framework of this survey. <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2" title="2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a> provides a succinct overview of the foundational aspects of LVLM safety. The safety of LVLMs is systematically analyzed from three principal perspectives: <span class="ltx_text ltx_font_bold" id="S1.SS2.p1.2.1">Attacks</span> in <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3" title="3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>, <span class="ltx_text ltx_font_bold" id="S1.SS2.p1.2.2">Defenses</span> in <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4" title="4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>, and <span class="ltx_text ltx_font_bold" id="S1.SS2.p1.2.3">Evaluations</span> in <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5" title="5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>. Lastly, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S7.SS1" title="7.1 Future Trends ‣ 7 Outlook ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">7.1</span></a> explores prospective research directions, followed by concluding remarks in <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S7.SS2" title="7.2 Conclusion ‣ 7 Outlook ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">7.2</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本文的其余部分结构如下：图 1 概述了本综述的整体框架。§ 2 简要介绍了 LVLM 安全的基础方面。LVLM 的安全性从三个主要视角进行了系统分析：§ 3 中的攻击，§ 4 中的防御，以及§ 5 中的评估。最后，§ 7.1 探讨了未来的研究方向，随后在§ 7.2 中进行总结。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Background</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2 背景 </font></font></font>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span class="ltx_text ltx_font_italic" id="S2.SS1.1.1">Large Vision-Language Models</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.1 大型视觉语言模型</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The development of Large Language Models (LLMs) has emerged as a cornerstone in the field of artificial intelligence, revolutionizing the way machines understand and generate human language. Examples of prominent LLMs include OpenAI’s GPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib57" title="">57</a>]</cite>, Google’s PaLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib58" title="">58</a>]</cite>, Meta’s LLaMA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib5" title="">5</a>]</cite>, and Vicuna&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib59" title="">59</a>]</cite>, all of which have demonstrated remarkable capabilities ranging from natural language understanding and generation.
To expand the applicability of LLMs, existing solutions normally integrated vision components, leading to the development of Large Vision-Language Models (LVLMs). By utilizing the visual extractor like CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib12" title="">12</a>]</cite> to encode visual features and utilize the connector module to project visual tokens into word embedding space of the LLM, LVLMs are capable of jointly processing text and visual inputs. This multimodal integration enables LVLMs to bridge the gap between vision and language, paving the way for more advanced applications in diverse fields.
Subsequent developments in LVLMs have led to the emergence of several notable models, including Flamingo&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib13" title="">13</a>]</cite>, BLIP-2&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib14" title="">14</a>]</cite>, GPT-4V&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib16" title="">16</a>]</cite>, Gemini&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib60" title="">60</a>]</cite>, MiniGPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib61" title="">61</a>]</cite>, PandaGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib62" title="">62</a>]</cite>, LLaVA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib15" title="">15</a>]</cite>, LLaVa-OneVision&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib63" title="">63</a>]</cite>, InternVL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib64" title="">64</a>]</cite>, Qwen-VL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib65" title="">65</a>]</cite>, and VILA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib66" title="">66</a>]</cite>.
The integration of vision and language in LVLMs has opened up new possibilities across a variety of application domains. For instance, LVLMs are widely utilized in image captioning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib68" title="">68</a>]</cite>, where they generate descriptive text for images, and in visual question answering (VQA), where they answer questions based on image content. These models are also employed in content moderation, combining text and visual inputs to detect inappropriate or harmful content, and in creative industries, enabling tasks such as generating creative narratives based on visual inputs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib21" title="">21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib22" title="">22</a>]</cite>. Beyond these, specialized applications include medical imaging for diagnostic insights&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib20" title="">20</a>]</cite>, autonomous driving for visual scene understanding&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib19" title="">19</a>]</cite>, and education for generating multimodal instructional content.
Despite their impressive capabilities, LVLMs face several significant challenges. Scalability remains a key issue as the integration of multimodal data requires increased computational resources, both during training and inference. Furthermore, robustness to adversarial inputs, especially in multimodal contexts, is a growing concern. Adversarial attacks can exploit the interaction between text and visual inputs, leading to unexpected or unsafe outputs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib25" title="">25</a>]</cite>. Bias and fairness are also critical issues, as LVLMs often inherit biases from their training data, which can result in unfair or harmful outputs in sensitive contexts&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib69" title="">69</a>]</cite>. Lastly, safety and alignment are ongoing challenges, as LVLMs are susceptible to producing toxic or misleading content due to gaps in their training or failure to understand multimodal queries.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大型语言模型（LLMs）的发展已成为人工智能领域的重要基石，彻底改变了机器理解和生成人类语言的方式。著名的 LLMs 包括 OpenAI 的 GPT-4 [3, 16, 57]、Google 的 PaLM [4, 58]、Meta 的 LLaMA [5]和 Vicuna [59]，它们都展示了从自然语言理解到生成等方面的卓越能力。为了扩展 LLMs 的应用范围，现有解决方案通常集成了视觉组件，从而推动了大型视觉语言模型（LVLMs）的发展。通过利用视觉提取器（如 CLIP [12]）对视觉特征进行编码，并使用连接模块将视觉标记投影到 LLM 的词嵌入空间，LVLMs 能够联合处理文本和视觉输入。这种多模态集成使 LVLMs 能够弥合视觉和语言之间的差距，为不同领域更高级的应用铺平了道路。 LVLMs 后续的发展催生了多个知名模型，包括 Flamingo [ 13]、BLIP-2 [ 14]、GPT-4V [ 16]、Gemini [ 60]、MiniGPT-4 [ 61]、PandaGPT [ 62]、LLaVA [ 15]、LLaVa-OneVision [ 63]、InternVL [ 64]、Qwen-VL [ 65]和 VILA [ 66]。LVLMs 中视觉与语言的融合为各种应用领域开辟了新的可能性。例如，LVLMs 广泛应用于图像描述 [ 67, 68]，为图像生成描述性文本，以及视觉问答（VQA），根据图像内容回答问题。这些模型也被用于内容审核，结合文本和视觉输入检测不当或有害内容，以及创意产业，实现基于视觉输入生成创意叙事等任务 [ 21, 22]。除此之外，专业应用还包括医学影像用于诊断分析 [ 20]、自动驾驶用于视觉场景理解 [ 19]以及教育用于生成多模态教学内容。尽管 LVLMs 能力令人印象深刻，但它们仍面临若干重大挑战。 可扩展性仍然是一个关键问题，因为多模态数据的集成需要更多的计算资源，无论是在训练还是在推理过程中。此外，对对抗性输入的鲁棒性，特别是在多模态环境中，是一个日益增长的担忧。对抗性攻击可以利用文本和视觉输入之间的交互，导致意外或不安全的输出[23, 24, 25]。偏差和公平性也是关键问题，因为 LVLMs 常常从其训练数据中继承偏差，这可能导致在敏感环境中产生不公平或有害的输出[42, 69]。最后，安全和一致性是持续的挑战，因为 LVLMs 容易产生有毒或误导性内容，这是由于其训练中的差距或无法理解多模态查询所致。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><span class="ltx_text ltx_font_italic" id="S2.SS2.1.1">Unique Vulnerabilities of LVLMs</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.2 LVLMs 的独特脆弱性</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The integration of visual modalities into LLMs has enhanced LVLMs’ multimodal capabilities but also introduced unique vulnerabilities. These include new attack surfaces from visual inputs and the degradation of safety alignment during fine-tuning, both of which compromise the model’s robustness and reliability. Details as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">将视觉模态整合到 LLMs 中增强了 LVLMs 的多模态能力，但也引入了独特的漏洞。这些漏洞包括来自视觉输入的新攻击面以及微调过程中安全对齐的退化，这两者都损害了模型的鲁棒性和可靠性。具体如下：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mo id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">Expansion Risks Introduced by Visual Inputs.</span>
The integration of visual modalities into LLMs inherently leads to an expansion of attack surfaces, exposing models to new security risks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib28" title="">28</a>]</cite>. In LLMs, adversarial attacks are constrained to the discrete nature of textual input&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib71" title="">71</a>]</cite>, making such manipulations more demanding, and defenses only need to address textual vulnerabilities. However, the introduction of visual inputs exposes the model to the inherently continuous and high-dimensional visual input space, which serves as a weak link&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib72" title="">72</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib25" title="">25</a>]</cite>. These characteristics make visual adversarial examples fundamentally challenging to defend against. Consequently, the transition from a purely textual domain to a composite textual-visual domain not only broadens the vulnerability surfaces but also escalates the complexity and burden of defensive measures.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS2.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS2.p2.1.m1.1a"><mo id="S2.SS2.p2.1.m1.1.1">∙</mo><annotation-xml id="S2.SS2.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS2.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS2.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 视觉输入引入的扩展风险。将视觉模态集成到 LLMs 中会内在地导致攻击面的扩展，使模型面临新的安全风险[23, 40, 41, 42, 28]。在 LLMs 中，对抗性攻击受限于文本输入的离散性[70, 71]，使得此类操纵更加困难，防御措施只需解决文本漏洞。然而，引入视觉输入使模型暴露于本质上连续且高维的视觉输入空间，这成为薄弱环节[72, 25]。这些特性使得视觉对抗性示例从根本上难以防御。因此，从纯文本领域过渡到文本-视觉复合领域不仅扩大了漏洞面，还增加了防御措施的复杂性和负担。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><mo id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><ci id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS2.p3.1.1">Degradation of Safety During Fine-Tuning.</span>
Degradation of Safety During Fine-Tuning. Visual Instruction Tuning has become essential for enabling Large Language Models (LLMs) to process multimodal inputs by integrating a pre-trained LLM with a vision encoder through a projector layer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib61" title="">61</a>]</cite>. This process allows LVLMs to reason across modalities, addressing tasks beyond the capabilities of language-only models. However, their performance depends heavily on the underlying vision and language components, making them susceptible to vulnerabilities caused by misalignment between these modules.
A significant limitation of current fine-tuning practices is the freezing of the vision encoder while updating only the projector layer and LLM. This approach leaves the vision encoder without robust safety defenses, exposing it to adversarial or harmful inputs. Additionally, the lack of safety-aware training often leads to the degradation of the model’s pre-trained safety alignment, a phenomenon referred to as catastrophic forgetting&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib42" title="">42</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib73" title="">73</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib74" title="">74</a>]</cite>. As a result, the model becomes increasingly prone to generating unsafe outputs, particularly in response to adversarial prompts.
This degradation is further amplified when a larger portion of the model’s parameters are fine-tuned&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib40" title="">40</a>]</cite>, as extensive updates disrupt the original safety alignment. Consequently, fine-tuning that prioritizes performance without adequately addressing safety risks can unintentionally increase the model’s vulnerabilities. This underscores the critical importance of developing training strategies that maintain both safety and performance, particularly as LVLMs are adapted to new multimodal tasks and domains.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS2.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS2.p3.1.m1.1a"><mo id="S2.SS2.p3.1.m1.1.1">∙</mo><annotation-xml id="S2.SS2.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS2.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS2.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 微调过程中的安全性退化。微调过程中的安全性退化。视觉指令微调已成为使大型语言模型（LLMs）能够处理多模态输入的关键，通过投影层将预训练的 LLM 与视觉编码器集成[15, 13, 14, 61]。这个过程使 LVLMs 能够在模态间进行推理，处理仅靠语言模型无法完成的任务。然而，它们的性能严重依赖于底层的视觉和语言组件，容易受到这些模块间错位导致的漏洞影响。当前微调实践的一个显著局限性是在仅更新投影层和 LLM 时冻结视觉编码器。这种方法使视觉编码器缺乏强大的安全防御，使其容易受到对抗性或有害输入的攻击。此外，缺乏安全意识训练常常导致模型预训练的安全对齐性退化，这种现象被称为灾难性遗忘[42, 49, 73, 74]。因此，模型越来越容易生成不安全的输出，尤其是在对抗性提示的响应下。 当模型更大一部分参数被微调时，这种退化会进一步加剧[40]，因为大量的更新会破坏原有的安全对齐。因此，那种优先考虑性能而未能充分解决安全风险的微调可能会无意中增加模型的风险。这突显了开发既能保持安全又能提升性能的训练策略的极端重要性，尤其是在大型视觉语言模型被应用于新的多模态任务和领域时。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span><span class="ltx_text ltx_font_italic" id="S2.SS3.1.1">Access Capabilities</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.3 访问能力</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.7">The interaction with LVLMs, whether for attacks or defenses can be categorized based on the knowledge set <math alttext="\mathcal{K}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">\mathcal{K}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">caligraphic_K</annotation></semantics></math> about the model <math alttext="f_{\theta}" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1"><semantics id="S2.SS3.p1.2.m2.1a"><msub id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml"><mi id="S2.SS3.p1.2.m2.1.1.2" xref="S2.SS3.p1.2.m2.1.1.2.cmml">f</mi><mi id="S2.SS3.p1.2.m2.1.1.3" xref="S2.SS3.p1.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><apply id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.2.m2.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.p1.2.m2.1.1.2.cmml" xref="S2.SS3.p1.2.m2.1.1.2">𝑓</ci><ci id="S2.SS3.p1.2.m2.1.1.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">f_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.1d">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> accessible to the entity (attacker or defender). The knowledge may encompass elements such as model parameters <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS3.p1.3.m3.1"><semantics id="S2.SS3.p1.3.m3.1a"><mi id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.1b"><ci id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.3.m3.1d">italic_θ</annotation></semantics></math>, model architecture <math alttext="\mathcal{A}_{\theta}" class="ltx_Math" display="inline" id="S2.SS3.p1.4.m4.1"><semantics id="S2.SS3.p1.4.m4.1a"><msub id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.4.m4.1.1.2" xref="S2.SS3.p1.4.m4.1.1.2.cmml">𝒜</mi><mi id="S2.SS3.p1.4.m4.1.1.3" xref="S2.SS3.p1.4.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.1b"><apply id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.4.m4.1.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS3.p1.4.m4.1.1.2.cmml" xref="S2.SS3.p1.4.m4.1.1.2">𝒜</ci><ci id="S2.SS3.p1.4.m4.1.1.3.cmml" xref="S2.SS3.p1.4.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.1c">\mathcal{A}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.4.m4.1d">caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, gradients <math alttext="\nabla_{\theta}\mathcal{L}" class="ltx_Math" display="inline" id="S2.SS3.p1.5.m5.1"><semantics id="S2.SS3.p1.5.m5.1a"><mrow id="S2.SS3.p1.5.m5.1.1" xref="S2.SS3.p1.5.m5.1.1.cmml"><msub id="S2.SS3.p1.5.m5.1.1.1" xref="S2.SS3.p1.5.m5.1.1.1.cmml"><mo id="S2.SS3.p1.5.m5.1.1.1.2" xref="S2.SS3.p1.5.m5.1.1.1.2.cmml">∇</mo><mi id="S2.SS3.p1.5.m5.1.1.1.3" xref="S2.SS3.p1.5.m5.1.1.1.3.cmml">θ</mi></msub><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.5.m5.1.1.2" xref="S2.SS3.p1.5.m5.1.1.2.cmml">ℒ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.5.m5.1b"><apply id="S2.SS3.p1.5.m5.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1"><apply id="S2.SS3.p1.5.m5.1.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.5.m5.1.1.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1.1">subscript</csymbol><ci id="S2.SS3.p1.5.m5.1.1.1.2.cmml" xref="S2.SS3.p1.5.m5.1.1.1.2">∇</ci><ci id="S2.SS3.p1.5.m5.1.1.1.3.cmml" xref="S2.SS3.p1.5.m5.1.1.1.3">𝜃</ci></apply><ci id="S2.SS3.p1.5.m5.1.1.2.cmml" xref="S2.SS3.p1.5.m5.1.1.2">ℒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.5.m5.1c">\nabla_{\theta}\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.5.m5.1d">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L</annotation></semantics></math>, input data <math alttext="x" class="ltx_Math" display="inline" id="S2.SS3.p1.6.m6.1"><semantics id="S2.SS3.p1.6.m6.1a"><mi id="S2.SS3.p1.6.m6.1.1" xref="S2.SS3.p1.6.m6.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.6.m6.1b"><ci id="S2.SS3.p1.6.m6.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.6.m6.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.6.m6.1d">italic_x</annotation></semantics></math>, and output data <math alttext="y" class="ltx_Math" display="inline" id="S2.SS3.p1.7.m7.1"><semantics id="S2.SS3.p1.7.m7.1a"><mi id="S2.SS3.p1.7.m7.1.1" xref="S2.SS3.p1.7.m7.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.7.m7.1b"><ci id="S2.SS3.p1.7.m7.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.7.m7.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.7.m7.1d">italic_y</annotation></semantics></math>. Based on the scope of accessible knowledge, three distinct capabilities are defined as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与大型视觉语言模型（LVLMs）的交互，无论是用于攻击还是防御，都可以根据实体（攻击者或防御者）可访问的知识集 <math id="S2.SS3.p1.1.m1.1" display="inline" class="ltx_Math" alttext="\mathcal{K}"><semantics id="S2.SS3.p1.1.m1.1a"><mi id="S2.SS3.p1.1.m1.1.1" class="ltx_font_mathcaligraphic">𝒦</mi><annotation-xml id="S2.SS3.p1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p1.1.m1.1c" encoding="application/x-tex">\mathcal{K}</annotation><annotation id="S2.SS3.p1.1.m1.1d" encoding="application/x-llamapun">caligraphic_K</annotation></semantics></math> 关于模型 <math id="S2.SS3.p1.2.m2.1" display="inline" class="ltx_Math" alttext="f_{\theta}"><semantics id="S2.SS3.p1.2.m2.1a"><msub id="S2.SS3.p1.2.m2.1.1"><mi id="S2.SS3.p1.2.m2.1.1.2">f</mi><mi id="S2.SS3.p1.2.m2.1.1.3">θ</mi></msub><annotation-xml id="S2.SS3.p1.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p1.2.m2.1c" encoding="application/x-tex">f_{\theta}</annotation><annotation id="S2.SS3.p1.2.m2.1d" encoding="application/x-llamapun">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 进行分类。这些知识可能包括模型参数 <math id="S2.SS3.p1.3.m3.1" display="inline" class="ltx_Math" alttext="\theta"><semantics id="S2.SS3.p1.3.m3.1a"><mi id="S2.SS3.p1.3.m3.1.1">θ</mi><annotation-xml id="S2.SS3.p1.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p1.3.m3.1c" encoding="application/x-tex">\theta</annotation><annotation id="S2.SS3.p1.3.m3.1d" encoding="application/x-llamapun">italic_θ</annotation></semantics></math> 、模型架构 <math id="S2.SS3.p1.4.m4.1" display="inline" class="ltx_Math" alttext="\mathcal{A}_{\theta}"><semantics id="S2.SS3.p1.4.m4.1a"><msub id="S2.SS3.p1.4.m4.1.1"><mi id="S2.SS3.p1.4.m4.1.1.2" class="ltx_font_mathcaligraphic">𝒜</mi><mi id="S2.SS3.p1.4.m4.1.1.3">θ</mi></msub><annotation-xml id="S2.SS3.p1.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p1.4.m4.1c" encoding="application/x-tex">\mathcal{A}_{\theta}</annotation><annotation id="S2.SS3.p1.4.m4.1d" encoding="application/x-llamapun">caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 、梯度 <math id="S2.SS3.p1.5.m5.1" display="inline" class="ltx_Math" alttext="\nabla_{\theta}\mathcal{L}"><semantics id="S2.SS3.p1.5.m5.1a"><mrow id="S2.SS3.p1.5.m5.1.1"><msub id="S2.SS3.p1.5.m5.1.1.1"><mo id="S2.SS3.p1.5.m5.1.1.1.2">∇</mo><mi id="S2.SS3.p1.5.m5.1.1.1.3">θ</mi></msub><mi id="S2.SS3.p1.5.m5.1.1.2" class="ltx_font_mathcaligraphic">ℒ</mi></mrow><annotation-xml id="S2.SS3.p1.5.m5.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p1.5.m5.1c" encoding="application/x-tex">\nabla_{\theta}\mathcal{L}</annotation><annotation id="S2.SS3.p1.5.m5.1d" encoding="application/x-llamapun">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L</annotation></semantics></math> 、输入数据 <math id="S2.SS3.p1.6.m6.1" display="inline" class="ltx_Math" alttext="x"><semantics id="S2.SS3.p1.6.m6.1a"><mi id="S2.SS3.p1.6.m6.1.1">x</mi><annotation-xml id="S2.SS3.p1.6.m6.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p1.6.m6.1c" encoding="application/x-tex">x</annotation><annotation id="S2.SS3.p1.6.m6.1d" encoding="application/x-llamapun">italic_x</annotation></semantics></math> 和输出数据 <math id="S2.SS3.p1.7.m7.1" display="inline" class="ltx_Math" alttext="y"><semantics id="S2.SS3.p1.7.m7.1a"><mi id="S2.SS3.p1.7.m7.1.1">y</mi><annotation-xml id="S2.SS3.p1.7.m7.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p1.7.m7.1c" encoding="application/x-tex">y</annotation><annotation id="S2.SS3.p1.7.m7.1d" encoding="application/x-llamapun">italic_y</annotation></semantics></math> 等元素。根据可访问知识的范围，定义了三种不同的能力，如下所示：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.4"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><mo id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><ci id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS3.p2.4.1">White-box Capability.</span>
White-box capability represents the highest level of access, where all internal details of the model are fully available, including the model parameters <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS3.p2.2.m2.1"><semantics id="S2.SS3.p2.2.m2.1a"><mi id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><ci id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.2.m2.1d">italic_θ</annotation></semantics></math>, the model architecture <math alttext="\mathcal{A}_{\theta}" class="ltx_Math" display="inline" id="S2.SS3.p2.3.m3.1"><semantics id="S2.SS3.p2.3.m3.1a"><msub id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.3.m3.1.1.2" xref="S2.SS3.p2.3.m3.1.1.2.cmml">𝒜</mi><mi id="S2.SS3.p2.3.m3.1.1.3" xref="S2.SS3.p2.3.m3.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><apply id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1.2">𝒜</ci><ci id="S2.SS3.p2.3.m3.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">\mathcal{A}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.3.m3.1d">caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, and the gradients <math alttext="\nabla_{\theta}\mathcal{L}" class="ltx_Math" display="inline" id="S2.SS3.p2.4.m4.1"><semantics id="S2.SS3.p2.4.m4.1a"><mrow id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml"><msub id="S2.SS3.p2.4.m4.1.1.1" xref="S2.SS3.p2.4.m4.1.1.1.cmml"><mo id="S2.SS3.p2.4.m4.1.1.1.2" xref="S2.SS3.p2.4.m4.1.1.1.2.cmml">∇</mo><mi id="S2.SS3.p2.4.m4.1.1.1.3" xref="S2.SS3.p2.4.m4.1.1.1.3.cmml">θ</mi></msub><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.4.m4.1.1.2" xref="S2.SS3.p2.4.m4.1.1.2.cmml">ℒ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><apply id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1"><apply id="S2.SS3.p2.4.m4.1.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.1.1.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1.1">subscript</csymbol><ci id="S2.SS3.p2.4.m4.1.1.1.2.cmml" xref="S2.SS3.p2.4.m4.1.1.1.2">∇</ci><ci id="S2.SS3.p2.4.m4.1.1.1.3.cmml" xref="S2.SS3.p2.4.m4.1.1.1.3">𝜃</ci></apply><ci id="S2.SS3.p2.4.m4.1.1.2.cmml" xref="S2.SS3.p2.4.m4.1.1.2">ℒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">\nabla_{\theta}\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.4.m4.1d">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L</annotation></semantics></math>. The knowledge set is formally defined as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS3.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS3.p2.1.m1.1a"><mo id="S2.SS3.p2.1.m1.1.1">∙</mo><annotation-xml id="S2.SS3.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS3.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 白盒能力。白盒能力代表最高级别的访问权限，其中模型的所有内部细节都完全可用，包括模型参数 <math id="S2.SS3.p2.2.m2.1" display="inline" class="ltx_Math" alttext="\theta"><semantics id="S2.SS3.p2.2.m2.1a"><mi id="S2.SS3.p2.2.m2.1.1">θ</mi><annotation-xml id="S2.SS3.p2.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p2.2.m2.1c" encoding="application/x-tex">\theta</annotation><annotation id="S2.SS3.p2.2.m2.1d" encoding="application/x-llamapun">italic_θ</annotation></semantics></math> 、模型架构 <math id="S2.SS3.p2.3.m3.1" display="inline" class="ltx_Math" alttext="\mathcal{A}_{\theta}"><semantics id="S2.SS3.p2.3.m3.1a"><msub id="S2.SS3.p2.3.m3.1.1"><mi id="S2.SS3.p2.3.m3.1.1.2" class="ltx_font_mathcaligraphic">𝒜</mi><mi id="S2.SS3.p2.3.m3.1.1.3">θ</mi></msub><annotation-xml id="S2.SS3.p2.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p2.3.m3.1c" encoding="application/x-tex">\mathcal{A}_{\theta}</annotation><annotation id="S2.SS3.p2.3.m3.1d" encoding="application/x-llamapun">caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 和梯度 <math id="S2.SS3.p2.4.m4.1" display="inline" class="ltx_Math" alttext="\nabla_{\theta}\mathcal{L}"><semantics id="S2.SS3.p2.4.m4.1a"><mrow id="S2.SS3.p2.4.m4.1.1"><msub id="S2.SS3.p2.4.m4.1.1.1"><mo id="S2.SS3.p2.4.m4.1.1.1.2">∇</mo><mi id="S2.SS3.p2.4.m4.1.1.1.3">θ</mi></msub><mi id="S2.SS3.p2.4.m4.1.1.2" class="ltx_font_mathcaligraphic">ℒ</mi></mrow><annotation-xml id="S2.SS3.p2.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p2.4.m4.1c" encoding="application/x-tex">\nabla_{\theta}\mathcal{L}</annotation><annotation id="S2.SS3.p2.4.m4.1d" encoding="application/x-llamapun">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L</annotation></semantics></math> 。知识集正式定义为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{K}_{\text{W}}=\{x,y,\theta,\mathcal{A}_{\theta},\nabla_{\theta}%
\mathcal{L}\mid x\in\mathcal{X},y=f_{\theta}(x)\}," class="ltx_Math" display="block" id="S2.E1.m1.5"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1" xref="S2.E1.m1.5.5.1.1.cmml"><msub id="S2.E1.m1.5.5.1.1.4" xref="S2.E1.m1.5.5.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.1.1.4.2" xref="S2.E1.m1.5.5.1.1.4.2.cmml">𝒦</mi><mtext id="S2.E1.m1.5.5.1.1.4.3" xref="S2.E1.m1.5.5.1.1.4.3a.cmml">W</mtext></msub><mo id="S2.E1.m1.5.5.1.1.3" xref="S2.E1.m1.5.5.1.1.3.cmml">=</mo><mrow id="S2.E1.m1.5.5.1.1.2.2" xref="S2.E1.m1.5.5.1.1.2.3.cmml"><mo id="S2.E1.m1.5.5.1.1.2.2.3" stretchy="false" xref="S2.E1.m1.5.5.1.1.2.3.1.cmml">{</mo><mrow id="S2.E1.m1.5.5.1.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">x</mi><mo id="S2.E1.m1.5.5.1.1.1.1.1.2.3" xref="S2.E1.m1.5.5.1.1.1.1.1.3.cmml">,</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">y</mi><mo id="S2.E1.m1.5.5.1.1.1.1.1.2.4" xref="S2.E1.m1.5.5.1.1.1.1.1.3.cmml">,</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">θ</mi><mo id="S2.E1.m1.5.5.1.1.1.1.1.2.5" xref="S2.E1.m1.5.5.1.1.1.1.1.3.cmml">,</mo><msub id="S2.E1.m1.5.5.1.1.1.1.1.1.1" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.2" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.2.cmml">𝒜</mi><mi id="S2.E1.m1.5.5.1.1.1.1.1.1.1.3" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.3.cmml">θ</mi></msub><mo id="S2.E1.m1.5.5.1.1.1.1.1.2.6" xref="S2.E1.m1.5.5.1.1.1.1.1.3.cmml">,</mo><mrow id="S2.E1.m1.5.5.1.1.1.1.1.2.2" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.cmml"><msub id="S2.E1.m1.5.5.1.1.1.1.1.2.2.1" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.cmml"><mo id="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.2" rspace="0.167em" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.2.cmml">∇</mo><mi id="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.3" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.3.cmml">θ</mi></msub><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.1.1.1.1.1.2.2.2" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.2.cmml">ℒ</mi></mrow></mrow><mo fence="true" id="S2.E1.m1.5.5.1.1.2.2.4" lspace="0em" rspace="0em" xref="S2.E1.m1.5.5.1.1.2.3.1.cmml">∣</mo><mrow id="S2.E1.m1.5.5.1.1.2.2.2.2" xref="S2.E1.m1.5.5.1.1.2.2.2.3.cmml"><mrow id="S2.E1.m1.5.5.1.1.2.2.2.1.1" xref="S2.E1.m1.5.5.1.1.2.2.2.1.1.cmml"><mi id="S2.E1.m1.5.5.1.1.2.2.2.1.1.2" xref="S2.E1.m1.5.5.1.1.2.2.2.1.1.2.cmml">x</mi><mo id="S2.E1.m1.5.5.1.1.2.2.2.1.1.1" xref="S2.E1.m1.5.5.1.1.2.2.2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.1.1.2.2.2.1.1.3" xref="S2.E1.m1.5.5.1.1.2.2.2.1.1.3.cmml">𝒳</mi></mrow><mo id="S2.E1.m1.5.5.1.1.2.2.2.2.3" xref="S2.E1.m1.5.5.1.1.2.2.2.3a.cmml">,</mo><mrow id="S2.E1.m1.5.5.1.1.2.2.2.2.2" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.cmml"><mi id="S2.E1.m1.5.5.1.1.2.2.2.2.2.2" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.2.cmml">y</mi><mo id="S2.E1.m1.5.5.1.1.2.2.2.2.2.1" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.1.cmml">=</mo><mrow id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.cmml"><msub id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.cmml"><mi id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.2" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.2.cmml">f</mi><mi id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.3" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.3.cmml">θ</mi></msub><mo id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.1" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.1.cmml">⁢</mo><mrow id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.3.2" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.cmml"><mo id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.3.2.1" stretchy="false" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.cmml">(</mo><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">x</mi><mo id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.3.2.2" stretchy="false" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.5.5.1.1.2.2.5" stretchy="false" xref="S2.E1.m1.5.5.1.1.2.3.1.cmml">}</mo></mrow></mrow><mo id="S2.E1.m1.5.5.1.2" xref="S2.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.1.1.cmml" xref="S2.E1.m1.5.5.1"><eq id="S2.E1.m1.5.5.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.3"></eq><apply id="S2.E1.m1.5.5.1.1.4.cmml" xref="S2.E1.m1.5.5.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.4.1.cmml" xref="S2.E1.m1.5.5.1.1.4">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.4.2.cmml" xref="S2.E1.m1.5.5.1.1.4.2">𝒦</ci><ci id="S2.E1.m1.5.5.1.1.4.3a.cmml" xref="S2.E1.m1.5.5.1.1.4.3"><mtext id="S2.E1.m1.5.5.1.1.4.3.cmml" mathsize="70%" xref="S2.E1.m1.5.5.1.1.4.3">W</mtext></ci></apply><apply id="S2.E1.m1.5.5.1.1.2.3.cmml" xref="S2.E1.m1.5.5.1.1.2.2"><csymbol cd="latexml" id="S2.E1.m1.5.5.1.1.2.3.1.cmml" xref="S2.E1.m1.5.5.1.1.2.2.3">conditional-set</csymbol><list id="S2.E1.m1.5.5.1.1.1.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝑥</ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝑦</ci><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">𝜃</ci><apply id="S2.E1.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.2">𝒜</ci><ci id="S2.E1.m1.5.5.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.1.1.3">𝜃</ci></apply><apply id="S2.E1.m1.5.5.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2"><apply id="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.1"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.1">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.2">∇</ci><ci id="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.3.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.1.3">𝜃</ci></apply><ci id="S2.E1.m1.5.5.1.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.5.5.1.1.1.1.1.2.2.2">ℒ</ci></apply></list><apply id="S2.E1.m1.5.5.1.1.2.2.2.3.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.2.2.2.3a.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.5.5.1.1.2.2.2.1.1.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.1.1"><in id="S2.E1.m1.5.5.1.1.2.2.2.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.1.1.1"></in><ci id="S2.E1.m1.5.5.1.1.2.2.2.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.1.1.2">𝑥</ci><ci id="S2.E1.m1.5.5.1.1.2.2.2.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.1.1.3">𝒳</ci></apply><apply id="S2.E1.m1.5.5.1.1.2.2.2.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2"><eq id="S2.E1.m1.5.5.1.1.2.2.2.2.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.1"></eq><ci id="S2.E1.m1.5.5.1.1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.2">𝑦</ci><apply id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3"><times id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.1.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.1"></times><apply id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.2">𝑓</ci><ci id="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.3.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2.2.2.3.2.3">𝜃</ci></apply><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">𝑥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">\mathcal{K}_{\text{W}}=\{x,y,\theta,\mathcal{A}_{\theta},\nabla_{\theta}%
\mathcal{L}\mid x\in\mathcal{X},y=f_{\theta}(x)\},</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.5d">caligraphic_K start_POSTSUBSCRIPT W end_POSTSUBSCRIPT = { italic_x , italic_y , italic_θ , caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT , ∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L ∣ italic_x ∈ caligraphic_X , italic_y = italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p2.5">this level of access enables precise computation of gradients, making it possible to craft adversarial inputs or design highly effective defense mechanisms. White-box scenarios are typically used in controlled research environments.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这种级别的访问权限能够精确计算梯度，从而可以制作对抗性输入或设计非常有效的防御机制。白盒场景通常用于受控的研究环境。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.4"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS3.p3.1.m1.1"><semantics id="S2.SS3.p3.1.m1.1a"><mo id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><ci id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS3.p3.4.1">Gray-box Capability.</span>
Gray-box capability assumes partial access to the model’s internal details, such as its architecture <math alttext="\mathcal{A}_{\theta}" class="ltx_Math" display="inline" id="S2.SS3.p3.2.m2.1"><semantics id="S2.SS3.p3.2.m2.1a"><msub id="S2.SS3.p3.2.m2.1.1" xref="S2.SS3.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p3.2.m2.1.1.2" xref="S2.SS3.p3.2.m2.1.1.2.cmml">𝒜</mi><mi id="S2.SS3.p3.2.m2.1.1.3" xref="S2.SS3.p3.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.2.m2.1b"><apply id="S2.SS3.p3.2.m2.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.2.m2.1.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.p3.2.m2.1.1.2.cmml" xref="S2.SS3.p3.2.m2.1.1.2">𝒜</ci><ci id="S2.SS3.p3.2.m2.1.1.3.cmml" xref="S2.SS3.p3.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.2.m2.1c">\mathcal{A}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.2.m2.1d">caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> or intermediate feature representations, but lacks full knowledge of <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS3.p3.3.m3.1"><semantics id="S2.SS3.p3.3.m3.1a"><mi id="S2.SS3.p3.3.m3.1.1" xref="S2.SS3.p3.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.3.m3.1b"><ci id="S2.SS3.p3.3.m3.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.3.m3.1d">italic_θ</annotation></semantics></math> or <math alttext="\nabla_{\theta}\mathcal{L}" class="ltx_Math" display="inline" id="S2.SS3.p3.4.m4.1"><semantics id="S2.SS3.p3.4.m4.1a"><mrow id="S2.SS3.p3.4.m4.1.1" xref="S2.SS3.p3.4.m4.1.1.cmml"><msub id="S2.SS3.p3.4.m4.1.1.1" xref="S2.SS3.p3.4.m4.1.1.1.cmml"><mo id="S2.SS3.p3.4.m4.1.1.1.2" xref="S2.SS3.p3.4.m4.1.1.1.2.cmml">∇</mo><mi id="S2.SS3.p3.4.m4.1.1.1.3" xref="S2.SS3.p3.4.m4.1.1.1.3.cmml">θ</mi></msub><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p3.4.m4.1.1.2" xref="S2.SS3.p3.4.m4.1.1.2.cmml">ℒ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.4.m4.1b"><apply id="S2.SS3.p3.4.m4.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1"><apply id="S2.SS3.p3.4.m4.1.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.4.m4.1.1.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.4.m4.1.1.1.2.cmml" xref="S2.SS3.p3.4.m4.1.1.1.2">∇</ci><ci id="S2.SS3.p3.4.m4.1.1.1.3.cmml" xref="S2.SS3.p3.4.m4.1.1.1.3">𝜃</ci></apply><ci id="S2.SS3.p3.4.m4.1.1.2.cmml" xref="S2.SS3.p3.4.m4.1.1.2">ℒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.4.m4.1c">\nabla_{\theta}\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.4.m4.1d">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L</annotation></semantics></math>. The knowledge set is defined as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS3.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS3.p3.1.m1.1a"><mo id="S2.SS3.p3.1.m1.1.1">∙</mo><annotation-xml id="S2.SS3.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS3.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 灰盒能力。灰盒能力假设对模型内部细节的部分访问，例如其架构 <math id="S2.SS3.p3.2.m2.1" display="inline" class="ltx_Math" alttext="\mathcal{A}_{\theta}"><semantics id="S2.SS3.p3.2.m2.1a"><msub id="S2.SS3.p3.2.m2.1.1"><mi id="S2.SS3.p3.2.m2.1.1.2" class="ltx_font_mathcaligraphic">𝒜</mi><mi id="S2.SS3.p3.2.m2.1.1.3">θ</mi></msub><annotation-xml id="S2.SS3.p3.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p3.2.m2.1c" encoding="application/x-tex">\mathcal{A}_{\theta}</annotation><annotation id="S2.SS3.p3.2.m2.1d" encoding="application/x-llamapun">caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 或中间特征表示，但缺乏对 <math id="S2.SS3.p3.3.m3.1" display="inline" class="ltx_Math" alttext="\theta"><semantics id="S2.SS3.p3.3.m3.1a"><mi id="S2.SS3.p3.3.m3.1.1">θ</mi><annotation-xml id="S2.SS3.p3.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p3.3.m3.1c" encoding="application/x-tex">\theta</annotation><annotation id="S2.SS3.p3.3.m3.1d" encoding="application/x-llamapun">italic_θ</annotation></semantics></math> 或 <math id="S2.SS3.p3.4.m4.1" display="inline" class="ltx_Math" alttext="\nabla_{\theta}\mathcal{L}"><semantics id="S2.SS3.p3.4.m4.1a"><mrow id="S2.SS3.p3.4.m4.1.1"><msub id="S2.SS3.p3.4.m4.1.1.1"><mo id="S2.SS3.p3.4.m4.1.1.1.2">∇</mo><mi id="S2.SS3.p3.4.m4.1.1.1.3">θ</mi></msub><mi id="S2.SS3.p3.4.m4.1.1.2" class="ltx_font_mathcaligraphic">ℒ</mi></mrow><annotation-xml id="S2.SS3.p3.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p3.4.m4.1c" encoding="application/x-tex">\nabla_{\theta}\mathcal{L}</annotation><annotation id="S2.SS3.p3.4.m4.1d" encoding="application/x-llamapun">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L</annotation></semantics></math> 的完全了解。知识集定义为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{K}_{\text{G}}=\{x,y,\mathcal{A}_{\theta}\mid x\in\mathcal{X},y=f_{%
\theta}(x)\}," class="ltx_Math" display="block" id="S2.E2.m1.4"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.4.1" xref="S2.E2.m1.4.4.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1" xref="S2.E2.m1.4.4.1.1.cmml"><msub id="S2.E2.m1.4.4.1.1.4" xref="S2.E2.m1.4.4.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.1.1.4.2" xref="S2.E2.m1.4.4.1.1.4.2.cmml">𝒦</mi><mtext id="S2.E2.m1.4.4.1.1.4.3" xref="S2.E2.m1.4.4.1.1.4.3a.cmml">G</mtext></msub><mo id="S2.E2.m1.4.4.1.1.3" xref="S2.E2.m1.4.4.1.1.3.cmml">=</mo><mrow id="S2.E2.m1.4.4.1.1.2.2" xref="S2.E2.m1.4.4.1.1.2.3.cmml"><mo id="S2.E2.m1.4.4.1.1.2.2.3" stretchy="false" xref="S2.E2.m1.4.4.1.1.2.3.1.cmml">{</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">x</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">y</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.2.cmml">,</mo><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml">𝒜</mi><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.cmml">θ</mi></msub></mrow><mo fence="true" id="S2.E2.m1.4.4.1.1.2.2.4" lspace="0em" rspace="0em" xref="S2.E2.m1.4.4.1.1.2.3.1.cmml">∣</mo><mrow id="S2.E2.m1.4.4.1.1.2.2.2.2" xref="S2.E2.m1.4.4.1.1.2.2.2.3.cmml"><mrow id="S2.E2.m1.4.4.1.1.2.2.2.1.1" xref="S2.E2.m1.4.4.1.1.2.2.2.1.1.cmml"><mi id="S2.E2.m1.4.4.1.1.2.2.2.1.1.2" xref="S2.E2.m1.4.4.1.1.2.2.2.1.1.2.cmml">x</mi><mo id="S2.E2.m1.4.4.1.1.2.2.2.1.1.1" xref="S2.E2.m1.4.4.1.1.2.2.2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.1.1.2.2.2.1.1.3" xref="S2.E2.m1.4.4.1.1.2.2.2.1.1.3.cmml">𝒳</mi></mrow><mo id="S2.E2.m1.4.4.1.1.2.2.2.2.3" xref="S2.E2.m1.4.4.1.1.2.2.2.3a.cmml">,</mo><mrow id="S2.E2.m1.4.4.1.1.2.2.2.2.2" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.cmml"><mi id="S2.E2.m1.4.4.1.1.2.2.2.2.2.2" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.2.cmml">y</mi><mo id="S2.E2.m1.4.4.1.1.2.2.2.2.2.1" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.1.cmml">=</mo><mrow id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.cmml"><msub id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.cmml"><mi id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.2" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.2.cmml">f</mi><mi id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.3" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.3.cmml">θ</mi></msub><mo id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.1" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.1.cmml">⁢</mo><mrow id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.3.2" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.cmml"><mo id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.3.2.1" stretchy="false" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.cmml">(</mo><mi id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">x</mi><mo id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.3.2.2" stretchy="false" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E2.m1.4.4.1.1.2.2.5" stretchy="false" xref="S2.E2.m1.4.4.1.1.2.3.1.cmml">}</mo></mrow></mrow><mo id="S2.E2.m1.4.4.1.2" xref="S2.E2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.4.1.1.cmml" xref="S2.E2.m1.4.4.1"><eq id="S2.E2.m1.4.4.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.3"></eq><apply id="S2.E2.m1.4.4.1.1.4.cmml" xref="S2.E2.m1.4.4.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.4.1.cmml" xref="S2.E2.m1.4.4.1.1.4">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.4.2.cmml" xref="S2.E2.m1.4.4.1.1.4.2">𝒦</ci><ci id="S2.E2.m1.4.4.1.1.4.3a.cmml" xref="S2.E2.m1.4.4.1.1.4.3"><mtext id="S2.E2.m1.4.4.1.1.4.3.cmml" mathsize="70%" xref="S2.E2.m1.4.4.1.1.4.3">G</mtext></ci></apply><apply id="S2.E2.m1.4.4.1.1.2.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2"><csymbol cd="latexml" id="S2.E2.m1.4.4.1.1.2.3.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.3">conditional-set</csymbol><list id="S2.E2.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1"><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">𝑥</ci><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">𝑦</ci><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.2">𝒜</ci><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.3">𝜃</ci></apply></list><apply id="S2.E2.m1.4.4.1.1.2.2.2.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.2.2.2.3a.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.4.4.1.1.2.2.2.1.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.1.1"><in id="S2.E2.m1.4.4.1.1.2.2.2.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.1.1.1"></in><ci id="S2.E2.m1.4.4.1.1.2.2.2.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.1.1.2">𝑥</ci><ci id="S2.E2.m1.4.4.1.1.2.2.2.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.1.1.3">𝒳</ci></apply><apply id="S2.E2.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2"><eq id="S2.E2.m1.4.4.1.1.2.2.2.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.1"></eq><ci id="S2.E2.m1.4.4.1.1.2.2.2.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.2">𝑦</ci><apply id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3"><times id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.1"></times><apply id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.1.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.2.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.2">𝑓</ci><ci id="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.3.cmml" xref="S2.E2.m1.4.4.1.1.2.2.2.2.2.3.2.3">𝜃</ci></apply><ci id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">𝑥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">\mathcal{K}_{\text{G}}=\{x,y,\mathcal{A}_{\theta}\mid x\in\mathcal{X},y=f_{%
\theta}(x)\},</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.4d">caligraphic_K start_POSTSUBSCRIPT G end_POSTSUBSCRIPT = { italic_x , italic_y , caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ∣ italic_x ∈ caligraphic_X , italic_y = italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p3.5">this level of access is common in scenarios where the model architecture is publicly known or inferred. For example, a surrogate model <math alttext="\mathcal{S_{\theta}}" class="ltx_Math" display="inline" id="S2.SS3.p3.5.m1.1"><semantics id="S2.SS3.p3.5.m1.1a"><msub id="S2.SS3.p3.5.m1.1.1" xref="S2.SS3.p3.5.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p3.5.m1.1.1.2" xref="S2.SS3.p3.5.m1.1.1.2.cmml">𝒮</mi><mi id="S2.SS3.p3.5.m1.1.1.3" xref="S2.SS3.p3.5.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.5.m1.1b"><apply id="S2.SS3.p3.5.m1.1.1.cmml" xref="S2.SS3.p3.5.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.5.m1.1.1.1.cmml" xref="S2.SS3.p3.5.m1.1.1">subscript</csymbol><ci id="S2.SS3.p3.5.m1.1.1.2.cmml" xref="S2.SS3.p3.5.m1.1.1.2">𝒮</ci><ci id="S2.SS3.p3.5.m1.1.1.3.cmml" xref="S2.SS3.p3.5.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.5.m1.1c">\mathcal{S_{\theta}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.5.m1.1d">caligraphic_S start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> can be trained to approximate the target model’s behavior, which can then be used for crafting adversarial inputs or testing defensive strategies.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这种级别的访问在模型架构公开或可推断的情况下很常见。例如，可以训练一个代理模型 <math id="S2.SS3.p3.5.m1.1" display="inline" class="ltx_Math" alttext="\mathcal{S_{\theta}}"><semantics id="S2.SS3.p3.5.m1.1a"><msub id="S2.SS3.p3.5.m1.1.1"><mi id="S2.SS3.p3.5.m1.1.1.2" class="ltx_font_mathcaligraphic">𝒮</mi><mi id="S2.SS3.p3.5.m1.1.1.3">θ</mi></msub><annotation-xml id="S2.SS3.p3.5.m1.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p3.5.m1.1c" encoding="application/x-tex">\mathcal{S_{\theta}}</annotation><annotation id="S2.SS3.p3.5.m1.1d" encoding="application/x-llamapun">caligraphic_S start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 来近似目标模型的行为，然后用于构建对抗性输入或测试防御策略。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.5"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS3.p4.1.m1.1"><semantics id="S2.SS3.p4.1.m1.1a"><mo id="S2.SS3.p4.1.m1.1.1" xref="S2.SS3.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.1.m1.1b"><ci id="S2.SS3.p4.1.m1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS3.p4.5.1">Black-box Capability.</span>
Black-box capability represents the lowest level of access, where the entity has no internal information about the model. The only accessible data are the input-output pairs <math alttext="\{x,f_{\theta}(x)\}" class="ltx_Math" display="inline" id="S2.SS3.p4.2.m2.3"><semantics id="S2.SS3.p4.2.m2.3a"><mrow id="S2.SS3.p4.2.m2.3.3.1" xref="S2.SS3.p4.2.m2.3.3.2.cmml"><mo id="S2.SS3.p4.2.m2.3.3.1.2" stretchy="false" xref="S2.SS3.p4.2.m2.3.3.2.cmml">{</mo><mi id="S2.SS3.p4.2.m2.2.2" xref="S2.SS3.p4.2.m2.2.2.cmml">x</mi><mo id="S2.SS3.p4.2.m2.3.3.1.3" xref="S2.SS3.p4.2.m2.3.3.2.cmml">,</mo><mrow id="S2.SS3.p4.2.m2.3.3.1.1" xref="S2.SS3.p4.2.m2.3.3.1.1.cmml"><msub id="S2.SS3.p4.2.m2.3.3.1.1.2" xref="S2.SS3.p4.2.m2.3.3.1.1.2.cmml"><mi id="S2.SS3.p4.2.m2.3.3.1.1.2.2" xref="S2.SS3.p4.2.m2.3.3.1.1.2.2.cmml">f</mi><mi id="S2.SS3.p4.2.m2.3.3.1.1.2.3" xref="S2.SS3.p4.2.m2.3.3.1.1.2.3.cmml">θ</mi></msub><mo id="S2.SS3.p4.2.m2.3.3.1.1.1" xref="S2.SS3.p4.2.m2.3.3.1.1.1.cmml">⁢</mo><mrow id="S2.SS3.p4.2.m2.3.3.1.1.3.2" xref="S2.SS3.p4.2.m2.3.3.1.1.cmml"><mo id="S2.SS3.p4.2.m2.3.3.1.1.3.2.1" stretchy="false" xref="S2.SS3.p4.2.m2.3.3.1.1.cmml">(</mo><mi id="S2.SS3.p4.2.m2.1.1" xref="S2.SS3.p4.2.m2.1.1.cmml">x</mi><mo id="S2.SS3.p4.2.m2.3.3.1.1.3.2.2" stretchy="false" xref="S2.SS3.p4.2.m2.3.3.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p4.2.m2.3.3.1.4" stretchy="false" xref="S2.SS3.p4.2.m2.3.3.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.2.m2.3b"><set id="S2.SS3.p4.2.m2.3.3.2.cmml" xref="S2.SS3.p4.2.m2.3.3.1"><ci id="S2.SS3.p4.2.m2.2.2.cmml" xref="S2.SS3.p4.2.m2.2.2">𝑥</ci><apply id="S2.SS3.p4.2.m2.3.3.1.1.cmml" xref="S2.SS3.p4.2.m2.3.3.1.1"><times id="S2.SS3.p4.2.m2.3.3.1.1.1.cmml" xref="S2.SS3.p4.2.m2.3.3.1.1.1"></times><apply id="S2.SS3.p4.2.m2.3.3.1.1.2.cmml" xref="S2.SS3.p4.2.m2.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p4.2.m2.3.3.1.1.2.1.cmml" xref="S2.SS3.p4.2.m2.3.3.1.1.2">subscript</csymbol><ci id="S2.SS3.p4.2.m2.3.3.1.1.2.2.cmml" xref="S2.SS3.p4.2.m2.3.3.1.1.2.2">𝑓</ci><ci id="S2.SS3.p4.2.m2.3.3.1.1.2.3.cmml" xref="S2.SS3.p4.2.m2.3.3.1.1.2.3">𝜃</ci></apply><ci id="S2.SS3.p4.2.m2.1.1.cmml" xref="S2.SS3.p4.2.m2.1.1">𝑥</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.2.m2.3c">\{x,f_{\theta}(x)\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.2.m2.3d">{ italic_x , italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) }</annotation></semantics></math> without any direct knowledge of <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS3.p4.3.m3.1"><semantics id="S2.SS3.p4.3.m3.1a"><mi id="S2.SS3.p4.3.m3.1.1" xref="S2.SS3.p4.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.3.m3.1b"><ci id="S2.SS3.p4.3.m3.1.1.cmml" xref="S2.SS3.p4.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.3.m3.1d">italic_θ</annotation></semantics></math>, <math alttext="\mathcal{A}_{\theta}" class="ltx_Math" display="inline" id="S2.SS3.p4.4.m4.1"><semantics id="S2.SS3.p4.4.m4.1a"><msub id="S2.SS3.p4.4.m4.1.1" xref="S2.SS3.p4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p4.4.m4.1.1.2" xref="S2.SS3.p4.4.m4.1.1.2.cmml">𝒜</mi><mi id="S2.SS3.p4.4.m4.1.1.3" xref="S2.SS3.p4.4.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.4.m4.1b"><apply id="S2.SS3.p4.4.m4.1.1.cmml" xref="S2.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.p4.4.m4.1.1.1.cmml" xref="S2.SS3.p4.4.m4.1.1">subscript</csymbol><ci id="S2.SS3.p4.4.m4.1.1.2.cmml" xref="S2.SS3.p4.4.m4.1.1.2">𝒜</ci><ci id="S2.SS3.p4.4.m4.1.1.3.cmml" xref="S2.SS3.p4.4.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.4.m4.1c">\mathcal{A}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.4.m4.1d">caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="\nabla_{\theta}\mathcal{L}" class="ltx_Math" display="inline" id="S2.SS3.p4.5.m5.1"><semantics id="S2.SS3.p4.5.m5.1a"><mrow id="S2.SS3.p4.5.m5.1.1" xref="S2.SS3.p4.5.m5.1.1.cmml"><msub id="S2.SS3.p4.5.m5.1.1.1" xref="S2.SS3.p4.5.m5.1.1.1.cmml"><mo id="S2.SS3.p4.5.m5.1.1.1.2" xref="S2.SS3.p4.5.m5.1.1.1.2.cmml">∇</mo><mi id="S2.SS3.p4.5.m5.1.1.1.3" xref="S2.SS3.p4.5.m5.1.1.1.3.cmml">θ</mi></msub><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p4.5.m5.1.1.2" xref="S2.SS3.p4.5.m5.1.1.2.cmml">ℒ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.5.m5.1b"><apply id="S2.SS3.p4.5.m5.1.1.cmml" xref="S2.SS3.p4.5.m5.1.1"><apply id="S2.SS3.p4.5.m5.1.1.1.cmml" xref="S2.SS3.p4.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p4.5.m5.1.1.1.1.cmml" xref="S2.SS3.p4.5.m5.1.1.1">subscript</csymbol><ci id="S2.SS3.p4.5.m5.1.1.1.2.cmml" xref="S2.SS3.p4.5.m5.1.1.1.2">∇</ci><ci id="S2.SS3.p4.5.m5.1.1.1.3.cmml" xref="S2.SS3.p4.5.m5.1.1.1.3">𝜃</ci></apply><ci id="S2.SS3.p4.5.m5.1.1.2.cmml" xref="S2.SS3.p4.5.m5.1.1.2">ℒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.5.m5.1c">\nabla_{\theta}\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.5.m5.1d">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L</annotation></semantics></math>. The knowledge set is defined as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS3.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS3.p4.1.m1.1a"><mo id="S2.SS3.p4.1.m1.1.1">∙</mo><annotation-xml id="S2.SS3.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS3.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 黑盒能力。黑盒能力代表最低级别的访问权限，实体对模型内部没有任何信息。唯一可访问的数据是输入输出对 <math id="S2.SS3.p4.2.m2.3" display="inline" class="ltx_Math" alttext="\{x,f_{\theta}(x)\}"><semantics id="S2.SS3.p4.2.m2.3a"><mrow id="S2.SS3.p4.2.m2.3.3.1"><mo stretchy="false" id="S2.SS3.p4.2.m2.3.3.1.2">{</mo><mi id="S2.SS3.p4.2.m2.2.2">x</mi><mo id="S2.SS3.p4.2.m2.3.3.1.3">,</mo><mrow id="S2.SS3.p4.2.m2.3.3.1.1"><msub id="S2.SS3.p4.2.m2.3.3.1.1.2"><mi id="S2.SS3.p4.2.m2.3.3.1.1.2.2">f</mi><mi id="S2.SS3.p4.2.m2.3.3.1.1.2.3">θ</mi></msub><mo id="S2.SS3.p4.2.m2.3.3.1.1.1">⁢</mo><mrow id="S2.SS3.p4.2.m2.3.3.1.1.3.2"><mo stretchy="false" id="S2.SS3.p4.2.m2.3.3.1.1.3.2.1">(</mo><mi id="S2.SS3.p4.2.m2.1.1">x</mi><mo stretchy="false" id="S2.SS3.p4.2.m2.3.3.1.1.3.2.2">)</mo></mrow></mrow><mo stretchy="false" id="S2.SS3.p4.2.m2.3.3.1.4">}</mo></mrow><annotation-xml id="S2.SS3.p4.2.m2.3b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p4.2.m2.3c" encoding="application/x-tex">\{x,f_{\theta}(x)\}</annotation><annotation id="S2.SS3.p4.2.m2.3d" encoding="application/x-llamapun">{ italic_x , italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) }</annotation></semantics></math> ，而没有任何关于 <math id="S2.SS3.p4.3.m3.1" display="inline" class="ltx_Math" alttext="\theta"><semantics id="S2.SS3.p4.3.m3.1a"><mi id="S2.SS3.p4.3.m3.1.1">θ</mi><annotation-xml id="S2.SS3.p4.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS3.p4.3.m3.1c" encoding="application/x-tex">\theta</annotation><annotation id="S2.SS3.p4.3.m3.1d" encoding="application/x-llamapun">italic_θ</annotation></semantics></math> 、 <math id="S2.SS3.p4.4.m4.1" display="inline" class="ltx_Math" alttext="\mathcal{A}_{\theta}"><semantics id="S2.SS3.p4.4.m4.1a"><msub id="S2.SS3.p4.4.m4.1.1"><mi id="S2.SS3.p4.4.m4.1.1.2" class="ltx_font_mathcaligraphic">𝒜</mi><mi id="S2.SS3.p4.4.m4.1.1.3">θ</mi></msub><annotation-xml id="S2.SS3.p4.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p4.4.m4.1c" encoding="application/x-tex">\mathcal{A}_{\theta}</annotation><annotation id="S2.SS3.p4.4.m4.1d" encoding="application/x-llamapun">caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 和 <math id="S2.SS3.p4.5.m5.1" display="inline" class="ltx_Math" alttext="\nabla_{\theta}\mathcal{L}"><semantics id="S2.SS3.p4.5.m5.1a"><mrow id="S2.SS3.p4.5.m5.1.1"><msub id="S2.SS3.p4.5.m5.1.1.1"><mo id="S2.SS3.p4.5.m5.1.1.1.2">∇</mo><mi id="S2.SS3.p4.5.m5.1.1.1.3">θ</mi></msub><mi id="S2.SS3.p4.5.m5.1.1.2" class="ltx_font_mathcaligraphic">ℒ</mi></mrow><annotation-xml id="S2.SS3.p4.5.m5.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS3.p4.5.m5.1c" encoding="application/x-tex">\nabla_{\theta}\mathcal{L}</annotation><annotation id="S2.SS3.p4.5.m5.1d" encoding="application/x-llamapun">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L</annotation></semantics></math> 的直接知识。知识集定义为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{K}_{\text{B}}=\{(x,f_{\theta}(x))\mid x\in\mathcal{X}\}," class="ltx_Math" display="block" id="S2.E3.m1.3"><semantics id="S2.E3.m1.3a"><mrow id="S2.E3.m1.3.3.1" xref="S2.E3.m1.3.3.1.1.cmml"><mrow id="S2.E3.m1.3.3.1.1" xref="S2.E3.m1.3.3.1.1.cmml"><msub id="S2.E3.m1.3.3.1.1.4" xref="S2.E3.m1.3.3.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.3.3.1.1.4.2" xref="S2.E3.m1.3.3.1.1.4.2.cmml">𝒦</mi><mtext id="S2.E3.m1.3.3.1.1.4.3" xref="S2.E3.m1.3.3.1.1.4.3a.cmml">B</mtext></msub><mo id="S2.E3.m1.3.3.1.1.3" xref="S2.E3.m1.3.3.1.1.3.cmml">=</mo><mrow id="S2.E3.m1.3.3.1.1.2.2" xref="S2.E3.m1.3.3.1.1.2.3.cmml"><mo id="S2.E3.m1.3.3.1.1.2.2.3" stretchy="false" xref="S2.E3.m1.3.3.1.1.2.3.1.cmml">{</mo><mrow id="S2.E3.m1.3.3.1.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.2.cmml"><mo id="S2.E3.m1.3.3.1.1.1.1.1.1.2" stretchy="false" xref="S2.E3.m1.3.3.1.1.1.1.1.2.cmml">(</mo><mi id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml">x</mi><mo id="S2.E3.m1.3.3.1.1.1.1.1.1.3" xref="S2.E3.m1.3.3.1.1.1.1.1.2.cmml">,</mo><mrow id="S2.E3.m1.3.3.1.1.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><msub id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.2.cmml">f</mi><mi id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.3" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.3.cmml">θ</mi></msub><mo id="S2.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mo id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mi id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">x</mi><mo id="S2.E3.m1.3.3.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.1.1.1.1.1.1.4" stretchy="false" xref="S2.E3.m1.3.3.1.1.1.1.1.2.cmml">)</mo></mrow><mo fence="true" id="S2.E3.m1.3.3.1.1.2.2.4" lspace="0em" rspace="0em" xref="S2.E3.m1.3.3.1.1.2.3.1.cmml">∣</mo><mrow id="S2.E3.m1.3.3.1.1.2.2.2" xref="S2.E3.m1.3.3.1.1.2.2.2.cmml"><mi id="S2.E3.m1.3.3.1.1.2.2.2.2" xref="S2.E3.m1.3.3.1.1.2.2.2.2.cmml">x</mi><mo id="S2.E3.m1.3.3.1.1.2.2.2.1" xref="S2.E3.m1.3.3.1.1.2.2.2.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.3.3.1.1.2.2.2.3" xref="S2.E3.m1.3.3.1.1.2.2.2.3.cmml">𝒳</mi></mrow><mo id="S2.E3.m1.3.3.1.1.2.2.5" stretchy="false" xref="S2.E3.m1.3.3.1.1.2.3.1.cmml">}</mo></mrow></mrow><mo id="S2.E3.m1.3.3.1.2" xref="S2.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.3b"><apply id="S2.E3.m1.3.3.1.1.cmml" xref="S2.E3.m1.3.3.1"><eq id="S2.E3.m1.3.3.1.1.3.cmml" xref="S2.E3.m1.3.3.1.1.3"></eq><apply id="S2.E3.m1.3.3.1.1.4.cmml" xref="S2.E3.m1.3.3.1.1.4"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.4.1.cmml" xref="S2.E3.m1.3.3.1.1.4">subscript</csymbol><ci id="S2.E3.m1.3.3.1.1.4.2.cmml" xref="S2.E3.m1.3.3.1.1.4.2">𝒦</ci><ci id="S2.E3.m1.3.3.1.1.4.3a.cmml" xref="S2.E3.m1.3.3.1.1.4.3"><mtext id="S2.E3.m1.3.3.1.1.4.3.cmml" mathsize="70%" xref="S2.E3.m1.3.3.1.1.4.3">B</mtext></ci></apply><apply id="S2.E3.m1.3.3.1.1.2.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2"><csymbol cd="latexml" id="S2.E3.m1.3.3.1.1.2.3.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.3">conditional-set</csymbol><interval closure="open" id="S2.E3.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1"><ci id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2">𝑥</ci><apply id="S2.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1"><times id="S2.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.1"></times><apply id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.2">𝑓</ci><ci id="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.3.3.1.1.1.1.1.1.1.2.3">𝜃</ci></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">𝑥</ci></apply></interval><apply id="S2.E3.m1.3.3.1.1.2.2.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2"><in id="S2.E3.m1.3.3.1.1.2.2.2.1.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.1"></in><ci id="S2.E3.m1.3.3.1.1.2.2.2.2.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.2">𝑥</ci><ci id="S2.E3.m1.3.3.1.1.2.2.2.3.cmml" xref="S2.E3.m1.3.3.1.1.2.2.2.3">𝒳</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.3c">\mathcal{K}_{\text{B}}=\{(x,f_{\theta}(x))\mid x\in\mathcal{X}\},</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.3d">caligraphic_K start_POSTSUBSCRIPT B end_POSTSUBSCRIPT = { ( italic_x , italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) ) ∣ italic_x ∈ caligraphic_X } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p4.6">in this scenario, interactions are limited to querying the model and observing its outputs. This setting are representative of real-world conditions, where attackers or defenders must work without any internal access to the model.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在这种情况下，交互仅限于查询模型并观察其输出。这种设置代表了现实世界条件，攻击者或防御者必须在不具备模型内部访问权限的情况下工作。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span><span class="ltx_text ltx_font_italic" id="S2.SS4.1.1">Attack Objectives</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.4 攻击目标</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">In the safety domain of Large Vision-Language Models (LVLMs), attacks typically fall into three main categories, each with distinct objectives:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在大视觉语言模型（LVLMs）的安全领域，攻击通常分为三大主要类别，每个类别都有不同的目标：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.5"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS4.p2.1.m1.1"><semantics id="S2.SS4.p2.1.m1.1a"><mo id="S2.SS4.p2.1.m1.1.1" xref="S2.SS4.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.1.m1.1b"><ci id="S2.SS4.p2.1.m1.1.1.cmml" xref="S2.SS4.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS4.p2.5.1">Targeted Attacks.</span>
Targeted attacks are designed to manipulate the model’s output for specific inputs <math alttext="x\in\mathcal{X}" class="ltx_Math" display="inline" id="S2.SS4.p2.2.m2.1"><semantics id="S2.SS4.p2.2.m2.1a"><mrow id="S2.SS4.p2.2.m2.1.1" xref="S2.SS4.p2.2.m2.1.1.cmml"><mi id="S2.SS4.p2.2.m2.1.1.2" xref="S2.SS4.p2.2.m2.1.1.2.cmml">x</mi><mo id="S2.SS4.p2.2.m2.1.1.1" xref="S2.SS4.p2.2.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p2.2.m2.1.1.3" xref="S2.SS4.p2.2.m2.1.1.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.2.m2.1b"><apply id="S2.SS4.p2.2.m2.1.1.cmml" xref="S2.SS4.p2.2.m2.1.1"><in id="S2.SS4.p2.2.m2.1.1.1.cmml" xref="S2.SS4.p2.2.m2.1.1.1"></in><ci id="S2.SS4.p2.2.m2.1.1.2.cmml" xref="S2.SS4.p2.2.m2.1.1.2">𝑥</ci><ci id="S2.SS4.p2.2.m2.1.1.3.cmml" xref="S2.SS4.p2.2.m2.1.1.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.2.m2.1c">x\in\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.2.m2.1d">italic_x ∈ caligraphic_X</annotation></semantics></math>, driving the model <math alttext="f_{\theta}" class="ltx_Math" display="inline" id="S2.SS4.p2.3.m3.1"><semantics id="S2.SS4.p2.3.m3.1a"><msub id="S2.SS4.p2.3.m3.1.1" xref="S2.SS4.p2.3.m3.1.1.cmml"><mi id="S2.SS4.p2.3.m3.1.1.2" xref="S2.SS4.p2.3.m3.1.1.2.cmml">f</mi><mi id="S2.SS4.p2.3.m3.1.1.3" xref="S2.SS4.p2.3.m3.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.3.m3.1b"><apply id="S2.SS4.p2.3.m3.1.1.cmml" xref="S2.SS4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.p2.3.m3.1.1.1.cmml" xref="S2.SS4.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS4.p2.3.m3.1.1.2.cmml" xref="S2.SS4.p2.3.m3.1.1.2">𝑓</ci><ci id="S2.SS4.p2.3.m3.1.1.3.cmml" xref="S2.SS4.p2.3.m3.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.3.m3.1c">f_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.3.m3.1d">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> to produce a predefined, incorrect output <math alttext="y_{\text{target}}\in\mathcal{Y}" class="ltx_Math" display="inline" id="S2.SS4.p2.4.m4.1"><semantics id="S2.SS4.p2.4.m4.1a"><mrow id="S2.SS4.p2.4.m4.1.1" xref="S2.SS4.p2.4.m4.1.1.cmml"><msub id="S2.SS4.p2.4.m4.1.1.2" xref="S2.SS4.p2.4.m4.1.1.2.cmml"><mi id="S2.SS4.p2.4.m4.1.1.2.2" xref="S2.SS4.p2.4.m4.1.1.2.2.cmml">y</mi><mtext id="S2.SS4.p2.4.m4.1.1.2.3" xref="S2.SS4.p2.4.m4.1.1.2.3a.cmml">target</mtext></msub><mo id="S2.SS4.p2.4.m4.1.1.1" xref="S2.SS4.p2.4.m4.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p2.4.m4.1.1.3" xref="S2.SS4.p2.4.m4.1.1.3.cmml">𝒴</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.4.m4.1b"><apply id="S2.SS4.p2.4.m4.1.1.cmml" xref="S2.SS4.p2.4.m4.1.1"><in id="S2.SS4.p2.4.m4.1.1.1.cmml" xref="S2.SS4.p2.4.m4.1.1.1"></in><apply id="S2.SS4.p2.4.m4.1.1.2.cmml" xref="S2.SS4.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS4.p2.4.m4.1.1.2.1.cmml" xref="S2.SS4.p2.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS4.p2.4.m4.1.1.2.2.cmml" xref="S2.SS4.p2.4.m4.1.1.2.2">𝑦</ci><ci id="S2.SS4.p2.4.m4.1.1.2.3a.cmml" xref="S2.SS4.p2.4.m4.1.1.2.3"><mtext id="S2.SS4.p2.4.m4.1.1.2.3.cmml" mathsize="70%" xref="S2.SS4.p2.4.m4.1.1.2.3">target</mtext></ci></apply><ci id="S2.SS4.p2.4.m4.1.1.3.cmml" xref="S2.SS4.p2.4.m4.1.1.3">𝒴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.4.m4.1c">y_{\text{target}}\in\mathcal{Y}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.4.m4.1d">italic_y start_POSTSUBSCRIPT target end_POSTSUBSCRIPT ∈ caligraphic_Y</annotation></semantics></math>, irrespective of the correct output <math alttext="y" class="ltx_Math" display="inline" id="S2.SS4.p2.5.m5.1"><semantics id="S2.SS4.p2.5.m5.1a"><mi id="S2.SS4.p2.5.m5.1.1" xref="S2.SS4.p2.5.m5.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.5.m5.1b"><ci id="S2.SS4.p2.5.m5.1.1.cmml" xref="S2.SS4.p2.5.m5.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.5.m5.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.5.m5.1d">italic_y</annotation></semantics></math>. These attacks may involve adversarial perturbations to the input, such as subtle modifications to images or text, or non-adversarial methods, such as crafted queries that exploit weaknesses in the model’s reasoning. The objective can be described as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS4.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS4.p2.1.m1.1a"><mo id="S2.SS4.p2.1.m1.1.1">∙</mo><annotation-xml id="S2.SS4.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS4.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS4.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 针对性攻击。针对性攻击旨在通过特定输入操纵模型的输出 <math id="S2.SS4.p2.2.m2.1" display="inline" class="ltx_Math" alttext="x\in\mathcal{X}"><semantics id="S2.SS4.p2.2.m2.1a"><mrow id="S2.SS4.p2.2.m2.1.1"><mi id="S2.SS4.p2.2.m2.1.1.2">x</mi><mo id="S2.SS4.p2.2.m2.1.1.1">∈</mo><mi id="S2.SS4.p2.2.m2.1.1.3" class="ltx_font_mathcaligraphic">𝒳</mi></mrow><annotation-xml id="S2.SS4.p2.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS4.p2.2.m2.1c" encoding="application/x-tex">x\in\mathcal{X}</annotation><annotation id="S2.SS4.p2.2.m2.1d" encoding="application/x-llamapun">italic_x ∈ caligraphic_X</annotation></semantics></math> ，迫使模型 <math id="S2.SS4.p2.3.m3.1" display="inline" class="ltx_Math" alttext="f_{\theta}"><semantics id="S2.SS4.p2.3.m3.1a"><msub id="S2.SS4.p2.3.m3.1.1"><mi id="S2.SS4.p2.3.m3.1.1.2">f</mi><mi id="S2.SS4.p2.3.m3.1.1.3">θ</mi></msub><annotation-xml id="S2.SS4.p2.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS4.p2.3.m3.1c" encoding="application/x-tex">f_{\theta}</annotation><annotation id="S2.SS4.p2.3.m3.1d" encoding="application/x-llamapun">italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 产生预定义的错误输出 <math id="S2.SS4.p2.4.m4.1" display="inline" class="ltx_Math" alttext="y_{\text{target}}\in\mathcal{Y}"><semantics id="S2.SS4.p2.4.m4.1a"><mrow id="S2.SS4.p2.4.m4.1.1"><msub id="S2.SS4.p2.4.m4.1.1.2"><mi id="S2.SS4.p2.4.m4.1.1.2.2">y</mi><mtext id="S2.SS4.p2.4.m4.1.1.2.3">target</mtext></msub><mo id="S2.SS4.p2.4.m4.1.1.1">∈</mo><mi id="S2.SS4.p2.4.m4.1.1.3" class="ltx_font_mathcaligraphic">𝒴</mi></mrow><annotation-xml id="S2.SS4.p2.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS4.p2.4.m4.1c" encoding="application/x-tex">y_{\text{target}}\in\mathcal{Y}</annotation><annotation id="S2.SS4.p2.4.m4.1d" encoding="application/x-llamapun">italic_y start_POSTSUBSCRIPT target end_POSTSUBSCRIPT ∈ caligraphic_Y</annotation></semantics></math> ，而忽略正确输出 <math id="S2.SS4.p2.5.m5.1" display="inline" class="ltx_Math" alttext="y"><semantics id="S2.SS4.p2.5.m5.1a"><mi id="S2.SS4.p2.5.m5.1.1">y</mi><annotation-xml id="S2.SS4.p2.5.m5.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS4.p2.5.m5.1c" encoding="application/x-tex">y</annotation><annotation id="S2.SS4.p2.5.m5.1d" encoding="application/x-llamapun">italic_y</annotation></semantics></math> 。这些攻击可能涉及对输入的对抗性扰动，例如对图像或文本进行细微修改，或使用非对抗性方法，例如利用模型推理缺陷的精心设计的查询。其目标可以描述为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\arg\min_{x_{\text{mod}}}\mathcal{L}(f_{\theta}(x_{\text{mod}}),y_{\text{%
target}})," class="ltx_Math" display="block" id="S2.E4.m1.1"><semantics id="S2.E4.m1.1a"><mrow id="S2.E4.m1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml"><mrow id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml"><mrow id="S2.E4.m1.1.1.1.1.4" xref="S2.E4.m1.1.1.1.1.4.cmml"><mi id="S2.E4.m1.1.1.1.1.4.1" xref="S2.E4.m1.1.1.1.1.4.1.cmml">arg</mi><mo id="S2.E4.m1.1.1.1.1.4a" lspace="0.167em" xref="S2.E4.m1.1.1.1.1.4.cmml">⁡</mo><mrow id="S2.E4.m1.1.1.1.1.4.2" xref="S2.E4.m1.1.1.1.1.4.2.cmml"><munder id="S2.E4.m1.1.1.1.1.4.2.1" xref="S2.E4.m1.1.1.1.1.4.2.1.cmml"><mi id="S2.E4.m1.1.1.1.1.4.2.1.2" xref="S2.E4.m1.1.1.1.1.4.2.1.2.cmml">min</mi><msub id="S2.E4.m1.1.1.1.1.4.2.1.3" xref="S2.E4.m1.1.1.1.1.4.2.1.3.cmml"><mi id="S2.E4.m1.1.1.1.1.4.2.1.3.2" xref="S2.E4.m1.1.1.1.1.4.2.1.3.2.cmml">x</mi><mtext id="S2.E4.m1.1.1.1.1.4.2.1.3.3" xref="S2.E4.m1.1.1.1.1.4.2.1.3.3a.cmml">mod</mtext></msub></munder><mo id="S2.E4.m1.1.1.1.1.4.2a" lspace="0.167em" xref="S2.E4.m1.1.1.1.1.4.2.cmml">⁡</mo><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.1.1.1.1.4.2.2" xref="S2.E4.m1.1.1.1.1.4.2.2.cmml">ℒ</mi></mrow></mrow><mo id="S2.E4.m1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.3.cmml">⁢</mo><mrow id="S2.E4.m1.1.1.1.1.2.2" xref="S2.E4.m1.1.1.1.1.2.3.cmml"><mo id="S2.E4.m1.1.1.1.1.2.2.3" stretchy="false" xref="S2.E4.m1.1.1.1.1.2.3.cmml">(</mo><mrow id="S2.E4.m1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml"><msub id="S2.E4.m1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.1.1.1.1.1.1.1.3.2" xref="S2.E4.m1.1.1.1.1.1.1.1.3.2.cmml">f</mi><mi id="S2.E4.m1.1.1.1.1.1.1.1.3.3" xref="S2.E4.m1.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S2.E4.m1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E4.m1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E4.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mtext id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.3a.cmml">mod</mtext></msub><mo id="S2.E4.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.1.1.1.1.2.2.4" xref="S2.E4.m1.1.1.1.1.2.3.cmml">,</mo><msub id="S2.E4.m1.1.1.1.1.2.2.2" xref="S2.E4.m1.1.1.1.1.2.2.2.cmml"><mi id="S2.E4.m1.1.1.1.1.2.2.2.2" xref="S2.E4.m1.1.1.1.1.2.2.2.2.cmml">y</mi><mtext id="S2.E4.m1.1.1.1.1.2.2.2.3" xref="S2.E4.m1.1.1.1.1.2.2.2.3a.cmml">target</mtext></msub><mo id="S2.E4.m1.1.1.1.1.2.2.5" stretchy="false" xref="S2.E4.m1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.1b"><apply id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1"><times id="S2.E4.m1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.3"></times><apply id="S2.E4.m1.1.1.1.1.4.cmml" xref="S2.E4.m1.1.1.1.1.4"><arg id="S2.E4.m1.1.1.1.1.4.1.cmml" xref="S2.E4.m1.1.1.1.1.4.1"></arg><apply id="S2.E4.m1.1.1.1.1.4.2.cmml" xref="S2.E4.m1.1.1.1.1.4.2"><apply id="S2.E4.m1.1.1.1.1.4.2.1.cmml" xref="S2.E4.m1.1.1.1.1.4.2.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.4.2.1.1.cmml" xref="S2.E4.m1.1.1.1.1.4.2.1">subscript</csymbol><min id="S2.E4.m1.1.1.1.1.4.2.1.2.cmml" xref="S2.E4.m1.1.1.1.1.4.2.1.2"></min><apply id="S2.E4.m1.1.1.1.1.4.2.1.3.cmml" xref="S2.E4.m1.1.1.1.1.4.2.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.4.2.1.3.1.cmml" xref="S2.E4.m1.1.1.1.1.4.2.1.3">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.4.2.1.3.2.cmml" xref="S2.E4.m1.1.1.1.1.4.2.1.3.2">𝑥</ci><ci id="S2.E4.m1.1.1.1.1.4.2.1.3.3a.cmml" xref="S2.E4.m1.1.1.1.1.4.2.1.3.3"><mtext id="S2.E4.m1.1.1.1.1.4.2.1.3.3.cmml" mathsize="50%" xref="S2.E4.m1.1.1.1.1.4.2.1.3.3">mod</mtext></ci></apply></apply><ci id="S2.E4.m1.1.1.1.1.4.2.2.cmml" xref="S2.E4.m1.1.1.1.1.4.2.2">ℒ</ci></apply></apply><interval closure="open" id="S2.E4.m1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.1.1.1.1.2.2"><apply id="S2.E4.m1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1"><times id="S2.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.2"></times><apply id="S2.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3.2">𝑓</ci><ci id="S2.E4.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.3"><mtext id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.3">mod</mtext></ci></apply></apply><apply id="S2.E4.m1.1.1.1.1.2.2.2.cmml" xref="S2.E4.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.2.2.2.1.cmml" xref="S2.E4.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.2.2.2.2.cmml" xref="S2.E4.m1.1.1.1.1.2.2.2.2">𝑦</ci><ci id="S2.E4.m1.1.1.1.1.2.2.2.3a.cmml" xref="S2.E4.m1.1.1.1.1.2.2.2.3"><mtext id="S2.E4.m1.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S2.E4.m1.1.1.1.1.2.2.2.3">target</mtext></ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.1c">\arg\min_{x_{\text{mod}}}\mathcal{L}(f_{\theta}(x_{\text{mod}}),y_{\text{%
target}}),</annotation><annotation encoding="application/x-llamapun" id="S2.E4.m1.1d">roman_arg roman_min start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT mod end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L ( italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT mod end_POSTSUBSCRIPT ) , italic_y start_POSTSUBSCRIPT target end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.p2.6">where <math alttext="x_{\text{mod}}" class="ltx_Math" display="inline" id="S2.SS4.p2.6.m1.1"><semantics id="S2.SS4.p2.6.m1.1a"><msub id="S2.SS4.p2.6.m1.1.1" xref="S2.SS4.p2.6.m1.1.1.cmml"><mi id="S2.SS4.p2.6.m1.1.1.2" xref="S2.SS4.p2.6.m1.1.1.2.cmml">x</mi><mtext id="S2.SS4.p2.6.m1.1.1.3" xref="S2.SS4.p2.6.m1.1.1.3a.cmml">mod</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p2.6.m1.1b"><apply id="S2.SS4.p2.6.m1.1.1.cmml" xref="S2.SS4.p2.6.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p2.6.m1.1.1.1.cmml" xref="S2.SS4.p2.6.m1.1.1">subscript</csymbol><ci id="S2.SS4.p2.6.m1.1.1.2.cmml" xref="S2.SS4.p2.6.m1.1.1.2">𝑥</ci><ci id="S2.SS4.p2.6.m1.1.1.3a.cmml" xref="S2.SS4.p2.6.m1.1.1.3"><mtext id="S2.SS4.p2.6.m1.1.1.3.cmml" mathsize="70%" xref="S2.SS4.p2.6.m1.1.1.3">mod</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p2.6.m1.1c">x_{\text{mod}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p2.6.m1.1d">italic_x start_POSTSUBSCRIPT mod end_POSTSUBSCRIPT</annotation></semantics></math> represents either adversarially perturbed inputs or specially crafted benign queries.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S2.SS4.p2.6.m1.1" display="inline" class="ltx_Math" alttext="x_{\text{mod}}"><semantics id="S2.SS4.p2.6.m1.1a"><msub id="S2.SS4.p2.6.m1.1.1"><mi id="S2.SS4.p2.6.m1.1.1.2">x</mi><mtext id="S2.SS4.p2.6.m1.1.1.3">mod</mtext></msub><annotation-xml id="S2.SS4.p2.6.m1.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS4.p2.6.m1.1c" encoding="application/x-tex">x_{\text{mod}}</annotation><annotation id="S2.SS4.p2.6.m1.1d" encoding="application/x-llamapun">italic_x start_POSTSUBSCRIPT mod end_POSTSUBSCRIPT</annotation></semantics></math> 代表对抗性扰动输入或特别设计的良性查询。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS4.p3.1.m1.1"><semantics id="S2.SS4.p3.1.m1.1a"><mo id="S2.SS4.p3.1.m1.1.1" xref="S2.SS4.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.1.m1.1b"><ci id="S2.SS4.p3.1.m1.1.1.cmml" xref="S2.SS4.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS4.p3.2.1">Untargeted Attacks.</span>
Untargeted attacks aim to degrade the model’s overall performance by causing it to produce any incorrect output <math alttext="y^{\prime}\neq y" class="ltx_Math" display="inline" id="S2.SS4.p3.2.m2.1"><semantics id="S2.SS4.p3.2.m2.1a"><mrow id="S2.SS4.p3.2.m2.1.1" xref="S2.SS4.p3.2.m2.1.1.cmml"><msup id="S2.SS4.p3.2.m2.1.1.2" xref="S2.SS4.p3.2.m2.1.1.2.cmml"><mi id="S2.SS4.p3.2.m2.1.1.2.2" xref="S2.SS4.p3.2.m2.1.1.2.2.cmml">y</mi><mo id="S2.SS4.p3.2.m2.1.1.2.3" xref="S2.SS4.p3.2.m2.1.1.2.3.cmml">′</mo></msup><mo id="S2.SS4.p3.2.m2.1.1.1" xref="S2.SS4.p3.2.m2.1.1.1.cmml">≠</mo><mi id="S2.SS4.p3.2.m2.1.1.3" xref="S2.SS4.p3.2.m2.1.1.3.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p3.2.m2.1b"><apply id="S2.SS4.p3.2.m2.1.1.cmml" xref="S2.SS4.p3.2.m2.1.1"><neq id="S2.SS4.p3.2.m2.1.1.1.cmml" xref="S2.SS4.p3.2.m2.1.1.1"></neq><apply id="S2.SS4.p3.2.m2.1.1.2.cmml" xref="S2.SS4.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS4.p3.2.m2.1.1.2.1.cmml" xref="S2.SS4.p3.2.m2.1.1.2">superscript</csymbol><ci id="S2.SS4.p3.2.m2.1.1.2.2.cmml" xref="S2.SS4.p3.2.m2.1.1.2.2">𝑦</ci><ci id="S2.SS4.p3.2.m2.1.1.2.3.cmml" xref="S2.SS4.p3.2.m2.1.1.2.3">′</ci></apply><ci id="S2.SS4.p3.2.m2.1.1.3.cmml" xref="S2.SS4.p3.2.m2.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p3.2.m2.1c">y^{\prime}\neq y</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p3.2.m2.1d">italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ≠ italic_y</annotation></semantics></math>. These attacks are not constrained by specific target outputs and can involve adversarial modifications to the input or non-adversarial strategies, such as exploiting ambiguities in the training data or the model’s inherent biases. The goal is defined as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS4.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS4.p3.1.m1.1a"><mo id="S2.SS4.p3.1.m1.1.1">∙</mo><annotation-xml id="S2.SS4.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS4.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS4.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 非针对性攻击。非针对性攻击旨在通过使模型产生任何错误输出 <math id="S2.SS4.p3.2.m2.1" display="inline" class="ltx_Math" alttext="y^{\prime}\neq y"><semantics id="S2.SS4.p3.2.m2.1a"><mrow id="S2.SS4.p3.2.m2.1.1"><msup id="S2.SS4.p3.2.m2.1.1.2"><mi id="S2.SS4.p3.2.m2.1.1.2.2">y</mi><mo id="S2.SS4.p3.2.m2.1.1.2.3">′</mo></msup><mo id="S2.SS4.p3.2.m2.1.1.1">≠</mo><mi id="S2.SS4.p3.2.m2.1.1.3">y</mi></mrow><annotation-xml id="S2.SS4.p3.2.m2.1b" encoding="MathML-Content">superscript</annotation-xml><annotation id="S2.SS4.p3.2.m2.1c" encoding="application/x-tex">y^{\prime}\neq y</annotation><annotation id="S2.SS4.p3.2.m2.1d" encoding="application/x-llamapun">italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ≠ italic_y</annotation></semantics></math> 来降低其整体性能。这些攻击不受特定目标输出的限制，可能涉及对输入的对抗性修改或非对抗性策略，例如利用训练数据中的模糊性或模型的固有偏差。其目标是：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\arg\min_{x_{\text{mod}}}\mathcal{L}(f_{\theta}(x_{\text{mod}}),y),\quad\text{%
subject to }f_{\theta}(x_{\text{mod}})\neq y," class="ltx_Math" display="block" id="S2.E5.m1.2"><semantics id="S2.E5.m1.2a"><mrow id="S2.E5.m1.2.2.1" xref="S2.E5.m1.2.2.1.1.cmml"><mrow id="S2.E5.m1.2.2.1.1" xref="S2.E5.m1.2.2.1.1.cmml"><mrow id="S2.E5.m1.2.2.1.1.2.2" xref="S2.E5.m1.2.2.1.1.2.3.cmml"><mrow id="S2.E5.m1.2.2.1.1.1.1.1" xref="S2.E5.m1.2.2.1.1.1.1.1.cmml"><mrow id="S2.E5.m1.2.2.1.1.1.1.1.3" xref="S2.E5.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S2.E5.m1.2.2.1.1.1.1.1.3.1" xref="S2.E5.m1.2.2.1.1.1.1.1.3.1.cmml">arg</mi><mo id="S2.E5.m1.2.2.1.1.1.1.1.3a" lspace="0.167em" xref="S2.E5.m1.2.2.1.1.1.1.1.3.cmml">⁡</mo><mrow id="S2.E5.m1.2.2.1.1.1.1.1.3.2" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.cmml"><munder id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.cmml"><mi id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.2" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.2.cmml">min</mi><msub id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.cmml"><mi id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.2" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.2.cmml">x</mi><mtext id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.3" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.3a.cmml">mod</mtext></msub></munder><mo id="S2.E5.m1.2.2.1.1.1.1.1.3.2a" lspace="0.167em" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.cmml">⁡</mo><mi class="ltx_font_mathcaligraphic" id="S2.E5.m1.2.2.1.1.1.1.1.3.2.2" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.2.cmml">ℒ</mi></mrow></mrow><mo id="S2.E5.m1.2.2.1.1.1.1.1.2" xref="S2.E5.m1.2.2.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E5.m1.2.2.1.1.1.1.1.1.1" xref="S2.E5.m1.2.2.1.1.1.1.1.1.2.cmml"><mo id="S2.E5.m1.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E5.m1.2.2.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml">f</mi><mi id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mtext id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3a.cmml">mod</mtext></msub><mo id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E5.m1.2.2.1.1.1.1.1.1.1.3" xref="S2.E5.m1.2.2.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E5.m1.1.1" xref="S2.E5.m1.1.1.cmml">y</mi><mo id="S2.E5.m1.2.2.1.1.1.1.1.1.1.4" stretchy="false" xref="S2.E5.m1.2.2.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E5.m1.2.2.1.1.2.2.3" rspace="1.167em" xref="S2.E5.m1.2.2.1.1.2.3.cmml">,</mo><mrow id="S2.E5.m1.2.2.1.1.2.2.2" xref="S2.E5.m1.2.2.1.1.2.2.2.cmml"><mtext id="S2.E5.m1.2.2.1.1.2.2.2.3" xref="S2.E5.m1.2.2.1.1.2.2.2.3a.cmml">subject to&nbsp;</mtext><mo id="S2.E5.m1.2.2.1.1.2.2.2.2" xref="S2.E5.m1.2.2.1.1.2.2.2.2.cmml">⁢</mo><msub id="S2.E5.m1.2.2.1.1.2.2.2.4" xref="S2.E5.m1.2.2.1.1.2.2.2.4.cmml"><mi id="S2.E5.m1.2.2.1.1.2.2.2.4.2" xref="S2.E5.m1.2.2.1.1.2.2.2.4.2.cmml">f</mi><mi id="S2.E5.m1.2.2.1.1.2.2.2.4.3" xref="S2.E5.m1.2.2.1.1.2.2.2.4.3.cmml">θ</mi></msub><mo id="S2.E5.m1.2.2.1.1.2.2.2.2a" xref="S2.E5.m1.2.2.1.1.2.2.2.2.cmml">⁢</mo><mrow id="S2.E5.m1.2.2.1.1.2.2.2.1.1" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.cmml"><mo id="S2.E5.m1.2.2.1.1.2.2.2.1.1.2" stretchy="false" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.cmml">(</mo><msub id="S2.E5.m1.2.2.1.1.2.2.2.1.1.1" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.cmml"><mi id="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.2" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.2.cmml">x</mi><mtext id="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.3" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.3a.cmml">mod</mtext></msub><mo id="S2.E5.m1.2.2.1.1.2.2.2.1.1.3" stretchy="false" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E5.m1.2.2.1.1.3" xref="S2.E5.m1.2.2.1.1.3.cmml">≠</mo><mi id="S2.E5.m1.2.2.1.1.4" xref="S2.E5.m1.2.2.1.1.4.cmml">y</mi></mrow><mo id="S2.E5.m1.2.2.1.2" xref="S2.E5.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.2b"><apply id="S2.E5.m1.2.2.1.1.cmml" xref="S2.E5.m1.2.2.1"><neq id="S2.E5.m1.2.2.1.1.3.cmml" xref="S2.E5.m1.2.2.1.1.3"></neq><list id="S2.E5.m1.2.2.1.1.2.3.cmml" xref="S2.E5.m1.2.2.1.1.2.2"><apply id="S2.E5.m1.2.2.1.1.1.1.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1"><times id="S2.E5.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.2"></times><apply id="S2.E5.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3"><arg id="S2.E5.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.1"></arg><apply id="S2.E5.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2"><apply id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1">subscript</csymbol><min id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.2"></min><apply id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3">subscript</csymbol><ci id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.2">𝑥</ci><ci id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.3a.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.3"><mtext id="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.3.cmml" mathsize="50%" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.1.3.3">mod</mtext></ci></apply></apply><ci id="S2.E5.m1.2.2.1.1.1.1.1.3.2.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.3.2.2">ℒ</ci></apply></apply><interval closure="open" id="S2.E5.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1"><apply id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1"><times id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.2"></times><apply id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.2">𝑓</ci><ci id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><mtext id="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">mod</mtext></ci></apply></apply><ci id="S2.E5.m1.1.1.cmml" xref="S2.E5.m1.1.1">𝑦</ci></interval></apply><apply id="S2.E5.m1.2.2.1.1.2.2.2.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2"><times id="S2.E5.m1.2.2.1.1.2.2.2.2.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.2"></times><ci id="S2.E5.m1.2.2.1.1.2.2.2.3a.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.3"><mtext id="S2.E5.m1.2.2.1.1.2.2.2.3.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.3">subject to&nbsp;</mtext></ci><apply id="S2.E5.m1.2.2.1.1.2.2.2.4.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.4"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.2.2.2.4.1.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.4">subscript</csymbol><ci id="S2.E5.m1.2.2.1.1.2.2.2.4.2.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.4.2">𝑓</ci><ci id="S2.E5.m1.2.2.1.1.2.2.2.4.3.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.4.3">𝜃</ci></apply><apply id="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.1.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1">subscript</csymbol><ci id="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.2.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.2">𝑥</ci><ci id="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.3a.cmml" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.3"><mtext id="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.3.cmml" mathsize="70%" xref="S2.E5.m1.2.2.1.1.2.2.2.1.1.1.3">mod</mtext></ci></apply></apply></list><ci id="S2.E5.m1.2.2.1.1.4.cmml" xref="S2.E5.m1.2.2.1.1.4">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.2c">\arg\min_{x_{\text{mod}}}\mathcal{L}(f_{\theta}(x_{\text{mod}}),y),\quad\text{%
subject to }f_{\theta}(x_{\text{mod}})\neq y,</annotation><annotation encoding="application/x-llamapun" id="S2.E5.m1.2d">roman_arg roman_min start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT mod end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L ( italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT mod end_POSTSUBSCRIPT ) , italic_y ) , subject to italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT mod end_POSTSUBSCRIPT ) ≠ italic_y ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.p3.3">this category focuses on reducing the model’s accuracy across tasks and scenarios.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这一类别专注于降低模型在各项任务和场景中的准确性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS4.p4">
<p class="ltx_p" id="S2.SS4.p4.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS4.p4.1.m1.1"><semantics id="S2.SS4.p4.1.m1.1a"><mo id="S2.SS4.p4.1.m1.1.1" xref="S2.SS4.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.1.m1.1b"><ci id="S2.SS4.p4.1.m1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS4.p4.2.1">Jailbreak Attacks.</span>
Jailbreak attacks seek to bypass the model’s safety mechanisms or ethical constraints, compelling it to generate harmful or restricted outputs <math alttext="y_{\text{restricted}}" class="ltx_Math" display="inline" id="S2.SS4.p4.2.m2.1"><semantics id="S2.SS4.p4.2.m2.1a"><msub id="S2.SS4.p4.2.m2.1.1" xref="S2.SS4.p4.2.m2.1.1.cmml"><mi id="S2.SS4.p4.2.m2.1.1.2" xref="S2.SS4.p4.2.m2.1.1.2.cmml">y</mi><mtext id="S2.SS4.p4.2.m2.1.1.3" xref="S2.SS4.p4.2.m2.1.1.3a.cmml">restricted</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.2.m2.1b"><apply id="S2.SS4.p4.2.m2.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p4.2.m2.1.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS4.p4.2.m2.1.1.2.cmml" xref="S2.SS4.p4.2.m2.1.1.2">𝑦</ci><ci id="S2.SS4.p4.2.m2.1.1.3a.cmml" xref="S2.SS4.p4.2.m2.1.1.3"><mtext id="S2.SS4.p4.2.m2.1.1.3.cmml" mathsize="70%" xref="S2.SS4.p4.2.m2.1.1.3">restricted</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.2.m2.1c">y_{\text{restricted}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.2.m2.1d">italic_y start_POSTSUBSCRIPT restricted end_POSTSUBSCRIPT</annotation></semantics></math>. Unlike targeted or untargeted attacks, jailbreak methods often do not require adversarial perturbations to the input; instead, they exploit flaws in the model’s safety alignment or prompt-handling mechanisms. Such attacks may involve carefully designed queries or prompts that trick the model into violating its safety policies. The objective is defined as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS4.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS4.p4.1.m1.1a"><mo id="S2.SS4.p4.1.m1.1.1">∙</mo><annotation-xml id="S2.SS4.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS4.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS4.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 越狱攻击。越狱攻击旨在绕过模型的安全机制或伦理约束，迫使模型生成有害或受限的输出 <math id="S2.SS4.p4.2.m2.1" display="inline" class="ltx_Math" alttext="y_{\text{restricted}}"><semantics id="S2.SS4.p4.2.m2.1a"><msub id="S2.SS4.p4.2.m2.1.1"><mi id="S2.SS4.p4.2.m2.1.1.2">y</mi><mtext id="S2.SS4.p4.2.m2.1.1.3">restricted</mtext></msub><annotation-xml id="S2.SS4.p4.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS4.p4.2.m2.1c" encoding="application/x-tex">y_{\text{restricted}}</annotation><annotation id="S2.SS4.p4.2.m2.1d" encoding="application/x-llamapun">italic_y start_POSTSUBSCRIPT restricted end_POSTSUBSCRIPT</annotation></semantics></math> 。与定向攻击或非定向攻击不同，越狱方法通常不需要对输入进行对抗性扰动；相反，它们利用模型安全对齐或提示处理机制中的缺陷。此类攻击可能涉及精心设计的查询或提示，诱使模型违反其安全策略。其目标定义为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\arg\min_{x}\mathcal{R}(f_{\theta}(x))\quad\text{subject to }y_{\text{%
restricted}}\in\mathcal{O}," class="ltx_Math" display="block" id="S2.E6.m1.2"><semantics id="S2.E6.m1.2a"><mrow id="S2.E6.m1.2.2.1" xref="S2.E6.m1.2.2.1.1.cmml"><mrow id="S2.E6.m1.2.2.1.1" xref="S2.E6.m1.2.2.1.1.cmml"><mrow id="S2.E6.m1.2.2.1.1.2.2" xref="S2.E6.m1.2.2.1.1.2.3.cmml"><mrow id="S2.E6.m1.2.2.1.1.1.1.1" xref="S2.E6.m1.2.2.1.1.1.1.1.cmml"><mrow id="S2.E6.m1.2.2.1.1.1.1.1.3" xref="S2.E6.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S2.E6.m1.2.2.1.1.1.1.1.3.1" xref="S2.E6.m1.2.2.1.1.1.1.1.3.1.cmml">arg</mi><mo id="S2.E6.m1.2.2.1.1.1.1.1.3a" lspace="0.167em" xref="S2.E6.m1.2.2.1.1.1.1.1.3.cmml">⁡</mo><mrow id="S2.E6.m1.2.2.1.1.1.1.1.3.2" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.cmml"><munder id="S2.E6.m1.2.2.1.1.1.1.1.3.2.1" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.cmml"><mi id="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.2" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.2.cmml">min</mi><mi id="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.3" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.3.cmml">x</mi></munder><mo id="S2.E6.m1.2.2.1.1.1.1.1.3.2a" lspace="0.167em" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.cmml">⁡</mo><mi class="ltx_font_mathcaligraphic" id="S2.E6.m1.2.2.1.1.1.1.1.3.2.2" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.2.cmml">ℛ</mi></mrow></mrow><mo id="S2.E6.m1.2.2.1.1.1.1.1.2" xref="S2.E6.m1.2.2.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E6.m1.2.2.1.1.1.1.1.1.1" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E6.m1.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.2" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml">f</mi><mi id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.3" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml">θ</mi></msub><mo id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S2.E6.m1.1.1" xref="S2.E6.m1.1.1.cmml">x</mi><mo id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E6.m1.2.2.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mspace id="S2.E6.m1.2.2.1.1.2.2.3" width="1em" xref="S2.E6.m1.2.2.1.1.2.3.cmml"></mspace><mrow id="S2.E6.m1.2.2.1.1.2.2.2" xref="S2.E6.m1.2.2.1.1.2.2.2.cmml"><mtext id="S2.E6.m1.2.2.1.1.2.2.2.2" xref="S2.E6.m1.2.2.1.1.2.2.2.2a.cmml">subject to&nbsp;</mtext><mo id="S2.E6.m1.2.2.1.1.2.2.2.1" xref="S2.E6.m1.2.2.1.1.2.2.2.1.cmml">⁢</mo><msub id="S2.E6.m1.2.2.1.1.2.2.2.3" xref="S2.E6.m1.2.2.1.1.2.2.2.3.cmml"><mi id="S2.E6.m1.2.2.1.1.2.2.2.3.2" xref="S2.E6.m1.2.2.1.1.2.2.2.3.2.cmml">y</mi><mtext id="S2.E6.m1.2.2.1.1.2.2.2.3.3" xref="S2.E6.m1.2.2.1.1.2.2.2.3.3a.cmml">restricted</mtext></msub></mrow></mrow><mo id="S2.E6.m1.2.2.1.1.3" xref="S2.E6.m1.2.2.1.1.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E6.m1.2.2.1.1.4" xref="S2.E6.m1.2.2.1.1.4.cmml">𝒪</mi></mrow><mo id="S2.E6.m1.2.2.1.2" xref="S2.E6.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m1.2b"><apply id="S2.E6.m1.2.2.1.1.cmml" xref="S2.E6.m1.2.2.1"><in id="S2.E6.m1.2.2.1.1.3.cmml" xref="S2.E6.m1.2.2.1.1.3"></in><list id="S2.E6.m1.2.2.1.1.2.3.cmml" xref="S2.E6.m1.2.2.1.1.2.2"><apply id="S2.E6.m1.2.2.1.1.1.1.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1"><times id="S2.E6.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.2"></times><apply id="S2.E6.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.3"><arg id="S2.E6.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.3.1"></arg><apply id="S2.E6.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2"><apply id="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.1">subscript</csymbol><min id="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.2.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.2"></min><ci id="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.3.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.1.3">𝑥</ci></apply><ci id="S2.E6.m1.2.2.1.1.1.1.1.3.2.2.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.3.2.2">ℛ</ci></apply></apply><apply id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1"><times id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.1"></times><apply id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.2">𝑓</ci><ci id="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E6.m1.2.2.1.1.1.1.1.1.1.1.2.3">𝜃</ci></apply><ci id="S2.E6.m1.1.1.cmml" xref="S2.E6.m1.1.1">𝑥</ci></apply></apply><apply id="S2.E6.m1.2.2.1.1.2.2.2.cmml" xref="S2.E6.m1.2.2.1.1.2.2.2"><times id="S2.E6.m1.2.2.1.1.2.2.2.1.cmml" xref="S2.E6.m1.2.2.1.1.2.2.2.1"></times><ci id="S2.E6.m1.2.2.1.1.2.2.2.2a.cmml" xref="S2.E6.m1.2.2.1.1.2.2.2.2"><mtext id="S2.E6.m1.2.2.1.1.2.2.2.2.cmml" xref="S2.E6.m1.2.2.1.1.2.2.2.2">subject to&nbsp;</mtext></ci><apply id="S2.E6.m1.2.2.1.1.2.2.2.3.cmml" xref="S2.E6.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S2.E6.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S2.E6.m1.2.2.1.1.2.2.2.3">subscript</csymbol><ci id="S2.E6.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S2.E6.m1.2.2.1.1.2.2.2.3.2">𝑦</ci><ci id="S2.E6.m1.2.2.1.1.2.2.2.3.3a.cmml" xref="S2.E6.m1.2.2.1.1.2.2.2.3.3"><mtext id="S2.E6.m1.2.2.1.1.2.2.2.3.3.cmml" mathsize="70%" xref="S2.E6.m1.2.2.1.1.2.2.2.3.3">restricted</mtext></ci></apply></apply></list><ci id="S2.E6.m1.2.2.1.1.4.cmml" xref="S2.E6.m1.2.2.1.1.4">𝒪</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.2c">\arg\min_{x}\mathcal{R}(f_{\theta}(x))\quad\text{subject to }y_{\text{%
restricted}}\in\mathcal{O},</annotation><annotation encoding="application/x-llamapun" id="S2.E6.m1.2d">roman_arg roman_min start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT caligraphic_R ( italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) ) subject to italic_y start_POSTSUBSCRIPT restricted end_POSTSUBSCRIPT ∈ caligraphic_O ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.p4.4">where <math alttext="\mathcal{R}" class="ltx_Math" display="inline" id="S2.SS4.p4.3.m1.1"><semantics id="S2.SS4.p4.3.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p4.3.m1.1.1" xref="S2.SS4.p4.3.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.3.m1.1b"><ci id="S2.SS4.p4.3.m1.1.1.cmml" xref="S2.SS4.p4.3.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.3.m1.1c">\mathcal{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.3.m1.1d">caligraphic_R</annotation></semantics></math> measures the effectiveness of the model’s safety mechanisms, and <math alttext="\mathcal{O}" class="ltx_Math" display="inline" id="S2.SS4.p4.4.m2.1"><semantics id="S2.SS4.p4.4.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p4.4.m2.1.1" xref="S2.SS4.p4.4.m2.1.1.cmml">𝒪</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.4.m2.1b"><ci id="S2.SS4.p4.4.m2.1.1.cmml" xref="S2.SS4.p4.4.m2.1.1">𝒪</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.4.m2.1c">\mathcal{O}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.4.m2.1d">caligraphic_O</annotation></semantics></math> is the set of restricted outputs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S2.SS4.p4.3.m1.1" display="inline" class="ltx_Math" alttext="\mathcal{R}"><semantics id="S2.SS4.p4.3.m1.1a"><mi id="S2.SS4.p4.3.m1.1.1" class="ltx_font_mathcaligraphic">ℛ</mi><annotation-xml id="S2.SS4.p4.3.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS4.p4.3.m1.1c" encoding="application/x-tex">\mathcal{R}</annotation><annotation id="S2.SS4.p4.3.m1.1d" encoding="application/x-llamapun">caligraphic_R</annotation></semantics></math> 衡量模型安全机制的有效性， <math id="S2.SS4.p4.4.m2.1" display="inline" class="ltx_Math" alttext="\mathcal{O}"><semantics id="S2.SS4.p4.4.m2.1a"><mi id="S2.SS4.p4.4.m2.1.1" class="ltx_font_mathcaligraphic">𝒪</mi><annotation-xml id="S2.SS4.p4.4.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS4.p4.4.m2.1c" encoding="application/x-tex">\mathcal{O}</annotation><annotation id="S2.SS4.p4.4.m2.1d" encoding="application/x-llamapun">caligraphic_O</annotation></semantics></math> 是受限输出的集合。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span><span class="ltx_text ltx_font_italic" id="S2.SS5.1.1">Attack Strategies</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.5 攻击策略</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.1">Basic attack strategies can be categorized based on the type of manipulation applied to the model. These strategies target different components of the model, ranging from input perturbations to poisoning the training data. We present five main categories of attack strategies as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基本的攻击策略可以根据对模型施加的操纵类型进行分类。这些策略针对模型的各个组件，范围从输入扰动到污染训练数据。我们介绍五种主要的攻击策略，如下所示：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p2">
<p class="ltx_p" id="S2.SS5.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS5.p2.1.m1.1"><semantics id="S2.SS5.p2.1.m1.1a"><mo id="S2.SS5.p2.1.m1.1.1" xref="S2.SS5.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS5.p2.1.m1.1b"><ci id="S2.SS5.p2.1.m1.1.1.cmml" xref="S2.SS5.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS5.p2.1.1">Perturbation-based Attacks.</span>
Perturbation-based attacks involve making small, often imperceptible changes to the input data in order to mislead the model into making incorrect predictions&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib75" title="">75</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib77" title="">77</a>]</cite>. These attacks typically rely on gradient-based methods to identify the most vulnerable parts of the input and introduce perturbations that maximize the model’s loss function. Examples include adversarial image attacks where slight modifications in pixel values cause misclassification without significantly altering the visual appearance to a human observer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib78" title="">78</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib79" title="">79</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS5.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS5.p2.1.m1.1a"><mo id="S2.SS5.p2.1.m1.1.1">∙</mo><annotation-xml id="S2.SS5.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS5.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS5.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 基于扰动的攻击。基于扰动的攻击涉及对输入数据进行微小且通常难以察觉的修改，以误导模型做出错误预测[75, 76, 77]。这些攻击通常依赖于基于梯度的方法来识别输入中最易受攻击的部分，并引入扰动以最大化模型的损失函数。例如，对抗性图像攻击中，对像素值的微小修改会导致错误分类，而不会显著改变人类观察者的视觉外观[78, 79]。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p3">
<p class="ltx_p" id="S2.SS5.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS5.p3.1.m1.1"><semantics id="S2.SS5.p3.1.m1.1a"><mo id="S2.SS5.p3.1.m1.1.1" xref="S2.SS5.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS5.p3.1.m1.1b"><ci id="S2.SS5.p3.1.m1.1.1.cmml" xref="S2.SS5.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS5.p3.1.1">Transfer-based Attacks.</span>
Transfer-based attacks exploit the phenomenon of transferability, where adversarial examples crafted for one model can often be used to deceive another model with similar architecture or function&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib80" title="">80</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib81" title="">81</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib82" title="">82</a>]</cite>. In these approaches, attackers generate adversarial examples using a source model and then test them on a target model. This type of attack is particularly useful in black-box settings where the attacker has no direct access to the target model’s parameters or training data, but can still craft adversarial examples by leveraging knowledge of a related model.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS5.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS5.p3.1.m1.1a"><mo id="S2.SS5.p3.1.m1.1.1">∙</mo><annotation-xml id="S2.SS5.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS5.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS5.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 基于迁移的攻击。基于迁移的攻击利用迁移性现象，即针对一个模型制作的对抗样本通常可以用来欺骗具有相似架构或功能的另一个模型[80, 81, 82]。在这些方法中，攻击者使用源模型生成对抗样本，然后在目标模型上测试它们。这种类型的攻击在黑盒设置中特别有用，攻击者无法直接访问目标模型的参数或训练数据，但仍然可以通过利用相关模型的知识来制作对抗样本。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p4">
<p class="ltx_p" id="S2.SS5.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS5.p4.1.m1.1"><semantics id="S2.SS5.p4.1.m1.1a"><mo id="S2.SS5.p4.1.m1.1.1" xref="S2.SS5.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS5.p4.1.m1.1b"><ci id="S2.SS5.p4.1.m1.1.1.cmml" xref="S2.SS5.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS5.p4.1.1">Prompt-based Attacks.</span>
Prompt-based attacks focus on manipulating the input prompt (in the case of language models, this could be a sentence or question&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib83" title="">83</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib84" title="">84</a>]</cite>, and for vision-language models, a textual prompt associated with an image&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib85" title="">85</a>]</cite>). The goal is to craft a prompt that causes the model to produce undesirable outputs or make incorrect predictions. In vision-language models (LVLMs), for example, an attacker may modify the textual prompt to confuse the model’s understanding of the image, thereby generating adversarial results. These attacks often leverage natural language understanding to create subtle prompt variations that lead to model misbehavior.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS5.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS5.p4.1.m1.1a"><mo id="S2.SS5.p4.1.m1.1.1">∙</mo><annotation-xml id="S2.SS5.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS5.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS5.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 基于提示的攻击。基于提示的攻击专注于操控输入提示（在语言模型的情况下，这可能是一个句子或问题[ 70, 83, 84]，在视觉语言模型的情况下，这是一个与图像相关的文本提示[ 41, 85]）。其目标是为模型制作一个提示，使其产生不希望的输出或做出错误的预测。例如，在视觉语言模型（LVLMs）中，攻击者可能会修改文本提示，以混淆模型对图像的理解，从而生成对抗性结果。这些攻击通常利用自然语言理解来创建微妙的提示变化，导致模型行为错误。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p5">
<p class="ltx_p" id="S2.SS5.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS5.p5.1.m1.1"><semantics id="S2.SS5.p5.1.m1.1a"><mo id="S2.SS5.p5.1.m1.1.1" xref="S2.SS5.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS5.p5.1.m1.1b"><ci id="S2.SS5.p5.1.m1.1.1.cmml" xref="S2.SS5.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p5.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p5.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS5.p5.1.1">Poison-based Attacks.</span>
Poison-based attacks target the model’s training data by injecting malicious data points designed to influence the model’s behavior during training&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib86" title="">86</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib30" title="">30</a>]</cite>. These attacks can be used to introduce subtle biases into the model or degrade its performance on specific tasks. The poisoned data is often carefully crafted to either cause misclassifications or degrade the generalization ability of the model, without being immediately apparent to the model trainer. This type of attack is particularly concerning for models that are continuously updated with new data or are trained on large datasets collected from various sources.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS5.p5.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS5.p5.1.m1.1a"><mo id="S2.SS5.p5.1.m1.1.1">∙</mo><annotation-xml id="S2.SS5.p5.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS5.p5.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS5.p5.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 基于中毒的攻击。基于中毒的攻击通过注入恶意数据点来针对模型的训练数据，这些数据点旨在影响模型在训练过程中的行为[86, 30]。这些攻击可用于向模型引入微妙的偏差或降低其在特定任务上的性能。中毒数据通常经过精心设计，旨在要么导致错误分类，要么降低模型的泛化能力，而不会立即被模型训练者察觉。对于那些不断用新数据更新或在大规模、来自各种来源的数据集上训练的模型，这种类型的攻击尤其令人担忧。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p6">
<p class="ltx_p" id="S2.SS5.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS5.p6.1.m1.1"><semantics id="S2.SS5.p6.1.m1.1a"><mo id="S2.SS5.p6.1.m1.1.1" xref="S2.SS5.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS5.p6.1.m1.1b"><ci id="S2.SS5.p6.1.m1.1.1.cmml" xref="S2.SS5.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p6.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p6.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S2.SS5.p6.1.1">Trigger-based Attacks.</span>
Trigger-based attacks involve embedding specific triggers (such as a particular pattern or set of features) into the training data or inputs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib87" title="">87</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib88" title="">88</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib89" title="">89</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib90" title="">90</a>]</cite>. When these triggers are present in the input data during inference, the model’s behavior is altered in a predefined way, often causing the model to misclassify the input. These attacks can be highly effective, as the trigger may only need to be present in a small portion of the data, making them difficult to detect. In some cases, the trigger may be imperceptible or unobtrusive, making it challenging for both humans and automated defenses to identify the malicious input.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S2.SS5.p6.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S2.SS5.p6.1.m1.1a"><mo id="S2.SS5.p6.1.m1.1.1">∙</mo><annotation-xml id="S2.SS5.p6.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS5.p6.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S2.SS5.p6.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 基于触发器的攻击。基于触发器的攻击涉及将特定的触发器（如特定模式或一组特征）嵌入训练数据或输入中[87, 88, 89, 90]。当这些触发器在推理时的输入数据中出现时，模型的行为会以预定义的方式改变，通常导致模型错误分类输入。这些攻击可以非常有效，因为触发器只需要存在于数据的一小部分中，使其难以检测。在某些情况下，触发器可能难以察觉或不显眼，这使得人类和自动化防御都难以识别恶意输入。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Attack</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3 攻击</font></font></font>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Summary of key characteristics of reviewed methods in Inference-Phase Attacks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1" title="3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1</span></a>). T, U, and J represent Targeted, Untargeted, and Jailbreak Attacks, respectively. <span class="ltx_ERROR undefined" id="S3.T2.12.1">\faFileTextO</span>&nbsp;and <span class="ltx_ERROR undefined" id="S3.T2.13.2">\faFilePhotoO</span>&nbsp;indicate Textual and Visual modalities, while <span class="ltx_ERROR undefined" id="S3.T2.14.3">\faCommentO</span>&nbsp;and <span class="ltx_ERROR undefined" id="S3.T2.15.4">\faCommentsO</span>&nbsp;denote Single-turn and Multi-turn attack modes, respectively.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 II：推理阶段攻击（§ 3.1）中审查方法的要点总结。T、U 和 J 分别代表定向攻击、非定向攻击和越狱攻击。\faFileTextO 和 \faFilePhotoO 表示文本和视觉模态，而 \faCommentO 和 \faCommentsO 分别指单轮攻击模式和多轮攻击模式。</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.16" style="width:867.2pt;height:768.6pt;vertical-align:-1.3pt;"><span class="ltx_transformed_inner" style="transform:translate(87.8pt,-77.6pt) scale(1.25371033954387,1.25371033954387) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.16.1">
<tbody><tr class="ltx_tr" id="S3.T2.16.1.1" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S3.T2.16.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.16.1.1.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.16.1.1.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S3.T2.16.1.1.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.1.1.4.1" style="font-size:90%;">Objectives<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">目标</font></font></font></span></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.16.1.1.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.16.1.1.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S3.T2.16.1.1.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.1.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.2" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.1.2.1.1" style="font-size:90%;background-color:#D8D6C4;">Methods</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.2.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.1.2.2.1" style="font-size:90%;background-color:#D8D6C4;">Venue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">会议地点</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.2.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.1.2.3.1" style="font-size:90%;background-color:#D8D6C4;">Attack Strategies<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">攻击策略</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.2.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.2.4.1" style="font-size:90%;background-color:#D8D6C4;">T</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.2.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.2.5.1" style="font-size:90%;background-color:#D8D6C4;">U</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.2.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.2.6.1" style="font-size:90%;background-color:#D8D6C4;">J</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.2.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.1.2.7.1" style="font-size:90%;background-color:#D8D6C4;">Trans.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">翻译</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.2.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.1.2.8.1" style="font-size:90%;background-color:#D8D6C4;">Modal.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">模态。</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.2.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.1.2.9.1" style="font-size:90%;background-color:#D8D6C4;">Turns<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">转换</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.2.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.16.1.2.10.1" style="font-size:90%;background-color:#D8D6C4;">Victim Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">受害者模型</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.3">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="10" id="S3.T2.16.1.3.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T2.16.1.3.1.1" style="font-size:90%;">White-Box Attacks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS1" title="3.1.1 White-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.1</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">白盒攻击（§ 3.1.1）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.4" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S3.T2.16.1.4.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.4.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a><span class="ltx_text" id="S3.T2.16.1.4.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.4.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.4.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[AAAI’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.4.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.4.3.1" style="font-size:90%;background-color:#F5F5F0;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.4.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.4.4.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.4.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.4.5.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.4.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.4.6.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.4.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.4.7.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.4.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.4.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.4.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.4.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.4.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.4.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVA/MiniGPT-4/InstructBLIP</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.5">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.5.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.5.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib24" title="">24</a><span class="ltx_text" id="S3.T2.16.1.5.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.5.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.5.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[ICCV’23]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.5.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.5.3.1" style="font-size:90%;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.5.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.5.4.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.5.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.5.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.5.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.5.6.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.5.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.5.7.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.5.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.5.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.5.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.5.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.5.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.5.10.1" style="font-size:90%;" data-imt_insert_failed="1">OpenFlamingo</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.6" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.6.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.6.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib91" title="">91</a><span class="ltx_text" id="S3.T2.16.1.6.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.6.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.6.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’23]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.6.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.6.3.1" style="font-size:90%;background-color:#F5F5F0;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.6.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.6.4.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.6.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.6.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.6.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.6.6.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.6.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.6.7.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.6.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.6.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.6.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.6.9.1" data-imt_insert_failed="1">\faCommentsO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.6.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.6.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVA/PandaGPT</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.7">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.7.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.7.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib27" title="">27</a><span class="ltx_text" id="S3.T2.16.1.7.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.7.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.7.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[ICML’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.7.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.7.3.1" style="font-size:90%;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.7.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.7.4.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.7.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.7.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.7.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.7.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.7.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.7.7.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.7.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.7.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.7.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.7.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.7.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.7.10.1" style="font-size:90%;" data-imt_insert_failed="1">LLaVA</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.8" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.8.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.8.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib92" title="">92</a><span class="ltx_text" id="S3.T2.16.1.8.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.8.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.8.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ICLR’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.8.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.8.3.1" style="font-size:90%;background-color:#F5F5F0;">Perturbation/Trigger-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">扰动/触发器</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.8.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.8.4.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.8.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.8.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.8.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.8.6.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.8.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.8.7.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.8.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.8.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.8.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.8.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.8.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.8.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">BLIP/BLIP-2/InstructBLIP/MiniGPT-4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.9">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.9.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.9.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib93" title="">93</a><span class="ltx_text" id="S3.T2.16.1.9.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.9.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.9.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.9.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.9.3.1" style="font-size:90%;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.9.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.9.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.9.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.9.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.9.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.9.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.9.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.9.7.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.9.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.9.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.9.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S3.T2.16.1.9.8.3">\faFileTextO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.9.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.9.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.9.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.9.10.1" style="font-size:90%;" data-imt_insert_failed="1">LLaVA/MiniGPT-4/InstructBLIP/BLIP-2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.10" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.10.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.10.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib94" title="">94</a><span class="ltx_text" id="S3.T2.16.1.10.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.10.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.10.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[COLM’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.10.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.10.3.1" style="font-size:90%;background-color:#F5F5F0;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.10.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.10.4.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.10.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.10.5.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.10.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.10.6.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.10.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.10.7.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.10.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.10.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.10.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.10.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.10.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.10.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">MiniGPT-4/OpenFlamingo/LLaVA</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.11">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.11.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.11.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib40" title="">40</a><span class="ltx_text" id="S3.T2.16.1.11.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.11.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.11.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[ECCV’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.11.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.11.3.1" style="font-size:90%;">Perturbation/Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">扰动/提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.11.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.11.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.11.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.11.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.11.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.11.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.11.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.11.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.11.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.11.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.11.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S3.T2.16.1.11.8.3">\faFileTextO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.11.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.11.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.11.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.11.10.1" style="font-size:90%;" data-imt_insert_failed="1">LLaVA/GeminiPro/GPT-4V</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.12" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.12.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.12.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib95" title="">95</a><span class="ltx_text" id="S3.T2.16.1.12.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.12.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.12.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ICLR’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.12.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.12.3.1" style="font-size:90%;background-color:#F5F5F0;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.12.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.12.4.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.12.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.12.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.12.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.12.6.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.12.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.12.7.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.12.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.12.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.12.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.12.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.12.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.12.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">OpenFlamingo/BLIP-2/InstructBLIP</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.13">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.13.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.13.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib96" title="">96</a><span class="ltx_text" id="S3.T2.16.1.13.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.13.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.13.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[ICLR’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.13.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.13.3.1" style="font-size:90%;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.13.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.13.4.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.13.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.13.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.13.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.13.6.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.13.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.13.7.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.13.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.13.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.13.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.13.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.13.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.13.10.1" style="font-size:90%;" data-imt_insert_failed="1">MiniGPT-v2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.14" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.14.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.14.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a><span class="ltx_text" id="S3.T2.16.1.14.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.14.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.14.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[MM’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.14.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.14.3.1" style="font-size:90%;background-color:#F5F5F0;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.14.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.14.4.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.14.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.14.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.14.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.14.6.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.14.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.14.7.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.14.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.14.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.14.8.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S3.T2.16.1.14.8.2.1">\faFileTextO</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.14.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.14.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.14.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.14.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">MiniGPT-4</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.15">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.15.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.15.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib97" title="">97</a><span class="ltx_text" id="S3.T2.16.1.15.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.15.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.15.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.15.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.15.3.1" style="font-size:90%;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.15.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.15.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.15.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.15.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.15.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.15.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.15.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.15.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.15.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.15.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.15.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S3.T2.16.1.15.8.3">\faFileTextO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.15.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.15.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.15.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.15.10.1" style="font-size:90%;" data-imt_insert_failed="1">LLaVA/MiniGPT-4/InstructBLIP</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.16" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.16.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.16.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib98" title="">98</a><span class="ltx_text" id="S3.T2.16.1.16.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.16.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.16.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.16.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.16.3.1" style="font-size:90%;background-color:#F5F5F0;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.16.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.16.4.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.16.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.16.5.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.16.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.16.6.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.16.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.16.7.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.16.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.16.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.16.8.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S3.T2.16.1.16.8.2.1">\faFileTextO</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.16.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.16.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.16.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.16.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVA/InstructBLIP/BLIP-2</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.17">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.17.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.17.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib99" title="">99</a><span class="ltx_text" id="S3.T2.16.1.17.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.17.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.17.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.17.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.17.3.1" style="font-size:90%;">Perturbation-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于扰动的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.17.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.17.4.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.17.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.17.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.17.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.17.6.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.17.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.17.7.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.17.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.17.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.17.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.17.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.17.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.17.10.1" style="font-size:90%;" data-imt_insert_failed="1">LLaVA</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.18">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="10" id="S3.T2.16.1.18.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T2.16.1.18.1.1" style="font-size:90%;">Gray-Box Attacks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS2" title="3.1.2 Gray-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">灰盒攻击（§ 3.1.2）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.19" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S3.T2.16.1.19.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.19.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib25" title="">25</a><span class="ltx_text" id="S3.T2.16.1.19.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.19.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.19.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[NeurIPS’23]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.19.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.19.3.1" style="font-size:90%;background-color:#F5F5F0;">Transfer-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">迁移式</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.19.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.19.4.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.19.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.19.5.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.19.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.19.6.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.19.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.19.7.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.19.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.19.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.19.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.19.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.19.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.19.10.1" style="font-size:90%;background-color:#F5F5F0;">BLIP/UniDiffuser/other 4<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">BLIP/UniDiffuser/其他 4</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.20">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.20.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.20.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib100" title="">100</a><span class="ltx_text" id="S3.T2.16.1.20.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.20.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.20.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[NeurIPS’23]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.20.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.20.3.1" style="font-size:90%;">Transfer-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于迁移</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.20.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.20.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.20.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.20.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.20.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.20.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.20.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.20.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.20.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.20.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.20.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.20.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.20.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.20.10.1" style="font-size:90%;" data-imt_insert_failed="1">Bard</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.21" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.21.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.21.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib85" title="">85</a><span class="ltx_text" id="S3.T2.16.1.21.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.21.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.21.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ICLR’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.21.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.21.3.1" style="font-size:90%;background-color:#F5F5F0;">Transfer/Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">迁移/提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.21.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.21.4.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.21.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.21.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.21.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.21.6.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.21.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.21.7.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.21.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.21.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.21.8.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S3.T2.16.1.21.8.2.1">\faFileTextO</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.21.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.21.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.21.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.21.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVA</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.22">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.22.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.22.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib101" title="">101</a><span class="ltx_text" id="S3.T2.16.1.22.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.22.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.22.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.22.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.22.3.1" style="font-size:90%;">Transfer-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于迁移的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.22.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.22.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.22.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.22.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.22.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.22.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.22.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.22.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.22.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.22.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.22.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.22.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.22.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.22.10.1" style="font-size:90%;">MiniGPT-4/MiniGPT-V2/other 3<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">MiniGPT-4/MiniGPT-V2/其他 3</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.23" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.23.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.23.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib102" title="">102</a><span class="ltx_text" id="S3.T2.16.1.23.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.23.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.23.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ICML’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.23.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.23.3.1" style="font-size:90%;background-color:#F5F5F0;">Transfer-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于迁移</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.23.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.23.4.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.23.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.23.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.23.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.23.6.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.23.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.23.7.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.23.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.23.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.23.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.23.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.23.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.23.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVA/InstructBLIP/BLIP</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.24">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.24.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.24.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib103" title="">103</a><span class="ltx_text" id="S3.T2.16.1.24.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.24.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.24.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.24.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.24.3.1" style="font-size:90%;">Transfer-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于迁移的</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.24.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.24.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.24.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.24.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.24.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.24.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.24.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.24.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.24.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.24.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.24.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.24.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.24.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.24.10.1" style="font-size:90%;" data-imt_insert_failed="1">LLaVA/PandaGPT</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.25" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.25.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.25.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib101" title="">101</a><span class="ltx_text" id="S3.T2.16.1.25.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.25.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.25.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[MM’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.25.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.25.3.1" style="font-size:90%;background-color:#F5F5F0;">Transfer-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于迁移</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.25.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.25.4.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.25.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.25.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.25.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.25.6.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.25.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.25.7.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.25.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.25.8.1" data-imt_insert_failed="1">\faFilePhotoO</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.25.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.25.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.25.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.25.10.1" style="font-size:90%;background-color:#F5F5F0;">LLaVA/Otter/other 5<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLaVA/Otter/其他 5</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.26">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="10" id="S3.T2.16.1.26.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T2.16.1.26.1.1" style="font-size:90%;">Black-Box Attacks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS3" title="3.1.3 Black-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.3</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">黑盒攻击（§ 3.1.3）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.27" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S3.T2.16.1.27.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.27.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a><span class="ltx_text" id="S3.T2.16.1.27.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.27.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.27.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’23]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.27.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.27.3.1" style="font-size:90%;background-color:#F5F5F0;">Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.27.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.27.4.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.27.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.27.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.27.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.27.6.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.27.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.27.7.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.27.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.27.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.27.8.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S3.T2.16.1.27.8.2.1">\faFileTextO</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.16.1.27.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.27.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.16.1.27.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.27.10.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVA/MiniGPT-4/CogLVLM</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.28">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.28.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.28.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib104" title="">104</a><span class="ltx_text" id="S3.T2.16.1.28.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.28.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.28.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[NeurIPS’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.28.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.28.3.1" style="font-size:90%;">Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.28.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.28.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.28.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.28.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.28.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.28.6.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.28.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.28.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.28.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.28.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.28.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S3.T2.16.1.28.8.3">\faFileTextO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.28.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.28.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.28.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.28.10.1" style="font-size:90%;" data-imt_insert_failed="1">LLaVA/MiniGPT-4/InstructBLIP/GPT-4V</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.29">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.29.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.29.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib105" title="">105</a><span class="ltx_text" id="S3.T2.16.1.29.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.29.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.29.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.29.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.29.3.1" style="font-size:90%;">Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.29.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.29.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.29.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.29.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.29.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.29.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.29.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.29.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.29.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.29.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.29.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S3.T2.16.1.29.8.3">\faFileTextO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.29.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.29.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.29.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.29.10.1" style="font-size:90%;">LLaVA/Qwen-VL/OmniLMM/other 2<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLaVA/Qwen-VL/OmniLMM/其他 2</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.30" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.30.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.30.1.1.1" style="font-size:90%;background-color:#F5F5F0;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib106" title="">106</a><span class="ltx_text" id="S3.T2.16.1.30.1.2.2" style="font-size:90%;background-color:#F5F5F0;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.30.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.30.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.30.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.30.3.1" style="font-size:90%;background-color:#F5F5F0;">Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.30.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.30.4.1" style="font-size:90%;color:#FF0000;background-color:#F5F5F0;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.30.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.30.5.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.30.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.30.6.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.30.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.30.7.1" style="font-size:90%;color:#5DAD55;background-color:#F5F5F0;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.30.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.30.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.30.8.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S3.T2.16.1.30.8.2.1">\faFileTextO</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.30.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.30.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.30.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.30.10.1" style="font-size:90%;background-color:#F5F5F0;">GPT-4V/GPT-4o/Qwen-VL/other 4<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">GPT-4V/GPT-4o/Qwen-VL/其他 4</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.31">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.31.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.31.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib107" title="">107</a><span class="ltx_text" id="S3.T2.16.1.31.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.31.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.31.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.31.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.31.3.1" style="font-size:90%;">Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.31.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.31.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.31.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.31.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.31.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.31.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.31.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.31.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.31.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.31.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.31.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S3.T2.16.1.31.8.3">\faFileTextO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.31.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.31.9.1" data-imt_insert_failed="1">\faCommentsO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.31.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.31.10.1" style="font-size:90%;" data-imt_insert_failed="1">MiniGPT-4/LLaVA/InstructBLIP/Chameleon</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.32">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.32.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.32.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib108" title="">108</a><span class="ltx_text" id="S3.T2.16.1.32.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.32.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.32.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.32.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.32.3.1" style="font-size:90%;">Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.32.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.32.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.32.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.32.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.32.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.32.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.32.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.32.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.32.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.32.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.32.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S3.T2.16.1.32.8.3">\faFileTextO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.32.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.32.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.32.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.32.10.1" style="font-size:90%;">GPT-4o/Qwen-VL/Claude/other 3<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">GPT-4o/Qwen-VL/Claude/其他 3</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.33">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S3.T2.16.1.33.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T2.16.1.33.1.1.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib109" title="">109</a><span class="ltx_text" id="S3.T2.16.1.33.1.2.2" style="font-size:90%;">]</span></cite></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.33.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.33.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.33.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.33.3.1" style="font-size:90%;">Prompt-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.33.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.33.4.1" style="font-size:90%;color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.33.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.33.5.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.33.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.33.6.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.33.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.33.7.1" style="font-size:90%;color:#5DAD55;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.33.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S3.T2.16.1.33.8.1">\faFilePhotoO</span><span class="ltx_text" id="S3.T2.16.1.33.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S3.T2.16.1.33.8.3">\faFileTextO</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.16.1.33.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S3.T2.16.1.33.9.1" data-imt_insert_failed="1">\faCommentO</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.16.1.33.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S3.T2.16.1.33.10.1" style="font-size:90%;">LLaVA/DeepSeek-VL/Qwen-VL/other 7<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLaVA/DeepSeek-VL/Qwen-VL/其他 7</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.16.1.34">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S3.T2.16.1.34.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T2.16.1.34.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Extensive research has been conducted to investigate strategies for attacking Large Vision-Language Models (LVLMs). These strategies are broadly classified into two principal categories: <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">Inference-Phase Attacks</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1" title="3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1</span></a>) and <span class="ltx_text ltx_font_bold" id="S3.p1.1.2">Training-Phase Attacks</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2" title="3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2</span></a>), each addressing distinct vulnerabilities across different stages of the LVLM lifecycle.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">针对大型视觉语言模型（LVLMs）的攻击策略已进行了广泛的研究。这些策略主要分为两类：推理阶段攻击（§ 3.1）和训练阶段攻击（§ 3.2），分别针对 LVLM 生命周期不同阶段的独特漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span class="ltx_text ltx_font_italic" id="S3.SS1.1.1">Inference-Phase Attacks</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1 推理阶段攻击</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Inference-Phase Attacks exploit meticulously crafted malicious inputs to compromise LVLMs without necessitating any modifications to the model’s parameters or architecture. This attribute renders them the most prevalently employed form of attack. Given that these attacks often employ multiple strategies simultaneously, they are systematically categorized based on their attack capabilities, as outlined in&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS3" title="2.3 Access Capabilities ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2.3</span></a>). Specifically, they are divided into <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">White-Box Attacks</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS1" title="3.1.1 White-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.1</span></a>), <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.2">Gray-Box Attacks</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS2" title="3.1.2 Gray-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a>), and <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.3">Black-Box Attacks</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS3" title="3.1.3 Black-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.3</span></a>), contingent on the degree of knowledge the adversary possesses regarding the target LVLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理阶段攻击利用精心设计的恶意输入来破坏大型视觉语言模型，而无需对模型的参数或架构进行任何修改。这一特性使它们成为最普遍使用的攻击形式。考虑到这些攻击通常同时使用多种策略，它们根据攻击能力系统地分类，如(§ 2.3)所述。具体来说，它们分为白盒攻击(§ 3.1.1)、灰盒攻击(§ 3.1.2)和黑盒攻击(§ 3.1.3)，这取决于攻击者对目标大型视觉语言模型的了解程度。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>White-Box Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1.1 白盒攻击</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">As the most stringent requirements for attack conditions method, White-box Attacks necessitate complete access to the model’s internal knowledge. As illustrated in the top of&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.F2" title="In 3.1.2 Gray-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Fig.</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, these attacks involve introducing adversarial noise to images and iteratively refining the noise using gradients from the model’s intermediate layers to achieve targeted outputs. Based on the type of modalities subjected to perturbations, they are further classified into two categories.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">作为攻击条件方法最严格的要求，白盒攻击需要完全访问模型的内部知识。如图 2 顶部所示，这些攻击涉及向图像中引入对抗性噪声，并使用模型中间层的梯度迭代地优化噪声，以实现目标输出。根据受扰动模态的类型，它们进一步分为两类。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.4"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.1.m1.1"><semantics id="S3.SS1.SSS1.p2.1.m1.1a"><mo id="S3.SS1.SSS1.p2.1.m1.1.1" xref="S3.SS1.SSS1.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.1.m1.1b"><ci id="S3.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p2.4.1">Single-Modality.</span>
Based on the vulnerabilities of LVLMs.
Qi <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.4.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>]</cite> propose a classic white-box attack method for crafting adversarial examples that can exploit the visual modality of LVLM to induce unsafe or misleading outputs, even when the model has been carefully aligned to follow ethical guidelines or constraints.
The attack is formulated as an optimization problem, where the adversarial example <math alttext="\widehat{v}_{adv}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.2.m2.1"><semantics id="S3.SS1.SSS1.p2.2.m2.1a"><msub id="S3.SS1.SSS1.p2.2.m2.1.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.cmml"><mover accent="true" id="S3.SS1.SSS1.p2.2.m2.1.1.2" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS1.p2.2.m2.1.1.2.2" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.2.cmml">v</mi><mo id="S3.SS1.SSS1.p2.2.m2.1.1.2.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.1.cmml">^</mo></mover><mrow id="S3.SS1.SSS1.p2.2.m2.1.1.3" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS1.p2.2.m2.1.1.3.2" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.2.cmml">a</mi><mo id="S3.SS1.SSS1.p2.2.m2.1.1.3.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS1.p2.2.m2.1.1.3.3" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.3.cmml">d</mi><mo id="S3.SS1.SSS1.p2.2.m2.1.1.3.1a" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS1.p2.2.m2.1.1.3.4" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.4.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.2.m2.1b"><apply id="S3.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2"><ci id="S3.SS1.SSS1.p2.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.1">^</ci><ci id="S3.SS1.SSS1.p2.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.2">𝑣</ci></apply><apply id="S3.SS1.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3"><times id="S3.SS1.SSS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.1"></times><ci id="S3.SS1.SSS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.2">𝑎</ci><ci id="S3.SS1.SSS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.3">𝑑</ci><ci id="S3.SS1.SSS1.p2.2.m2.1.1.3.4.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.4">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.2.m2.1c">\widehat{v}_{adv}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p2.2.m2.1d">over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT</annotation></semantics></math> is selected from a perturbation space <math alttext="\mathscr{B}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.3.m3.1"><semantics id="S3.SS1.SSS1.p2.3.m3.1a"><mi class="ltx_font_mathscript" id="S3.SS1.SSS1.p2.3.m3.1.1" xref="S3.SS1.SSS1.p2.3.m3.1.1.cmml">ℬ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.3.m3.1b"><ci id="S3.SS1.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1">ℬ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.3.m3.1c">\mathscr{B}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p2.3.m3.1d">script_B</annotation></semantics></math> to minimize the log-probability of the model’s output for the target class <math alttext="y_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.4.m4.1"><semantics id="S3.SS1.SSS1.p2.4.m4.1a"><msub id="S3.SS1.SSS1.p2.4.m4.1.1" xref="S3.SS1.SSS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.SSS1.p2.4.m4.1.1.2" xref="S3.SS1.SSS1.p2.4.m4.1.1.2.cmml">y</mi><mi id="S3.SS1.SSS1.p2.4.m4.1.1.3" xref="S3.SS1.SSS1.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.4.m4.1b"><apply id="S3.SS1.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.2">𝑦</ci><ci id="S3.SS1.SSS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.4.m4.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p2.4.m4.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. The attack objective is mathematically expressed as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS1.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S3.SS1.SSS1.p2.1.m1.1a"><mo id="S3.SS1.SSS1.p2.1.m1.1.1">∙</mo><annotation-xml id="S3.SS1.SSS1.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS1.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S3.SS1.SSS1.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 单模态。基于 LVLMs 的漏洞，Qi 等人[ 23]提出了一种经典的白盒攻击方法，用于制作对抗样本，该方法可以利用 LVLM 的视觉模态来诱导不安全或误导性的输出，即使模型已经经过精心校准以遵循道德准则或约束。该攻击被表述为一个优化问题，其中对抗样本 <math id="S3.SS1.SSS1.p2.2.m2.1" display="inline" class="ltx_Math" alttext="\widehat{v}_{adv}"><semantics id="S3.SS1.SSS1.p2.2.m2.1a"><msub id="S3.SS1.SSS1.p2.2.m2.1.1"><mover id="S3.SS1.SSS1.p2.2.m2.1.1.2" accent="true"><mi id="S3.SS1.SSS1.p2.2.m2.1.1.2.2">v</mi><mo id="S3.SS1.SSS1.p2.2.m2.1.1.2.1">^</mo></mover><mrow id="S3.SS1.SSS1.p2.2.m2.1.1.3"><mi id="S3.SS1.SSS1.p2.2.m2.1.1.3.2">a</mi><mo id="S3.SS1.SSS1.p2.2.m2.1.1.3.1">⁢</mo><mi id="S3.SS1.SSS1.p2.2.m2.1.1.3.3">d</mi><mo id="S3.SS1.SSS1.p2.2.m2.1.1.3.1a">⁢</mo><mi id="S3.SS1.SSS1.p2.2.m2.1.1.3.4">v</mi></mrow></msub><annotation-xml id="S3.SS1.SSS1.p2.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS1.SSS1.p2.2.m2.1c" encoding="application/x-tex">\widehat{v}_{adv}</annotation><annotation id="S3.SS1.SSS1.p2.2.m2.1d" encoding="application/x-llamapun">over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT</annotation></semantics></math> 从扰动空间 <math id="S3.SS1.SSS1.p2.3.m3.1" display="inline" class="ltx_Math" alttext="\mathscr{B}"><semantics id="S3.SS1.SSS1.p2.3.m3.1a"><mi id="S3.SS1.SSS1.p2.3.m3.1.1" class="ltx_font_mathscript">ℬ</mi><annotation-xml id="S3.SS1.SSS1.p2.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS1.p2.3.m3.1c" encoding="application/x-tex">\mathscr{B}</annotation><annotation id="S3.SS1.SSS1.p2.3.m3.1d" encoding="application/x-llamapun">script_B</annotation></semantics></math> 中选取，以最小化模型对目标类别 <math id="S3.SS1.SSS1.p2.4.m4.1" display="inline" class="ltx_Math" alttext="y_{i}"><semantics id="S3.SS1.SSS1.p2.4.m4.1a"><msub id="S3.SS1.SSS1.p2.4.m4.1.1"><mi id="S3.SS1.SSS1.p2.4.m4.1.1.2">y</mi><mi id="S3.SS1.SSS1.p2.4.m4.1.1.3">i</mi></msub><annotation-xml id="S3.SS1.SSS1.p2.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS1.SSS1.p2.4.m4.1c" encoding="application/x-tex">y_{i}</annotation><annotation id="S3.SS1.SSS1.p2.4.m4.1d" encoding="application/x-llamapun">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> 输出的对数概率。攻击目标用数学公式表示为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="v_{adv}:=\underset{\widehat{v}_{adv}\in\mathscr{B}}{\operatorname{argmin}}\sum%
_{i=1}^{m}-\log\left(p\left(y_{i}\mid\widehat{v}_{adv}\right)\right)," class="ltx_Math" display="block" id="S3.E7.m1.2"><semantics id="S3.E7.m1.2a"><mrow id="S3.E7.m1.2.2.1" xref="S3.E7.m1.2.2.1.1.cmml"><mrow id="S3.E7.m1.2.2.1.1" xref="S3.E7.m1.2.2.1.1.cmml"><msub id="S3.E7.m1.2.2.1.1.3" xref="S3.E7.m1.2.2.1.1.3.cmml"><mi id="S3.E7.m1.2.2.1.1.3.2" xref="S3.E7.m1.2.2.1.1.3.2.cmml">v</mi><mrow id="S3.E7.m1.2.2.1.1.3.3" xref="S3.E7.m1.2.2.1.1.3.3.cmml"><mi id="S3.E7.m1.2.2.1.1.3.3.2" xref="S3.E7.m1.2.2.1.1.3.3.2.cmml">a</mi><mo id="S3.E7.m1.2.2.1.1.3.3.1" xref="S3.E7.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E7.m1.2.2.1.1.3.3.3" xref="S3.E7.m1.2.2.1.1.3.3.3.cmml">d</mi><mo id="S3.E7.m1.2.2.1.1.3.3.1a" xref="S3.E7.m1.2.2.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E7.m1.2.2.1.1.3.3.4" xref="S3.E7.m1.2.2.1.1.3.3.4.cmml">v</mi></mrow></msub><mo id="S3.E7.m1.2.2.1.1.2" lspace="0.278em" rspace="0.278em" xref="S3.E7.m1.2.2.1.1.2.cmml">:=</mo><mrow id="S3.E7.m1.2.2.1.1.1" xref="S3.E7.m1.2.2.1.1.1.cmml"><mrow id="S3.E7.m1.2.2.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.3.cmml"><munder accentunder="true" id="S3.E7.m1.2.2.1.1.1.3.2" xref="S3.E7.m1.2.2.1.1.1.3.2.cmml"><mi id="S3.E7.m1.2.2.1.1.1.3.2.2" xref="S3.E7.m1.2.2.1.1.1.3.2.2.cmml">argmin</mi><mrow id="S3.E7.m1.2.2.1.1.1.3.2.1" xref="S3.E7.m1.2.2.1.1.1.3.2.1.cmml"><msub id="S3.E7.m1.2.2.1.1.1.3.2.1.2" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.cmml"><mover accent="true" id="S3.E7.m1.2.2.1.1.1.3.2.1.2.2" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.cmml"><mi id="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.2" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.2.cmml">v</mi><mo id="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.1" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.1.cmml">^</mo></mover><mrow id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.cmml"><mi id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.2" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.2.cmml">a</mi><mo id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.1" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.1.cmml">⁢</mo><mi id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.3" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.3.cmml">d</mi><mo id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.1a" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.1.cmml">⁢</mo><mi id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.4" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.4.cmml">v</mi></mrow></msub><mo id="S3.E7.m1.2.2.1.1.1.3.2.1.1" xref="S3.E7.m1.2.2.1.1.1.3.2.1.1.cmml">∈</mo><mi class="ltx_font_mathscript" id="S3.E7.m1.2.2.1.1.1.3.2.1.3" xref="S3.E7.m1.2.2.1.1.1.3.2.1.3.cmml">ℬ</mi></mrow></munder><mo id="S3.E7.m1.2.2.1.1.1.3.1" xref="S3.E7.m1.2.2.1.1.1.3.1.cmml">⁢</mo><munderover id="S3.E7.m1.2.2.1.1.1.3.3" xref="S3.E7.m1.2.2.1.1.1.3.3.cmml"><mo id="S3.E7.m1.2.2.1.1.1.3.3.2.2" movablelimits="false" rspace="0em" xref="S3.E7.m1.2.2.1.1.1.3.3.2.2.cmml">∑</mo><mrow id="S3.E7.m1.2.2.1.1.1.3.3.2.3" xref="S3.E7.m1.2.2.1.1.1.3.3.2.3.cmml"><mi id="S3.E7.m1.2.2.1.1.1.3.3.2.3.2" xref="S3.E7.m1.2.2.1.1.1.3.3.2.3.2.cmml">i</mi><mo id="S3.E7.m1.2.2.1.1.1.3.3.2.3.1" xref="S3.E7.m1.2.2.1.1.1.3.3.2.3.1.cmml">=</mo><mn id="S3.E7.m1.2.2.1.1.1.3.3.2.3.3" xref="S3.E7.m1.2.2.1.1.1.3.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E7.m1.2.2.1.1.1.3.3.3" xref="S3.E7.m1.2.2.1.1.1.3.3.3.cmml">m</mi></munderover></mrow><mo id="S3.E7.m1.2.2.1.1.1.2" lspace="0em" xref="S3.E7.m1.2.2.1.1.1.2.cmml">−</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.2.cmml"><mi id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml">log</mi><mo id="S3.E7.m1.2.2.1.1.1.1.1a" xref="S3.E7.m1.2.2.1.1.1.1.2.cmml">⁡</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.2.cmml"><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.2.cmml">(</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml">p</mi><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">∣</mo><msub id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">v</mi><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">a</mi><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">d</mi><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.1a" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.4" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.4.cmml">v</mi></mrow></msub></mrow><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E7.m1.2.2.1.2" xref="S3.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.2b"><apply id="S3.E7.m1.2.2.1.1.cmml" xref="S3.E7.m1.2.2.1"><csymbol cd="latexml" id="S3.E7.m1.2.2.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.2">assign</csymbol><apply id="S3.E7.m1.2.2.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.3.1.cmml" xref="S3.E7.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.3.2.cmml" xref="S3.E7.m1.2.2.1.1.3.2">𝑣</ci><apply id="S3.E7.m1.2.2.1.1.3.3.cmml" xref="S3.E7.m1.2.2.1.1.3.3"><times id="S3.E7.m1.2.2.1.1.3.3.1.cmml" xref="S3.E7.m1.2.2.1.1.3.3.1"></times><ci id="S3.E7.m1.2.2.1.1.3.3.2.cmml" xref="S3.E7.m1.2.2.1.1.3.3.2">𝑎</ci><ci id="S3.E7.m1.2.2.1.1.3.3.3.cmml" xref="S3.E7.m1.2.2.1.1.3.3.3">𝑑</ci><ci id="S3.E7.m1.2.2.1.1.3.3.4.cmml" xref="S3.E7.m1.2.2.1.1.3.3.4">𝑣</ci></apply></apply><apply id="S3.E7.m1.2.2.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1"><minus id="S3.E7.m1.2.2.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.2"></minus><apply id="S3.E7.m1.2.2.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3"><times id="S3.E7.m1.2.2.1.1.1.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.1"></times><apply id="S3.E7.m1.2.2.1.1.1.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2"><apply id="S3.E7.m1.2.2.1.1.1.3.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1"><in id="S3.E7.m1.2.2.1.1.1.3.2.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.1"></in><apply id="S3.E7.m1.2.2.1.1.1.3.2.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.3.2.1.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2">subscript</csymbol><apply id="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.2"><ci id="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.1">^</ci><ci id="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.2.2">𝑣</ci></apply><apply id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3"><times id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.1"></times><ci id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.2">𝑎</ci><ci id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.3">𝑑</ci><ci id="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.4.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.2.3.4">𝑣</ci></apply></apply><ci id="S3.E7.m1.2.2.1.1.1.3.2.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.1.3">ℬ</ci></apply><ci id="S3.E7.m1.2.2.1.1.1.3.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.2">argmin</ci></apply><apply id="S3.E7.m1.2.2.1.1.1.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.3.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3">superscript</csymbol><apply id="S3.E7.m1.2.2.1.1.1.3.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.3.3.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3">subscript</csymbol><sum id="S3.E7.m1.2.2.1.1.1.3.3.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3.2.2"></sum><apply id="S3.E7.m1.2.2.1.1.1.3.3.2.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3.2.3"><eq id="S3.E7.m1.2.2.1.1.1.3.3.2.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3.2.3.1"></eq><ci id="S3.E7.m1.2.2.1.1.1.3.3.2.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3.2.3.2">𝑖</ci><cn id="S3.E7.m1.2.2.1.1.1.3.3.2.3.3.cmml" type="integer" xref="S3.E7.m1.2.2.1.1.1.3.3.2.3.3">1</cn></apply></apply><ci id="S3.E7.m1.2.2.1.1.1.3.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3.3">𝑚</ci></apply></apply><apply id="S3.E7.m1.2.2.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1"><log id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"></log><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2"></times><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3">𝑝</ci><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.1">^</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2">𝑣</ci></apply><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3"><times id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2">𝑎</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3">𝑑</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.4">𝑣</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.2c">v_{adv}:=\underset{\widehat{v}_{adv}\in\mathscr{B}}{\operatorname{argmin}}\sum%
_{i=1}^{m}-\log\left(p\left(y_{i}\mid\widehat{v}_{adv}\right)\right),</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.2d">italic_v start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT := start_UNDERACCENT over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT ∈ script_B end_UNDERACCENT start_ARG roman_argmin end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT - roman_log ( italic_p ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∣ over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS1.p2.5">where the goal is to force the model to misclassify or generate undesired outputs.
Using the same approach to generate adversarial images, Schlarmann <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.5.1">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib24" title="">24</a>]</cite> further investigate the success rates of both targeted and untargeted attacks against the OpenFlamingo model&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib110" title="">110</a>]</cite>.
To expand the applicability of adversarial attacks, Bailey <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.5.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib27" title="">27</a>]</cite> propose a general-purpose Behaviour Matching algorithm for generating adversarial images with enhanced context transferability. This algorithm enables adversarial examples to maintain their effectiveness across diverse scenarios and tasks. Additionally, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib27" title="">27</a>]</cite> introduces Prompt Matching method, which is designed to train hijacking models capable of mimicking the behavior elicited by an arbitrary text prompt.
Luo <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.5.3">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib95" title="">95</a>]</cite> introduce the concept of cross-prompt adversarial transferability. The proposed CroPA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib95" title="">95</a>]</cite> method refines visual adversarial perturbations using learnable prompts, specifically designed to counteract the misleading effects of adversarial images. CroPA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib95" title="">95</a>]</cite> enables a single adversarial example to mislead all predictions of a LVLM across different prompts.
From an unusual perspective, Gao <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.5.4">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib92" title="">92</a>]</cite> explore a novel approach to induce high energy-latency&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib111" title="">111</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib112" title="">112</a>]</cite> in order to induce safety issues in LVLMs by causing them to generate endless outputs. Specifically, they introduced the concept of delayed End-of-Sequence (EOS) loss, leveraging it to create verbose images with perturbations that disrupt the model’s ability to terminate its responses appropriately. This specific loss function not only inhibits the model from halting its responses but also increases token diversity during generation. This results in the model producing lengthy and often irrelevant outputs, which can degrade user experience or lead to the propagation of unintended or incoherent information.
Besides, Wang <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.5.5">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib94" title="">94</a>]</cite> investigate the impact of Chain-of-Thought (CoT) reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib113" title="">113</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib114" title="">114</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib115" title="">115</a>]</cite> on the robustness of LVLMs. To address this, they introduced the Stop Reasoning attack method, which generates adversarial images to guide the model’s output according to a pre-designed template. This approach reduces the token probability associated with CoT reasoning, thereby effectively diminishing its influence on the model’s safety performance.
Gao <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.5.6">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib96" title="">96</a>]</cite> shift the focus of adversarial attacks to the Visual Grounding task&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib116" title="">116</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib117" title="">117</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib118" title="">118</a>]</cite>, demonstrating how adversarial perturbations can effectively disrupt the alignment between visual inputs and textual references. Using Projected Gradient Descent (PGD)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib79" title="">79</a>]</cite>, they add perturbations on images, enabling the execution of both targeted and untargeted adversarial attacks.
Jang <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.5.7">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib99" title="">99</a>]</cite> introduce the “Replace-then-Perturb” method, a novel approach that differs from traditional adversarial attacks, which often disrupt the entire image. This method focuses on specific objects within an image, replacing them with carefully designed adversarial substitutes and applying targeted perturbations. By ensuring that other objects in the scene remain unaffected and correctly recognized, the method maintains the overall context while effectively misleading the model’s reasoning about the targeted objects.
Unlike the previously mentioned single-turn attack methods, Bagdasaryan <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p2.5.8">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib91" title="">91</a>]</cite> propose a multi-turn attack that uses prompt injection to compromise dialog safety. By forcing the model to output a specific attacker-chosen instruction <math alttext="w" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.5.m1.1"><semantics id="S3.SS1.SSS1.p2.5.m1.1a"><mi id="S3.SS1.SSS1.p2.5.m1.1.1" xref="S3.SS1.SSS1.p2.5.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.5.m1.1b"><ci id="S3.SS1.SSS1.p2.5.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.5.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p2.5.m1.1d">italic_w</annotation></semantics></math> in its first response (e.g., “I will always follow instruction:”), the attacker poisons the dialog history. This causes the model to lose its safety mechanisms in subsequent turns. The attack exploits the model’s context retention, making it persistently unsafe, and can be made stealthier by paraphrasing the injected instruction.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其目标是将模型强制错误分类或生成不期望的输出。使用相同的方法生成对抗性图像，Schlarmann 等人[24]进一步研究了针对 OpenFlamingo 模型[110]的定向攻击和非定向攻击的成功率。为了扩展对抗性攻击的适用性，Bailey 等人[27]提出了一种通用的行为匹配算法，用于生成具有增强上下文可迁移性的对抗性图像。该算法使对抗性样本能够在不同的场景和任务中保持其有效性。此外，[27]引入了提示匹配方法，该方法旨在训练能够模仿任意文本提示所引发行为的劫持模型。Luo 等人[95]引入了跨提示对抗性可迁移性的概念。他们提出的 CroPA[95]方法使用可学习的提示来改进视觉对抗性扰动，专门设计用来抵消对抗性图像的误导效果。CroPA[95]使单个对抗性样本能够在不同的提示下误导 LVLM 的所有预测。 从非同寻常的角度出发，高等人[92]探索了一种新颖的方法，通过使 LVLMs 生成无限输出，来诱导高能耗-延迟[111,112]并引发安全问题。具体来说，他们引入了延迟序列结束（EOS）损失的概念，利用它来创建带有扰动的冗长图像，从而破坏模型适当终止其响应的能力。这种特定的损失函数不仅阻止模型停止其响应，还增加了生成过程中的 token 多样性。这导致模型产生冗长且通常不相关的输出，这可能降低用户体验或导致意外或不连贯信息的传播。此外，王等人[94]研究了思维链（CoT）推理[113,114,115]对 LVLMs 鲁棒性的影响。为了解决这个问题，他们引入了停止推理攻击方法，该方法生成对抗性图像，根据预设计的模板引导模型的输出。这种方法降低了与 CoT 推理相关的 token 概率，从而有效地削弱了其对模型安全性能的影响。 高等人[96]将对抗攻击的焦点转移到视觉定位任务[116,117,118]上，展示了对抗扰动如何有效破坏视觉输入与文本参考之间的对齐。他们使用投影梯度下降（PGD）[79]，在图像上添加扰动，从而能够执行有目标和无目标的对抗攻击。蒋等人[99]引入了“替换后扰动”方法，这是一种与传统对抗攻击（通常破坏整个图像）不同的新方法。该方法专注于图像中的特定对象，用精心设计的对抗替代物替换它们，并施加有目标的扰动。通过确保场景中的其他对象保持未受影响且被正确识别，该方法在保持整体上下文的同时有效误导模型对目标对象的推理。与之前提到的单轮攻击方法不同，巴加达萨扬等人[91]提出了一种多轮攻击，该攻击使用提示注入来破坏对话安全。 通过迫使模型在其首次回应中输出攻击者选择的特定指令 <math id="S3.SS1.SSS1.p2.5.m1.1" display="inline" class="ltx_Math" alttext="w"><semantics id="S3.SS1.SSS1.p2.5.m1.1a"><mi id="S3.SS1.SSS1.p2.5.m1.1.1">w</mi><annotation-xml id="S3.SS1.SSS1.p2.5.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS1.p2.5.m1.1c" encoding="application/x-tex">w</annotation><annotation id="S3.SS1.SSS1.p2.5.m1.1d" encoding="application/x-llamapun">italic_w</annotation></semantics></math> （例如，“我将始终遵循指令：”），攻击者污染了对话历史。这导致模型在后续回合中失去了安全机制。 该攻击利用了模型保持上下文的能力，使其持续不安全，并且可以通过改写注入的指令来使其更加隐蔽。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p3">
<p class="ltx_p" id="S3.SS1.SSS1.p3.4"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.1.m1.1"><semantics id="S3.SS1.SSS1.p3.1.m1.1a"><mo id="S3.SS1.SSS1.p3.1.m1.1.1" xref="S3.SS1.SSS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.1.m1.1b"><ci id="S3.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS1.p3.4.1">Cross-Modality.</span>
While single-modality attacks target visual components of LVLMs, cross-modality attacks exploit the interaction between modalities to achieve more robust and transferable adversarial effects. These methods aim to misalign the model’s multimodal understanding by jointly perturbing both visual and textual inputs, leveraging the complex dependencies between modalities to amplify the attack’s impact.
Wang <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p3.4.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a>]</cite> propose the Universal Master Key (UMK) method, comprises an adversarial image prefix and an adversarial text suffix. Firstly, UMK&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a>]</cite> establish a corpus containing several few-shot examples of harmful sentences <math alttext="Y:=\{y_{i}\}_{i=1}^{m}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.2.m2.1"><semantics id="S3.SS1.SSS1.p3.2.m2.1a"><mrow id="S3.SS1.SSS1.p3.2.m2.1.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p3.2.m2.1.1.3" xref="S3.SS1.SSS1.p3.2.m2.1.1.3.cmml">Y</mi><mo id="S3.SS1.SSS1.p3.2.m2.1.1.2" lspace="0.278em" rspace="0.278em" xref="S3.SS1.SSS1.p3.2.m2.1.1.2.cmml">:=</mo><msubsup id="S3.SS1.SSS1.p3.2.m2.1.1.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.cmml"><mrow id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.2.cmml"><mo id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.2.cmml">{</mo><msub id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.2" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.2.cmml">y</mi><mi id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.3" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.cmml"><mi id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.2" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.1" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.3" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.SSS1.p3.2.m2.1.1.1.3" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.3.cmml">m</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.2.m2.1b"><apply id="S3.SS1.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1"><csymbol cd="latexml" id="S3.SS1.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.2">assign</csymbol><ci id="S3.SS1.SSS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.3">𝑌</ci><apply id="S3.SS1.SSS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.2.m2.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1">superscript</csymbol><apply id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1">subscript</csymbol><set id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1"><apply id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3"><eq id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.1.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.1"></eq><ci id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.2.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.2">𝑖</ci><cn id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.3.cmml" type="integer" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.SSS1.p3.2.m2.1.1.1.3.cmml" xref="S3.SS1.SSS1.p3.2.m2.1.1.1.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.2.m2.1c">Y:=\{y_{i}\}_{i=1}^{m}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.2.m2.1d">italic_Y := { italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT</annotation></semantics></math>. The methodology for embedding toxic semantics into the adversarial image prefix <math alttext="\widehat{v}_{\text{adv}}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.3.m3.1"><semantics id="S3.SS1.SSS1.p3.3.m3.1a"><msub id="S3.SS1.SSS1.p3.3.m3.1.1" xref="S3.SS1.SSS1.p3.3.m3.1.1.cmml"><mover accent="true" id="S3.SS1.SSS1.p3.3.m3.1.1.2" xref="S3.SS1.SSS1.p3.3.m3.1.1.2.cmml"><mi id="S3.SS1.SSS1.p3.3.m3.1.1.2.2" xref="S3.SS1.SSS1.p3.3.m3.1.1.2.2.cmml">v</mi><mo id="S3.SS1.SSS1.p3.3.m3.1.1.2.1" xref="S3.SS1.SSS1.p3.3.m3.1.1.2.1.cmml">^</mo></mover><mtext id="S3.SS1.SSS1.p3.3.m3.1.1.3" xref="S3.SS1.SSS1.p3.3.m3.1.1.3a.cmml">adv</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.3.m3.1b"><apply id="S3.SS1.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1.2"><ci id="S3.SS1.SSS1.p3.3.m3.1.1.2.1.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1.2.1">^</ci><ci id="S3.SS1.SSS1.p3.3.m3.1.1.2.2.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1.2.2">𝑣</ci></apply><ci id="S3.SS1.SSS1.p3.3.m3.1.1.3a.cmml" xref="S3.SS1.SSS1.p3.3.m3.1.1.3"><mtext id="S3.SS1.SSS1.p3.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p3.3.m3.1.1.3">adv</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.3.m3.1c">\widehat{v}_{\text{adv}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.3.m3.1d">over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT</annotation></semantics></math> is straightforward: UMK&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a>]</cite> initialize <math alttext="\widehat{v}_{\text{adv}}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.4.m4.1"><semantics id="S3.SS1.SSS1.p3.4.m4.1a"><msub id="S3.SS1.SSS1.p3.4.m4.1.1" xref="S3.SS1.SSS1.p3.4.m4.1.1.cmml"><mover accent="true" id="S3.SS1.SSS1.p3.4.m4.1.1.2" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.cmml"><mi id="S3.SS1.SSS1.p3.4.m4.1.1.2.2" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.2.cmml">v</mi><mo id="S3.SS1.SSS1.p3.4.m4.1.1.2.1" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.1.cmml">^</mo></mover><mtext id="S3.SS1.SSS1.p3.4.m4.1.1.3" xref="S3.SS1.SSS1.p3.4.m4.1.1.3a.cmml">adv</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.4.m4.1b"><apply id="S3.SS1.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1.2"><ci id="S3.SS1.SSS1.p3.4.m4.1.1.2.1.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.1">^</ci><ci id="S3.SS1.SSS1.p3.4.m4.1.1.2.2.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1.2.2">𝑣</ci></apply><ci id="S3.SS1.SSS1.p3.4.m4.1.1.3a.cmml" xref="S3.SS1.SSS1.p3.4.m4.1.1.3"><mtext id="S3.SS1.SSS1.p3.4.m4.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p3.4.m4.1.1.3">adv</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.4.m4.1c">\widehat{v}_{\text{adv}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.4.m4.1d">over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT</annotation></semantics></math> with random noise and optimize it to maximize the generation probability of this few-shot corpus in the absence of text input. The optimization objective is formulated as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS1.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S3.SS1.SSS1.p3.1.m1.1a"><mo id="S3.SS1.SSS1.p3.1.m1.1.1">∙</mo><annotation-xml id="S3.SS1.SSS1.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS1.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S3.SS1.SSS1.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 跨模态。虽然单模态攻击针对 LVLMs 的视觉组件，但跨模态攻击利用模态间的交互来实现更鲁棒和可迁移的对抗效果。这些方法旨在通过联合扰动视觉和文本输入来错位模型的跨模态理解，利用模态间的复杂依赖关系来放大攻击的影响。Wang 等人[ 26]提出了通用主密钥（UMK）方法，包含一个对抗图像前缀和一个对抗文本后缀。首先，UMK[ 26]建立了一个包含几个有害句子少样本示例的语料库 <math id="S3.SS1.SSS1.p3.2.m2.1" display="inline" class="ltx_Math"><semantics id="S3.SS1.SSS1.p3.2.m2.1a"><mrow id="S3.SS1.SSS1.p3.2.m2.1.1"><mi id="S3.SS1.SSS1.p3.2.m2.1.1.3">Y</mi><mo rspace="0.278em" lspace="0.278em" id="S3.SS1.SSS1.p3.2.m2.1.1.2">:=</mo><msubsup id="S3.SS1.SSS1.p3.2.m2.1.1.1"><mrow id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1"><mo stretchy="false" id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.2">{</mo><msub id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1"><mi id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.2">y</mi><mi id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.1.3">i</mi></msub><mo stretchy="false" id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.1.1.3">}</mo></mrow><mrow id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3"><mi id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.2">i</mi><mo id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.1">=</mo><mn id="S3.SS1.SSS1.p3.2.m2.1.1.1.1.3.3">1</mn></mrow><mi id="S3.SS1.SSS1.p3.2.m2.1.1.1.3">m</mi></msubsup></mrow><annotation-xml id="S3.SS1.SSS1.p3.2.m2.1b" encoding="MathML-Content">assignsuperscriptsubscriptsubscript1</annotation-xml><annotation id="S3.SS1.SSS1.p3.2.m2.1c" encoding="application/x-tex">Y:=\{y_{i}\}_{i=1}^{m}</annotation><annotation id="S3.SS1.SSS1.p3.2.m2.1d" encoding="application/x-llamapun">italic_Y := { italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT</annotation></semantics></math> 。将有害语义嵌入对抗图像前缀 <math id="S3.SS1.SSS1.p3.3.m3.1" display="inline" class="ltx_Math" alttext="\widehat{v}_{\text{adv}}"><semantics id="S3.SS1.SSS1.p3.3.m3.1a"><msub id="S3.SS1.SSS1.p3.3.m3.1.1"><mover id="S3.SS1.SSS1.p3.3.m3.1.1.2" accent="true"><mi id="S3.SS1.SSS1.p3.3.m3.1.1.2.2">v</mi><mo id="S3.SS1.SSS1.p3.3.m3.1.1.2.1">^</mo></mover><mtext id="S3.SS1.SSS1.p3.3.m3.1.1.3">adv</mtext></msub><annotation-xml id="S3.SS1.SSS1.p3.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS1.SSS1.p3.3.m3.1c" encoding="application/x-tex">\widehat{v}_{\text{adv}}</annotation><annotation id="S3.SS1.SSS1.p3.3.m3.1d" encoding="application/x-llamapun">over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT</annotation></semantics></math> 的方法很简单：UMK[ 26]用随机噪声初始化 <math id="S3.SS1.SSS1.p3.4.m4.1" display="inline" class="ltx_Math" alttext="\widehat{v}_{\text{adv}}"><semantics id="S3.SS1.SSS1.p3.4.m4.1a"><msub id="S3.SS1.SSS1.p3.4.m4.1.1"><mover id="S3.SS1.SSS1.p3.4.m4.1.1.2" accent="true"><mi id="S3.SS1.SSS1.p3.4.m4.1.1.2.2">v</mi><mo id="S3.SS1.SSS1.p3.4.m4.1.1.2.1">^</mo></mover><mtext id="S3.SS1.SSS1.p3.4.m4.1.1.3">adv</mtext></msub><annotation-xml id="S3.SS1.SSS1.p3.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS1.SSS1.p3.4.m4.1c" encoding="application/x-tex">\widehat{v}_{\text{adv}}</annotation><annotation id="S3.SS1.SSS1.p3.4.m4.1d" encoding="application/x-llamapun">over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT</annotation></semantics></math> ，并优化它以在无文本输入的情况下最大化该少样本语料库的生成概率。优化目标如下：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="v_{\text{adv}}:=\underset{\widehat{v}_{\text{adv}}}{\operatorname{argmin}}\sum%
_{i=1}^{m}-\log\left(p(y_{i}\mid\widehat{x}_{\text{adv}},\varnothing)\right)," class="ltx_Math" display="block" id="S3.E8.m1.3"><semantics id="S3.E8.m1.3a"><mrow id="S3.E8.m1.3.3.1" xref="S3.E8.m1.3.3.1.1.cmml"><mrow id="S3.E8.m1.3.3.1.1" xref="S3.E8.m1.3.3.1.1.cmml"><msub id="S3.E8.m1.3.3.1.1.3" xref="S3.E8.m1.3.3.1.1.3.cmml"><mi id="S3.E8.m1.3.3.1.1.3.2" xref="S3.E8.m1.3.3.1.1.3.2.cmml">v</mi><mtext id="S3.E8.m1.3.3.1.1.3.3" xref="S3.E8.m1.3.3.1.1.3.3a.cmml">adv</mtext></msub><mo id="S3.E8.m1.3.3.1.1.2" lspace="0.278em" rspace="0.278em" xref="S3.E8.m1.3.3.1.1.2.cmml">:=</mo><mrow id="S3.E8.m1.3.3.1.1.1" xref="S3.E8.m1.3.3.1.1.1.cmml"><mrow id="S3.E8.m1.3.3.1.1.1.3" xref="S3.E8.m1.3.3.1.1.1.3.cmml"><munder accentunder="true" id="S3.E8.m1.3.3.1.1.1.3.2" xref="S3.E8.m1.3.3.1.1.1.3.2.cmml"><mi id="S3.E8.m1.3.3.1.1.1.3.2.2" xref="S3.E8.m1.3.3.1.1.1.3.2.2.cmml">argmin</mi><msub id="S3.E8.m1.3.3.1.1.1.3.2.1" xref="S3.E8.m1.3.3.1.1.1.3.2.1.cmml"><mover accent="true" id="S3.E8.m1.3.3.1.1.1.3.2.1.2" xref="S3.E8.m1.3.3.1.1.1.3.2.1.2.cmml"><mi id="S3.E8.m1.3.3.1.1.1.3.2.1.2.2" xref="S3.E8.m1.3.3.1.1.1.3.2.1.2.2.cmml">v</mi><mo id="S3.E8.m1.3.3.1.1.1.3.2.1.2.1" xref="S3.E8.m1.3.3.1.1.1.3.2.1.2.1.cmml">^</mo></mover><mtext id="S3.E8.m1.3.3.1.1.1.3.2.1.3" xref="S3.E8.m1.3.3.1.1.1.3.2.1.3a.cmml">adv</mtext></msub></munder><mo id="S3.E8.m1.3.3.1.1.1.3.1" xref="S3.E8.m1.3.3.1.1.1.3.1.cmml">⁢</mo><munderover id="S3.E8.m1.3.3.1.1.1.3.3" xref="S3.E8.m1.3.3.1.1.1.3.3.cmml"><mo id="S3.E8.m1.3.3.1.1.1.3.3.2.2" movablelimits="false" rspace="0em" xref="S3.E8.m1.3.3.1.1.1.3.3.2.2.cmml">∑</mo><mrow id="S3.E8.m1.3.3.1.1.1.3.3.2.3" xref="S3.E8.m1.3.3.1.1.1.3.3.2.3.cmml"><mi id="S3.E8.m1.3.3.1.1.1.3.3.2.3.2" xref="S3.E8.m1.3.3.1.1.1.3.3.2.3.2.cmml">i</mi><mo id="S3.E8.m1.3.3.1.1.1.3.3.2.3.1" xref="S3.E8.m1.3.3.1.1.1.3.3.2.3.1.cmml">=</mo><mn id="S3.E8.m1.3.3.1.1.1.3.3.2.3.3" xref="S3.E8.m1.3.3.1.1.1.3.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E8.m1.3.3.1.1.1.3.3.3" xref="S3.E8.m1.3.3.1.1.1.3.3.3.cmml">m</mi></munderover></mrow><mo id="S3.E8.m1.3.3.1.1.1.2" lspace="0em" xref="S3.E8.m1.3.3.1.1.1.2.cmml">−</mo><mrow id="S3.E8.m1.3.3.1.1.1.1.1" xref="S3.E8.m1.3.3.1.1.1.1.2.cmml"><mi id="S3.E8.m1.2.2" xref="S3.E8.m1.2.2.cmml">log</mi><mo id="S3.E8.m1.3.3.1.1.1.1.1a" xref="S3.E8.m1.3.3.1.1.1.1.2.cmml">⁡</mo><mrow id="S3.E8.m1.3.3.1.1.1.1.1.1" xref="S3.E8.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E8.m1.3.3.1.1.1.1.1.1.2" xref="S3.E8.m1.3.3.1.1.1.1.2.cmml">(</mo><mrow id="S3.E8.m1.3.3.1.1.1.1.1.1.1" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.3.cmml">p</mi><mo id="S3.E8.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml">y</mi><mi id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">∣</mo><mrow id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><msub id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mo id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mtext id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3a.cmml">adv</mtext></msub><mo id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E8.m1.1.1" mathvariant="normal" xref="S3.E8.m1.1.1.cmml">∅</mi></mrow></mrow><mo id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.3.3.1.1.1.1.1.1.3" xref="S3.E8.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E8.m1.3.3.1.2" xref="S3.E8.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.3b"><apply id="S3.E8.m1.3.3.1.1.cmml" xref="S3.E8.m1.3.3.1"><csymbol cd="latexml" id="S3.E8.m1.3.3.1.1.2.cmml" xref="S3.E8.m1.3.3.1.1.2">assign</csymbol><apply id="S3.E8.m1.3.3.1.1.3.cmml" xref="S3.E8.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.1.1.3.1.cmml" xref="S3.E8.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E8.m1.3.3.1.1.3.2.cmml" xref="S3.E8.m1.3.3.1.1.3.2">𝑣</ci><ci id="S3.E8.m1.3.3.1.1.3.3a.cmml" xref="S3.E8.m1.3.3.1.1.3.3"><mtext id="S3.E8.m1.3.3.1.1.3.3.cmml" mathsize="70%" xref="S3.E8.m1.3.3.1.1.3.3">adv</mtext></ci></apply><apply id="S3.E8.m1.3.3.1.1.1.cmml" xref="S3.E8.m1.3.3.1.1.1"><minus id="S3.E8.m1.3.3.1.1.1.2.cmml" xref="S3.E8.m1.3.3.1.1.1.2"></minus><apply id="S3.E8.m1.3.3.1.1.1.3.cmml" xref="S3.E8.m1.3.3.1.1.1.3"><times id="S3.E8.m1.3.3.1.1.1.3.1.cmml" xref="S3.E8.m1.3.3.1.1.1.3.1"></times><apply id="S3.E8.m1.3.3.1.1.1.3.2.cmml" xref="S3.E8.m1.3.3.1.1.1.3.2"><apply id="S3.E8.m1.3.3.1.1.1.3.2.1.cmml" xref="S3.E8.m1.3.3.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.1.1.1.3.2.1.1.cmml" xref="S3.E8.m1.3.3.1.1.1.3.2.1">subscript</csymbol><apply id="S3.E8.m1.3.3.1.1.1.3.2.1.2.cmml" xref="S3.E8.m1.3.3.1.1.1.3.2.1.2"><ci id="S3.E8.m1.3.3.1.1.1.3.2.1.2.1.cmml" xref="S3.E8.m1.3.3.1.1.1.3.2.1.2.1">^</ci><ci id="S3.E8.m1.3.3.1.1.1.3.2.1.2.2.cmml" xref="S3.E8.m1.3.3.1.1.1.3.2.1.2.2">𝑣</ci></apply><ci id="S3.E8.m1.3.3.1.1.1.3.2.1.3a.cmml" xref="S3.E8.m1.3.3.1.1.1.3.2.1.3"><mtext id="S3.E8.m1.3.3.1.1.1.3.2.1.3.cmml" mathsize="70%" xref="S3.E8.m1.3.3.1.1.1.3.2.1.3">adv</mtext></ci></apply><ci id="S3.E8.m1.3.3.1.1.1.3.2.2.cmml" xref="S3.E8.m1.3.3.1.1.1.3.2.2">argmin</ci></apply><apply id="S3.E8.m1.3.3.1.1.1.3.3.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.1.1.1.3.3.1.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3">superscript</csymbol><apply id="S3.E8.m1.3.3.1.1.1.3.3.2.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.1.1.1.3.3.2.1.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3">subscript</csymbol><sum id="S3.E8.m1.3.3.1.1.1.3.3.2.2.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3.2.2"></sum><apply id="S3.E8.m1.3.3.1.1.1.3.3.2.3.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3.2.3"><eq id="S3.E8.m1.3.3.1.1.1.3.3.2.3.1.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3.2.3.1"></eq><ci id="S3.E8.m1.3.3.1.1.1.3.3.2.3.2.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3.2.3.2">𝑖</ci><cn id="S3.E8.m1.3.3.1.1.1.3.3.2.3.3.cmml" type="integer" xref="S3.E8.m1.3.3.1.1.1.3.3.2.3.3">1</cn></apply></apply><ci id="S3.E8.m1.3.3.1.1.1.3.3.3.cmml" xref="S3.E8.m1.3.3.1.1.1.3.3.3">𝑚</ci></apply></apply><apply id="S3.E8.m1.3.3.1.1.1.1.2.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1"><log id="S3.E8.m1.2.2.cmml" xref="S3.E8.m1.2.2"></log><apply id="S3.E8.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1"><times id="S3.E8.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.2"></times><ci id="S3.E8.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.3">𝑝</ci><apply id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2">𝑦</ci><ci id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply><list id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><ci id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑥</ci></apply><ci id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><mtext id="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3">adv</mtext></ci></apply><emptyset id="S3.E8.m1.1.1.cmml" xref="S3.E8.m1.1.1"></emptyset></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.3c">v_{\text{adv}}:=\underset{\widehat{v}_{\text{adv}}}{\operatorname{argmin}}\sum%
_{i=1}^{m}-\log\left(p(y_{i}\mid\widehat{x}_{\text{adv}},\varnothing)\right),</annotation><annotation encoding="application/x-llamapun" id="S3.E8.m1.3d">italic_v start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT := start_UNDERACCENT over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT end_UNDERACCENT start_ARG roman_argmin end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT - roman_log ( italic_p ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∣ over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT , ∅ ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS1.p3.7">where <math alttext="\varnothing" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.5.m1.1"><semantics id="S3.SS1.SSS1.p3.5.m1.1a"><mi id="S3.SS1.SSS1.p3.5.m1.1.1" mathvariant="normal" xref="S3.SS1.SSS1.p3.5.m1.1.1.cmml">∅</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.5.m1.1b"><emptyset id="S3.SS1.SSS1.p3.5.m1.1.1.cmml" xref="S3.SS1.SSS1.p3.5.m1.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.5.m1.1c">\varnothing</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.5.m1.1d">∅</annotation></semantics></math> denotes an empty text input. This optimization problem can be efficiently solved using prevalent techniques in image adversarial attacks, such as PGD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib79" title="">79</a>]</cite>. To maximize the probability of generating affirmative responses, UMK&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a>]</cite> further introduce an adversarial text suffix <math alttext="\widehat{t}_{\text{adv}}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.6.m2.1"><semantics id="S3.SS1.SSS1.p3.6.m2.1a"><msub id="S3.SS1.SSS1.p3.6.m2.1.1" xref="S3.SS1.SSS1.p3.6.m2.1.1.cmml"><mover accent="true" id="S3.SS1.SSS1.p3.6.m2.1.1.2" xref="S3.SS1.SSS1.p3.6.m2.1.1.2.cmml"><mi id="S3.SS1.SSS1.p3.6.m2.1.1.2.2" xref="S3.SS1.SSS1.p3.6.m2.1.1.2.2.cmml">t</mi><mo id="S3.SS1.SSS1.p3.6.m2.1.1.2.1" xref="S3.SS1.SSS1.p3.6.m2.1.1.2.1.cmml">^</mo></mover><mtext id="S3.SS1.SSS1.p3.6.m2.1.1.3" xref="S3.SS1.SSS1.p3.6.m2.1.1.3a.cmml">adv</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.6.m2.1b"><apply id="S3.SS1.SSS1.p3.6.m2.1.1.cmml" xref="S3.SS1.SSS1.p3.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.6.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p3.6.m2.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p3.6.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p3.6.m2.1.1.2"><ci id="S3.SS1.SSS1.p3.6.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p3.6.m2.1.1.2.1">^</ci><ci id="S3.SS1.SSS1.p3.6.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p3.6.m2.1.1.2.2">𝑡</ci></apply><ci id="S3.SS1.SSS1.p3.6.m2.1.1.3a.cmml" xref="S3.SS1.SSS1.p3.6.m2.1.1.3"><mtext id="S3.SS1.SSS1.p3.6.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p3.6.m2.1.1.3">adv</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.6.m2.1c">\widehat{t}_{\text{adv}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.6.m2.1d">over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT</annotation></semantics></math> in conjunction with the adversarial image prefix <math alttext="\widehat{v}_{\text{adv}}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p3.7.m3.1"><semantics id="S3.SS1.SSS1.p3.7.m3.1a"><msub id="S3.SS1.SSS1.p3.7.m3.1.1" xref="S3.SS1.SSS1.p3.7.m3.1.1.cmml"><mover accent="true" id="S3.SS1.SSS1.p3.7.m3.1.1.2" xref="S3.SS1.SSS1.p3.7.m3.1.1.2.cmml"><mi id="S3.SS1.SSS1.p3.7.m3.1.1.2.2" xref="S3.SS1.SSS1.p3.7.m3.1.1.2.2.cmml">v</mi><mo id="S3.SS1.SSS1.p3.7.m3.1.1.2.1" xref="S3.SS1.SSS1.p3.7.m3.1.1.2.1.cmml">^</mo></mover><mtext id="S3.SS1.SSS1.p3.7.m3.1.1.3" xref="S3.SS1.SSS1.p3.7.m3.1.1.3a.cmml">adv</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.7.m3.1b"><apply id="S3.SS1.SSS1.p3.7.m3.1.1.cmml" xref="S3.SS1.SSS1.p3.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.7.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p3.7.m3.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p3.7.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p3.7.m3.1.1.2"><ci id="S3.SS1.SSS1.p3.7.m3.1.1.2.1.cmml" xref="S3.SS1.SSS1.p3.7.m3.1.1.2.1">^</ci><ci id="S3.SS1.SSS1.p3.7.m3.1.1.2.2.cmml" xref="S3.SS1.SSS1.p3.7.m3.1.1.2.2">𝑣</ci></apply><ci id="S3.SS1.SSS1.p3.7.m3.1.1.3a.cmml" xref="S3.SS1.SSS1.p3.7.m3.1.1.3"><mtext id="S3.SS1.SSS1.p3.7.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS1.p3.7.m3.1.1.3">adv</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.7.m3.1c">\widehat{v}_{\text{adv}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p3.7.m3.1d">over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT</annotation></semantics></math>, which is embedded with toxic semantics. This multimodal attack strategy aims to thoroughly exploit the inherent vulnerabilities of LVLMs. The optimization objective is as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S3.SS1.SSS1.p3.5.m1.1" display="inline" class="ltx_Math" alttext="\varnothing"><semantics id="S3.SS1.SSS1.p3.5.m1.1a"><mi mathvariant="normal" id="S3.SS1.SSS1.p3.5.m1.1.1">∅</mi><annotation-xml id="S3.SS1.SSS1.p3.5.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS1.p3.5.m1.1c" encoding="application/x-tex">\varnothing</annotation><annotation id="S3.SS1.SSS1.p3.5.m1.1d" encoding="application/x-llamapun">∅</annotation></semantics></math> 表示空文本输入。这个优化问题可以使用图像对抗攻击中的常用技术（如 PGD [ 79]）高效解决。为了最大化生成肯定回答的概率，UMK [ 26] 进一步引入了带有毒性语义的对抗文本后缀 <math id="S3.SS1.SSS1.p3.6.m2.1" display="inline" class="ltx_Math" alttext="\widehat{t}_{\text{adv}}"><semantics id="S3.SS1.SSS1.p3.6.m2.1a"><msub id="S3.SS1.SSS1.p3.6.m2.1.1"><mover id="S3.SS1.SSS1.p3.6.m2.1.1.2" accent="true"><mi id="S3.SS1.SSS1.p3.6.m2.1.1.2.2">t</mi><mo id="S3.SS1.SSS1.p3.6.m2.1.1.2.1">^</mo></mover><mtext id="S3.SS1.SSS1.p3.6.m2.1.1.3">adv</mtext></msub><annotation-xml id="S3.SS1.SSS1.p3.6.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS1.SSS1.p3.6.m2.1c" encoding="application/x-tex">\widehat{t}_{\text{adv}}</annotation><annotation id="S3.SS1.SSS1.p3.6.m2.1d" encoding="application/x-llamapun">over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT</annotation></semantics></math> ，并与对抗图像前缀 <math id="S3.SS1.SSS1.p3.7.m3.1" display="inline" class="ltx_Math" alttext="\widehat{v}_{\text{adv}}"><semantics id="S3.SS1.SSS1.p3.7.m3.1a"><msub id="S3.SS1.SSS1.p3.7.m3.1.1"><mover id="S3.SS1.SSS1.p3.7.m3.1.1.2" accent="true"><mi id="S3.SS1.SSS1.p3.7.m3.1.1.2.2">v</mi><mo id="S3.SS1.SSS1.p3.7.m3.1.1.2.1">^</mo></mover><mtext id="S3.SS1.SSS1.p3.7.m3.1.1.3">adv</mtext></msub><annotation-xml id="S3.SS1.SSS1.p3.7.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS1.SSS1.p3.7.m3.1c" encoding="application/x-tex">\widehat{v}_{\text{adv}}</annotation><annotation id="S3.SS1.SSS1.p3.7.m3.1d" encoding="application/x-llamapun">over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT</annotation></semantics></math> 结合使用。这种多模态攻击策略旨在彻底利用大型视觉语言模型（LVLMs）的固有漏洞。优化目标如下：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E9">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="v_{\text{adv}},t_{\text{adv}}:=\underset{\widehat{v}_{\text{adv}},\widehat{t}_%
{\text{adv}}}{\operatorname{argmin}}\sum_{i=1}^{n}-\log\left(p(y_{i}\mid%
\widehat{v}_{\text{adv}},\widehat{t}_{\text{adv}})\right)." class="ltx_Math" display="block" id="S3.E9.m1.4"><semantics id="S3.E9.m1.4a"><mrow id="S3.E9.m1.4.4.1" xref="S3.E9.m1.4.4.1.1.cmml"><mrow id="S3.E9.m1.4.4.1.1" xref="S3.E9.m1.4.4.1.1.cmml"><mrow id="S3.E9.m1.4.4.1.1.2.2" xref="S3.E9.m1.4.4.1.1.2.3.cmml"><msub id="S3.E9.m1.4.4.1.1.1.1.1" xref="S3.E9.m1.4.4.1.1.1.1.1.cmml"><mi id="S3.E9.m1.4.4.1.1.1.1.1.2" xref="S3.E9.m1.4.4.1.1.1.1.1.2.cmml">v</mi><mtext id="S3.E9.m1.4.4.1.1.1.1.1.3" xref="S3.E9.m1.4.4.1.1.1.1.1.3a.cmml">adv</mtext></msub><mo id="S3.E9.m1.4.4.1.1.2.2.3" xref="S3.E9.m1.4.4.1.1.2.3.cmml">,</mo><msub id="S3.E9.m1.4.4.1.1.2.2.2" xref="S3.E9.m1.4.4.1.1.2.2.2.cmml"><mi id="S3.E9.m1.4.4.1.1.2.2.2.2" xref="S3.E9.m1.4.4.1.1.2.2.2.2.cmml">t</mi><mtext id="S3.E9.m1.4.4.1.1.2.2.2.3" xref="S3.E9.m1.4.4.1.1.2.2.2.3a.cmml">adv</mtext></msub></mrow><mo id="S3.E9.m1.4.4.1.1.4" lspace="0.278em" rspace="0.278em" xref="S3.E9.m1.4.4.1.1.4.cmml">:=</mo><mrow id="S3.E9.m1.4.4.1.1.3" xref="S3.E9.m1.4.4.1.1.3.cmml"><mrow id="S3.E9.m1.4.4.1.1.3.3" xref="S3.E9.m1.4.4.1.1.3.3.cmml"><munder accentunder="true" id="S3.E9.m1.2.2" xref="S3.E9.m1.2.2.cmml"><mi id="S3.E9.m1.2.2.3" xref="S3.E9.m1.2.2.3.cmml">argmin</mi><mrow id="S3.E9.m1.2.2.2.2" xref="S3.E9.m1.2.2.2.3.cmml"><msub id="S3.E9.m1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E9.m1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.2.cmml"><mi id="S3.E9.m1.1.1.1.1.1.2.2" xref="S3.E9.m1.1.1.1.1.1.2.2.cmml">v</mi><mo id="S3.E9.m1.1.1.1.1.1.2.1" xref="S3.E9.m1.1.1.1.1.1.2.1.cmml">^</mo></mover><mtext id="S3.E9.m1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.3a.cmml">adv</mtext></msub><mo id="S3.E9.m1.2.2.2.2.3" xref="S3.E9.m1.2.2.2.3.cmml">,</mo><msub id="S3.E9.m1.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.cmml"><mover accent="true" id="S3.E9.m1.2.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.2.cmml"><mi id="S3.E9.m1.2.2.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.2.2.cmml">t</mi><mo id="S3.E9.m1.2.2.2.2.2.2.1" xref="S3.E9.m1.2.2.2.2.2.2.1.cmml">^</mo></mover><mtext id="S3.E9.m1.2.2.2.2.2.3" xref="S3.E9.m1.2.2.2.2.2.3a.cmml">adv</mtext></msub></mrow></munder><mo id="S3.E9.m1.4.4.1.1.3.3.1" xref="S3.E9.m1.4.4.1.1.3.3.1.cmml">⁢</mo><munderover id="S3.E9.m1.4.4.1.1.3.3.2" xref="S3.E9.m1.4.4.1.1.3.3.2.cmml"><mo id="S3.E9.m1.4.4.1.1.3.3.2.2.2" movablelimits="false" rspace="0em" xref="S3.E9.m1.4.4.1.1.3.3.2.2.2.cmml">∑</mo><mrow id="S3.E9.m1.4.4.1.1.3.3.2.2.3" xref="S3.E9.m1.4.4.1.1.3.3.2.2.3.cmml"><mi id="S3.E9.m1.4.4.1.1.3.3.2.2.3.2" xref="S3.E9.m1.4.4.1.1.3.3.2.2.3.2.cmml">i</mi><mo id="S3.E9.m1.4.4.1.1.3.3.2.2.3.1" xref="S3.E9.m1.4.4.1.1.3.3.2.2.3.1.cmml">=</mo><mn id="S3.E9.m1.4.4.1.1.3.3.2.2.3.3" xref="S3.E9.m1.4.4.1.1.3.3.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E9.m1.4.4.1.1.3.3.2.3" xref="S3.E9.m1.4.4.1.1.3.3.2.3.cmml">n</mi></munderover></mrow><mo id="S3.E9.m1.4.4.1.1.3.2" lspace="0em" xref="S3.E9.m1.4.4.1.1.3.2.cmml">−</mo><mrow id="S3.E9.m1.4.4.1.1.3.1.1" xref="S3.E9.m1.4.4.1.1.3.1.2.cmml"><mi id="S3.E9.m1.3.3" xref="S3.E9.m1.3.3.cmml">log</mi><mo id="S3.E9.m1.4.4.1.1.3.1.1a" xref="S3.E9.m1.4.4.1.1.3.1.2.cmml">⁡</mo><mrow id="S3.E9.m1.4.4.1.1.3.1.1.1" xref="S3.E9.m1.4.4.1.1.3.1.2.cmml"><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.2" xref="S3.E9.m1.4.4.1.1.3.1.2.cmml">(</mo><mrow id="S3.E9.m1.4.4.1.1.3.1.1.1.1" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.cmml"><mi id="S3.E9.m1.4.4.1.1.3.1.1.1.1.3" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.3.cmml">p</mi><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.1.2" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.cmml"><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.2" stretchy="false" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.cmml"><msub id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.2" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.2.cmml">y</mi><mi id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.3" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.3.cmml">i</mi></msub><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.3" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.3.cmml">∣</mo><mrow id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.3.cmml"><msub id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.2.cmml">v</mi><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mtext id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.3a.cmml">adv</mtext></msub><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.3" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.cmml"><mover accent="true" id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.2.cmml">t</mi><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.1" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.1.cmml">^</mo></mover><mtext id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.3a.cmml">adv</mtext></msub></mrow></mrow><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.3" stretchy="false" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E9.m1.4.4.1.1.3.1.1.1.3" xref="S3.E9.m1.4.4.1.1.3.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E9.m1.4.4.1.2" lspace="0em" xref="S3.E9.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.4b"><apply id="S3.E9.m1.4.4.1.1.cmml" xref="S3.E9.m1.4.4.1"><csymbol cd="latexml" id="S3.E9.m1.4.4.1.1.4.cmml" xref="S3.E9.m1.4.4.1.1.4">assign</csymbol><list id="S3.E9.m1.4.4.1.1.2.3.cmml" xref="S3.E9.m1.4.4.1.1.2.2"><apply id="S3.E9.m1.4.4.1.1.1.1.1.cmml" xref="S3.E9.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E9.m1.4.4.1.1.1.1.1">subscript</csymbol><ci id="S3.E9.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E9.m1.4.4.1.1.1.1.1.2">𝑣</ci><ci id="S3.E9.m1.4.4.1.1.1.1.1.3a.cmml" xref="S3.E9.m1.4.4.1.1.1.1.1.3"><mtext id="S3.E9.m1.4.4.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E9.m1.4.4.1.1.1.1.1.3">adv</mtext></ci></apply><apply id="S3.E9.m1.4.4.1.1.2.2.2.cmml" xref="S3.E9.m1.4.4.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.1.1.2.2.2.1.cmml" xref="S3.E9.m1.4.4.1.1.2.2.2">subscript</csymbol><ci id="S3.E9.m1.4.4.1.1.2.2.2.2.cmml" xref="S3.E9.m1.4.4.1.1.2.2.2.2">𝑡</ci><ci id="S3.E9.m1.4.4.1.1.2.2.2.3a.cmml" xref="S3.E9.m1.4.4.1.1.2.2.2.3"><mtext id="S3.E9.m1.4.4.1.1.2.2.2.3.cmml" mathsize="70%" xref="S3.E9.m1.4.4.1.1.2.2.2.3">adv</mtext></ci></apply></list><apply id="S3.E9.m1.4.4.1.1.3.cmml" xref="S3.E9.m1.4.4.1.1.3"><minus id="S3.E9.m1.4.4.1.1.3.2.cmml" xref="S3.E9.m1.4.4.1.1.3.2"></minus><apply id="S3.E9.m1.4.4.1.1.3.3.cmml" xref="S3.E9.m1.4.4.1.1.3.3"><times id="S3.E9.m1.4.4.1.1.3.3.1.cmml" xref="S3.E9.m1.4.4.1.1.3.3.1"></times><apply id="S3.E9.m1.2.2.cmml" xref="S3.E9.m1.2.2"><list id="S3.E9.m1.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2"><apply id="S3.E9.m1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1">subscript</csymbol><apply id="S3.E9.m1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.2"><ci id="S3.E9.m1.1.1.1.1.1.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.2.1">^</ci><ci id="S3.E9.m1.1.1.1.1.1.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.2.2">𝑣</ci></apply><ci id="S3.E9.m1.1.1.1.1.1.3a.cmml" xref="S3.E9.m1.1.1.1.1.1.3"><mtext id="S3.E9.m1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E9.m1.1.1.1.1.1.3">adv</mtext></ci></apply><apply id="S3.E9.m1.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.2.2.2.1.cmml" xref="S3.E9.m1.2.2.2.2.2">subscript</csymbol><apply id="S3.E9.m1.2.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2.2"><ci id="S3.E9.m1.2.2.2.2.2.2.1.cmml" xref="S3.E9.m1.2.2.2.2.2.2.1">^</ci><ci id="S3.E9.m1.2.2.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2.2.2">𝑡</ci></apply><ci id="S3.E9.m1.2.2.2.2.2.3a.cmml" xref="S3.E9.m1.2.2.2.2.2.3"><mtext id="S3.E9.m1.2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.E9.m1.2.2.2.2.2.3">adv</mtext></ci></apply></list><ci id="S3.E9.m1.2.2.3.cmml" xref="S3.E9.m1.2.2.3">argmin</ci></apply><apply id="S3.E9.m1.4.4.1.1.3.3.2.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.1.1.3.3.2.1.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2">superscript</csymbol><apply id="S3.E9.m1.4.4.1.1.3.3.2.2.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.1.1.3.3.2.2.1.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2">subscript</csymbol><sum id="S3.E9.m1.4.4.1.1.3.3.2.2.2.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2.2.2"></sum><apply id="S3.E9.m1.4.4.1.1.3.3.2.2.3.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2.2.3"><eq id="S3.E9.m1.4.4.1.1.3.3.2.2.3.1.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2.2.3.1"></eq><ci id="S3.E9.m1.4.4.1.1.3.3.2.2.3.2.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2.2.3.2">𝑖</ci><cn id="S3.E9.m1.4.4.1.1.3.3.2.2.3.3.cmml" type="integer" xref="S3.E9.m1.4.4.1.1.3.3.2.2.3.3">1</cn></apply></apply><ci id="S3.E9.m1.4.4.1.1.3.3.2.3.cmml" xref="S3.E9.m1.4.4.1.1.3.3.2.3">𝑛</ci></apply></apply><apply id="S3.E9.m1.4.4.1.1.3.1.2.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1"><log id="S3.E9.m1.3.3.cmml" xref="S3.E9.m1.3.3"></log><apply id="S3.E9.m1.4.4.1.1.3.1.1.1.1.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1"><times id="S3.E9.m1.4.4.1.1.3.1.1.1.1.2.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.2"></times><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.3.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.3">𝑝</ci><apply id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.3">conditional</csymbol><apply id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.2">𝑦</ci><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.4.3">𝑖</ci></apply><list id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2"><apply id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2"><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.2.2">𝑣</ci></apply><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.3"><mtext id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.1.1.1.3">adv</mtext></ci></apply><apply id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><apply id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2"><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.1">^</ci><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.2.2">𝑡</ci></apply><ci id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.3a.cmml" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.3"><mtext id="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S3.E9.m1.4.4.1.1.3.1.1.1.1.1.1.1.2.2.2.3">adv</mtext></ci></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.4c">v_{\text{adv}},t_{\text{adv}}:=\underset{\widehat{v}_{\text{adv}},\widehat{t}_%
{\text{adv}}}{\operatorname{argmin}}\sum_{i=1}^{n}-\log\left(p(y_{i}\mid%
\widehat{v}_{\text{adv}},\widehat{t}_{\text{adv}})\right).</annotation><annotation encoding="application/x-llamapun" id="S3.E9.m1.4d">italic_v start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT := start_UNDERACCENT over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT , over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT end_UNDERACCENT start_ARG roman_argmin end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT - roman_log ( italic_p ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∣ over^ start_ARG italic_v end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT , over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT ) ) .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS1.p3.8">Similar to&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a>]</cite>, Ying <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.p3.8.1">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib97" title="">97</a>]</cite> introduce the Bi-Modal Adversarial Prompt Attack (BAP) method, which perturbs images and rewrites text inputs to compromise the safety mechanisms of LVLMs. BAP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib97" title="">97</a>]</cite> crafts the visual perturbation by constructing a query-agnostic corpus, ensuring the model consistently generates positive responses regardless of the query’s harmful intent. Differing from&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a>]</cite>, BAP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib97" title="">97</a>]</cite> incorporates an iterative refinement of the textual prompt using CoT strategy&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib119" title="">119</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib120" title="">120</a>]</cite>, leverages the reasoning capabilities of LLMs to progressively optimize the textual input, ensuring it aligns with the visual perturbation while effectively bypassing safety mechanisms. This alignment between visual and textual modalities enables the model to produce harmful outputs with higher success and precision.
Extending these insights, HADES&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib40" title="">40</a>]</cite> demonstrates that images can act as alignment backdoors for LVLMs. HADES&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib40" title="">40</a>]</cite> combines multiple attack strategies in a systematic process: it first removes harmful textual content by embedding it into typography, then pairs it with a harmful image generated using a diffusion model guided by an iteratively refined prompt from an LLM. Finally, an adversarial image is appended to the composite image, effectively eliciting affirmative responses from LVLMs for harmful instructions. Presented strong evidence that the visual modality poses the alignment vulnerability of LVLMs, underscoring the urgent need for further exploration into cross-modal alignment.
While <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib95" title="">95</a>]</cite> introduces cross-prompt attack by using single-modality method. CIA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib98" title="">98</a>]</cite> further improves CroPA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib95" title="">95</a>]</cite> by employing gradient-based perturbation to inject target tokens into both visual and textual contexts. CIA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib98" title="">98</a>]</cite> shifts contextual semantics towards the target tokens instead of preserving the original image semantics, thereby enhancing the cross-prompt transferability of adversarial images.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与[ 26]类似，Ying 等人[ 97]提出了双模态对抗提示攻击（BAP）方法，该方法通过扰动图像和重写文本输入来破坏大型视觉语言模型（LVLMs）的安全机制。BAP[ 97]通过构建一个查询无关的语料库来制作视觉扰动，确保模型无论查询的恶意意图如何，始终生成正面响应。与[ 26]不同，BAP[ 97]采用 CoT 策略[ 119, 120]对文本提示进行迭代优化，利用 LLMs 的推理能力逐步优化文本输入，确保其与视觉扰动一致，同时有效绕过安全机制。这种视觉和文本模态之间的对齐使模型能够以更高的成功率和精度生成有害输出。基于这些见解，HADES[ 40]表明图像可以作为 LVLMs 的校准后门。HADES[ 40]在系统过程中结合了多种攻击策略：首先通过将其嵌入到排版中移除有害文本内容，然后将其与一个由 LLM 迭代优化的提示引导的扩散模型生成的有害图像配对。 最后，将对抗性图像附加到合成图像中，有效引出 LVLMs 对有害指令的肯定响应。提供了强有力的证据，表明视觉模态导致了 LVLMs 的校准漏洞，突显了进一步探索跨模态校准的紧迫性。虽然[ 95]通过使用单模态方法引入了跨提示攻击。CIA [ 98]通过采用基于梯度的扰动，将目标标记注入视觉和文本上下文中，进一步改进了 CroPA [ 95]。CIA [ 98]将上下文语义转向目标标记，而不是保留原始图像语义，从而增强了对抗性图像的跨提示可迁移性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Gray-Box Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1.2 灰盒攻击</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">As a distinctive category of attack methods, Gray-Box Attacks leverage the attacker’s partial knowledge of the model architecture. As depicted in the middle of&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.F2" title="In 3.1.2 Gray-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Fig.</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, despite the absence of access to the model’s complete parameters or gradients, attackers can exploit structural information inherent to LVLMs. For models employing known vision encoders, such as CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib12" title="">12</a>]</cite> or BLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib121" title="">121</a>]</cite>, attackers are able to construct an surrogate model set to generate adversarial images analogous to those produced in White-Box Attacks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS1" title="3.1.1 White-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.1</span></a>). These adversarial images exhibit sufficient generalization capabilities, enabling effective attacks on other models that utilize the same vision encoder architecture.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">作为一种独特的攻击方法，灰盒攻击利用了攻击者对模型架构的部分知识。如图 2 中间所示，尽管无法访问模型的完整参数或梯度，攻击者仍能利用 LVLMs 固有的结构信息。对于采用已知视觉编码器的模型，如 CLIP [12]或 BLIP [121]，攻击者能够构建一个替代模型集，以生成类似于白盒攻击（§ 3.1.1）中产生的对抗图像。这些对抗图像具有足够的泛化能力，能够对使用相同视觉编码器架构的其他模型进行有效攻击。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p2.1.m1.1"><semantics id="S3.SS1.SSS2.p2.1.m1.1a"><mo id="S3.SS1.SSS2.p2.1.m1.1.1" xref="S3.SS1.SSS2.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.1.m1.1b"><ci id="S3.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p2.1.1">Single-Modality.</span>
Focusing on visual modality, Zhao <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS2.p2.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib25" title="">25</a>]</cite> conducts both transfer-based and query-based attacks against image-grounded text generation, focusing on adversaries with only black-box system access. CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib12" title="">12</a>]</cite> and BLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib121" title="">121</a>]</cite> are employed as surrogate models to generate adversarial examples by aligning textual and image embeddings, which are subsequently transferred to other LVLMs. This methodology achieves a notably high success rate in generating targeted responses.
Dong <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS2.p2.1.3">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib100" title="">100</a>]</cite> and Niu <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS2.p2.1.4">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib101" title="">101</a>]</cite> both employing more white-box surrogate vision encoders of LVLMs.
Dong <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS2.p2.1.5">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib100" title="">100</a>]</cite> further investigated the vulnerability of Google’s Bard<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bard.google.com/" title="">https://bard.google.com/</a></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS2.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S3.SS1.SSS2.p2.1.m1.1a"><mo id="S3.SS1.SSS2.p2.1.m1.1.1">∙</mo><annotation-xml id="S3.SS1.SSS2.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS2.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S3.SS1.SSS2.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 单模态。聚焦于视觉模态，赵等人[ 25]对图像-文本生成进行了基于迁移和基于查询的攻击，专注于只有黑盒系统访问的对手。CLIP[ 12]和 BLIP[ 121]被用作替代模型，通过对齐文本和图像嵌入来生成对抗样本，这些样本随后被迁移到其他大型视觉语言模型（LVLMs）。这种方法在生成目标响应方面取得了显著的高成功率。董等人[ 100]和牛等人[ 101]都采用了更白盒的 LVLM 替代视觉编码器。董等人[ 100]进一步研究了 Google 的 Bard <sup class="ltx_note_mark">1</sup> </font></font></font>, a black-box model. The generated adversarial examples demonstrated the capability to mislead Bard, producing incorrect image descriptions with a 22% attack success rate (ASR) based solely on their transferability. These examples were also highly effective against other commercial LVLMs, achieving similarly high ASRs.
Wang <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS2.p2.1.6">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib122" title="">122</a>]</cite> introduces a novel attack method called VT-Attack. This method disrupts encoded visual tokens by comprehensively targeting their features, relationships, and semantic properties. It employs a multi-faceted approach to alter the internal representations of these tokens, effectively interfering with the model’s ability to generate untargeted outputs across various tasks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">，一个黑盒模型。生成的对抗样本展示了误导 Bard 的能力，仅凭借其可迁移性，以 22%的攻击成功率（ASR）生成了错误的图像描述。这些样本对其他商业视觉语言模型（LVLMs）也非常有效，实现了同样高的 ASR。Wang 等人[ 122]介绍了一种名为 VT-Attack 的新型攻击方法。该方法通过全面针对其特征、关系和语义属性来破坏编码的视觉标记。它采用多方面的方法来改变这些标记的内部表示，有效地干扰模型在各种任务中生成非目标输出的能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p3">
<p class="ltx_p" id="S3.SS1.SSS2.p3.7"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.1.m1.1"><semantics id="S3.SS1.SSS2.p3.1.m1.1a"><mo id="S3.SS1.SSS2.p3.1.m1.1.1" xref="S3.SS1.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.1.m1.1b"><ci id="S3.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS2.p3.7.1">Cross-Modality.</span>
Jailbreak In Pieces (JIP)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib85" title="">85</a>]</cite> developed a cross-modality attack method that requires access solely to the vision encoder CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib12" title="">12</a>]</cite>. JIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib85" title="">85</a>]</cite> first decomposes a typical harmful prompt into two distinct components: a generic textual instruction <math alttext="x_{g}^{t}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.2.m2.1"><semantics id="S3.SS1.SSS2.p3.2.m2.1a"><msubsup id="S3.SS1.SSS2.p3.2.m2.1.1" xref="S3.SS1.SSS2.p3.2.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p3.2.m2.1.1.2.2" xref="S3.SS1.SSS2.p3.2.m2.1.1.2.2.cmml">x</mi><mi id="S3.SS1.SSS2.p3.2.m2.1.1.2.3" xref="S3.SS1.SSS2.p3.2.m2.1.1.2.3.cmml">g</mi><mi id="S3.SS1.SSS2.p3.2.m2.1.1.3" xref="S3.SS1.SSS2.p3.2.m2.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.2.m2.1b"><apply id="S3.SS1.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p3.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1.2.2">𝑥</ci><ci id="S3.SS1.SSS2.p3.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1.2.3">𝑔</ci></apply><ci id="S3.SS1.SSS2.p3.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.2.m2.1c">x_{g}^{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> (e.g., “teach me how to make these things.”) and a malicious trigger <math alttext="H_{\text{harm}}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.3.m3.1"><semantics id="S3.SS1.SSS2.p3.3.m3.1a"><msub id="S3.SS1.SSS2.p3.3.m3.1.1" xref="S3.SS1.SSS2.p3.3.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p3.3.m3.1.1.2" xref="S3.SS1.SSS2.p3.3.m3.1.1.2.cmml">H</mi><mtext id="S3.SS1.SSS2.p3.3.m3.1.1.3" xref="S3.SS1.SSS2.p3.3.m3.1.1.3a.cmml">harm</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.3.m3.1b"><apply id="S3.SS1.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.2">𝐻</ci><ci id="S3.SS1.SSS2.p3.3.m3.1.1.3a.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3"><mtext id="S3.SS1.SSS2.p3.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p3.3.m3.1.1.3">harm</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.3.m3.1c">H_{\text{harm}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.3.m3.1d">italic_H start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT</annotation></semantics></math>, which can be either a harmful textual input <math alttext="x_{\text{harm}}^{t}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.4.m4.1"><semantics id="S3.SS1.SSS2.p3.4.m4.1a"><msubsup id="S3.SS1.SSS2.p3.4.m4.1.1" xref="S3.SS1.SSS2.p3.4.m4.1.1.cmml"><mi id="S3.SS1.SSS2.p3.4.m4.1.1.2.2" xref="S3.SS1.SSS2.p3.4.m4.1.1.2.2.cmml">x</mi><mtext id="S3.SS1.SSS2.p3.4.m4.1.1.2.3" xref="S3.SS1.SSS2.p3.4.m4.1.1.2.3a.cmml">harm</mtext><mi id="S3.SS1.SSS2.p3.4.m4.1.1.3" xref="S3.SS1.SSS2.p3.4.m4.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.4.m4.1b"><apply id="S3.SS1.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m4.1.1.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p3.4.m4.1.1.2.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m4.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.4.m4.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.2.2">𝑥</ci><ci id="S3.SS1.SSS2.p3.4.m4.1.1.2.3a.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.2.3"><mtext id="S3.SS1.SSS2.p3.4.m4.1.1.2.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p3.4.m4.1.1.2.3">harm</mtext></ci></apply><ci id="S3.SS1.SSS2.p3.4.m4.1.1.3.cmml" xref="S3.SS1.SSS2.p3.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.4.m4.1c">x_{\text{harm}}^{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.4.m4.1d">italic_x start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> or an image input <math alttext="x_{\text{harm}}^{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.5.m5.1"><semantics id="S3.SS1.SSS2.p3.5.m5.1a"><msubsup id="S3.SS1.SSS2.p3.5.m5.1.1" xref="S3.SS1.SSS2.p3.5.m5.1.1.cmml"><mi id="S3.SS1.SSS2.p3.5.m5.1.1.2.2" xref="S3.SS1.SSS2.p3.5.m5.1.1.2.2.cmml">x</mi><mtext id="S3.SS1.SSS2.p3.5.m5.1.1.2.3" xref="S3.SS1.SSS2.p3.5.m5.1.1.2.3a.cmml">harm</mtext><mi id="S3.SS1.SSS2.p3.5.m5.1.1.3" xref="S3.SS1.SSS2.p3.5.m5.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.5.m5.1b"><apply id="S3.SS1.SSS2.p3.5.m5.1.1.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.5.m5.1.1.1.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p3.5.m5.1.1.2.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.5.m5.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.5.m5.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1.2.2">𝑥</ci><ci id="S3.SS1.SSS2.p3.5.m5.1.1.2.3a.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1.2.3"><mtext id="S3.SS1.SSS2.p3.5.m5.1.1.2.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p3.5.m5.1.1.2.3">harm</mtext></ci></apply><ci id="S3.SS1.SSS2.p3.5.m5.1.1.3.cmml" xref="S3.SS1.SSS2.p3.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.5.m5.1c">x_{\text{harm}}^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.5.m5.1d">italic_x start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> generated using visual or OCR methods. Therefore craft the adversarial input images <math alttext="\widehat{x}_{adv}^{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.6.m6.1"><semantics id="S3.SS1.SSS2.p3.6.m6.1a"><msubsup id="S3.SS1.SSS2.p3.6.m6.1.1" xref="S3.SS1.SSS2.p3.6.m6.1.1.cmml"><mover accent="true" id="S3.SS1.SSS2.p3.6.m6.1.1.2.2" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.2.cmml"><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.2.2" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.2.2.cmml">x</mi><mo id="S3.SS1.SSS2.p3.6.m6.1.1.2.2.1" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.2.1.cmml">^</mo></mover><mrow id="S3.SS1.SSS2.p3.6.m6.1.1.2.3" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.cmml"><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.2" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.2.cmml">a</mi><mo id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.1" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.3" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.3.cmml">d</mi><mo id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.1a" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.4" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.4.cmml">v</mi></mrow><mi id="S3.SS1.SSS2.p3.6.m6.1.1.3" xref="S3.SS1.SSS2.p3.6.m6.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.6.m6.1b"><apply id="S3.SS1.SSS2.p3.6.m6.1.1.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.6.m6.1.1.1.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p3.6.m6.1.1.2.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.6.m6.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1">subscript</csymbol><apply id="S3.SS1.SSS2.p3.6.m6.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.2"><ci id="S3.SS1.SSS2.p3.6.m6.1.1.2.2.1.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.2.1">^</ci><ci id="S3.SS1.SSS2.p3.6.m6.1.1.2.2.2.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.2.2">𝑥</ci></apply><apply id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3"><times id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.1.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.1"></times><ci id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.2.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.2">𝑎</ci><ci id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.3.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.3">𝑑</ci><ci id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.4.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.2.3.4">𝑣</ci></apply></apply><ci id="S3.SS1.SSS2.p3.6.m6.1.1.3.cmml" xref="S3.SS1.SSS2.p3.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.6.m6.1c">\widehat{x}_{adv}^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.6.m6.1d">over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> that mapped into the dangerous embedding regions close to <math alttext="H_{\text{harm}}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.7.m7.1"><semantics id="S3.SS1.SSS2.p3.7.m7.1a"><msub id="S3.SS1.SSS2.p3.7.m7.1.1" xref="S3.SS1.SSS2.p3.7.m7.1.1.cmml"><mi id="S3.SS1.SSS2.p3.7.m7.1.1.2" xref="S3.SS1.SSS2.p3.7.m7.1.1.2.cmml">H</mi><mtext id="S3.SS1.SSS2.p3.7.m7.1.1.3" xref="S3.SS1.SSS2.p3.7.m7.1.1.3a.cmml">harm</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.7.m7.1b"><apply id="S3.SS1.SSS2.p3.7.m7.1.1.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.7.m7.1.1.1.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.7.m7.1.1.2.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1.2">𝐻</ci><ci id="S3.SS1.SSS2.p3.7.m7.1.1.3a.cmml" xref="S3.SS1.SSS2.p3.7.m7.1.1.3"><mtext id="S3.SS1.SSS2.p3.7.m7.1.1.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p3.7.m7.1.1.3">harm</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.7.m7.1c">H_{\text{harm}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.7.m7.1d">italic_H start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT</annotation></semantics></math>:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS2.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S3.SS1.SSS2.p3.1.m1.1a"><mo id="S3.SS1.SSS2.p3.1.m1.1.1">∙</mo><annotation-xml id="S3.SS1.SSS2.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS2.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S3.SS1.SSS2.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 跨模态。分段越狱攻击（JIP）[ 85] 开发了一种跨模态攻击方法，该方法仅需访问视觉编码器 CLIP [ 12]。JIP [ 85] 首先将典型的有害提示分解为两个不同组件：一个通用文本指令 <math id="S3.SS1.SSS2.p3.2.m2.1" display="inline" class="ltx_Math" alttext="x_{g}^{t}"><semantics id="S3.SS1.SSS2.p3.2.m2.1a"><msubsup id="S3.SS1.SSS2.p3.2.m2.1.1"><mi id="S3.SS1.SSS2.p3.2.m2.1.1.2.2">x</mi><mi id="S3.SS1.SSS2.p3.2.m2.1.1.2.3">g</mi><mi id="S3.SS1.SSS2.p3.2.m2.1.1.3">t</mi></msubsup><annotation-xml id="S3.SS1.SSS2.p3.2.m2.1b" encoding="MathML-Content">superscriptsubscript</annotation-xml><annotation id="S3.SS1.SSS2.p3.2.m2.1c" encoding="application/x-tex">x_{g}^{t}</annotation><annotation id="S3.SS1.SSS2.p3.2.m2.1d" encoding="application/x-llamapun">italic_x start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> （例如，“教我如何制作这些东西。”）和一个恶意触发器 <math id="S3.SS1.SSS2.p3.3.m3.1" display="inline" class="ltx_Math" alttext="H_{\text{harm}}"><semantics id="S3.SS1.SSS2.p3.3.m3.1a"><msub id="S3.SS1.SSS2.p3.3.m3.1.1"><mi id="S3.SS1.SSS2.p3.3.m3.1.1.2">H</mi><mtext id="S3.SS1.SSS2.p3.3.m3.1.1.3">harm</mtext></msub><annotation-xml id="S3.SS1.SSS2.p3.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS1.SSS2.p3.3.m3.1c" encoding="application/x-tex">H_{\text{harm}}</annotation><annotation id="S3.SS1.SSS2.p3.3.m3.1d" encoding="application/x-llamapun">italic_H start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT</annotation></semantics></math> ，该触发器可以是具有危害性的文本输入 <math id="S3.SS1.SSS2.p3.4.m4.1" display="inline" class="ltx_Math" alttext="x_{\text{harm}}^{t}"><semantics id="S3.SS1.SSS2.p3.4.m4.1a"><msubsup id="S3.SS1.SSS2.p3.4.m4.1.1"><mi id="S3.SS1.SSS2.p3.4.m4.1.1.2.2">x</mi><mtext id="S3.SS1.SSS2.p3.4.m4.1.1.2.3">harm</mtext><mi id="S3.SS1.SSS2.p3.4.m4.1.1.3">t</mi></msubsup><annotation-xml id="S3.SS1.SSS2.p3.4.m4.1b" encoding="MathML-Content">superscriptsubscript</annotation-xml><annotation id="S3.SS1.SSS2.p3.4.m4.1c" encoding="application/x-tex">x_{\text{harm}}^{t}</annotation><annotation id="S3.SS1.SSS2.p3.4.m4.1d" encoding="application/x-llamapun">italic_x start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> 或使用视觉或 OCR 方法生成的图像输入 <math id="S3.SS1.SSS2.p3.5.m5.1" display="inline" class="ltx_Math" alttext="x_{\text{harm}}^{i}"><semantics id="S3.SS1.SSS2.p3.5.m5.1a"><msubsup id="S3.SS1.SSS2.p3.5.m5.1.1"><mi id="S3.SS1.SSS2.p3.5.m5.1.1.2.2">x</mi><mtext id="S3.SS1.SSS2.p3.5.m5.1.1.2.3">harm</mtext><mi id="S3.SS1.SSS2.p3.5.m5.1.1.3">i</mi></msubsup><annotation-xml id="S3.SS1.SSS2.p3.5.m5.1b" encoding="MathML-Content">superscriptsubscript</annotation-xml><annotation id="S3.SS1.SSS2.p3.5.m5.1c" encoding="application/x-tex">x_{\text{harm}}^{i}</annotation><annotation id="S3.SS1.SSS2.p3.5.m5.1d" encoding="application/x-llamapun">italic_x start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> 。因此，制作对抗性输入图像 <math id="S3.SS1.SSS2.p3.6.m6.1" display="inline" class="ltx_Math" alttext="\widehat{x}_{adv}^{i}"><semantics id="S3.SS1.SSS2.p3.6.m6.1a"><msubsup id="S3.SS1.SSS2.p3.6.m6.1.1"><mover id="S3.SS1.SSS2.p3.6.m6.1.1.2.2" accent="true"><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.2.2">x</mi><mo id="S3.SS1.SSS2.p3.6.m6.1.1.2.2.1">^</mo></mover><mrow id="S3.SS1.SSS2.p3.6.m6.1.1.2.3"><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.2">a</mi><mo id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.1">⁢</mo><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.3">d</mi><mo id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.1a">⁢</mo><mi id="S3.SS1.SSS2.p3.6.m6.1.1.2.3.4">v</mi></mrow><mi id="S3.SS1.SSS2.p3.6.m6.1.1.3">i</mi></msubsup><annotation-xml id="S3.SS1.SSS2.p3.6.m6.1b" encoding="MathML-Content">superscriptsubscript</annotation-xml><annotation id="S3.SS1.SSS2.p3.6.m6.1c" encoding="application/x-tex">\widehat{x}_{adv}^{i}</annotation><annotation id="S3.SS1.SSS2.p3.6.m6.1d" encoding="application/x-llamapun">over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> ，使其映射到接近 <math id="S3.SS1.SSS2.p3.7.m7.1" display="inline" class="ltx_Math" alttext="H_{\text{harm}}"><semantics id="S3.SS1.SSS2.p3.7.m7.1a"><msub id="S3.SS1.SSS2.p3.7.m7.1.1"><mi id="S3.SS1.SSS2.p3.7.m7.1.1.2">H</mi><mtext id="S3.SS1.SSS2.p3.7.m7.1.1.3">harm</mtext></msub><annotation-xml id="S3.SS1.SSS2.p3.7.m7.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS1.SSS2.p3.7.m7.1c" encoding="application/x-tex">H_{\text{harm}}</annotation><annotation id="S3.SS1.SSS2.p3.7.m7.1d" encoding="application/x-llamapun">italic_H start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT</annotation></semantics></math> 的危险嵌入区域。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E10">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{x}_{adv}^{i}=\underset{x_{adv}\in\mathcal{B}}{\operatorname{argmin}}%
\mathcal{L}_{2}\left(H_{\text{harm }},\mathcal{I}_{\phi}\left(x_{adv}^{i}%
\right)\right),\quad\mathcal{I}_{\phi}(\cdot)-\operatorname{CLIP}," class="ltx_Math" display="block" id="S3.E10.m1.2"><semantics id="S3.E10.m1.2a"><mrow id="S3.E10.m1.2.2.1" xref="S3.E10.m1.2.2.1.1.cmml"><mrow id="S3.E10.m1.2.2.1.1" xref="S3.E10.m1.2.2.1.1.cmml"><msubsup id="S3.E10.m1.2.2.1.1.4" xref="S3.E10.m1.2.2.1.1.4.cmml"><mover accent="true" id="S3.E10.m1.2.2.1.1.4.2.2" xref="S3.E10.m1.2.2.1.1.4.2.2.cmml"><mi id="S3.E10.m1.2.2.1.1.4.2.2.2" xref="S3.E10.m1.2.2.1.1.4.2.2.2.cmml">x</mi><mo id="S3.E10.m1.2.2.1.1.4.2.2.1" xref="S3.E10.m1.2.2.1.1.4.2.2.1.cmml">^</mo></mover><mrow id="S3.E10.m1.2.2.1.1.4.2.3" xref="S3.E10.m1.2.2.1.1.4.2.3.cmml"><mi id="S3.E10.m1.2.2.1.1.4.2.3.2" xref="S3.E10.m1.2.2.1.1.4.2.3.2.cmml">a</mi><mo id="S3.E10.m1.2.2.1.1.4.2.3.1" xref="S3.E10.m1.2.2.1.1.4.2.3.1.cmml">⁢</mo><mi id="S3.E10.m1.2.2.1.1.4.2.3.3" xref="S3.E10.m1.2.2.1.1.4.2.3.3.cmml">d</mi><mo id="S3.E10.m1.2.2.1.1.4.2.3.1a" xref="S3.E10.m1.2.2.1.1.4.2.3.1.cmml">⁢</mo><mi id="S3.E10.m1.2.2.1.1.4.2.3.4" xref="S3.E10.m1.2.2.1.1.4.2.3.4.cmml">v</mi></mrow><mi id="S3.E10.m1.2.2.1.1.4.3" xref="S3.E10.m1.2.2.1.1.4.3.cmml">i</mi></msubsup><mo id="S3.E10.m1.2.2.1.1.3" xref="S3.E10.m1.2.2.1.1.3.cmml">=</mo><mrow id="S3.E10.m1.2.2.1.1.2.2" xref="S3.E10.m1.2.2.1.1.2.3.cmml"><mrow id="S3.E10.m1.2.2.1.1.1.1.1" xref="S3.E10.m1.2.2.1.1.1.1.1.cmml"><munder accentunder="true" id="S3.E10.m1.2.2.1.1.1.1.1.4" xref="S3.E10.m1.2.2.1.1.1.1.1.4.cmml"><mi id="S3.E10.m1.2.2.1.1.1.1.1.4.2" xref="S3.E10.m1.2.2.1.1.1.1.1.4.2.cmml">argmin</mi><mrow id="S3.E10.m1.2.2.1.1.1.1.1.4.1" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.cmml"><msub id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.cmml"><mi id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.2" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.2.cmml">x</mi><mrow id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.cmml"><mi id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.2" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.2.cmml">a</mi><mo id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.1" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.1.cmml">⁢</mo><mi id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.3" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.3.cmml">d</mi><mo id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.1a" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.1.cmml">⁢</mo><mi id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.4" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.4.cmml">v</mi></mrow></msub><mo id="S3.E10.m1.2.2.1.1.1.1.1.4.1.1" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E10.m1.2.2.1.1.1.1.1.4.1.3" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.3.cmml">ℬ</mi></mrow></munder><mo id="S3.E10.m1.2.2.1.1.1.1.1.3" lspace="0.167em" xref="S3.E10.m1.2.2.1.1.1.1.1.3.cmml">⁢</mo><msub id="S3.E10.m1.2.2.1.1.1.1.1.5" xref="S3.E10.m1.2.2.1.1.1.1.1.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E10.m1.2.2.1.1.1.1.1.5.2" xref="S3.E10.m1.2.2.1.1.1.1.1.5.2.cmml">ℒ</mi><mn id="S3.E10.m1.2.2.1.1.1.1.1.5.3" xref="S3.E10.m1.2.2.1.1.1.1.1.5.3.cmml">2</mn></msub><mo id="S3.E10.m1.2.2.1.1.1.1.1.3a" xref="S3.E10.m1.2.2.1.1.1.1.1.3.cmml">⁢</mo><mrow id="S3.E10.m1.2.2.1.1.1.1.1.2.2" xref="S3.E10.m1.2.2.1.1.1.1.1.2.3.cmml"><mo id="S3.E10.m1.2.2.1.1.1.1.1.2.2.3" xref="S3.E10.m1.2.2.1.1.1.1.1.2.3.cmml">(</mo><msub id="S3.E10.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">H</mi><mtext id="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.3a.cmml">harm&nbsp;</mtext></msub><mo id="S3.E10.m1.2.2.1.1.1.1.1.2.2.4" xref="S3.E10.m1.2.2.1.1.1.1.1.2.3.cmml">,</mo><mrow id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.cmml"><msub id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.2" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.2.cmml">ℐ</mi><mi id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.3" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.3.cmml">ϕ</mi></msub><mo id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.2" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.2.cmml">⁢</mo><mrow id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.cmml"><mo id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.2" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.cmml">(</mo><msubsup id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.cmml"><mi id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.2" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.2.cmml">x</mi><mrow id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.cmml"><mi id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.2" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.2.cmml">a</mi><mo id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.1" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.3" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.3.cmml">d</mi><mo id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.1a" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.4" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.4.cmml">v</mi></mrow><mi id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.3" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.3" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E10.m1.2.2.1.1.1.1.1.2.2.5" xref="S3.E10.m1.2.2.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E10.m1.2.2.1.1.2.2.3" rspace="1.167em" xref="S3.E10.m1.2.2.1.1.2.3.cmml">,</mo><mrow id="S3.E10.m1.2.2.1.1.2.2.2" xref="S3.E10.m1.2.2.1.1.2.2.2.cmml"><mrow id="S3.E10.m1.2.2.1.1.2.2.2.2" xref="S3.E10.m1.2.2.1.1.2.2.2.2.cmml"><msub id="S3.E10.m1.2.2.1.1.2.2.2.2.2" xref="S3.E10.m1.2.2.1.1.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E10.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E10.m1.2.2.1.1.2.2.2.2.2.2.cmml">ℐ</mi><mi id="S3.E10.m1.2.2.1.1.2.2.2.2.2.3" xref="S3.E10.m1.2.2.1.1.2.2.2.2.2.3.cmml">ϕ</mi></msub><mo id="S3.E10.m1.2.2.1.1.2.2.2.2.1" xref="S3.E10.m1.2.2.1.1.2.2.2.2.1.cmml">⁢</mo><mrow id="S3.E10.m1.2.2.1.1.2.2.2.2.3.2" xref="S3.E10.m1.2.2.1.1.2.2.2.2.cmml"><mo id="S3.E10.m1.2.2.1.1.2.2.2.2.3.2.1" stretchy="false" xref="S3.E10.m1.2.2.1.1.2.2.2.2.cmml">(</mo><mo id="S3.E10.m1.1.1" lspace="0em" rspace="0em" xref="S3.E10.m1.1.1.cmml">⋅</mo><mo id="S3.E10.m1.2.2.1.1.2.2.2.2.3.2.2" stretchy="false" xref="S3.E10.m1.2.2.1.1.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E10.m1.2.2.1.1.2.2.2.1" xref="S3.E10.m1.2.2.1.1.2.2.2.1.cmml">−</mo><mi id="S3.E10.m1.2.2.1.1.2.2.2.3" xref="S3.E10.m1.2.2.1.1.2.2.2.3.cmml">CLIP</mi></mrow></mrow></mrow><mo id="S3.E10.m1.2.2.1.2" xref="S3.E10.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E10.m1.2b"><apply id="S3.E10.m1.2.2.1.1.cmml" xref="S3.E10.m1.2.2.1"><eq id="S3.E10.m1.2.2.1.1.3.cmml" xref="S3.E10.m1.2.2.1.1.3"></eq><apply id="S3.E10.m1.2.2.1.1.4.cmml" xref="S3.E10.m1.2.2.1.1.4"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.4.1.cmml" xref="S3.E10.m1.2.2.1.1.4">superscript</csymbol><apply id="S3.E10.m1.2.2.1.1.4.2.cmml" xref="S3.E10.m1.2.2.1.1.4"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.4.2.1.cmml" xref="S3.E10.m1.2.2.1.1.4">subscript</csymbol><apply id="S3.E10.m1.2.2.1.1.4.2.2.cmml" xref="S3.E10.m1.2.2.1.1.4.2.2"><ci id="S3.E10.m1.2.2.1.1.4.2.2.1.cmml" xref="S3.E10.m1.2.2.1.1.4.2.2.1">^</ci><ci id="S3.E10.m1.2.2.1.1.4.2.2.2.cmml" xref="S3.E10.m1.2.2.1.1.4.2.2.2">𝑥</ci></apply><apply id="S3.E10.m1.2.2.1.1.4.2.3.cmml" xref="S3.E10.m1.2.2.1.1.4.2.3"><times id="S3.E10.m1.2.2.1.1.4.2.3.1.cmml" xref="S3.E10.m1.2.2.1.1.4.2.3.1"></times><ci id="S3.E10.m1.2.2.1.1.4.2.3.2.cmml" xref="S3.E10.m1.2.2.1.1.4.2.3.2">𝑎</ci><ci id="S3.E10.m1.2.2.1.1.4.2.3.3.cmml" xref="S3.E10.m1.2.2.1.1.4.2.3.3">𝑑</ci><ci id="S3.E10.m1.2.2.1.1.4.2.3.4.cmml" xref="S3.E10.m1.2.2.1.1.4.2.3.4">𝑣</ci></apply></apply><ci id="S3.E10.m1.2.2.1.1.4.3.cmml" xref="S3.E10.m1.2.2.1.1.4.3">𝑖</ci></apply><list id="S3.E10.m1.2.2.1.1.2.3.cmml" xref="S3.E10.m1.2.2.1.1.2.2"><apply id="S3.E10.m1.2.2.1.1.1.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1"><times id="S3.E10.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.3"></times><apply id="S3.E10.m1.2.2.1.1.1.1.1.4.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4"><apply id="S3.E10.m1.2.2.1.1.1.1.1.4.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1"><in id="S3.E10.m1.2.2.1.1.1.1.1.4.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.1"></in><apply id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2">subscript</csymbol><ci id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.2">𝑥</ci><apply id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3"><times id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.1"></times><ci id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.2">𝑎</ci><ci id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.3">𝑑</ci><ci id="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.4.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.2.3.4">𝑣</ci></apply></apply><ci id="S3.E10.m1.2.2.1.1.1.1.1.4.1.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.1.3">ℬ</ci></apply><ci id="S3.E10.m1.2.2.1.1.1.1.1.4.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.4.2">argmin</ci></apply><apply id="S3.E10.m1.2.2.1.1.1.1.1.5.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.1.1.1.5.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.5">subscript</csymbol><ci id="S3.E10.m1.2.2.1.1.1.1.1.5.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.5.2">ℒ</ci><cn id="S3.E10.m1.2.2.1.1.1.1.1.5.3.cmml" type="integer" xref="S3.E10.m1.2.2.1.1.1.1.1.5.3">2</cn></apply><interval closure="open" id="S3.E10.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2"><apply id="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.2">𝐻</ci><ci id="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.3"><mtext id="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E10.m1.2.2.1.1.1.1.1.1.1.1.3">harm&nbsp;</mtext></ci></apply><apply id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2"><times id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.2"></times><apply id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3">subscript</csymbol><ci id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.2">ℐ</ci><ci id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.3.3">italic-ϕ</ci></apply><apply id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1">superscript</csymbol><apply id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1">subscript</csymbol><ci id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.2">𝑥</ci><apply id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3"><times id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.1.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.1"></times><ci id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.2.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.2">𝑎</ci><ci id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.3">𝑑</ci><ci id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.4.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.2.3.4">𝑣</ci></apply></apply><ci id="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.3.cmml" xref="S3.E10.m1.2.2.1.1.1.1.1.2.2.2.1.1.1.3">𝑖</ci></apply></apply></interval></apply><apply id="S3.E10.m1.2.2.1.1.2.2.2.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2"><minus id="S3.E10.m1.2.2.1.1.2.2.2.1.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2.1"></minus><apply id="S3.E10.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2.2"><times id="S3.E10.m1.2.2.1.1.2.2.2.2.1.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2.2.1"></times><apply id="S3.E10.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E10.m1.2.2.1.1.2.2.2.2.2.1.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.E10.m1.2.2.1.1.2.2.2.2.2.2.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2.2.2.2">ℐ</ci><ci id="S3.E10.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2.2.2.3">italic-ϕ</ci></apply><ci id="S3.E10.m1.1.1.cmml" xref="S3.E10.m1.1.1">⋅</ci></apply><ci id="S3.E10.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E10.m1.2.2.1.1.2.2.2.3">CLIP</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E10.m1.2c">\hat{x}_{adv}^{i}=\underset{x_{adv}\in\mathcal{B}}{\operatorname{argmin}}%
\mathcal{L}_{2}\left(H_{\text{harm }},\mathcal{I}_{\phi}\left(x_{adv}^{i}%
\right)\right),\quad\mathcal{I}_{\phi}(\cdot)-\operatorname{CLIP},</annotation><annotation encoding="application/x-llamapun" id="S3.E10.m1.2d">over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = start_UNDERACCENT italic_x start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT ∈ caligraphic_B end_UNDERACCENT start_ARG roman_argmin end_ARG caligraphic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_H start_POSTSUBSCRIPT harm end_POSTSUBSCRIPT , caligraphic_I start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_a italic_d italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) ) , caligraphic_I start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT ( ⋅ ) - roman_CLIP ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS2.p3.9"><math alttext="\hat{x}_{\text{adv}}^{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.8.m1.1"><semantics id="S3.SS1.SSS2.p3.8.m1.1a"><msubsup id="S3.SS1.SSS2.p3.8.m1.1.1" xref="S3.SS1.SSS2.p3.8.m1.1.1.cmml"><mover accent="true" id="S3.SS1.SSS2.p3.8.m1.1.1.2.2" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.2.cmml"><mi id="S3.SS1.SSS2.p3.8.m1.1.1.2.2.2" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.2.2.cmml">x</mi><mo id="S3.SS1.SSS2.p3.8.m1.1.1.2.2.1" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.SS1.SSS2.p3.8.m1.1.1.2.3" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.3a.cmml">adv</mtext><mi id="S3.SS1.SSS2.p3.8.m1.1.1.3" xref="S3.SS1.SSS2.p3.8.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.8.m1.1b"><apply id="S3.SS1.SSS2.p3.8.m1.1.1.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.8.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p3.8.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.8.m1.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1">subscript</csymbol><apply id="S3.SS1.SSS2.p3.8.m1.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.2"><ci id="S3.SS1.SSS2.p3.8.m1.1.1.2.2.1.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.2.1">^</ci><ci id="S3.SS1.SSS2.p3.8.m1.1.1.2.2.2.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.2.2">𝑥</ci></apply><ci id="S3.SS1.SSS2.p3.8.m1.1.1.2.3a.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.3"><mtext id="S3.SS1.SSS2.p3.8.m1.1.1.2.3.cmml" mathsize="70%" xref="S3.SS1.SSS2.p3.8.m1.1.1.2.3">adv</mtext></ci></apply><ci id="S3.SS1.SSS2.p3.8.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p3.8.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.8.m1.1c">\hat{x}_{\text{adv}}^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.8.m1.1d">over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="x_{g}^{t}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p3.9.m2.1"><semantics id="S3.SS1.SSS2.p3.9.m2.1a"><msubsup id="S3.SS1.SSS2.p3.9.m2.1.1" xref="S3.SS1.SSS2.p3.9.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p3.9.m2.1.1.2.2" xref="S3.SS1.SSS2.p3.9.m2.1.1.2.2.cmml">x</mi><mi id="S3.SS1.SSS2.p3.9.m2.1.1.2.3" xref="S3.SS1.SSS2.p3.9.m2.1.1.2.3.cmml">g</mi><mi id="S3.SS1.SSS2.p3.9.m2.1.1.3" xref="S3.SS1.SSS2.p3.9.m2.1.1.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.9.m2.1b"><apply id="S3.SS1.SSS2.p3.9.m2.1.1.cmml" xref="S3.SS1.SSS2.p3.9.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.9.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p3.9.m2.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p3.9.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p3.9.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.9.m2.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.9.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.9.m2.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.9.m2.1.1.2.2">𝑥</ci><ci id="S3.SS1.SSS2.p3.9.m2.1.1.2.3.cmml" xref="S3.SS1.SSS2.p3.9.m2.1.1.2.3">𝑔</ci></apply><ci id="S3.SS1.SSS2.p3.9.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p3.9.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.9.m2.1c">x_{g}^{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p3.9.m2.1d">italic_x start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> are then input jointly into LVLMs, where their embeddings are combined in a manner that circumvents the model’s textual-only safety alignment. JIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib85" title="">85</a>]</cite> enables the generation of harmful outputs by exploiting the multimodal integration, thereby highlighting the increased vulnerability of LVLMs to sophisticated cross-modality attacks. JIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib85" title="">85</a>]</cite> achieve a high success rate across different LVLMs, highlighting the risk of cross-modality alignment vulnerabilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS2.p3.8.m1.1" display="inline" class="ltx_Math" alttext="\hat{x}_{\text{adv}}^{i}"><semantics id="S3.SS1.SSS2.p3.8.m1.1a"><msubsup id="S3.SS1.SSS2.p3.8.m1.1.1"><mover id="S3.SS1.SSS2.p3.8.m1.1.1.2.2" accent="true"><mi id="S3.SS1.SSS2.p3.8.m1.1.1.2.2.2">x</mi><mo id="S3.SS1.SSS2.p3.8.m1.1.1.2.2.1">^</mo></mover><mtext id="S3.SS1.SSS2.p3.8.m1.1.1.2.3">adv</mtext><mi id="S3.SS1.SSS2.p3.8.m1.1.1.3">i</mi></msubsup><annotation-xml id="S3.SS1.SSS2.p3.8.m1.1b" encoding="MathML-Content">superscriptsubscript</annotation-xml><annotation id="S3.SS1.SSS2.p3.8.m1.1c" encoding="application/x-tex">\hat{x}_{\text{adv}}^{i}</annotation><annotation id="S3.SS1.SSS2.p3.8.m1.1d" encoding="application/x-llamapun">over^ start_ARG italic_x end_ARG start_POSTSUBSCRIPT adv end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math> 和 <math id="S3.SS1.SSS2.p3.9.m2.1" display="inline" class="ltx_Math" alttext="x_{g}^{t}"><semantics id="S3.SS1.SSS2.p3.9.m2.1a"><msubsup id="S3.SS1.SSS2.p3.9.m2.1.1"><mi id="S3.SS1.SSS2.p3.9.m2.1.1.2.2">x</mi><mi id="S3.SS1.SSS2.p3.9.m2.1.1.2.3">g</mi><mi id="S3.SS1.SSS2.p3.9.m2.1.1.3">t</mi></msubsup><annotation-xml id="S3.SS1.SSS2.p3.9.m2.1b" encoding="MathML-Content">superscriptsubscript</annotation-xml><annotation id="S3.SS1.SSS2.p3.9.m2.1c" encoding="application/x-tex">x_{g}^{t}</annotation><annotation id="S3.SS1.SSS2.p3.9.m2.1d" encoding="application/x-llamapun">italic_x start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> 随后被共同输入到大型视觉语言模型（LVLMs）中，它们的嵌入以一种绕过模型纯文本安全对齐的方式被组合。JIP [85]通过利用多模态集成来生成有害输出，从而突显了 LVLMs 在面对复杂跨模态攻击时的脆弱性。JIP [85]在不同的 LVLMs 上实现了高成功率，突显了跨模态对齐漏洞的风险。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" height="1073" id="S3.F2.g1" src="./《大型视觉语言模型安全综述：攻击、防御与评估》 --- A Survey of Safety on Large Vision-Language Models_ Attacks, Defenses and Evaluations_files/x2.png" width="830"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S3.F2.1"><svg height="45.66" overflow="visible" version="1.1" width="669.62"><g transform="translate(0,45.66) scale(1,-1)"><g transform="translate(-226.93,437.25)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="167.012591670126"><a class="ltx_ref ltx_font_bold" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS1" style="font-size:70%;" title="3.1.1 White-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.1</span></a></foreignobject></g></g><g transform="translate(-311.33,422.03)"><g transform="translate(0,13.83700013837) scale(1, -1)"><foreignobject height="10.3777501037775" overflow="visible" width="340.666943406669"><math alttext="\mathcal{K}_{\text{W}}=\{x,y,\theta,\mathcal{A}_{\theta},\nabla_{\theta}%
\mathcal{L}\mid x\in\mathcal{X},y=f_{\theta}(x)\}" class="ltx_Math" display="inline" id="S3.F2.1.pic1.1.m1.6"><semantics id="S3.F2.1.pic1.1.m1.6a"><mrow id="S3.F2.1.pic1.1.m1.6.6" xref="S3.F2.1.pic1.1.m1.6.6.cmml"><msub id="S3.F2.1.pic1.1.m1.6.6.4" xref="S3.F2.1.pic1.1.m1.6.6.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.1.m1.6.6.4.2" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.4.2.cmml">𝒦</mi><mtext id="S3.F2.1.pic1.1.m1.6.6.4.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.4.3a.cmml">W</mtext></msub><mo id="S3.F2.1.pic1.1.m1.6.6.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.3.cmml">=</mo><mrow id="S3.F2.1.pic1.1.m1.6.6.2.2" xref="S3.F2.1.pic1.1.m1.6.6.2.3.cmml"><mo id="S3.F2.1.pic1.1.m1.6.6.2.2.3" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.3.1.cmml">{</mo><mrow id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.3.cmml"><mi id="S3.F2.1.pic1.1.m1.1.1" mathsize="70%" xref="S3.F2.1.pic1.1.m1.1.1.cmml">x</mi><mo id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.3.cmml">,</mo><mi id="S3.F2.1.pic1.1.m1.2.2" mathsize="70%" xref="S3.F2.1.pic1.1.m1.2.2.cmml">y</mi><mo id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.4" mathsize="70%" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.3.cmml">,</mo><mi id="S3.F2.1.pic1.1.m1.3.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.3.3.cmml">θ</mi><mo id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.5" mathsize="70%" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.3.cmml">,</mo><msub id="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.2" mathsize="70%" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.2.cmml">𝒜</mi><mi id="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.3.cmml">θ</mi></msub><mo id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.6" mathsize="70%" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.3.cmml">,</mo><mrow id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.cmml"><msub id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.cmml"><mo id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.2" mathsize="70%" rspace="0.167em" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.2.cmml">∇</mo><mi id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.3.cmml">θ</mi></msub><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.2" mathsize="70%" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.2.cmml">ℒ</mi></mrow></mrow><mo fence="true" id="S3.F2.1.pic1.1.m1.6.6.2.2.4" lspace="0em" mathsize="70%" rspace="0em" xref="S3.F2.1.pic1.1.m1.6.6.2.3.1.cmml">∣</mo><mrow id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.3.cmml"><mrow id="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.cmml"><mi id="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.2" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.2.cmml">x</mi><mo id="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.1" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.3.cmml">𝒳</mi></mrow><mo id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.3a.cmml">,</mo><mrow id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.cmml"><mi id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.2" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.2.cmml">y</mi><mo id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.1" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.1.cmml">=</mo><mrow id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.cmml"><msub id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.cmml"><mi id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.2" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.2.cmml">f</mi><mi id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.3" mathsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.3.cmml">θ</mi></msub><mo id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.1" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.1.cmml">⁢</mo><mrow id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.3.2" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.cmml"><mo id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.3.2.1" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.cmml">(</mo><mi id="S3.F2.1.pic1.1.m1.4.4" mathsize="70%" xref="S3.F2.1.pic1.1.m1.4.4.cmml">x</mi><mo id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.3.2.2" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.F2.1.pic1.1.m1.6.6.2.2.5" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.1.m1.6.6.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.1.pic1.1.m1.6b"><apply id="S3.F2.1.pic1.1.m1.6.6.cmml" xref="S3.F2.1.pic1.1.m1.6.6"><eq id="S3.F2.1.pic1.1.m1.6.6.3.cmml" xref="S3.F2.1.pic1.1.m1.6.6.3"></eq><apply id="S3.F2.1.pic1.1.m1.6.6.4.cmml" xref="S3.F2.1.pic1.1.m1.6.6.4"><csymbol cd="ambiguous" id="S3.F2.1.pic1.1.m1.6.6.4.1.cmml" xref="S3.F2.1.pic1.1.m1.6.6.4">subscript</csymbol><ci id="S3.F2.1.pic1.1.m1.6.6.4.2.cmml" xref="S3.F2.1.pic1.1.m1.6.6.4.2">𝒦</ci><ci id="S3.F2.1.pic1.1.m1.6.6.4.3a.cmml" xref="S3.F2.1.pic1.1.m1.6.6.4.3"><mtext id="S3.F2.1.pic1.1.m1.6.6.4.3.cmml" mathsize="49%" xref="S3.F2.1.pic1.1.m1.6.6.4.3">W</mtext></ci></apply><apply id="S3.F2.1.pic1.1.m1.6.6.2.3.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2"><csymbol cd="latexml" id="S3.F2.1.pic1.1.m1.6.6.2.3.1.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.3">conditional-set</csymbol><list id="S3.F2.1.pic1.1.m1.5.5.1.1.1.3.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2"><ci id="S3.F2.1.pic1.1.m1.1.1.cmml" xref="S3.F2.1.pic1.1.m1.1.1">𝑥</ci><ci id="S3.F2.1.pic1.1.m1.2.2.cmml" xref="S3.F2.1.pic1.1.m1.2.2">𝑦</ci><ci id="S3.F2.1.pic1.1.m1.3.3.cmml" xref="S3.F2.1.pic1.1.m1.3.3">𝜃</ci><apply id="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.1.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1">subscript</csymbol><ci id="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.2">𝒜</ci><ci id="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.3.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.1.1.3">𝜃</ci></apply><apply id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2"><apply id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1"><csymbol cd="ambiguous" id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.1.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1">subscript</csymbol><ci id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.2.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.2">∇</ci><ci id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.3.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.1.3">𝜃</ci></apply><ci id="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.2.cmml" xref="S3.F2.1.pic1.1.m1.5.5.1.1.1.2.2.2">ℒ</ci></apply></list><apply id="S3.F2.1.pic1.1.m1.6.6.2.2.2.3.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S3.F2.1.pic1.1.m1.6.6.2.2.2.3a.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1"><in id="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.1.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.1"></in><ci id="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.2.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.2">𝑥</ci><ci id="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.3.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.1.1.3">𝒳</ci></apply><apply id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2"><eq id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.1.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.1"></eq><ci id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.2.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.2">𝑦</ci><apply id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3"><times id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.1.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.1"></times><apply id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.1.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2">subscript</csymbol><ci id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.2.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.2">𝑓</ci><ci id="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.3.cmml" xref="S3.F2.1.pic1.1.m1.6.6.2.2.2.2.2.3.2.3">𝜃</ci></apply><ci id="S3.F2.1.pic1.1.m1.4.4.cmml" xref="S3.F2.1.pic1.1.m1.4.4">𝑥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.1.pic1.1.m1.6c">\mathcal{K}_{\text{W}}=\{x,y,\theta,\mathcal{A}_{\theta},\nabla_{\theta}%
\mathcal{L}\mid x\in\mathcal{X},y=f_{\theta}(x)\}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.1.pic1.1.m1.6d">caligraphic_K start_POSTSUBSCRIPT W end_POSTSUBSCRIPT = { italic_x , italic_y , italic_θ , caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT , ∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT caligraphic_L ∣ italic_x ∈ caligraphic_X , italic_y = italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) }</annotation></semantics></math></foreignobject></g><g transform="translate(0,13.83700013837) scale(1, -1)"><foreignobject height="10.3777501037775" overflow="visible" width="340.666943406669"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.E1" style="font-size:70%;" title="In 2.3 Access Capabilities ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Eq.</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a></foreignobject></g></g><g transform="translate(-229.69,296.11)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="161.892901618929"><a class="ltx_ref ltx_font_bold" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS2" style="font-size:70%;" title="3.1.2 Gray-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a></foreignobject></g></g><g transform="translate(-311.33,280.89)"><g transform="translate(0,13.83700013837) scale(1, -1)"><foreignobject height="10.3777501037775" overflow="visible" width="304.552373045524"><math alttext="\mathcal{K}_{\text{G}}=\{x,y,\mathcal{A}_{\theta}\mid x\in\mathcal{X},y=f_{%
\theta}(x)\}" class="ltx_Math" display="inline" id="S3.F2.1.pic1.2.m1.5"><semantics id="S3.F2.1.pic1.2.m1.5a"><mrow id="S3.F2.1.pic1.2.m1.5.5" xref="S3.F2.1.pic1.2.m1.5.5.cmml"><msub id="S3.F2.1.pic1.2.m1.5.5.4" xref="S3.F2.1.pic1.2.m1.5.5.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.2.m1.5.5.4.2" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.4.2.cmml">𝒦</mi><mtext id="S3.F2.1.pic1.2.m1.5.5.4.3" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.4.3a.cmml">G</mtext></msub><mo id="S3.F2.1.pic1.2.m1.5.5.3" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.3.cmml">=</mo><mrow id="S3.F2.1.pic1.2.m1.5.5.2.2" xref="S3.F2.1.pic1.2.m1.5.5.2.3.cmml"><mo id="S3.F2.1.pic1.2.m1.5.5.2.2.3" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.3.1.cmml">{</mo><mrow id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.2.cmml"><mi id="S3.F2.1.pic1.2.m1.1.1" mathsize="70%" xref="S3.F2.1.pic1.2.m1.1.1.cmml">x</mi><mo id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.2" mathsize="70%" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.2.cmml">,</mo><mi id="S3.F2.1.pic1.2.m1.2.2" mathsize="70%" xref="S3.F2.1.pic1.2.m1.2.2.cmml">y</mi><mo id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.3" mathsize="70%" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.2.cmml">,</mo><msub id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.2" mathsize="70%" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.2.cmml">𝒜</mi><mi id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.3" mathsize="70%" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.3.cmml">θ</mi></msub></mrow><mo fence="true" id="S3.F2.1.pic1.2.m1.5.5.2.2.4" lspace="0em" mathsize="70%" rspace="0em" xref="S3.F2.1.pic1.2.m1.5.5.2.3.1.cmml">∣</mo><mrow id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.3.cmml"><mrow id="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.cmml"><mi id="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.2" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.2.cmml">x</mi><mo id="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.1" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.3" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.3.cmml">𝒳</mi></mrow><mo id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.3" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.3a.cmml">,</mo><mrow id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.cmml"><mi id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.2" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.2.cmml">y</mi><mo id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.1" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.1.cmml">=</mo><mrow id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.cmml"><msub id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.cmml"><mi id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.2" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.2.cmml">f</mi><mi id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.3" mathsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.3.cmml">θ</mi></msub><mo id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.1" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.1.cmml">⁢</mo><mrow id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.3.2" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.cmml"><mo id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.3.2.1" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.cmml">(</mo><mi id="S3.F2.1.pic1.2.m1.3.3" mathsize="70%" xref="S3.F2.1.pic1.2.m1.3.3.cmml">x</mi><mo id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.3.2.2" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.F2.1.pic1.2.m1.5.5.2.2.5" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.2.m1.5.5.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.1.pic1.2.m1.5b"><apply id="S3.F2.1.pic1.2.m1.5.5.cmml" xref="S3.F2.1.pic1.2.m1.5.5"><eq id="S3.F2.1.pic1.2.m1.5.5.3.cmml" xref="S3.F2.1.pic1.2.m1.5.5.3"></eq><apply id="S3.F2.1.pic1.2.m1.5.5.4.cmml" xref="S3.F2.1.pic1.2.m1.5.5.4"><csymbol cd="ambiguous" id="S3.F2.1.pic1.2.m1.5.5.4.1.cmml" xref="S3.F2.1.pic1.2.m1.5.5.4">subscript</csymbol><ci id="S3.F2.1.pic1.2.m1.5.5.4.2.cmml" xref="S3.F2.1.pic1.2.m1.5.5.4.2">𝒦</ci><ci id="S3.F2.1.pic1.2.m1.5.5.4.3a.cmml" xref="S3.F2.1.pic1.2.m1.5.5.4.3"><mtext id="S3.F2.1.pic1.2.m1.5.5.4.3.cmml" mathsize="49%" xref="S3.F2.1.pic1.2.m1.5.5.4.3">G</mtext></ci></apply><apply id="S3.F2.1.pic1.2.m1.5.5.2.3.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2"><csymbol cd="latexml" id="S3.F2.1.pic1.2.m1.5.5.2.3.1.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.3">conditional-set</csymbol><list id="S3.F2.1.pic1.2.m1.4.4.1.1.1.2.cmml" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.1"><ci id="S3.F2.1.pic1.2.m1.1.1.cmml" xref="S3.F2.1.pic1.2.m1.1.1">𝑥</ci><ci id="S3.F2.1.pic1.2.m1.2.2.cmml" xref="S3.F2.1.pic1.2.m1.2.2">𝑦</ci><apply id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.cmml" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1">subscript</csymbol><ci id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.2">𝒜</ci><ci id="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.3.cmml" xref="S3.F2.1.pic1.2.m1.4.4.1.1.1.1.1.3">𝜃</ci></apply></list><apply id="S3.F2.1.pic1.2.m1.5.5.2.2.2.3.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S3.F2.1.pic1.2.m1.5.5.2.2.2.3a.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1"><in id="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.1.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.1"></in><ci id="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.2.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.2">𝑥</ci><ci id="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.3.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.1.1.3">𝒳</ci></apply><apply id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2"><eq id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.1.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.1"></eq><ci id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.2.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.2">𝑦</ci><apply id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3"><times id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.1.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.1"></times><apply id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.1.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2">subscript</csymbol><ci id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.2.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.2">𝑓</ci><ci id="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.3.cmml" xref="S3.F2.1.pic1.2.m1.5.5.2.2.2.2.2.3.2.3">𝜃</ci></apply><ci id="S3.F2.1.pic1.2.m1.3.3.cmml" xref="S3.F2.1.pic1.2.m1.3.3">𝑥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.1.pic1.2.m1.5c">\mathcal{K}_{\text{G}}=\{x,y,\mathcal{A}_{\theta}\mid x\in\mathcal{X},y=f_{%
\theta}(x)\}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.1.pic1.2.m1.5d">caligraphic_K start_POSTSUBSCRIPT G end_POSTSUBSCRIPT = { italic_x , italic_y , caligraphic_A start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ∣ italic_x ∈ caligraphic_X , italic_y = italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) }</annotation></semantics></math></foreignobject></g><g transform="translate(0,13.83700013837) scale(1, -1)"><foreignobject height="10.3777501037775" overflow="visible" width="304.552373045524"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.E2" style="font-size:70%;" title="In 2.3 Access Capabilities ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Eq.</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a></foreignobject></g></g><g transform="translate(-226.93,128.68)"><g transform="translate(0,8.7173100871731) scale(1, -1)"><foreignobject height="6.7801300678013" overflow="visible" width="164.383561643836"><a class="ltx_ref ltx_font_bold" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS3" style="font-size:70%;" title="3.1.3 Black-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.3</span></a></foreignobject></g></g><g transform="translate(-311.33,113.46)"><g transform="translate(0,13.83700013837) scale(1, -1)"><foreignobject height="10.3777501037775" overflow="visible" width="276.324892763249"><math alttext="\mathcal{K}_{\text{B}}=\{(x,f_{\theta}(x))\mid x\in\mathcal{X}\}" class="ltx_Math" display="inline" id="S3.F2.1.pic1.3.m1.4"><semantics id="S3.F2.1.pic1.3.m1.4a"><mrow id="S3.F2.1.pic1.3.m1.4.4" xref="S3.F2.1.pic1.3.m1.4.4.cmml"><msub id="S3.F2.1.pic1.3.m1.4.4.4" xref="S3.F2.1.pic1.3.m1.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.3.m1.4.4.4.2" mathsize="70%" xref="S3.F2.1.pic1.3.m1.4.4.4.2.cmml">𝒦</mi><mtext id="S3.F2.1.pic1.3.m1.4.4.4.3" mathsize="70%" xref="S3.F2.1.pic1.3.m1.4.4.4.3a.cmml">B</mtext></msub><mo id="S3.F2.1.pic1.3.m1.4.4.3" mathsize="70%" xref="S3.F2.1.pic1.3.m1.4.4.3.cmml">=</mo><mrow id="S3.F2.1.pic1.3.m1.4.4.2.2" xref="S3.F2.1.pic1.3.m1.4.4.2.3.cmml"><mo id="S3.F2.1.pic1.3.m1.4.4.2.2.3" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.3.m1.4.4.2.3.1.cmml">{</mo><mrow id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.2.cmml"><mo id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.2" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.2.cmml">(</mo><mi id="S3.F2.1.pic1.3.m1.2.2" mathsize="70%" xref="S3.F2.1.pic1.3.m1.2.2.cmml">x</mi><mo id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.3" mathsize="70%" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.2.cmml">,</mo><mrow id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.cmml"><msub id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.cmml"><mi id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.2" mathsize="70%" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.2.cmml">f</mi><mi id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.3" mathsize="70%" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.3.cmml">θ</mi></msub><mo id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.1" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.3.2" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.cmml"><mo id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.3.2.1" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.cmml">(</mo><mi id="S3.F2.1.pic1.3.m1.1.1" mathsize="70%" xref="S3.F2.1.pic1.3.m1.1.1.cmml">x</mi><mo id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.3.2.2" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.4" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.2.cmml">)</mo></mrow><mo fence="true" id="S3.F2.1.pic1.3.m1.4.4.2.2.4" lspace="0em" mathsize="70%" rspace="0em" xref="S3.F2.1.pic1.3.m1.4.4.2.3.1.cmml">∣</mo><mrow id="S3.F2.1.pic1.3.m1.4.4.2.2.2" xref="S3.F2.1.pic1.3.m1.4.4.2.2.2.cmml"><mi id="S3.F2.1.pic1.3.m1.4.4.2.2.2.2" mathsize="70%" xref="S3.F2.1.pic1.3.m1.4.4.2.2.2.2.cmml">x</mi><mo id="S3.F2.1.pic1.3.m1.4.4.2.2.2.1" mathsize="70%" xref="S3.F2.1.pic1.3.m1.4.4.2.2.2.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.F2.1.pic1.3.m1.4.4.2.2.2.3" mathsize="70%" xref="S3.F2.1.pic1.3.m1.4.4.2.2.2.3.cmml">𝒳</mi></mrow><mo id="S3.F2.1.pic1.3.m1.4.4.2.2.5" maxsize="70%" minsize="70%" xref="S3.F2.1.pic1.3.m1.4.4.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.1.pic1.3.m1.4b"><apply id="S3.F2.1.pic1.3.m1.4.4.cmml" xref="S3.F2.1.pic1.3.m1.4.4"><eq id="S3.F2.1.pic1.3.m1.4.4.3.cmml" xref="S3.F2.1.pic1.3.m1.4.4.3"></eq><apply id="S3.F2.1.pic1.3.m1.4.4.4.cmml" xref="S3.F2.1.pic1.3.m1.4.4.4"><csymbol cd="ambiguous" id="S3.F2.1.pic1.3.m1.4.4.4.1.cmml" xref="S3.F2.1.pic1.3.m1.4.4.4">subscript</csymbol><ci id="S3.F2.1.pic1.3.m1.4.4.4.2.cmml" xref="S3.F2.1.pic1.3.m1.4.4.4.2">𝒦</ci><ci id="S3.F2.1.pic1.3.m1.4.4.4.3a.cmml" xref="S3.F2.1.pic1.3.m1.4.4.4.3"><mtext id="S3.F2.1.pic1.3.m1.4.4.4.3.cmml" mathsize="49%" xref="S3.F2.1.pic1.3.m1.4.4.4.3">B</mtext></ci></apply><apply id="S3.F2.1.pic1.3.m1.4.4.2.3.cmml" xref="S3.F2.1.pic1.3.m1.4.4.2.2"><csymbol cd="latexml" id="S3.F2.1.pic1.3.m1.4.4.2.3.1.cmml" xref="S3.F2.1.pic1.3.m1.4.4.2.2.3">conditional-set</csymbol><interval closure="open" id="S3.F2.1.pic1.3.m1.3.3.1.1.1.2.cmml" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1"><ci id="S3.F2.1.pic1.3.m1.2.2.cmml" xref="S3.F2.1.pic1.3.m1.2.2">𝑥</ci><apply id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.cmml" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1"><times id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.1"></times><apply id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2">subscript</csymbol><ci id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.2">𝑓</ci><ci id="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S3.F2.1.pic1.3.m1.3.3.1.1.1.1.1.2.3">𝜃</ci></apply><ci id="S3.F2.1.pic1.3.m1.1.1.cmml" xref="S3.F2.1.pic1.3.m1.1.1">𝑥</ci></apply></interval><apply id="S3.F2.1.pic1.3.m1.4.4.2.2.2.cmml" xref="S3.F2.1.pic1.3.m1.4.4.2.2.2"><in id="S3.F2.1.pic1.3.m1.4.4.2.2.2.1.cmml" xref="S3.F2.1.pic1.3.m1.4.4.2.2.2.1"></in><ci id="S3.F2.1.pic1.3.m1.4.4.2.2.2.2.cmml" xref="S3.F2.1.pic1.3.m1.4.4.2.2.2.2">𝑥</ci><ci id="S3.F2.1.pic1.3.m1.4.4.2.2.2.3.cmml" xref="S3.F2.1.pic1.3.m1.4.4.2.2.2.3">𝒳</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.1.pic1.3.m1.4c">\mathcal{K}_{\text{B}}=\{(x,f_{\theta}(x))\mid x\in\mathcal{X}\}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.1.pic1.3.m1.4d">caligraphic_K start_POSTSUBSCRIPT B end_POSTSUBSCRIPT = { ( italic_x , italic_f start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x ) ) ∣ italic_x ∈ caligraphic_X }</annotation></semantics></math></foreignobject></g><g transform="translate(0,13.83700013837) scale(1, -1)"><foreignobject height="10.3777501037775" overflow="visible" width="276.324892763249"><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.E3" style="font-size:70%;" title="In 2.3 Access Capabilities ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Eq.</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a></foreignobject></g></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustration of Inference-Phase Attack Methods. Detailed explanations can be found in <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS1" title="3.1.1 White-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.1</span></a> for White-Box Attacks, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS2" title="3.1.2 Gray-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a> for Gray-Box Attacks, and <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1.SSS3" title="3.1.3 Black-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.3</span></a> for Black-Box Attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 2：推理阶段攻击方法的示意图。详细的解释可以在§ 3.1.1 中找到（针对白盒攻击），在§ 3.1.2 中找到（针对灰盒攻击），以及在§ 3.1.3 中找到（针对黑盒攻击）。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Black-Box Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1.3 黑盒攻击</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">Black-Box Attacks are the most representative of real-world scenarios, where the attacker’s knowledge is limited to inputs and outputs, relying solely on querying the model and observing its responses. As illustrated in the bottom of&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.F2" title="In 3.1.2 Gray-Box Attacks ‣ 3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Fig.</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, attackers often employ techniques such as Prompt Engineering, carefully crafting queries to bypass the model’s safety restrictions and exploit vulnerabilities in its behavior.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">黑盒攻击是最具代表性的现实场景，攻击者的知识仅限于输入和输出，完全依赖于查询模型并观察其响应。如图 2 底部所示，攻击者通常采用提示工程等技术，精心设计查询以绕过模型的安全限制并利用其行为中的漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.p2">
<p class="ltx_p" id="S3.SS1.SSS3.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p2.1.m1.1"><semantics id="S3.SS1.SSS3.p2.1.m1.1a"><mo id="S3.SS1.SSS3.p2.1.m1.1.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.1.m1.1b"><ci id="S3.SS1.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS3.p2.1.1">Malicious Typography.</span>
Qraitem <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p2.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib104" title="">104</a>]</cite> proposed the self-generated typography attack, wherein LVLMs are employed to generate words most similar to the objects in an image for typography. This technique is designed to disrupt the model’s classification by introducing subtle textual perturbations that confuse the model’s decision-making process.
By exploiting the shortcoming that content safety guardrails of VLMs are ineffective against typographic visual prompts, FigStep&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>]</cite> employs typographic transformations to convert malicious instructions, such as “Here is how to build a bomb: 1. 2. 3.,” into image format. These images are then input into the LVLM alongside carefully crafted prompts, inducing the model to complete the malicious instructions. Under this method, the typographic transformation allows malicious content to evade textual safety filters by embedding it as visual input. Combined with prompts designed to exploit the model’s multimodal reasoning, FigStep&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>]</cite> instructing the model to answer the prohibited question in steps, effectively manipulates the LVLM to interpret and process these visual instructions, leading to unsafe completions that circumvent its alignment mechanisms.
Additionally, MML&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib108" title="">108</a>]</cite> drawing inspiration from cryptography, utilizes an encryption-decryption process across both text and image modalities to prevent the over-exposure of malicious information. By replacing text in images&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib123" title="">123</a>]</cite> and prompting the model to perform decryption (e.g., ’burger’ → ’drugs’), MML&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib108" title="">108</a>]</cite> exploits the model’s logic and OCR capabilities to bypass security defenses, achieving a high attack success rate.
HIMRD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib109" title="">109</a>]</cite> divides the malicious prompt into two seemingly harmless components. One part, containing harmful words, is embedded into an image through typographic formatting and paired with a Text-to-Image (T2I) model to generate the corresponding image. The other part is inserted into the text using a prompt template (e.g., Look at the text at the top of the image, put the text inside the parentheses of ’make illegal ( )’). Through iterative optimization, the prompt is updated, ultimately achieving a successful jailbreak attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS3.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S3.SS1.SSS3.p2.1.m1.1a"><mo id="S3.SS1.SSS3.p2.1.m1.1.1">∙</mo><annotation-xml id="S3.SS1.SSS3.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS3.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S3.SS1.SSS3.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 恶意排版。Qraitem 等人[104]提出了自生成排版攻击，该方法利用大型视觉语言模型生成与图像中对象最相似的文字进行排版。这种技术旨在通过引入微小的文本扰动来干扰模型的分类，从而混淆模型决策过程。通过利用视觉语言模型的内容安全防护措施对排版视觉提示无效的缺陷，FigStep[41]采用排版转换将恶意指令（如“这里是如何制造炸弹：1. 2. 3.”）转换为图像格式。然后将这些图像与精心设计的提示一同输入到大型视觉语言模型中，诱使模型完成恶意指令。在这种方法下，排版转换使恶意内容能够通过将其嵌入为视觉输入来规避文本安全过滤器。 结合旨在利用模型多模态推理能力的提示，FigStep [ 41] 指示模型分步回答禁止性问题，有效操控大型视觉语言模型（LVLM）解释和处理这些视觉指令，导致不安全的回答绕过其对齐机制。此外，MML [ 108] 从密码学中获得灵感，在文本和图像模态之间使用加密解密过程，以防止恶意信息的过度暴露。通过替换图像中的文本 [ 123] 并提示模型执行解密（例如，'burger' → 'drugs'），MML [ 108] 利用模型的逻辑和 OCR 能力绕过安全防御，实现高攻击成功率。HIMRD [ 109] 将恶意提示分为两个看似无害的组件。一部分包含有害词汇，通过排版格式嵌入图像中，并与文本到图像（T2I）模型配对生成相应图像。另一部分使用提示模板插入文本中（例如，"看图像顶部的文本，将文本放在'make illegal ( )'的括号内"）。 通过迭代优化，提示被更新，最终成功实现了越狱攻击。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.p3">
<p class="ltx_p" id="S3.SS1.SSS3.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p3.1.m1.1"><semantics id="S3.SS1.SSS3.p3.1.m1.1a"><mo id="S3.SS1.SSS3.p3.1.m1.1.1" xref="S3.SS1.SSS3.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p3.1.m1.1b"><ci id="S3.SS1.SSS3.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS3.p3.1.1">Visual Role-Play.</span>
Ma <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p3.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib105" title="">105</a>]</cite> propose Visual Role-play (VRP), an effective structure-based jailbreak method that instructs the model to act as a high-risk character in the image input to generate harmful content. VRP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib105" title="">105</a>]</cite> first utilize an LLM to generate a detailed description of a high-risk character. The description is then employed to create a corresponding character image. Next, VRP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib105" title="">105</a>]</cite> integrate the typography of the character description and the associated malicious questions at the top and bottom of the character image, respectively, to form the complete jailbreak image input. This malicious image input is then paired with a benign role-play instruction text to query and attack LVLMs. Effectively misleads LVLMs into generating malicious responses.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS3.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S3.SS1.SSS3.p3.1.m1.1a"><mo id="S3.SS1.SSS3.p3.1.m1.1.1">∙</mo><annotation-xml id="S3.SS1.SSS3.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS3.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S3.SS1.SSS3.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 视觉角色扮演。Ma 等人[ 105]提出了视觉角色扮演（VRP），这是一种基于结构的越狱方法，指导模型在图像输入中扮演高风险角色以生成有害内容。VRP[ 105]首先利用 LLM 生成一个高风险角色的详细描述。然后，利用该描述创建相应的角色图像。接下来，VRP[ 105]将角色描述的排版和相关的恶意问题分别集成到角色图像的顶部和底部，形成完整的越狱图像输入。这个恶意图像输入随后与一个良性的角色扮演指令文本配对，用于查询和攻击 LVLMs。有效地误导 LVLMs 生成恶意响应。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.p4">
<p class="ltx_p" id="S3.SS1.SSS3.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p4.1.m1.1"><semantics id="S3.SS1.SSS3.p4.1.m1.1a"><mo id="S3.SS1.SSS3.p4.1.m1.1.1" xref="S3.SS1.SSS3.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p4.1.m1.1b"><ci id="S3.SS1.SSS3.p4.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS3.p4.1.1">Logical Questioning.</span>
Zou <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS3.p4.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib106" title="">106</a>]</cite> explore the use of LVLMs’ logic understanding capabilities, particularly in interpreting flowcharts, for jailbreak attacks. They transform harmful textual instructions into visual flowchart representations, leveraging the model’s multimodal processing to bypass safety measures. This method is further enhanced by integrating visual instructions with textual prompts to generate detailed harmful outputs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS3.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S3.SS1.SSS3.p4.1.m1.1a"><mo id="S3.SS1.SSS3.p4.1.m1.1.1">∙</mo><annotation-xml id="S3.SS1.SSS3.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS3.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S3.SS1.SSS3.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 逻辑提问。Zou 等人[ 106]探索了 LVLM 的逻辑理解能力，特别是在解释流程图方面的应用，用于越狱攻击。他们将有害的文本指令转换为视觉流程图表示，利用模型的多模态处理能力绕过安全措施。该方法通过将视觉指令与文本提示相结合，生成详细的有害输出，进一步得到增强。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS3.p5">
<p class="ltx_p" id="S3.SS1.SSS3.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p5.1.m1.1"><semantics id="S3.SS1.SSS3.p5.1.m1.1a"><mo id="S3.SS1.SSS3.p5.1.m1.1.1" xref="S3.SS1.SSS3.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p5.1.m1.1b"><ci id="S3.SS1.SSS3.p5.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p5.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p5.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S3.SS1.SSS3.p5.1.1">Red Teaming.</span>
IDEATOR<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib107" title="">107</a>]</cite> utilizes LVLMs as red team models to generate multimodal jailbreak prompts. Through an iterative dialogue between the attack and victim models, the system continuously refines and optimizes the generated prompts. This approach effectively explores a wide range of LVLM vulnerabilities without relying on white-box access or manual intervention, showcasing a robust and automated red teaming framework.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S3.SS1.SSS3.p5.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S3.SS1.SSS3.p5.1.m1.1a"><mo id="S3.SS1.SSS3.p5.1.m1.1.1">∙</mo><annotation-xml id="S3.SS1.SSS3.p5.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS1.SSS3.p5.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S3.SS1.SSS3.p5.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 红队测试。IDEATOR[ 107]将 LVLM 用作红队模型，生成多模态越狱提示。通过攻击模型和受害者模型之间的迭代对话，系统不断优化和改进生成的提示。这种方法有效地探索了 LVLM 的多种漏洞，而无需依赖白盒访问或人工干预，展示了一个强大且自动化的红队测试框架。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span class="ltx_text ltx_font_italic" id="S3.SS2.1.1">Training-Phase Attacks</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2 训练阶段攻击</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Training-phase attacks typically necessitate that adversaries have access to training data of the model. By employing diverse data poisoning methodologies, these attacks are categorized into two distinct categories: <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.1">Label Poisoning Attacks</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2.SSS1" title="3.2.1 Label Poisoning Attacks ‣ 3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2.1</span></a>) and <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.2">Backdoor Trigger Attacks</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2.SSS2" title="3.2.2 Backdoor Trigger Attacks ‣ 3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2.2</span></a>). In contrast to Inference-Phase Attacks&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS1" title="3.1 Inference-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1</span></a>, these strategies involve the modification of the model’s parameters, thereby facilitating not only malicious behaviors but also inducing disruptions in responses to benign queries.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">训练阶段攻击通常需要攻击者能够访问模型的训练数据。通过采用多种数据污染方法，这些攻击被分为两类：标签污染攻击（§ 3.2.1）和后门触发攻击（§ 3.2.2）。与推理阶段攻击（§ 3.1）相比，这些策略涉及修改模型的参数，从而不仅能够实现恶意行为，还能导致对良性查询的响应出现干扰。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Label Poisoning Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.1 标签污染攻击</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">LVLMs are predominantly trained through visual instruction tuning methodologies&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib110" title="">110</a>]</cite>.
Rather than relying on conspicuous triggers&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib124" title="">124</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib125" title="">125</a>]</cite> (e.g., specific keywords or unique images), Shadowcast&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib30" title="">30</a>]</cite> operates within a gray-box capability framework by utilizing the vision encoder of LVLMs to introduce noise into images. Shadowcast&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib30" title="">30</a>]</cite> induces LVLMs to misidentify class labels, such as confusing Donald Trump with Joe Biden. Furthermore, poisoned text-image pairs are injected into the training data, causing the model to generate irrelevant or erroneous responses when processing benign inputs. Experiments demonstrate that Shadowcast&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib30" title="">30</a>]</cite> is effective across different LVLM architectures and prompts, and is resilient to image augmentation and compression.
Instead of relying on multiple poisoned samples or complex triggers, ImgTrojan&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib126" title="">126</a>]</cite> employs clean images as Trojan vectors by injecting a single benign image paired with malicious textual prompts—thereby replacing the original captions—into the training dataset. By strategically selecting and crafting malicious prompts, ImgTrojan&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib126" title="">126</a>]</cite> seeks to exploit inherent vulnerabilities within the behavior of LVLMs. Notably, the insertion of merely one poisoned image-text pair has been demonstrated to successfully jailbreak the model with a 50% success rate, inducing it to generate attacker-intended outputs in response to ostensibly benign queries. This demonstrates that even minimal data manipulation can undermine a LVLM’s safety mechanisms.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LVLMs 主要通过视觉指令微调方法进行训练 [14, 15, 110]。与依赖显眼触发器（例如特定关键词或独特图像）[124, 125] 不同，Shadowcast [30] 在灰盒能力框架内运行，通过利用 LVLM 的视觉编码器向图像中引入噪声。Shadowcast [30] 使 LVLM 误识别类别标签，例如将唐纳德·特朗普与乔·拜登混淆。此外，中毒的文本-图像对被注入训练数据中，导致模型在处理良性输入时生成不相关或错误响应。实验表明，Shadowcast [30] 对不同的 LVLM 架构和提示都有效，并且对图像增强和压缩具有抵抗力。ImgTrojan [126] 不依赖多个中毒样本或复杂触发器，而是通过将一个良性图像与恶意文本提示（从而替换原始标题）一起注入训练数据集，将干净图像用作特洛伊木马载体。通过策略性地选择和设计恶意提示，ImgTrojan [126] 试图利用 LVLM 行为中的固有漏洞。 值得注意的是，仅插入一个被污染的图像-文本对就被证明能够以 50%的成功率成功绕过模型，使其在看似无害的查询下生成攻击者期望的输出。这表明即使是微小的数据操作也可能破坏大型视觉语言模型的安全机制。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Backdoor Trigger Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.2 后门触发攻击</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Summary of essential characteristics for reviewed methods in Training-Phase Attacks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2" title="3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2</span></a>).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 III：训练阶段攻击（§ 3.2）中审查方法的本质特征总结</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T3.4" style="width:433.6pt;height:249.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(44.5pt,-25.6pt) scale(1.25841744896369,1.25841744896369) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.4.1">
<tbody><tr class="ltx_tr" id="S3.T3.4.1.1" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_rr ltx_border_t" id="S3.T3.4.1.1.1" style="padding:0.9pt 1.0pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span><span class="ltx_text" id="S3.T3.4.1.1.1.1" style="font-size:90%;background-color:#D8D6C4;">
<span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.1.1.1">Methods<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></span>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.4.1.1.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.2.1" style="font-size:90%;background-color:#D8D6C4;">Venue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">场所</font></font></font></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T3.4.1.1.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T3.4.1.1.3.1" style="font-size:90%;background-color:#D8D6C4;">Highlight<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">重点</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.2">
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_tt" colspan="3" id="S3.T3.4.1.2.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T3.4.1.2.1.1" style="font-size:90%;">Label Poisoning Attacks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2.SSS1" title="3.2.1 Label Poisoning Attacks ‣ 3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2.1</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">标签中毒攻击（§ 3.2.1）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.3" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr ltx_border_t" id="S3.T3.4.1.3.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.3.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">Shadowcast<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib30" title="">30</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.4.1.3.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.3.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[NeurIPS’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T3.4.1.3.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.3.3.1" style="font-size:90%;background-color:#F5F5F0;">Adversarial label replacement<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对抗性标签替换</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S3.T3.4.1.4.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S3.T3.4.1.4.1.1" style="font-size:90%;">ImgTrojan</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T3.4.1.4.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib126" title="">126</a><span class="ltx_text" id="S3.T3.4.1.4.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S3.T3.4.1.4.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.4.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.4.1.4.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.4.3.1" style="font-size:90%;">Inject clean image as trojan<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">将干净图像作为木马注入</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.5">
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_tt" colspan="3" id="S3.T3.4.1.5.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T3.4.1.5.1.1" style="font-size:90%;">Backdoor Trigger Attacks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3.SS2.SSS2" title="3.2.2 Backdoor Trigger Attacks ‣ 3.2 Training-Phase Attacks ‣ 3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2.2</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">后门触发攻击 (§ 3.2.2)</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.6" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr ltx_border_t" id="S3.T3.4.1.6.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.6.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">VL-Trojan<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib31" title="">31</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.4.1.6.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.6.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S3.T3.4.1.6.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.6.3.1" style="font-size:90%;background-color:#F5F5F0;">Poisoned instruction-response pairs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">中毒指令-响应对</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.7">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S3.T3.4.1.7.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S3.T3.4.1.7.1.1" style="font-size:90%;">BadVLMDriver</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T3.4.1.7.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib32" title="">32</a><span class="ltx_text" id="S3.T3.4.1.7.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S3.T3.4.1.7.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.7.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.4.1.7.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.7.3.1" style="font-size:90%;">Backdoor in autonomous driving<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">自动驾驶中的后门</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.8" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S3.T3.4.1.8.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.8.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">MABA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib127" title="">127</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S3.T3.4.1.8.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.8.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.4.1.8.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.8.3.1" style="font-size:90%;background-color:#F5F5F0;">Domain-agnostic triggers<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">领域无关触发器</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.9">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S3.T3.4.1.9.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S3.T3.4.1.9.1.1" style="font-size:90%;">TrojVLM</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S3.T3.4.1.9.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib128" title="">128</a><span class="ltx_text" id="S3.T3.4.1.9.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S3.T3.4.1.9.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.9.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[ECCV’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.4.1.9.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.9.3.1" style="font-size:90%;">Semantic preserving loss<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">语义保留损失</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.10" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S3.T3.4.1.10.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.10.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">VLOOD<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib129" title="">129</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S3.T3.4.1.10.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.10.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.T3.4.1.10.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S3.T3.4.1.10.3.1" style="font-size:90%;background-color:#F5F5F0;">Backdoor using OOD data<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">使用 OOD 数据的后门攻击</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.1.11">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_rr ltx_border_t" id="S3.T3.4.1.11.1" style="padding:0.9pt 1.0pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_t" id="S3.T3.4.1.11.2" style="padding:0.9pt 1.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S3.T3.4.1.11.3" style="padding:0.9pt 1.0pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">In contrast to direct label poisoning, backdoor trigger attacks typically involve training a subtle noise trigger to be embedded within images.
VL-Trojan&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib31" title="">31</a>]</cite> implant backdoors into autoregressive LVLMs through a small set of poisoned instruction-response pairs. While the model maintains normal functionality under standard scenarios, encountering these specially crafted multimodal instructions leads it to produce malicious content. Compared to the diffuse, pattern-based manipulation in Shadowcast&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib30" title="">30</a>]</cite>, VL-Trojan&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib31" title="">31</a>]</cite> centers on a more defined, though still hidden, instruction-based trigger.
MABA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib127" title="">127</a>]</cite> conducts an empirical assessment of the threats posed by mainstream backdoor attacks during the instruction-tuning phase of LVLMs under data distribution shifts. The findings demonstrate that the generalizability of backdoor attacks is positively associated with the independence of trigger patterns from specific data domains or model architectures, as well as with the models’ preference for trigger patterns over clean semantic regions. By utilizing attribution-based interpretation to position domain-agnostic triggers in critical decision-making regions, MABA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib127" title="">127</a>]</cite> improves robustness across domains while mitigating vulnerabilities to backdoor activation.
TrojVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib128" title="">128</a>]</cite> manipulates specific pixels in an image to embed an attack trigger, enabling the model to insert predetermined target text into its output when processing poisoned images. Notably, TrojVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib128" title="">128</a>]</cite> does not compromise the model’s ability to maintain its semantic understanding of the original image, highlighting the subtle yet impactful nature of the attack.
VLOOD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib129" title="">129</a>]</cite> explores backdoor attacks on LVLMs for image-to-text generation using Out-of-Distribution (OOD) data, addressing a realistic scenario where attackers lack access to the original training dataset. VLOOD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib129" title="">129</a>]</cite> framework introduces new loss functions for maintaining conceptual consistency under poisoned inputs, aiming to balance model performance across clean and backdoored samples.
Beyond digital triggers, recent work shows that physical cues can also serve as potent backdoors. In real world, BadVLMDriver&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib32" title="">32</a>]</cite> demonstrates a scenario where adversaries embed triggers into the physical environment, such as signage placed in a driving context. These physical artifacts, when captured by vehicle-mounted cameras and processed by a LVLM integrated into an autonomous driving system, can lead the model astray. Such triggers need not be digital, instead, strategically placed real-world elements can cause the model to misunderstand critical instructions or ignore safety constraints, posing a tangible threat to autonomous vehicles and other systems that rely heavily on LVLM-based perception.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与直接标签污染不同，后门触发攻击通常涉及在图像中嵌入一个微妙的噪声触发器。VL-Trojan [31] 通过一小批污染的指令-响应对将后门植入自回归视觉语言模型。虽然该模型在标准场景下保持正常功能，但遇到这些特别设计的多模态指令时，会导致其生成恶意内容。与 Shadowcast [30] 中那种弥散的、基于模式的操纵相比，VL-Trojan [31] 更侧重于一个更明确、尽管仍然隐藏的基于指令的触发器。MABA [127] 对主流后门攻击在 LVLMs（视觉语言模型）数据分布变化时的指令微调阶段所构成的威胁进行了实证评估。研究结果表明，后门攻击的泛化能力与触发模式与特定数据域或模型架构的独立性呈正相关，同时也与模型对触发模式相对于干净语义区域的偏好程度呈正相关。 通过利用基于归因的解释在关键决策区域定位领域无关的触发器，MABA [ 127] 提高了跨领域的鲁棒性，同时减轻了后门激活的漏洞。TrojVLM [ 128] 通过操纵图像中的特定像素嵌入攻击触发器，使模型在处理中毒图像时能够将其输出的目标文本插入为预定文本。值得注意的是，TrojVLM [ 128] 并未损害模型维持原始图像语义理解的能力，突出了这种攻击的隐蔽性和影响力。VLOOD [ 129] 探索了使用分布外（OOD）数据对 LVLMs 进行图像到文本生成的后门攻击，解决了一种现实场景，即攻击者无法访问原始训练数据集。VLOOD [ 129] 框架引入了新的损失函数，以在中毒输入下保持概念一致性，旨在平衡模型在干净样本和后门样本上的性能。除了数字触发器，最近的研究表明，物理线索也可以作为强大的后门。 在现实世界中，BadVLMDriver [ 32] 展示了一个攻击者将触发器嵌入物理环境的场景，例如在驾驶环境中放置标志物。这些物理物品被车载摄像头捕捉，并由集成到自动驾驶系统中的视觉语言模型（LVLM）处理时，会导致模型产生错误。 这些触发器不必是数字化的，相反，策略性地放置的现实世界元素会导致模型误解关键指令或忽略安全约束，对依赖视觉语言模型（LVLM）感知的自动驾驶车辆和其他系统构成实际威胁。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Defense</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4 防御</font></font></font>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Similar to the attack methods discussed earlier&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S3" title="3 Attack ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>), defense strategies for Large Vision-Language Models&nbsp;(LVLMs) can be systematically classified into two major categories according to the stage of the model’s lifecycle: <span class="ltx_text ltx_font_bold" id="S4.p1.1.1">Inference-Phase Defenses</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1" title="4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1</span></a>) and <span class="ltx_text ltx_font_bold" id="S4.p1.1.2">Training-Phase Defenses</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2" title="4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.2</span></a>).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与前面讨论的攻击方法（§ 3）类似，大型视觉语言模型（LVLMs）的防御策略可以根据模型生命周期的阶段系统地分为两大类：推理阶段防御（§ 4.1）和训练阶段防御（§ 4.2）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span class="ltx_text ltx_font_italic" id="S4.SS1.1.1">Inference-Phase Defenses</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1 推理阶段防御</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Inference-Phase Defenses protect models during deployment, avoiding the high costs and limitations of training-phase defenses. These methods offer lower computational overhead, greater flexibility, and adaptability to new threats without retraining. As post-hoc solutions, they enhance pre-trained models’ safety, providing efficient strategies to improve LVLM robustness during inference.
Specifically, we categorize these strategies into four classes:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理阶段防御在模型部署时提供保护，避免了训练阶段防御的高成本和局限性。这些方法具有较低的计算开销，更高的灵活性和对新威胁的适应性，无需重新训练。作为事后解决方案，它们增强了预训练模型的安全性，为在推理过程中提高 LVLM 鲁棒性提供了有效的策略。具体来说，我们将这些策略分为四类：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Input Sanization Defenses<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1.1 输入净化防御</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Summary of key characteristics of reviewed methods in Inference-Phase Defenses&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1" title="4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1</span></a>). <span class="ltx_ERROR undefined" id="S4.T4.8.1">\faCircle</span>&nbsp;and <span class="ltx_ERROR undefined" id="S4.T4.9.2">\faCircleThin</span>&nbsp;represent Black-Box and White-Box Capability respectively.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 IV：推理阶段防御中（§ 4.1）所审查方法的关键特征总结。\faCircle 和\faCircleThin 分别代表黑盒和白盒能力。</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.10" style="width:433.6pt;height:428.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(25.4pt,-25.1pt) scale(1.1327566121801,1.1327566121801) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T4.10.1">
<tbody><tr class="ltx_tr" id="S4.T4.10.1.1" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_rr ltx_border_t" id="S4.T4.10.1.1.1" style="padding:0.9pt 1.0pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span><span class="ltx_text" id="S4.T4.10.1.1.1.1" style="font-size:90%;background-color:#D8D6C4;">
<span class="ltx_text ltx_font_bold" id="S4.T4.10.1.1.1.1.1">Methods<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></span>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.1.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.10.1.1.2.1" style="font-size:90%;background-color:#D8D6C4;">Venue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">场地</font></font></font></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.1.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.10.1.1.3.1" style="font-size:90%;background-color:#D8D6C4;">Cap.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">章节</font></font></font></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.10.1.1.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.10.1.1.4.1" style="font-size:90%;background-color:#D8D6C4;">Highlight<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">重点</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.2">
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_tt" colspan="4" id="S4.T4.10.1.2.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T4.10.1.2.1.1" style="font-size:90%;">Input Sanization Defenses&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS1" title="4.1.1 Input Sanization Defenses ‣ 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1.1</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">输入净化防御（§ 4.1.1）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.3" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr ltx_border_t" id="S4.T4.10.1.3.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.3.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">AdaShield<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib43" title="">43</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.3.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.3.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ECCV’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.3.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.3.3.1" data-imt_insert_failed="1">\faCircle</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.10.1.3.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.3.4.1" style="font-size:90%;background-color:#F5F5F0;">Defense prompt injection<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">防御提示注入</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.4.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T4.10.1.4.1.1" style="font-size:90%;">SmoothVLM</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.10.1.4.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib130" title="">130</a><span class="ltx_text" id="S4.T4.10.1.4.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.4.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.4.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.4.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.4.3.1" data-imt_insert_failed="1">\faCircleThin</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.4.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.4.4.1" style="font-size:90%;">Randomized smoothing defense<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">随机平滑防御</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.5" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.5.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.5.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">CIDER<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib44" title="">44</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.5.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.5.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[EMNLP’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.5.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.5.3.1" data-imt_insert_failed="1">\faCircle</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.5.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.5.4.1" style="font-size:90%;background-color:#F5F5F0;">Image semantic distance check<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图像语义距离检查</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.6.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T4.10.1.6.1.1" style="font-size:90%;">BlueSuffix</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.10.1.6.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib131" title="">131</a><span class="ltx_text" id="S4.T4.10.1.6.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.6.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.6.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.6.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.6.3.1" data-imt_insert_failed="1">\faCircle</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.6.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.6.4.1" style="font-size:90%;">Image &amp; text purifier<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图像与文本净化器</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.7" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.7.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.7.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">UniGuard<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib132" title="">132</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.7.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.7.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.7.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.7.3.1" data-imt_insert_failed="1">\faCircleThin</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.7.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.7.4.1" style="font-size:90%;background-color:#F5F5F0;">Safe noise &amp; prompt suffix<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全噪声与提示后缀</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.8">
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_tt" colspan="4" id="S4.T4.10.1.8.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T4.10.1.8.1.1" style="font-size:90%;">Internal Optimization Defenses&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS2" title="4.1.2 Internal Optimization Defenses ‣ 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1.2</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">内部优化防御（§ 4.1.2）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.9" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr ltx_border_t" id="S4.T4.10.1.9.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.9.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">InferAligner<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib45" title="">45</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.9.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.9.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[EMNLP’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.9.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.9.3.1" data-imt_insert_failed="1">\faCircleThin</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.10.1.9.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.9.4.1" style="font-size:90%;background-color:#F5F5F0;">Harmful activation difference<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">有害激活差异</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.10">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.10.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T4.10.1.10.1.1" style="font-size:90%;">CoCA</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.10.1.10.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib46" title="">46</a><span class="ltx_text" id="S4.T4.10.1.10.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.10.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.10.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[COLM’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.10.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.10.3.1" data-imt_insert_failed="1">\faCircleThin</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.10.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.10.4.1" style="font-size:90%;">Safe &amp; Unsafe logits bias<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全与不安全 logits 偏差</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.11" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.11.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.11.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">CMRM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib133" title="">133</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.11.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.11.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.11.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.11.3.1" data-imt_insert_failed="1">\faCircleThin</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.11.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.11.4.1" style="font-size:90%;background-color:#F5F5F0;">Correct visual representation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">正确的视觉表示</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.12">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.12.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T4.10.1.12.1.1" style="font-size:90%;">ASTRA</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.10.1.12.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib134" title="">134</a><span class="ltx_text" id="S4.T4.10.1.12.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.12.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.12.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.12.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.12.3.1" data-imt_insert_failed="1">\faCircleThin</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.12.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.12.4.1" style="font-size:90%;">Decompose input image<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">分解输入图像</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.13" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.13.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.13.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">IMMUNE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib135" title="">135</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.13.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.13.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.13.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.13.3.1" data-imt_insert_failed="1">\faCircleThin</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.13.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.13.4.1" style="font-size:90%;background-color:#F5F5F0;">Inference time token alignment<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理时间标记对齐</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.14">
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_tt" colspan="4" id="S4.T4.10.1.14.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T4.10.1.14.1.1" style="font-size:90%;">Output Validation Defenses&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS3" title="4.1.3 Output Validation Defenses ‣ 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1.3</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">输出验证防御（§ 4.1.3）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.15" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr ltx_border_t" id="S4.T4.10.1.15.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.15.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">JailGuard<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib47" title="">47</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.15.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.15.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’23]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.15.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.15.3.1" data-imt_insert_failed="1">\faCircle</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.10.1.15.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.15.4.1" style="font-size:90%;background-color:#F5F5F0;">Mutated query diversity<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">变异查询多样性</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.16">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.16.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T4.10.1.16.1.1" style="font-size:90%;">MLLM-P</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.10.1.16.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib48" title="">48</a><span class="ltx_text" id="S4.T4.10.1.16.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.16.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.16.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[EMNLP’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.16.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.16.3.1" data-imt_insert_failed="1">\faCircle</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.16.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.16.4.1" style="font-size:90%;">Harm detector &amp; response detoxifier<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">伤害检测器 &amp; 响应解毒器</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.17" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.17.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.17.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">ECSO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib136" title="">136</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.17.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.17.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ECCV’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.17.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.17.3.1" data-imt_insert_failed="1">\faCircle</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.17.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.17.4.1" style="font-size:90%;background-color:#F5F5F0;">Transfer visual into textual<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">将视觉转换为文本</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.18">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T4.10.1.18.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T4.10.1.18.1.1" style="font-size:90%;">MirrorCheck</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T4.10.1.18.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib137" title="">137</a><span class="ltx_text" id="S4.T4.10.1.18.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.18.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.18.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T4.10.1.18.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.18.3.1" data-imt_insert_failed="1">\faCircle</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T4.10.1.18.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.18.4.1" style="font-size:90%;">Text-to-image transfer<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">文本到图像转换</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.19">
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_tt" colspan="4" id="S4.T4.10.1.19.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T4.10.1.19.1.1" style="font-size:90%;">Multi-Stage Integration Defenses&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1.SSS4" title="4.1.4 Multi-Stage Integration Defenses ‣ 4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1.4</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多阶段集成防御（§ 4.1.4）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.20" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr ltx_border_t" id="S4.T4.10.1.20.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.20.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">ETA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib28" title="">28</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.20.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.20.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.10.1.20.3" style="padding:0.9pt 1.0pt;"><span class="ltx_ERROR undefined" id="S4.T4.10.1.20.3.1" data-imt_insert_failed="1">\faCircle</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T4.10.1.20.4" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T4.10.1.20.4.1" style="font-size:90%;background-color:#F5F5F0;">Safety score &amp; reward model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全评分与奖励模型</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.10.1.21">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_rr ltx_border_t" id="S4.T4.10.1.21.1" style="padding:0.9pt 1.0pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_t" id="S4.T4.10.1.21.2" style="padding:0.9pt 1.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S4.T4.10.1.21.3" style="padding:0.9pt 1.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S4.T4.10.1.21.4" style="padding:0.9pt 1.0pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">Input data plays a pivotal role throughout the inference process of LVLMs, serving as a primary entry point for attacks. Attack strategies, whether prompt-based or perturbation-based, are meticulously designed to manipulate inputs, exploit model vulnerabilities, and compromise safety mechanisms. Input Sanization Defenses address these threats by analyzing, filtering, and transforming input data to neutralize malicious patterns. Key techniques include prompt engineering and image perturbation, all of which aim to enhance input reliability and reduce susceptibility to attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">输入数据在整个 LVLM 推理过程中起着关键作用，是攻击的主要入口。攻击策略，无论是基于提示还是基于扰动，都经过精心设计以操纵输入、利用模型漏洞并破坏安全机制。输入净化防御通过分析、过滤和转换输入数据来消除恶意模式，从而应对这些威胁。关键技术包括提示工程和图像扰动，所有这些目标都是为了提高输入可靠性并降低遭受攻击的易感性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS1.p2">
<p class="ltx_p" id="S4.SS1.SSS1.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p2.1.m1.1"><semantics id="S4.SS1.SSS1.p2.1.m1.1a"><mo id="S4.SS1.SSS1.p2.1.m1.1.1" xref="S4.SS1.SSS1.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p2.1.m1.1b"><ci id="S4.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS1.p2.1.1">Prompt Engineering.</span>
To defend against prompt-based attacks,
AdaShield&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib43" title="">43</a>]</cite> leverages the instruction-following capabilities of LVLMs by incorporating safety prefixes into the input, aiming to activate the model’s inherent safety mechanisms through prompting techniques. Specifically, the safety prefixes are categorized into fixed and adaptive textual prefixes, which are dynamically optimized based on the characteristics of malicious input queries. By utilizing a defender model to iteratively generate, evaluate, and refine these prompts, AdaShield&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib43" title="">43</a>]</cite> improves the robustness of LVLMs without the need for fine-tuning or additional modules.
BlueSuffix&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib131" title="">131</a>]</cite> employs a diffusion-based method to purify jailbreak images and introduces an LLM-based text purifier to rewrite adversarial textual prompts while preserving their original meaning. Based on the purified data, a trained Suffix Generator is utilized to produce prompt suffixes that guide the model, thereby enhancing its safety capabilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS1.SSS1.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS1.SSS1.p2.1.m1.1a"><mo id="S4.SS1.SSS1.p2.1.m1.1.1">∙</mo><annotation-xml id="S4.SS1.SSS1.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS1.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS1.SSS1.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 提示工程。为了防御基于提示的攻击，AdaShield [ 43] 利用 LVLMs 的指令跟随能力，通过将安全前缀整合到输入中，旨在通过提示技术激活模型的内在安全机制。具体来说，安全前缀被分为固定和自适应文本前缀，这些前缀根据恶意输入查询的特征进行动态优化。通过利用防御模型迭代生成、评估和优化这些提示，AdaShield [ 43] 在无需微调或额外模块的情况下提高了 LVLMs 的鲁棒性。BlueSuffix [ 131] 采用基于扩散的方法净化越狱图像，并引入基于 LLM 的文本净化器来重写对抗性文本提示，同时保留其原始含义。基于净化后的数据，一个训练好的后缀生成器被用于生成引导模型的提示后缀，从而增强其安全能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS1.p3">
<p class="ltx_p" id="S4.SS1.SSS1.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p3.1.m1.1"><semantics id="S4.SS1.SSS1.p3.1.m1.1a"><mo id="S4.SS1.SSS1.p3.1.m1.1.1" xref="S4.SS1.SSS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p3.1.m1.1b"><ci id="S4.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS1.p3.1.1">Image Perturbation.</span>
To address perturbation-based attacks, detecting and removing adversarial noise has proven to be highly effective. Specifically, CIDER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib44" title="">44</a>]</cite> leverages the observation that the semantic distance between clean and adversarial images, relative to harmful queries, exhibits significant differences. As a denoising model, CIDER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib44" title="">44</a>]</cite> iteratively removes noise from the input images and evaluates the semantic distance before and after denoising. If the distance exceeds a predefined threshold, the input is identified as malicious and rejected. CIDER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib44" title="">44</a>]</cite> effectively filters out adversarial inputs while preserving the integrity of benign ones.
Drawing inspiration from SmoothLLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib138" title="">138</a>]</cite>, SmoothVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib130" title="">130</a>]</cite> enhances the robustness of LVLMs against adversarial patch attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib85" title="">85</a>]</cite>, which employs randomized smoothing by introducing controlled noise to input images, which helps mitigate the impact of adversarial patches. Ensures that small, localized perturbations are smoothed out, reducing their ability to mislead the model while maintaining the semantic fidelity of the input. Significantly reduces the success rate of attacks on two leading LVLMs under 5%, while achieving up to 95% context recovery of the benign images, demonstrating a balance between security, usability, and efficiency.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS1.SSS1.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS1.SSS1.p3.1.m1.1a"><mo id="S4.SS1.SSS1.p3.1.m1.1.1">∙</mo><annotation-xml id="S4.SS1.SSS1.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS1.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS1.SSS1.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 图像扰动。为了应对基于扰动的攻击，检测并移除对抗性噪声已被证明非常有效。具体来说，CIDER [ 44] 利用了一个观察结果：相对于有害查询，干净图像和对抗性图像之间的语义距离表现出显著差异。作为去噪模型，CIDER [ 44] 迭代地从输入图像中移除噪声，并在去噪前后评估语义距离。如果距离超过预设阈值，输入就会被识别为恶意并拒绝。CIDER [ 44] 有效过滤掉对抗性输入，同时保留良性输入的完整性。受 SmoothLLM [ 138] 启发，SmoothVLM [ 130] 增强了 LVLMs 对对抗性补丁攻击 [ 23, 27, 85] 的鲁棒性，该攻击通过向输入图像引入受控噪声进行随机平滑，有助于减轻对抗性补丁的影响。确保小的、局部的扰动被平滑掉，从而降低它们误导模型的能力，同时保持输入的语义保真度。 显著降低了针对两个领先 LVLM 的攻击成功率至 5%以下，同时实现了良性图像高达 95%的上下文恢复，展示了在安全性、可用性和效率之间的平衡。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS1.p4">
<p class="ltx_p" id="S4.SS1.SSS1.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS1.p4.1.m1.1"><semantics id="S4.SS1.SSS1.p4.1.m1.1a"><mo id="S4.SS1.SSS1.p4.1.m1.1.1" xref="S4.SS1.SSS1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p4.1.m1.1b"><ci id="S4.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS1.p4.1.1">Hybrid Perturbation.</span>
UniGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib132" title="">132</a>]</cite> combines prompt engineering and image perturbation, jointly addressing unimodal and cross-modal harmful inputs. Specifically, UniGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib132" title="">132</a>]</cite> introduces additive safe noise for image inputs and applies suffix modifications to text prompts, effectively reducing the likelihood of generating unsafe responses. By training on a targeted small corpus of toxic content, UniGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib132" title="">132</a>]</cite> achieves significant robustness against a wide range of adversarial attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS1.SSS1.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS1.SSS1.p4.1.m1.1a"><mo id="S4.SS1.SSS1.p4.1.m1.1.1">∙</mo><annotation-xml id="S4.SS1.SSS1.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS1.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS1.SSS1.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 混合扰动。UniGuard [ 132] 结合了提示工程和图像扰动，共同处理单模态和跨模态的有害输入。具体来说，UniGuard [ 132] 为图像输入引入加性安全噪声，并对文本提示应用后缀修改，有效降低了生成不安全响应的可能性。通过在有毒内容的小型目标语料库上训练，UniGuard [ 132] 实现了对广泛对抗性攻击的显著鲁棒性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Internal Optimization Defenses<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1.2 内部优化防御</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">As the critical stage determining model outputs, the generation of unsafe responses in LVLMs is heavily influenced by the alignment and robustness of their internal safety mechanisms. As discussed earlier in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S2.SS2" title="2.2 Unique Vulnerabilities of LVLMs ‣ 2 Background ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">2.2</span></a>, the safety capabilities of LVLMs are particularly impacted by the vision modality, which often lags behind the text modality due to insufficient alignment at the hidden states. To address these vulnerabilities, internal-level defenses enhance model safety by directly intervening in its internal activations, representations, and computation processes. Closely related methods mainly divide into two factions.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">作为决定模型输出的关键阶段，LVLMs 中不安全响应的产生受到其内部安全机制对齐性和鲁棒性的严重影响。如§ 2.2 中所述，LVLMs 的安全能力特别受视觉模态的影响，由于隐藏状态对齐不足，视觉模态往往落后于文本模态。为解决这些漏洞，内部级别的防御通过直接干预其内部激活、表征和计算过程来增强模型安全性。密切相关的方法主要分为两大阵营。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.1.m1.1"><semantics id="S4.SS1.SSS2.p2.1.m1.1a"><mo id="S4.SS1.SSS2.p2.1.m1.1.1" xref="S4.SS1.SSS2.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.1.m1.1b"><ci id="S4.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p2.2.1">Activation Alignment.</span>
As researches in LLM safety&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib139" title="">139</a>]</cite>, the model’s parameter activations exhibit noticeable differences when processing safe and unsafe requests respectively.
To leverage this observation, InferAligner&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib45" title="">45</a>]</cite> calculates the mean activation difference of the last token between harmful and harmless prompts. Based on this calculation, a threshold is established to identify unsafe responses. When the activation value of a token surpasses the threshold, the mean activation difference is applied to bias-correct the output, effectively mitigating unsafe content and ensuring more secure and reliable responses.
Additionally, CMRM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib133" title="">133</a>]</cite> highlights that LVLMs exhibit vulnerabilities when queried with images but tend to restore safety when images are excluded. To address this issue, CMRM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib133" title="">133</a>]</cite> computes the hidden state activation bias between pure text inputs and text-image inputs at the same layer <math alttext="l" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.2.m2.1"><semantics id="S4.SS1.SSS2.p2.2.m2.1a"><mi id="S4.SS1.SSS2.p2.2.m2.1.1" xref="S4.SS1.SSS2.p2.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.2.m2.1b"><ci id="S4.SS1.SSS2.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS2.p2.2.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.2.m2.1c">l</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.2.m2.1d">italic_l</annotation></semantics></math>, as defined:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS1.SSS2.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS1.SSS2.p2.1.m1.1a"><mo id="S4.SS1.SSS2.p2.1.m1.1.1">∙</mo><annotation-xml id="S4.SS1.SSS2.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS2.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS1.SSS2.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 激活对齐。在 LLM 安全研究[ 139]中，模型在处理安全请求与不安全请求时，其参数激活表现出明显差异。为利用这一观察结果，InferAligner[ 45]计算了有害提示和无害提示之间最后一个 token 的平均激活差异。基于此计算，建立了一个阈值来识别不安全响应。当 token 的激活值超过阈值时，将应用平均激活差异对输出进行偏差校正，有效减轻不安全内容并确保更安全可靠的响应。此外，CMRM[ 133]指出，LVLMs 在接收图像查询时表现出漏洞，但在排除图像时倾向于恢复安全性。为解决此问题，CMRM[ 133]计算了同一层纯文本输入与文本-图像输入之间的隐藏状态激活偏差，定义如下： <math id="S4.SS1.SSS2.p2.2.m2.1" display="inline" class="ltx_Math" alttext="l"><semantics id="S4.SS1.SSS2.p2.2.m2.1a"><mi id="S4.SS1.SSS2.p2.2.m2.1.1">l</mi><annotation-xml id="S4.SS1.SSS2.p2.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS2.p2.2.m2.1c" encoding="application/x-tex">l</annotation><annotation id="S4.SS1.SSS2.p2.2.m2.1d" encoding="application/x-llamapun">italic_l</annotation></semantics></math> </font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.E11">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Bias^{l}=\text{PCA}\left(\left\{\mathbf{h}_{t}^{l(i)}-\mathbf{h}_{c}^{l(i)}%
\right\}_{i=1}^{N}\right)," class="ltx_Math" display="block" id="S4.E11.m1.3"><semantics id="S4.E11.m1.3a"><mrow id="S4.E11.m1.3.3.1" xref="S4.E11.m1.3.3.1.1.cmml"><mrow id="S4.E11.m1.3.3.1.1" xref="S4.E11.m1.3.3.1.1.cmml"><mrow id="S4.E11.m1.3.3.1.1.3" xref="S4.E11.m1.3.3.1.1.3.cmml"><mi id="S4.E11.m1.3.3.1.1.3.2" xref="S4.E11.m1.3.3.1.1.3.2.cmml">B</mi><mo id="S4.E11.m1.3.3.1.1.3.1" xref="S4.E11.m1.3.3.1.1.3.1.cmml">⁢</mo><mi id="S4.E11.m1.3.3.1.1.3.3" xref="S4.E11.m1.3.3.1.1.3.3.cmml">i</mi><mo id="S4.E11.m1.3.3.1.1.3.1a" xref="S4.E11.m1.3.3.1.1.3.1.cmml">⁢</mo><mi id="S4.E11.m1.3.3.1.1.3.4" xref="S4.E11.m1.3.3.1.1.3.4.cmml">a</mi><mo id="S4.E11.m1.3.3.1.1.3.1b" xref="S4.E11.m1.3.3.1.1.3.1.cmml">⁢</mo><msup id="S4.E11.m1.3.3.1.1.3.5" xref="S4.E11.m1.3.3.1.1.3.5.cmml"><mi id="S4.E11.m1.3.3.1.1.3.5.2" xref="S4.E11.m1.3.3.1.1.3.5.2.cmml">s</mi><mi id="S4.E11.m1.3.3.1.1.3.5.3" xref="S4.E11.m1.3.3.1.1.3.5.3.cmml">l</mi></msup></mrow><mo id="S4.E11.m1.3.3.1.1.2" xref="S4.E11.m1.3.3.1.1.2.cmml">=</mo><mrow id="S4.E11.m1.3.3.1.1.1" xref="S4.E11.m1.3.3.1.1.1.cmml"><mtext id="S4.E11.m1.3.3.1.1.1.3" xref="S4.E11.m1.3.3.1.1.1.3a.cmml">PCA</mtext><mo id="S4.E11.m1.3.3.1.1.1.2" xref="S4.E11.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S4.E11.m1.3.3.1.1.1.1.1" xref="S4.E11.m1.3.3.1.1.1.1.1.1.cmml"><mo id="S4.E11.m1.3.3.1.1.1.1.1.2" xref="S4.E11.m1.3.3.1.1.1.1.1.1.cmml">(</mo><msubsup id="S4.E11.m1.3.3.1.1.1.1.1.1" xref="S4.E11.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.2.cmml"><mo id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">{</mo><mrow id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">𝐡</mi><mi id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">t</mi><mrow id="S4.E11.m1.1.1.1" xref="S4.E11.m1.1.1.1.cmml"><mi id="S4.E11.m1.1.1.1.3" xref="S4.E11.m1.1.1.1.3.cmml">l</mi><mo id="S4.E11.m1.1.1.1.2" xref="S4.E11.m1.1.1.1.2.cmml">⁢</mo><mrow id="S4.E11.m1.1.1.1.4.2" xref="S4.E11.m1.1.1.1.cmml"><mo id="S4.E11.m1.1.1.1.4.2.1" stretchy="false" xref="S4.E11.m1.1.1.1.cmml">(</mo><mi id="S4.E11.m1.1.1.1.1" xref="S4.E11.m1.1.1.1.1.cmml">i</mi><mo id="S4.E11.m1.1.1.1.4.2.2" stretchy="false" xref="S4.E11.m1.1.1.1.cmml">)</mo></mrow></mrow></msubsup><mo id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msubsup id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">𝐡</mi><mi id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">c</mi><mrow id="S4.E11.m1.2.2.1" xref="S4.E11.m1.2.2.1.cmml"><mi id="S4.E11.m1.2.2.1.3" xref="S4.E11.m1.2.2.1.3.cmml">l</mi><mo id="S4.E11.m1.2.2.1.2" xref="S4.E11.m1.2.2.1.2.cmml">⁢</mo><mrow id="S4.E11.m1.2.2.1.4.2" xref="S4.E11.m1.2.2.1.cmml"><mo id="S4.E11.m1.2.2.1.4.2.1" stretchy="false" xref="S4.E11.m1.2.2.1.cmml">(</mo><mi id="S4.E11.m1.2.2.1.1" xref="S4.E11.m1.2.2.1.1.cmml">i</mi><mo id="S4.E11.m1.2.2.1.4.2.2" stretchy="false" xref="S4.E11.m1.2.2.1.cmml">)</mo></mrow></mrow></msubsup></mrow><mo id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.E11.m1.3.3.1.1.1.1.1.1.1.3" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.2" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.1" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.1.cmml">=</mo><mn id="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.3" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.E11.m1.3.3.1.1.1.1.1.1.3" xref="S4.E11.m1.3.3.1.1.1.1.1.1.3.cmml">N</mi></msubsup><mo id="S4.E11.m1.3.3.1.1.1.1.1.3" xref="S4.E11.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E11.m1.3.3.1.2" xref="S4.E11.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E11.m1.3b"><apply id="S4.E11.m1.3.3.1.1.cmml" xref="S4.E11.m1.3.3.1"><eq id="S4.E11.m1.3.3.1.1.2.cmml" xref="S4.E11.m1.3.3.1.1.2"></eq><apply id="S4.E11.m1.3.3.1.1.3.cmml" xref="S4.E11.m1.3.3.1.1.3"><times id="S4.E11.m1.3.3.1.1.3.1.cmml" xref="S4.E11.m1.3.3.1.1.3.1"></times><ci id="S4.E11.m1.3.3.1.1.3.2.cmml" xref="S4.E11.m1.3.3.1.1.3.2">𝐵</ci><ci id="S4.E11.m1.3.3.1.1.3.3.cmml" xref="S4.E11.m1.3.3.1.1.3.3">𝑖</ci><ci id="S4.E11.m1.3.3.1.1.3.4.cmml" xref="S4.E11.m1.3.3.1.1.3.4">𝑎</ci><apply id="S4.E11.m1.3.3.1.1.3.5.cmml" xref="S4.E11.m1.3.3.1.1.3.5"><csymbol cd="ambiguous" id="S4.E11.m1.3.3.1.1.3.5.1.cmml" xref="S4.E11.m1.3.3.1.1.3.5">superscript</csymbol><ci id="S4.E11.m1.3.3.1.1.3.5.2.cmml" xref="S4.E11.m1.3.3.1.1.3.5.2">𝑠</ci><ci id="S4.E11.m1.3.3.1.1.3.5.3.cmml" xref="S4.E11.m1.3.3.1.1.3.5.3">𝑙</ci></apply></apply><apply id="S4.E11.m1.3.3.1.1.1.cmml" xref="S4.E11.m1.3.3.1.1.1"><times id="S4.E11.m1.3.3.1.1.1.2.cmml" xref="S4.E11.m1.3.3.1.1.1.2"></times><ci id="S4.E11.m1.3.3.1.1.1.3a.cmml" xref="S4.E11.m1.3.3.1.1.1.3"><mtext id="S4.E11.m1.3.3.1.1.1.3.cmml" xref="S4.E11.m1.3.3.1.1.1.3">PCA</mtext></ci><apply id="S4.E11.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E11.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1">superscript</csymbol><apply id="S4.E11.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E11.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1">subscript</csymbol><set id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1"><apply id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1"><minus id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.2">𝐡</ci><ci id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.2.3">𝑡</ci></apply><apply id="S4.E11.m1.1.1.1.cmml" xref="S4.E11.m1.1.1.1"><times id="S4.E11.m1.1.1.1.2.cmml" xref="S4.E11.m1.1.1.1.2"></times><ci id="S4.E11.m1.1.1.1.3.cmml" xref="S4.E11.m1.1.1.1.3">𝑙</ci><ci id="S4.E11.m1.1.1.1.1.cmml" xref="S4.E11.m1.1.1.1.1">𝑖</ci></apply></apply><apply id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.2">𝐡</ci><ci id="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.3">𝑐</ci></apply><apply id="S4.E11.m1.2.2.1.cmml" xref="S4.E11.m1.2.2.1"><times id="S4.E11.m1.2.2.1.2.cmml" xref="S4.E11.m1.2.2.1.2"></times><ci id="S4.E11.m1.2.2.1.3.cmml" xref="S4.E11.m1.2.2.1.3">𝑙</ci><ci id="S4.E11.m1.2.2.1.1.cmml" xref="S4.E11.m1.2.2.1.1">𝑖</ci></apply></apply></apply></set><apply id="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.3"><eq id="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.1"></eq><ci id="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.2">𝑖</ci><cn id="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S4.E11.m1.3.3.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.E11.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S4.E11.m1.3.3.1.1.1.1.1.1.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E11.m1.3c">Bias^{l}=\text{PCA}\left(\left\{\mathbf{h}_{t}^{l(i)}-\mathbf{h}_{c}^{l(i)}%
\right\}_{i=1}^{N}\right),</annotation><annotation encoding="application/x-llamapun" id="S4.E11.m1.3d">italic_B italic_i italic_a italic_s start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = PCA ( { bold_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l ( italic_i ) end_POSTSUPERSCRIPT - bold_h start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l ( italic_i ) end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.SSS2.p2.7">where <math alttext="\mathbf{h}_{t}^{l(i)}" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.3.m1.1"><semantics id="S4.SS1.SSS2.p2.3.m1.1a"><msubsup id="S4.SS1.SSS2.p2.3.m1.1.2" xref="S4.SS1.SSS2.p2.3.m1.1.2.cmml"><mi id="S4.SS1.SSS2.p2.3.m1.1.2.2.2" xref="S4.SS1.SSS2.p2.3.m1.1.2.2.2.cmml">𝐡</mi><mi id="S4.SS1.SSS2.p2.3.m1.1.2.2.3" xref="S4.SS1.SSS2.p2.3.m1.1.2.2.3.cmml">t</mi><mrow id="S4.SS1.SSS2.p2.3.m1.1.1.1" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.cmml"><mi id="S4.SS1.SSS2.p2.3.m1.1.1.1.3" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.3.cmml">l</mi><mo id="S4.SS1.SSS2.p2.3.m1.1.1.1.2" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.2.cmml">⁢</mo><mrow id="S4.SS1.SSS2.p2.3.m1.1.1.1.4.2" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.cmml"><mo id="S4.SS1.SSS2.p2.3.m1.1.1.1.4.2.1" stretchy="false" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.cmml">(</mo><mi id="S4.SS1.SSS2.p2.3.m1.1.1.1.1" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.1.cmml">i</mi><mo id="S4.SS1.SSS2.p2.3.m1.1.1.1.4.2.2" stretchy="false" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.cmml">)</mo></mrow></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.3.m1.1b"><apply id="S4.SS1.SSS2.p2.3.m1.1.2.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p2.3.m1.1.2.1.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.2">superscript</csymbol><apply id="S4.SS1.SSS2.p2.3.m1.1.2.2.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p2.3.m1.1.2.2.1.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.2">subscript</csymbol><ci id="S4.SS1.SSS2.p2.3.m1.1.2.2.2.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.2.2.2">𝐡</ci><ci id="S4.SS1.SSS2.p2.3.m1.1.2.2.3.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.2.2.3">𝑡</ci></apply><apply id="S4.SS1.SSS2.p2.3.m1.1.1.1.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.1.1"><times id="S4.SS1.SSS2.p2.3.m1.1.1.1.2.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.2"></times><ci id="S4.SS1.SSS2.p2.3.m1.1.1.1.3.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.3">𝑙</ci><ci id="S4.SS1.SSS2.p2.3.m1.1.1.1.1.cmml" xref="S4.SS1.SSS2.p2.3.m1.1.1.1.1">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.3.m1.1c">\mathbf{h}_{t}^{l(i)}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.3.m1.1d">bold_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\mathbf{h}_{c}^{l(i)}" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.4.m2.1"><semantics id="S4.SS1.SSS2.p2.4.m2.1a"><msubsup id="S4.SS1.SSS2.p2.4.m2.1.2" xref="S4.SS1.SSS2.p2.4.m2.1.2.cmml"><mi id="S4.SS1.SSS2.p2.4.m2.1.2.2.2" xref="S4.SS1.SSS2.p2.4.m2.1.2.2.2.cmml">𝐡</mi><mi id="S4.SS1.SSS2.p2.4.m2.1.2.2.3" xref="S4.SS1.SSS2.p2.4.m2.1.2.2.3.cmml">c</mi><mrow id="S4.SS1.SSS2.p2.4.m2.1.1.1" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.cmml"><mi id="S4.SS1.SSS2.p2.4.m2.1.1.1.3" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.3.cmml">l</mi><mo id="S4.SS1.SSS2.p2.4.m2.1.1.1.2" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.2.cmml">⁢</mo><mrow id="S4.SS1.SSS2.p2.4.m2.1.1.1.4.2" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.cmml"><mo id="S4.SS1.SSS2.p2.4.m2.1.1.1.4.2.1" stretchy="false" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.cmml">(</mo><mi id="S4.SS1.SSS2.p2.4.m2.1.1.1.1" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.1.cmml">i</mi><mo id="S4.SS1.SSS2.p2.4.m2.1.1.1.4.2.2" stretchy="false" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.cmml">)</mo></mrow></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.4.m2.1b"><apply id="S4.SS1.SSS2.p2.4.m2.1.2.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p2.4.m2.1.2.1.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.2">superscript</csymbol><apply id="S4.SS1.SSS2.p2.4.m2.1.2.2.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p2.4.m2.1.2.2.1.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.2">subscript</csymbol><ci id="S4.SS1.SSS2.p2.4.m2.1.2.2.2.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.2.2.2">𝐡</ci><ci id="S4.SS1.SSS2.p2.4.m2.1.2.2.3.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.2.2.3">𝑐</ci></apply><apply id="S4.SS1.SSS2.p2.4.m2.1.1.1.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.1.1"><times id="S4.SS1.SSS2.p2.4.m2.1.1.1.2.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.2"></times><ci id="S4.SS1.SSS2.p2.4.m2.1.1.1.3.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.3">𝑙</ci><ci id="S4.SS1.SSS2.p2.4.m2.1.1.1.1.cmml" xref="S4.SS1.SSS2.p2.4.m2.1.1.1.1">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.4.m2.1c">\mathbf{h}_{c}^{l(i)}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.4.m2.1d">bold_h start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math> represent the hidden state activations of the <math alttext="i" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.5.m3.1"><semantics id="S4.SS1.SSS2.p2.5.m3.1a"><mi id="S4.SS1.SSS2.p2.5.m3.1.1" xref="S4.SS1.SSS2.p2.5.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.5.m3.1b"><ci id="S4.SS1.SSS2.p2.5.m3.1.1.cmml" xref="S4.SS1.SSS2.p2.5.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.5.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.5.m3.1d">italic_i</annotation></semantics></math>-th input in the <math alttext="l" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.6.m4.1"><semantics id="S4.SS1.SSS2.p2.6.m4.1a"><mi id="S4.SS1.SSS2.p2.6.m4.1.1" xref="S4.SS1.SSS2.p2.6.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.6.m4.1b"><ci id="S4.SS1.SSS2.p2.6.m4.1.1.cmml" xref="S4.SS1.SSS2.p2.6.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.6.m4.1c">l</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.6.m4.1d">italic_l</annotation></semantics></math>-th layer for pure text input and text-image input, respectively. Here, <math alttext="N" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p2.7.m5.1"><semantics id="S4.SS1.SSS2.p2.7.m5.1a"><mi id="S4.SS1.SSS2.p2.7.m5.1.1" xref="S4.SS1.SSS2.p2.7.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.7.m5.1b"><ci id="S4.SS1.SSS2.p2.7.m5.1.1.cmml" xref="S4.SS1.SSS2.p2.7.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.7.m5.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.7.m5.1d">italic_N</annotation></semantics></math> denotes the total number of samples in the dataset. By applying PCA (Principal Component Analysis) to the activation differences, CMRM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib133" title="">133</a>]</cite> identifies the principal direction of variation caused by the visual input. This bias is then used to correct the visual-induced misalignment, aligning multimodal representations closer to the original LLM text-only distribution while retaining the benefits of visual information.
To defend against adversarial jailbreaks, ASTRA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib134" title="">134</a>]</cite> decomposes input images to identify regions with high correlation to the attack. Based on these regions, steering vectors are constructed to capture adversarial directions in the activation space. During inference, ASTRA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib134" title="">134</a>]</cite> projects the model’s activations onto the steering vectors and applies corrections to remove components aligned with the jailbreak-related directions, thereby mitigating adversarial influence while maintaining the model’s performance.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在纯文本输入和文本-图像输入中， <math id="S4.SS1.SSS2.p2.3.m1.1" display="inline" class="ltx_Math" alttext="\mathbf{h}_{t}^{l(i)}"><semantics id="S4.SS1.SSS2.p2.3.m1.1a"><msubsup id="S4.SS1.SSS2.p2.3.m1.1.2"><mi id="S4.SS1.SSS2.p2.3.m1.1.2.2.2">𝐡</mi><mi id="S4.SS1.SSS2.p2.3.m1.1.2.2.3">t</mi><mrow id="S4.SS1.SSS2.p2.3.m1.1.1.1"><mi id="S4.SS1.SSS2.p2.3.m1.1.1.1.3">l</mi><mo id="S4.SS1.SSS2.p2.3.m1.1.1.1.2">⁢</mo><mrow id="S4.SS1.SSS2.p2.3.m1.1.1.1.4.2"><mo stretchy="false" id="S4.SS1.SSS2.p2.3.m1.1.1.1.4.2.1">(</mo><mi id="S4.SS1.SSS2.p2.3.m1.1.1.1.1">i</mi><mo stretchy="false" id="S4.SS1.SSS2.p2.3.m1.1.1.1.4.2.2">)</mo></mrow></mrow></msubsup><annotation-xml id="S4.SS1.SSS2.p2.3.m1.1b" encoding="MathML-Content">superscriptsubscript</annotation-xml><annotation id="S4.SS1.SSS2.p2.3.m1.1c" encoding="application/x-tex">\mathbf{h}_{t}^{l(i)}</annotation><annotation id="S4.SS1.SSS2.p2.3.m1.1d" encoding="application/x-llamapun">bold_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math> 和 <math id="S4.SS1.SSS2.p2.4.m2.1" display="inline" class="ltx_Math" alttext="\mathbf{h}_{c}^{l(i)}"><semantics id="S4.SS1.SSS2.p2.4.m2.1a"><msubsup id="S4.SS1.SSS2.p2.4.m2.1.2"><mi id="S4.SS1.SSS2.p2.4.m2.1.2.2.2">𝐡</mi><mi id="S4.SS1.SSS2.p2.4.m2.1.2.2.3">c</mi><mrow id="S4.SS1.SSS2.p2.4.m2.1.1.1"><mi id="S4.SS1.SSS2.p2.4.m2.1.1.1.3">l</mi><mo id="S4.SS1.SSS2.p2.4.m2.1.1.1.2">⁢</mo><mrow id="S4.SS1.SSS2.p2.4.m2.1.1.1.4.2"><mo stretchy="false" id="S4.SS1.SSS2.p2.4.m2.1.1.1.4.2.1">(</mo><mi id="S4.SS1.SSS2.p2.4.m2.1.1.1.1">i</mi><mo stretchy="false" id="S4.SS1.SSS2.p2.4.m2.1.1.1.4.2.2">)</mo></mrow></mrow></msubsup><annotation-xml id="S4.SS1.SSS2.p2.4.m2.1b" encoding="MathML-Content">superscriptsubscript</annotation-xml><annotation id="S4.SS1.SSS2.p2.4.m2.1c" encoding="application/x-tex">\mathbf{h}_{c}^{l(i)}</annotation><annotation id="S4.SS1.SSS2.p2.4.m2.1d" encoding="application/x-llamapun">bold_h start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math> 分别表示第 <math id="S4.SS1.SSS2.p2.5.m3.1" display="inline" class="ltx_Math" alttext="i"><semantics id="S4.SS1.SSS2.p2.5.m3.1a"><mi id="S4.SS1.SSS2.p2.5.m3.1.1">i</mi><annotation-xml id="S4.SS1.SSS2.p2.5.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS2.p2.5.m3.1c" encoding="application/x-tex">i</annotation><annotation id="S4.SS1.SSS2.p2.5.m3.1d" encoding="application/x-llamapun">italic_i</annotation></semantics></math> 个输入在第 <math id="S4.SS1.SSS2.p2.6.m4.1" display="inline" class="ltx_Math" alttext="l"><semantics id="S4.SS1.SSS2.p2.6.m4.1a"><mi id="S4.SS1.SSS2.p2.6.m4.1.1">l</mi><annotation-xml id="S4.SS1.SSS2.p2.6.m4.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS2.p2.6.m4.1c" encoding="application/x-tex">l</annotation><annotation id="S4.SS1.SSS2.p2.6.m4.1d" encoding="application/x-llamapun">italic_l</annotation></semantics></math> 层的隐藏状态激活。这里， <math id="S4.SS1.SSS2.p2.7.m5.1" display="inline" class="ltx_Math" alttext="N"><semantics id="S4.SS1.SSS2.p2.7.m5.1a"><mi id="S4.SS1.SSS2.p2.7.m5.1.1">N</mi><annotation-xml id="S4.SS1.SSS2.p2.7.m5.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS2.p2.7.m5.1c" encoding="application/x-tex">N</annotation><annotation id="S4.SS1.SSS2.p2.7.m5.1d" encoding="application/x-llamapun">italic_N</annotation></semantics></math> 表示数据集中的样本总数。通过将主成分分析（PCA）应用于激活差异，CMRM [ 133] 识别出由视觉输入引起的变异主方向。然后利用这种偏差来纠正视觉引起的错位，使多模态表示更接近原始 LLM 文本分布，同时保留视觉信息的好处。为了防御对抗性越狱攻击，ASTRA [ 134] 将输入图像分解以识别与攻击高度相关的区域。基于这些区域，构建引导向量以捕获激活空间中的对抗方向。在推理过程中，ASTRA [ 134] 将模型的激活投影到引导向量上，并对与越狱相关方向对齐的分量应用校正，从而减轻对抗影响，同时保持模型性能。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS2.p3">
<p class="ltx_p" id="S4.SS1.SSS2.p3.2"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p3.1.m1.1"><semantics id="S4.SS1.SSS2.p3.1.m1.1a"><mo id="S4.SS1.SSS2.p3.1.m1.1.1" xref="S4.SS1.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p3.1.m1.1b"><ci id="S4.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS2.p3.2.1">Logits Adjustment.</span>
CoCA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib46" title="">46</a>]</cite> introducing a safe instruction to harmful queries and calculating the resulting logits bias. This bias represents the adjustment required to align the model’s outputs with safer responses. During inference, the logits bias is directly applied to the model’s output layer, allowing it to maintain robust safety capabilities without explicitly adding safe instructions to the input.
Similar to CoCA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib46" title="">46</a>]</cite>, IMMUNE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib135" title="">135</a>]</cite> enhances the safety of model outputs by aligning responses during the inference stage. Instead of explicitly modifying inputs, IMMUNE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib135" title="">135</a>]</cite> evaluates the safety of candidate tokens by introducing a safe reward model <math alttext="Q_{\text{safe}}" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p3.2.m2.1"><semantics id="S4.SS1.SSS2.p3.2.m2.1a"><msub id="S4.SS1.SSS2.p3.2.m2.1.1" xref="S4.SS1.SSS2.p3.2.m2.1.1.cmml"><mi id="S4.SS1.SSS2.p3.2.m2.1.1.2" xref="S4.SS1.SSS2.p3.2.m2.1.1.2.cmml">Q</mi><mtext id="S4.SS1.SSS2.p3.2.m2.1.1.3" xref="S4.SS1.SSS2.p3.2.m2.1.1.3a.cmml">safe</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p3.2.m2.1b"><apply id="S4.SS1.SSS2.p3.2.m2.1.1.cmml" xref="S4.SS1.SSS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p3.2.m2.1.1.1.cmml" xref="S4.SS1.SSS2.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS2.p3.2.m2.1.1.2.cmml" xref="S4.SS1.SSS2.p3.2.m2.1.1.2">𝑄</ci><ci id="S4.SS1.SSS2.p3.2.m2.1.1.3a.cmml" xref="S4.SS1.SSS2.p3.2.m2.1.1.3"><mtext id="S4.SS1.SSS2.p3.2.m2.1.1.3.cmml" mathsize="70%" xref="S4.SS1.SSS2.p3.2.m2.1.1.3">safe</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p3.2.m2.1c">Q_{\text{safe}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p3.2.m2.1d">italic_Q start_POSTSUBSCRIPT safe end_POSTSUBSCRIPT</annotation></semantics></math> that quantifies the likelihood of a token contributing to a harmful response. The reward score is combined with the model’s original logits to compute an adjusted decoding score, which guides the generation process toward safer outputs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS1.SSS2.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS1.SSS2.p3.1.m1.1a"><mo id="S4.SS1.SSS2.p3.1.m1.1.1">∙</mo><annotation-xml id="S4.SS1.SSS2.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS2.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS1.SSS2.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> Logits 调整。CoCA [ 46] 向有害查询引入安全指令并计算由此产生的 logits 偏差。该偏差表示使模型输出与更安全响应对齐所需的调整。在推理过程中，logits 偏差直接应用于模型的输出层，使其能够在不向输入显式添加安全指令的情况下保持强大的安全能力。类似于 CoCA [ 46]，IMMUNE [ 135] 通过在推理阶段对齐响应来增强模型输出的安全性。IMMUNE [ 135] 不是通过显式修改输入，而是通过引入一个安全奖励模型 <math id="S4.SS1.SSS2.p3.2.m2.1" display="inline" class="ltx_Math" alttext="Q_{\text{safe}}"><semantics id="S4.SS1.SSS2.p3.2.m2.1a"><msub id="S4.SS1.SSS2.p3.2.m2.1.1"><mi id="S4.SS1.SSS2.p3.2.m2.1.1.2">Q</mi><mtext id="S4.SS1.SSS2.p3.2.m2.1.1.3">safe</mtext></msub><annotation-xml id="S4.SS1.SSS2.p3.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS1.SSS2.p3.2.m2.1c" encoding="application/x-tex">Q_{\text{safe}}</annotation><annotation id="S4.SS1.SSS2.p3.2.m2.1d" encoding="application/x-llamapun">italic_Q start_POSTSUBSCRIPT safe end_POSTSUBSCRIPT</annotation></semantics></math> 来评估候选 token 的安全性，该模型量化了 token 导致有害响应的可能性。奖励分数与模型的原始 logits 结合，计算出一个调整后的解码分数，从而引导生成过程朝向更安全的输出。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Output Validation Defenses<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1.3 输出验证防御</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">Output-Level Defenses focus on safeguarding the model’s final outputs by mitigating unsafe responses before they are delivered to users. These defenses primarily rely on techniques such as detection and response rewriting, which are both straightforward and computationally efficient.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">输出级防御专注于通过在输出交付给用户之前减轻不安全响应来保护模型的最终输出。这些防御主要依赖于检测和响应重写等技术，这些技术既简单又计算高效。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS3.p2">
<p class="ltx_p" id="S4.SS1.SSS3.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p2.1.m1.1"><semantics id="S4.SS1.SSS3.p2.1.m1.1a"><mo id="S4.SS1.SSS3.p2.1.m1.1.1" xref="S4.SS1.SSS3.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p2.1.m1.1b"><ci id="S4.SS1.SSS3.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS3.p2.1.1">Harmful Detecting.</span>
JailGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib47" title="">47</a>]</cite> observes that attack inputs inherently exhibit lower robustness compared to benign queries, irrespective of the attack methods or modalities. To exploit this property, JailGuard systematically designs and implements 16 random mutators and 2 semantic-driven targeted mutators to introduce perturbations at various levels of text and image inputs. By comparing the cosine similarity between the mutated and original inputs, JailGuard identifies significant discrepancies as indicators of adversarial attacks. This approach serves as a universal detection method capable of handling diverse attack types and modalities.
Pi <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS3.p2.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib48" title="">48</a>]</cite> propose MLLM-Protector, a defense framework that fine-tunes two separate LLMs to serve as a Harm Detector and a Response Detoxifier. The Harm Detector is designed to accurately identify outputs that violate predefined safety protocols, ensuring that harmful responses are flagged before being delivered to users. Meanwhile, the Response Detoxifier enhances the model’s helpfulness by rewriting harmful outputs into safe and constructive responses, effectively balances safety and utility.
Unlike previous approaches, ECSO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib136" title="">136</a>]</cite> operates without introducing additional modules. It demonstrates that LVLMs are inherently capable of assessing the safety of their outputs. When the model detects that its response may be harmful, ECSO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib136" title="">136</a>]</cite> mitigates this risk by converting the visual input into a textual caption and proceeding with text-only processing. This method highlights the ability to harness the intrinsic safety mechanisms of the LLM component within LVLMs, effectively reducing the generation of unsafe outputs while maintaining computational efficiency.
For adversarial attacks, MirrorCheck&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib137" title="">137</a>]</cite> employs Text-to-Image (T2I) models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib140" title="">140</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib141" title="">141</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib142" title="">142</a>]</cite> to generate images from captions produced by the target VLMs and then computes the similarity between the feature embeddings of the input and generated images to identify adversarial samples. MirrorCheck&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib137" title="">137</a>]</cite> demonstrates robust defense capabilities, offering an effective, training-free approach to detect and mitigate adversarial threats in LVLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS1.SSS3.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS1.SSS3.p2.1.m1.1a"><mo id="S4.SS1.SSS3.p2.1.m1.1.1">∙</mo><annotation-xml id="S4.SS1.SSS3.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS3.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS1.SSS3.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 有害检测。JailGuard [ 47] 观察到攻击输入相较于良性查询，无论攻击方法或模态如何，都表现出较低的鲁棒性。为了利用这一特性，JailGuard 系统性地设计和实现了 16 个随机变异器和 2 个语义驱动的目标变异器，以在文本和图像输入的不同层次引入扰动。通过比较变异输入和原始输入之间的余弦相似度，JailGuard 将显著差异识别为对抗性攻击的指标。这种方法是一种通用的检测方法，能够处理各种攻击类型和模态。Pi 等人[ 48]提出了 MLLM-Protector，这是一个防御框架，通过微调两个独立的 LLMs 来充当有害检测器和响应解毒器。有害检测器被设计为准确识别违反预定义安全协议的输出，确保在将有害响应交付给用户之前将其标记。同时，响应解毒器通过将有害输出重写为安全且建设性的响应来增强模型的有用性，有效地平衡了安全性和实用性。 与先前方法不同，ECSO [ 136] 不需要引入额外模块。它证明了视觉语言模型（LVLMs）本质上能够评估其输出的安全性。当模型检测到其响应可能有害时，ECSO [ 136] 通过将视觉输入转换为文本标题，并继续仅进行文本处理来缓解这种风险。这种方法突出了利用 LVLMs 中 LLM 组件的内在安全机制的能力，有效减少不安全输出的生成，同时保持计算效率。对于对抗性攻击，MirrorCheck [ 137] 采用文本到图像（T2I）模型 [ 140, 141, 142] 从目标视觉语言模型（VLMs）生成的标题中生成图像，然后计算输入图像和生成图像的特征嵌入之间的相似度，以识别对抗性样本。 MirrorCheck [ 137] 展示了强大的防御能力，提供了一种有效的、无需训练的方法来检测和缓解 LVLMs 中的对抗性威胁。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4 </span>Multi-Stage Integration Defenses<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1.4 多阶段集成防御</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS4.p1">
<p class="ltx_p" id="S4.SS1.SSS4.p1.1">Multi-Level Defenses combine strategies from input, internal, and output levels to create a comprehensive defense framework that ensures model safety. Provide robust and highly effective solutions to maintain safe and reliable outputs in LVLMs, harness the strengths of diverse techniques.
ETA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib28" title="">28</a>]</cite> integrates defense mechanisms across the input and output stages to enhance model safety. During the pre-generation phase, ETA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib28" title="">28</a>]</cite> employs an evaluation prompt <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="S4.SS1.SSS4.p1.1.m1.1"><semantics id="S4.SS1.SSS4.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS4.p1.1.m1.1.1" xref="S4.SS1.SSS4.p1.1.m1.1.1.cmml">𝒫</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS4.p1.1.m1.1b"><ci id="S4.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS4.p1.1.m1.1.1">𝒫</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS4.p1.1.m1.1c">\mathcal{P}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS4.p1.1.m1.1d">caligraphic_P</annotation></semantics></math> with CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib12" title="">12</a>]</cite> to calculate a safety score for the visual input. In the post-generation phase, a reward model (RM) evaluates the safety of the generated output. If both the pre-generation and post-generation scores indicate unsafety, a predefined prefix (e.g., ”As an AI assistant,”) is appended to the prompt to guide the model toward generating safer responses. In the output stage, ETA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib28" title="">28</a>]</cite> utilizes a Best-of-N strategy, generating multiple candidate responses and selecting the one that optimizes a weighted combination of safety and relevance scores.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多层防御结合输入、内部和输出层面的策略，构建一个全面的防御框架以确保模型安全。为 LVLM 提供稳健且高效解决方案，以维持安全可靠的输出，并利用多种技术的优势。ETA [ 28] 融合输入和输出阶段的防御机制，以增强模型安全。在预生成阶段，ETA [ 28] 采用带有 CLIP [ 12] 的评估提示 <math id="S4.SS1.SSS4.p1.1.m1.1" display="inline" class="ltx_Math" alttext="\mathcal{P}"><semantics id="S4.SS1.SSS4.p1.1.m1.1a"><mi id="S4.SS1.SSS4.p1.1.m1.1.1" class="ltx_font_mathcaligraphic">𝒫</mi><annotation-xml id="S4.SS1.SSS4.p1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS1.SSS4.p1.1.m1.1c" encoding="application/x-tex">\mathcal{P}</annotation><annotation id="S4.SS1.SSS4.p1.1.m1.1d" encoding="application/x-llamapun">caligraphic_P</annotation></semantics></math> 来计算视觉输入的安全分数。在生成后阶段，奖励模型（RM）评估生成输出的安全性。如果预生成和生成后的分数均显示不安全，则向提示附加预定义的前缀（例如，“作为 AI 助手，”）以引导模型生成更安全的响应。在输出阶段，ETA [ 28] 采用最佳 N 策略，生成多个候选响应，并选择在安全性和相关性分数的加权组合中表现最优的那个。 </font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span class="ltx_text ltx_font_italic" id="S4.SS2.1.1">Training-Phase Defenses</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2 训练阶段防御</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The training phase is crucial in developing machine learning models, especially Large Models. Training-Phase Defenses integrate safety mechanisms during this foundational stage, enhancing the model’s robustness by strengthening its internal architecture. Unlike inference-phase strategies&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS1" title="4.1 Inference-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1</span></a>), these defenses enable models to autonomously mitigate adversarial challenges without relying on external mechanisms. Based on the data collection and processing pipeline, these strategies are classified into two main categories:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">训练阶段在开发机器学习模型中至关重要，尤其是大型模型。训练阶段防御在基础阶段整合安全机制，通过强化模型内部架构来提升其鲁棒性。与推理阶段策略（§ 4.1）不同，这些防御使模型能够自主应对对抗性挑战，无需依赖外部机制。基于数据收集和处理流程，这些策略分为两大类：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Data-Driven Refinement<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2.1 数据驱动优化</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">The quality of training data is fundamental to ensuring model safety, forming the basis for robust performance and resilience against adversarial challenges. This part examines existing efforts dedicated to the construction and refinement of secure datasets, which play a pivotal role in enhancing both the robustness and alignment of LVLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">训练数据的质量是确保模型安全的基础，是提升模型鲁棒性和对抗性挑战适应性的关键。本部分考察了致力于构建和优化安全数据集的现有工作，这些数据集在增强大型视觉语言模型的鲁棒性和一致性方面发挥着关键作用。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p2.1.m1.1"><semantics id="S4.SS2.SSS1.p2.1.m1.1a"><mo id="S4.SS2.SSS1.p2.1.m1.1.1" xref="S4.SS2.SSS1.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p2.1.m1.1b"><ci id="S4.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.1">Adversarial Specific Dataset.</span>
In adversarial detection, Huang <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS1.p2.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib143" title="">143</a>]</cite> introduce RADAR, a large-scale open-source adversarial dataset containing 4,000 samples. RADAR offers diverse harmful queries and responses, with samples sourced from the COCO dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib144" title="">144</a>]</cite> and adversarial inputs generated using the PGD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib79" title="">79</a>]</cite> method. To ensure high-quality samples, RADAR incorporates filtering procedures during construction, verifying that responses to benign inputs remain harmless while those to adversarial inputs are appropriately harmful.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS2.SSS1.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS2.SSS1.p2.1.m1.1a"><mo id="S4.SS2.SSS1.p2.1.m1.1.1">∙</mo><annotation-xml id="S4.SS2.SSS1.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS2.SSS1.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS2.SSS1.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 对抗特定数据集。在对抗检测中，Huang 等人[ 143]介绍了 RADAR，这是一个包含 4,000 个样本的大规模开源对抗数据集。RADAR 提供了多样化的有害查询和响应，样本来源于 COCO 数据集[ 144]，并使用 PGD[ 79]方法生成对抗输入。为确保样本质量，RADAR 在构建过程中加入了过滤流程，验证对良性输入的响应保持无害，而对对抗输入的响应则适当有害。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p3">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS1.p3.1.m1.1"><semantics id="S4.SS2.SSS1.p3.1.m1.1a"><mo id="S4.SS2.SSS1.p3.1.m1.1.1" xref="S4.SS2.SSS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p3.1.m1.1b"><ci id="S4.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS1.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p3.1.1">General Safety Dataset.</span>
Chen <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS1.p3.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib145" title="">145</a>]</cite> collet VLSafe, a harmless alignment dataset related to images, created using an LLM-Human-in-the-Loop approach and GPT-3.5-Turbo&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib3" title="">3</a>]</cite>. VLSafe&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib145" title="">145</a>]</cite> construction involves iterative refinement and filtering to ensure safety and quality, borrowing methods from textual adversarial attack research. Based on the COCO dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib144" title="">144</a>]</cite>, multiple iterations refine the dataset, followed by rounds of filtering to eliminate failure modes. The final dataset contains 5,874 samples, split into 4,764 training samples and 1,110 evaluation samples.
Zong <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS1.p3.1.3">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib49" title="">49</a>]</cite> demonstrate through experiments that the inclusion of the vision modality significantly reduces the safety capabilities of LVLMs. Currently, a substantial portion of training data is generated by LLMs, which often contains harmful content, thereby contributing to the degradation of safety alignment in LVLMs. Furthermore, the use of LoRA fine-tuning has been shown to introduce additional safety risks. While cleaning the training data can partially restore safety alignment, its overall effectiveness remains limited. Based on these findings, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib49" title="">49</a>]</cite> set out to collect a new safe vision-language instruction-following dataset VLGuard, significantly reduces the harmfulness of models across all fine-tuning strategies and models considered.
To address the lack of high-quality open-source training datasets necessary for achieving the safety alignment of LVLMs, Zhang <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS1.p3.1.4">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib50" title="">50</a>]</cite> introduce SPA-VL, a large-scale safety alignment dataset that encompasses 6 harmfulness domains, 13 categories, and 53 subcategories. The dataset consists of 100,788 quadruple samples, with responses collected from 12 diverse LVLMs, including both open-source models (e.g., QwenVL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib65" title="">65</a>]</cite>) and closed-source models (e.g., Gemini&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib60" title="">60</a>]</cite>), to ensure diversity. SPA-VL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib50" title="">50</a>]</cite> reveals that increasing data volume, incorporating diverse responses, and using a mix of question types significantly enhance the safety and performance of aligned models.
Helff <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS1.p3.1.5">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib146" title="">146</a>]</cite> propose LlavaGuard for dataset annotation and safeguarding generative models, leveraging curated datasets and structured evaluation methods. It uses a JSON-formatted output with safety ratings, category classifications, and natural language rationales to ensure comprehensive assessments. The dataset, built on the Socio-Moral Image Database (SMID)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib147" title="">147</a>]</cite> and expanded with web-scraped images, addresses category imbalances with at least 100 images per category. LlavaGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib146" title="">146</a>]</cite> incorporates refined safety ratings&nbsp;(e.g., “Highly Unsafe”, “Moderately Unsafe”) and synthetic rationales generated by the Llava-34B model&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib15" title="">15</a>]</cite> to enhance generalization. Data augmentation techniques improve dataset balance and adaptability, resulting in 4,940 samples, with 599 reserved for testing.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS2.SSS1.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS2.SSS1.p3.1.m1.1a"><mo id="S4.SS2.SSS1.p3.1.m1.1.1">∙</mo><annotation-xml id="S4.SS2.SSS1.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS2.SSS1.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS2.SSS1.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 通用安全数据集。陈等人 [ 145] 收集了 VLSafe，这是一个与图像相关的无害对齐数据集，使用 LLM-人类参与循环方法（LLM-Human-in-the-Loop approach）和 GPT-3.5-Turbo [ 3] 创建。VLSafe [ 145] 的构建涉及迭代优化和过滤，以确保安全性和质量，借鉴了文本对抗性攻击研究中的方法。基于 COCO 数据集 [ 144]，经过多次迭代优化数据集，然后进行多轮过滤以消除失效模式。最终数据集包含 5,874 个样本，分为 4,764 个训练样本和 1,110 个评估样本。宗等人 [ 49] 通过实验表明，包含视觉模态会显著降低 LVLMs 的安全能力。目前，大量训练数据由 LLMs 生成，其中常包含有害内容，从而导致 LVLMs 的安全对齐能力下降。此外，LoRA 微调已被证明会引入额外的安全风险。虽然清理训练数据可以部分恢复安全对齐，但其整体效果仍然有限。 基于这些发现，[49] 致力于收集新的安全视觉语言指令遵循数据集 VLGuard，显著降低了所有考虑的微调策略和模型的有害性。为了解决实现 LVLM 安全对齐所需的高质量开源训练数据缺乏的问题，Zhang 等人 [50] 引入了 SPA-VL，这是一个包含 6 个有害性领域、13 个类别和 53 个子类的大型安全对齐数据集。该数据集包含 100,788 个四元组样本，从 12 种不同的 LVLM 收集了响应，包括开源模型（例如 QwenVL [65]）和闭源模型（例如 Gemini [60]），以确保多样性。SPA-VL [50] 表明，增加数据量、包含多样化的响应以及使用多种题型可以显著提高对齐模型的安全性和性能。Helff 等人 [146] 提出了 LlavaGuard 用于数据集标注和安全防护生成模型，利用精选数据集和结构化评估方法。 它使用 JSON 格式的输出，包含安全评级、类别分类和自然语言理由，以确保全面评估。该数据集基于社会道德图像数据库（SMID）[147]构建，并通过网络抓取的图像进行扩展，以解决类别不平衡问题，每个类别至少包含 100 张图像。LlavaGuard [146] 结合了更精细的安全评级（例如，“高度危险”、“中度危险”）以及由 Llava-34B 模型[15]生成的合成理由，以增强泛化能力。 数据增强技术提高了数据集的平衡性和适应性，最终得到 4,940 个样本，其中 599 个用于测试。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Summary of essential characteristics for reviewed methods in Training-Phase Defenses&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2" title="4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.2</span></a>).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 V：训练阶段防御（§ 4.2）中审查方法的必要特征总结</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.4" style="width:433.6pt;height:365.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(35.1pt,-29.6pt) scale(1.19314634001336,1.19314634001336) ;">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.4.1">
<tbody><tr class="ltx_tr" id="S4.T5.4.1.1" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_rr ltx_border_t" id="S4.T5.4.1.1.1" style="padding:0.9pt 1.0pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span><span class="ltx_text" id="S4.T5.4.1.1.1.1" style="font-size:90%;background-color:#D8D6C4;">
<span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.1.1">Methods<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></span>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.4.1.1.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.2.1" style="font-size:90%;background-color:#D8D6C4;">Venue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">场地</font></font></font></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T5.4.1.1.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.3.1" style="font-size:90%;background-color:#D8D6C4;">Highlight<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">重点</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.2">
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_tt" colspan="3" id="S4.T5.4.1.2.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T5.4.1.2.1.1" style="font-size:90%;">Data-Driven Refinement&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2.SSS1" title="4.2.1 Data-Driven Refinement ‣ 4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.2.1</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">数据驱动优化（§ 4.2.1）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.3" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr ltx_border_t" id="S4.T5.4.1.3.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.3.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">VLSafe<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib145" title="">145</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.4.1.3.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.3.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[CVPR’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T5.4.1.3.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.3.3.1" style="font-size:90%;background-color:#F5F5F0;">LLM-Human-in-the-Loop<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLM-人机交互</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.4.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T5.4.1.4.1.1" style="font-size:90%;">VLGuard</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.4.1.4.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib49" title="">49</a><span class="ltx_text" id="S4.T5.4.1.4.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.4.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.4.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[ICML’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.4.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.4.3.1" style="font-size:90%;">Safe instruction following dataset<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全指令遵循数据集</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.5" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.5.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.5.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVAGuard<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib146" title="">146</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.5.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.5.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.5.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.5.3.1" style="font-size:90%;background-color:#F5F5F0;">Refined ratings &amp; rationales dataset<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">细化评分与理由数据集</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.6">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.6.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T5.4.1.6.1.1" style="font-size:90%;">SPA-VL</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.4.1.6.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib50" title="">50</a><span class="ltx_text" id="S4.T5.4.1.6.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.6.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.6.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.6.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.6.3.1" style="font-size:90%;">Large-scale &amp; domain diversity<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大规模与领域多样性</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.7" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.7.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.7.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">RADAR<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib143" title="">143</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.7.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.7.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.7.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.7.3.1" style="font-size:90%;background-color:#F5F5F0;">Adversarial detection dataset<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对抗检测数据集</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.8">
<td class="ltx_td ltx_nopad_l ltx_align_left ltx_border_tt" colspan="3" id="S4.T5.4.1.8.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T5.4.1.8.1.1" style="font-size:90%;">Strategy-Driven Optimization&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S4.SS2.SSS2" title="4.2.2 Strategy-Driven Optimization ‣ 4.2 Training-Phase Defenses ‣ 4 Defense ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.2.2</span></a>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">策略驱动优化（§ 4.2.2）</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.9" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr ltx_border_t" id="S4.T5.4.1.9.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.9.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">FARE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib148" title="">148</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.4.1.9.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.9.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ICML’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T5.4.1.9.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.9.3.1" style="font-size:90%;background-color:#F5F5F0;">Unsupervised CLIP robust training<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">无监督 CLIP 鲁棒训练</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.10">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.10.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T5.4.1.10.1.1" style="font-size:90%;">SIU</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.4.1.10.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib149" title="">149</a><span class="ltx_text" id="S4.T5.4.1.10.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.10.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.10.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[NeurIPS’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.10.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.10.3.1" style="font-size:90%;">Selective unlearning framework<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">选择性遗忘框架</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.11" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.11.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.11.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">SafeVLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib51" title="">51</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.11.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.11.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.11.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.11.3.1" style="font-size:90%;background-color:#F5F5F0;">Safety projection &amp; token &amp; head<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全投影 &amp; 令牌 &amp; 头</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.12">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.12.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T5.4.1.12.1.1" style="font-size:90%;">TextUnlearn</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.4.1.12.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib150" title="">150</a><span class="ltx_text" id="S4.T5.4.1.12.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.12.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.12.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[EMNLP’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.12.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.12.3.1" style="font-size:90%;">Unlearning solely in textual<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">仅文本中的去学习</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.13" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.13.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.13.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">Sim-CLIP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib151" title="">151</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.13.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.13.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.13.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.13.3.1" style="font-size:90%;background-color:#F5F5F0;">Siamese architecture<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Siamese 架构</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.14">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.14.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T5.4.1.14.1.1" style="font-size:90%;">Sim-CLIP+</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.4.1.14.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib152" title="">152</a><span class="ltx_text" id="S4.T5.4.1.14.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.14.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.14.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.14.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.14.3.1" style="font-size:90%;">Stop-gradient mechanism<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">停止梯度机制</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.15" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.15.1" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.15.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">BaThe<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib153" title="">153</a>]</cite></span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.15.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.15.2.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.15.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.15.3.1" style="font-size:90%;background-color:#F5F5F0;">Harmful instruction as trigger<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">有害指令作为触发器</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.16">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_rr" id="S4.T5.4.1.16.1" style="padding:0.9pt 1.0pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S4.T5.4.1.16.1.1" style="font-size:90%;">TGA</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S4.T5.4.1.16.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib29" title="">29</a><span class="ltx_text" id="S4.T5.4.1.16.1.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" id="S4.T5.4.1.16.2" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.16.2.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T5.4.1.16.3" style="padding:0.9pt 1.0pt;"><span class="ltx_text" id="S4.T5.4.1.16.3.1" style="font-size:90%;">Transfer safety from LLM to LVLM<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">将安全从 LLM 转移到 LVLM</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.17">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_rr ltx_border_t" id="S4.T5.4.1.17.1" style="padding:0.9pt 1.0pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_t" id="S4.T5.4.1.17.2" style="padding:0.9pt 1.0pt;"></td>
<td class="ltx_td ltx_border_t" id="S4.T5.4.1.17.3" style="padding:0.9pt 1.0pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Strategy-Driven Optimization<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2.2 策略驱动优化</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">Beyond data quality, the design of effective training strategies is equally critical for enhancing model safety and robustness. This part explores optimization techniques and training paradigms that aim to fortify models against attacks and improving their alignment with safety objectives.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">除了数据质量，设计有效的训练策略对于提升模型安全性和鲁棒性同样至关重要。本部分探讨了旨在增强模型抗攻击能力和提高其与安全目标一致性的优化技术和训练范式。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p2.1.m1.1"><semantics id="S4.SS2.SSS2.p2.1.m1.1a"><mo id="S4.SS2.SSS2.p2.1.m1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.1.m1.1b"><ci id="S4.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p2.1.1">Visual Enhancement.</span>
Schlarmann <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.p2.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib148" title="">148</a>]</cite> introduce FARE, an unsupervised adversarial fine-tuning approach for improving the robustness of the CLIP vision encoder against adversarial attacks while preserving its clean zero-shot performance. FARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib148" title="">148</a>]</cite> optimizes an embedding loss that ensures perturbed inputs produce embeddings close to their unperturbed counterparts, enabling the vision encoder to retain compatibility with downstream tasks like LVLMs without additional re-training. FARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib148" title="">148</a>]</cite> implemented using PGD-based&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib79" title="">79</a>]</cite> adversarial training, is dataset-agnostic and can generalize to other foundation models with intermediate embedding layers.
Sim-CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib151" title="">151</a>]</cite> tackles the challenges present in FARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib148" title="">148</a>]</cite> by integrating a Siamese architecture with cosine similarity loss. During training, Sim-CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib151" title="">151</a>]</cite> generates perturbed views of input images using PGD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib79" title="">79</a>]</cite> and optimizes the alignment between clean and perturbed representations to ensure robustness against adversarial attacks. The method minimizes negative cosine similarity to enforce invariance between these representations while maintaining model coherence. Additionally, a stop-gradient mechanism is incorporated to prevent loss collapse, enabling efficient adversarial training without the need for negative samples or momentum encoders.
Sim-CLIP+&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib152" title="">152</a>]</cite> extends Sim-CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib151" title="">151</a>]</cite> to defend against advanced optimization-based jailbreak attacks targeting LVLMs. By leveraging a tailored cosine similarity loss and a stop-gradient mechanism, Sim-CLIP+&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib152" title="">152</a>]</cite> prevents symmetric loss collapse, ensuring computational efficiency while maintaining robustness.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS2.SSS2.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS2.SSS2.p2.1.m1.1a"><mo id="S4.SS2.SSS2.p2.1.m1.1.1">∙</mo><annotation-xml id="S4.SS2.SSS2.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS2.SSS2.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS2.SSS2.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 视觉增强。Schlarmann 等人[148]提出了 FARE，这是一种无监督对抗微调方法，旨在提高 CLIP 视觉编码器对对抗攻击的鲁棒性，同时保持其干净的零样本性能。FARE[148]优化了一个嵌入损失，确保扰动输入产生的嵌入与其未扰动版本接近，使视觉编码器能够在无需额外重新训练的情况下保持与下游任务（如 LVLMs）的兼容性。FARE[148]采用基于 PGD[79]的对抗训练实现，具有数据集无关性，并能泛化到其他具有中间嵌入层的基础模型。Sim-CLIP[151]通过集成 Siamese 架构和余弦相似度损失来解决 FARE[148]中存在的问题。在训练过程中，Sim-CLIP[151]使用 PGD[79]生成输入图像的扰动视图，并优化干净表示和扰动表示之间的对齐，以确保对对抗攻击的鲁棒性。该方法最小化负余弦相似度，以强制执行这些表示之间的不变性，同时保持模型一致性。 此外，还引入了停止梯度机制以防止损失坍塌，从而无需负样本或动量编码器即可进行高效的对抗训练。Sim-CLIP+ [ 152] 扩展了 Sim-CLIP [ 151]，用于防御针对大型视觉语言模型（LVLMs）的高级基于优化的越狱攻击。通过利用定制的余弦相似度损失和停止梯度机制，Sim-CLIP+ [ 152] 防止了对称损失坍塌，确保了计算效率的同时保持了鲁棒性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p3.1.m1.1"><semantics id="S4.SS2.SSS2.p3.1.m1.1a"><mo id="S4.SS2.SSS2.p3.1.m1.1.1" xref="S4.SS2.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p3.1.m1.1b"><ci id="S4.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p3.1.1">Knowledge Unlearning.</span>
Chakraborty <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.p3.1.2">et al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib150" title="">150</a>]</cite> propose SIU, a novel framework for implementing machine unlearning in LVLM safety. SIU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib150" title="">150</a>]</cite> addresses the challenge of selectively removing visual data associated with specific concepts by leveraging fine-tuning on a single representative image. The approach is composed of two key components: (i) the construction of multifaceted fine-tuning datasets designed to target four distinct unlearning objectives and (ii) the incorporation of a Dual Masked KL-divergence Loss, which enables the simultaneous unlearning of targeted concepts while maintaining the overall functional integrity and utility of the LVLMs.
TextUnlearning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib150" title="">150</a>]</cite> notes that irrespective of the input modalities, all information is ultimately fused within the language space. Comparative experiments reveal that unlearning focused solely on the text modality outperforms multimodal unlearning approaches. By performing “textual” unlearning exclusively on the LLM component of LVLMs, while keeping the remaining modules frozen, this method achieves remarkable levels of harmlessness against cross-modality attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS2.SSS2.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS2.SSS2.p3.1.m1.1a"><mo id="S4.SS2.SSS2.p3.1.m1.1.1">∙</mo><annotation-xml id="S4.SS2.SSS2.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS2.SSS2.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS2.SSS2.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 知识去学习。Chakraborty 等人[ 150]提出了 SIU，这是一个用于在 LVLM 安全中实现机器去学习的新框架。SIU[ 150]通过在单个代表性图像上进行微调，解决了选择性地移除与特定概念相关的视觉数据这一挑战。该方法由两个关键组件组成：(i) 构建旨在针对四个不同去学习目标的多样化微调数据集，以及(ii) 结合双掩码 KL 散度损失，该损失能够在保持 LVLM 的整体功能完整性和实用性的同时，实现对目标概念的同时去学习。TextUnlearning[ 150]指出，无论输入模态如何，所有信息最终都在语言空间中融合。比较实验表明，仅针对文本模态进行去学习的效果优于多模态去学习方法。通过仅对 LVLM 的 LLM 组件进行“文本”去学习，同时冻结其余模块，该方法在抵御跨模态攻击方面达到了极高的无害性水平。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p4">
<p class="ltx_p" id="S4.SS2.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p4.1.m1.1"><semantics id="S4.SS2.SSS2.p4.1.m1.1a"><mo id="S4.SS2.SSS2.p4.1.m1.1.1" xref="S4.SS2.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p4.1.m1.1b"><ci id="S4.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p4.1.1">Module Integration.</span>
SafeVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib51" title="">51</a>]</cite> integrating three key safety modules: safety projection, safety tokens, and a safety head into LLaVA to enhance safety. SafeVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib51" title="">51</a>]</cite> employs two-stage training strategy, where safety modules are first trained with the base model frozen, followed by fine-tuning the language model to align safety measures with vision features. During inference, safety embeddings generated by the safety head provide dynamic and customizable risk control, enabling flexible adjustments based on user needs, such as content grading and categorization.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS2.SSS2.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS2.SSS2.p4.1.m1.1a"><mo id="S4.SS2.SSS2.p4.1.m1.1.1">∙</mo><annotation-xml id="S4.SS2.SSS2.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS2.SSS2.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS2.SSS2.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 模块集成。SafeVLM [ 51] 将三个关键安全模块——安全投影、安全标记和安全头部集成到 LLaVA 中，以增强安全性。SafeVLM [ 51] 采用两阶段训练策略，首先冻结基础模型训练安全模块，然后微调语言模型以使安全措施与视觉特征保持一致。在推理过程中，安全头部生成的安全嵌入提供动态和可定制的风险控制，能够根据用户需求进行灵活调整，例如内容分级和分类。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p5">
<p class="ltx_p" id="S4.SS2.SSS2.p5.12"><math alttext="\bullet" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.1.m1.1"><semantics id="S4.SS2.SSS2.p5.1.m1.1a"><mo id="S4.SS2.SSS2.p5.1.m1.1.1" xref="S4.SS2.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.1.m1.1b"><ci id="S4.SS2.SSS2.p5.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p5.12.1">Advanced Fine-tuning.</span>
BaThe&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib153" title="">153</a>]</cite> treats harmful instructions as potential triggers that can exploit backdoored models to produce prohibited outputs. BaThe&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib153" title="">153</a>]</cite> replaces manually designed triggers (e.g., “SUDO”) with rejection prompts embedded as “soft text embeddings” called the wedge, maps harmful instructions to rejection responses. BaThe also defends against more advanced virtual prompt backdoor attacks, where harmful instructions combined with subtle prompts act as triggers. By embedding rejection prompts into the model’s soft text embeddings and including multimodal QA datasets in training, BaThe effectively mitigates backdoor risks, ensuring safer and more robust model behavior.
TGA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib29" title="">29</a>]</cite> finds that the hidden states at specific transformer layers play a crucial role in the successful activation of safety mechanisms, highlighting that the vision-language alignment at the hidden state level in current methods is insufficient. To address this, TGA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib29" title="">29</a>]</cite> aligns the hidden states of visual (<math alttext="X_{\text{image}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.2.m2.1"><semantics id="S4.SS2.SSS2.p5.2.m2.1a"><msub id="S4.SS2.SSS2.p5.2.m2.1.1" xref="S4.SS2.SSS2.p5.2.m2.1.1.cmml"><mi id="S4.SS2.SSS2.p5.2.m2.1.1.2" xref="S4.SS2.SSS2.p5.2.m2.1.1.2.cmml">X</mi><mtext id="S4.SS2.SSS2.p5.2.m2.1.1.3" xref="S4.SS2.SSS2.p5.2.m2.1.1.3a.cmml">image</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.2.m2.1b"><apply id="S4.SS2.SSS2.p5.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.2.m2.1.1.1.cmml" xref="S4.SS2.SSS2.p5.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.2.m2.1.1.2.cmml" xref="S4.SS2.SSS2.p5.2.m2.1.1.2">𝑋</ci><ci id="S4.SS2.SSS2.p5.2.m2.1.1.3a.cmml" xref="S4.SS2.SSS2.p5.2.m2.1.1.3"><mtext id="S4.SS2.SSS2.p5.2.m2.1.1.3.cmml" mathsize="70%" xref="S4.SS2.SSS2.p5.2.m2.1.1.3">image</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.2.m2.1c">X_{\text{image}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.2.m2.1d">italic_X start_POSTSUBSCRIPT image end_POSTSUBSCRIPT</annotation></semantics></math>) and textual (<math alttext="X_{\text{caption}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.3.m3.1"><semantics id="S4.SS2.SSS2.p5.3.m3.1a"><msub id="S4.SS2.SSS2.p5.3.m3.1.1" xref="S4.SS2.SSS2.p5.3.m3.1.1.cmml"><mi id="S4.SS2.SSS2.p5.3.m3.1.1.2" xref="S4.SS2.SSS2.p5.3.m3.1.1.2.cmml">X</mi><mtext id="S4.SS2.SSS2.p5.3.m3.1.1.3" xref="S4.SS2.SSS2.p5.3.m3.1.1.3a.cmml">caption</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.3.m3.1b"><apply id="S4.SS2.SSS2.p5.3.m3.1.1.cmml" xref="S4.SS2.SSS2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.3.m3.1.1.1.cmml" xref="S4.SS2.SSS2.p5.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.3.m3.1.1.2.cmml" xref="S4.SS2.SSS2.p5.3.m3.1.1.2">𝑋</ci><ci id="S4.SS2.SSS2.p5.3.m3.1.1.3a.cmml" xref="S4.SS2.SSS2.p5.3.m3.1.1.3"><mtext id="S4.SS2.SSS2.p5.3.m3.1.1.3.cmml" mathsize="70%" xref="S4.SS2.SSS2.p5.3.m3.1.1.3">caption</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.3.m3.1c">X_{\text{caption}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.3.m3.1d">italic_X start_POSTSUBSCRIPT caption end_POSTSUBSCRIPT</annotation></semantics></math>) inputs across transformer layers in LVLMs by introducing a pair-wise loss function (<math alttext="\mathcal{L}_{\text{guide}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.4.m4.1"><semantics id="S4.SS2.SSS2.p5.4.m4.1a"><msub id="S4.SS2.SSS2.p5.4.m4.1.1" xref="S4.SS2.SSS2.p5.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS2.p5.4.m4.1.1.2" xref="S4.SS2.SSS2.p5.4.m4.1.1.2.cmml">ℒ</mi><mtext id="S4.SS2.SSS2.p5.4.m4.1.1.3" xref="S4.SS2.SSS2.p5.4.m4.1.1.3a.cmml">guide</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.4.m4.1b"><apply id="S4.SS2.SSS2.p5.4.m4.1.1.cmml" xref="S4.SS2.SSS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.4.m4.1.1.1.cmml" xref="S4.SS2.SSS2.p5.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.4.m4.1.1.2.cmml" xref="S4.SS2.SSS2.p5.4.m4.1.1.2">ℒ</ci><ci id="S4.SS2.SSS2.p5.4.m4.1.1.3a.cmml" xref="S4.SS2.SSS2.p5.4.m4.1.1.3"><mtext id="S4.SS2.SSS2.p5.4.m4.1.1.3.cmml" mathsize="70%" xref="S4.SS2.SSS2.p5.4.m4.1.1.3">guide</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.4.m4.1c">\mathcal{L}_{\text{guide}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT guide end_POSTSUBSCRIPT</annotation></semantics></math>). In this process, retrieved text (<math alttext="X_{\text{retrieval}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.5.m5.1"><semantics id="S4.SS2.SSS2.p5.5.m5.1a"><msub id="S4.SS2.SSS2.p5.5.m5.1.1" xref="S4.SS2.SSS2.p5.5.m5.1.1.cmml"><mi id="S4.SS2.SSS2.p5.5.m5.1.1.2" xref="S4.SS2.SSS2.p5.5.m5.1.1.2.cmml">X</mi><mtext id="S4.SS2.SSS2.p5.5.m5.1.1.3" xref="S4.SS2.SSS2.p5.5.m5.1.1.3a.cmml">retrieval</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.5.m5.1b"><apply id="S4.SS2.SSS2.p5.5.m5.1.1.cmml" xref="S4.SS2.SSS2.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.5.m5.1.1.1.cmml" xref="S4.SS2.SSS2.p5.5.m5.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.5.m5.1.1.2.cmml" xref="S4.SS2.SSS2.p5.5.m5.1.1.2">𝑋</ci><ci id="S4.SS2.SSS2.p5.5.m5.1.1.3a.cmml" xref="S4.SS2.SSS2.p5.5.m5.1.1.3"><mtext id="S4.SS2.SSS2.p5.5.m5.1.1.3.cmml" mathsize="70%" xref="S4.SS2.SSS2.p5.5.m5.1.1.3">retrieval</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.5.m5.1c">X_{\text{retrieval}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.5.m5.1d">italic_X start_POSTSUBSCRIPT retrieval end_POSTSUBSCRIPT</annotation></semantics></math>) serves as a guide, ensuring that <math alttext="I_{j}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.6.m6.1"><semantics id="S4.SS2.SSS2.p5.6.m6.1a"><msub id="S4.SS2.SSS2.p5.6.m6.1.1" xref="S4.SS2.SSS2.p5.6.m6.1.1.cmml"><mi id="S4.SS2.SSS2.p5.6.m6.1.1.2" xref="S4.SS2.SSS2.p5.6.m6.1.1.2.cmml">I</mi><mi id="S4.SS2.SSS2.p5.6.m6.1.1.3" xref="S4.SS2.SSS2.p5.6.m6.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.6.m6.1b"><apply id="S4.SS2.SSS2.p5.6.m6.1.1.cmml" xref="S4.SS2.SSS2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.6.m6.1.1.1.cmml" xref="S4.SS2.SSS2.p5.6.m6.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.6.m6.1.1.2.cmml" xref="S4.SS2.SSS2.p5.6.m6.1.1.2">𝐼</ci><ci id="S4.SS2.SSS2.p5.6.m6.1.1.3.cmml" xref="S4.SS2.SSS2.p5.6.m6.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.6.m6.1c">I_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.6.m6.1d">italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> (hidden states of <math alttext="X_{\text{image}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.7.m7.1"><semantics id="S4.SS2.SSS2.p5.7.m7.1a"><msub id="S4.SS2.SSS2.p5.7.m7.1.1" xref="S4.SS2.SSS2.p5.7.m7.1.1.cmml"><mi id="S4.SS2.SSS2.p5.7.m7.1.1.2" xref="S4.SS2.SSS2.p5.7.m7.1.1.2.cmml">X</mi><mtext id="S4.SS2.SSS2.p5.7.m7.1.1.3" xref="S4.SS2.SSS2.p5.7.m7.1.1.3a.cmml">image</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.7.m7.1b"><apply id="S4.SS2.SSS2.p5.7.m7.1.1.cmml" xref="S4.SS2.SSS2.p5.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.7.m7.1.1.1.cmml" xref="S4.SS2.SSS2.p5.7.m7.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.7.m7.1.1.2.cmml" xref="S4.SS2.SSS2.p5.7.m7.1.1.2">𝑋</ci><ci id="S4.SS2.SSS2.p5.7.m7.1.1.3a.cmml" xref="S4.SS2.SSS2.p5.7.m7.1.1.3"><mtext id="S4.SS2.SSS2.p5.7.m7.1.1.3.cmml" mathsize="70%" xref="S4.SS2.SSS2.p5.7.m7.1.1.3">image</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.7.m7.1c">X_{\text{image}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.7.m7.1d">italic_X start_POSTSUBSCRIPT image end_POSTSUBSCRIPT</annotation></semantics></math>) is closer to <math alttext="C_{j}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.8.m8.1"><semantics id="S4.SS2.SSS2.p5.8.m8.1a"><msub id="S4.SS2.SSS2.p5.8.m8.1.1" xref="S4.SS2.SSS2.p5.8.m8.1.1.cmml"><mi id="S4.SS2.SSS2.p5.8.m8.1.1.2" xref="S4.SS2.SSS2.p5.8.m8.1.1.2.cmml">C</mi><mi id="S4.SS2.SSS2.p5.8.m8.1.1.3" xref="S4.SS2.SSS2.p5.8.m8.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.8.m8.1b"><apply id="S4.SS2.SSS2.p5.8.m8.1.1.cmml" xref="S4.SS2.SSS2.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.8.m8.1.1.1.cmml" xref="S4.SS2.SSS2.p5.8.m8.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.8.m8.1.1.2.cmml" xref="S4.SS2.SSS2.p5.8.m8.1.1.2">𝐶</ci><ci id="S4.SS2.SSS2.p5.8.m8.1.1.3.cmml" xref="S4.SS2.SSS2.p5.8.m8.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.8.m8.1c">C_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.8.m8.1d">italic_C start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> (hidden states of <math alttext="X_{\text{caption}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.9.m9.1"><semantics id="S4.SS2.SSS2.p5.9.m9.1a"><msub id="S4.SS2.SSS2.p5.9.m9.1.1" xref="S4.SS2.SSS2.p5.9.m9.1.1.cmml"><mi id="S4.SS2.SSS2.p5.9.m9.1.1.2" xref="S4.SS2.SSS2.p5.9.m9.1.1.2.cmml">X</mi><mtext id="S4.SS2.SSS2.p5.9.m9.1.1.3" xref="S4.SS2.SSS2.p5.9.m9.1.1.3a.cmml">caption</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.9.m9.1b"><apply id="S4.SS2.SSS2.p5.9.m9.1.1.cmml" xref="S4.SS2.SSS2.p5.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.9.m9.1.1.1.cmml" xref="S4.SS2.SSS2.p5.9.m9.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.9.m9.1.1.2.cmml" xref="S4.SS2.SSS2.p5.9.m9.1.1.2">𝑋</ci><ci id="S4.SS2.SSS2.p5.9.m9.1.1.3a.cmml" xref="S4.SS2.SSS2.p5.9.m9.1.1.3"><mtext id="S4.SS2.SSS2.p5.9.m9.1.1.3.cmml" mathsize="70%" xref="S4.SS2.SSS2.p5.9.m9.1.1.3">caption</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.9.m9.1c">X_{\text{caption}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.9.m9.1d">italic_X start_POSTSUBSCRIPT caption end_POSTSUBSCRIPT</annotation></semantics></math>) than <math alttext="R_{j}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.10.m10.1"><semantics id="S4.SS2.SSS2.p5.10.m10.1a"><msub id="S4.SS2.SSS2.p5.10.m10.1.1" xref="S4.SS2.SSS2.p5.10.m10.1.1.cmml"><mi id="S4.SS2.SSS2.p5.10.m10.1.1.2" xref="S4.SS2.SSS2.p5.10.m10.1.1.2.cmml">R</mi><mi id="S4.SS2.SSS2.p5.10.m10.1.1.3" xref="S4.SS2.SSS2.p5.10.m10.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.10.m10.1b"><apply id="S4.SS2.SSS2.p5.10.m10.1.1.cmml" xref="S4.SS2.SSS2.p5.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.10.m10.1.1.1.cmml" xref="S4.SS2.SSS2.p5.10.m10.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.10.m10.1.1.2.cmml" xref="S4.SS2.SSS2.p5.10.m10.1.1.2">𝑅</ci><ci id="S4.SS2.SSS2.p5.10.m10.1.1.3.cmml" xref="S4.SS2.SSS2.p5.10.m10.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.10.m10.1c">R_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.10.m10.1d">italic_R start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> (hidden states of <math alttext="X_{\text{retrieval}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.11.m11.1"><semantics id="S4.SS2.SSS2.p5.11.m11.1a"><msub id="S4.SS2.SSS2.p5.11.m11.1.1" xref="S4.SS2.SSS2.p5.11.m11.1.1.cmml"><mi id="S4.SS2.SSS2.p5.11.m11.1.1.2" xref="S4.SS2.SSS2.p5.11.m11.1.1.2.cmml">X</mi><mtext id="S4.SS2.SSS2.p5.11.m11.1.1.3" xref="S4.SS2.SSS2.p5.11.m11.1.1.3a.cmml">retrieval</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.11.m11.1b"><apply id="S4.SS2.SSS2.p5.11.m11.1.1.cmml" xref="S4.SS2.SSS2.p5.11.m11.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.11.m11.1.1.1.cmml" xref="S4.SS2.SSS2.p5.11.m11.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.11.m11.1.1.2.cmml" xref="S4.SS2.SSS2.p5.11.m11.1.1.2">𝑋</ci><ci id="S4.SS2.SSS2.p5.11.m11.1.1.3a.cmml" xref="S4.SS2.SSS2.p5.11.m11.1.1.3"><mtext id="S4.SS2.SSS2.p5.11.m11.1.1.3.cmml" mathsize="70%" xref="S4.SS2.SSS2.p5.11.m11.1.1.3">retrieval</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.11.m11.1c">X_{\text{retrieval}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.11.m11.1d">italic_X start_POSTSUBSCRIPT retrieval end_POSTSUBSCRIPT</annotation></semantics></math>), achieving semantic consistency. The total loss combines <math alttext="\mathcal{L}_{\text{guide}}" class="ltx_Math" display="inline" id="S4.SS2.SSS2.p5.12.m12.1"><semantics id="S4.SS2.SSS2.p5.12.m12.1a"><msub id="S4.SS2.SSS2.p5.12.m12.1.1" xref="S4.SS2.SSS2.p5.12.m12.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS2.p5.12.m12.1.1.2" xref="S4.SS2.SSS2.p5.12.m12.1.1.2.cmml">ℒ</mi><mtext id="S4.SS2.SSS2.p5.12.m12.1.1.3" xref="S4.SS2.SSS2.p5.12.m12.1.1.3a.cmml">guide</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p5.12.m12.1b"><apply id="S4.SS2.SSS2.p5.12.m12.1.1.cmml" xref="S4.SS2.SSS2.p5.12.m12.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p5.12.m12.1.1.1.cmml" xref="S4.SS2.SSS2.p5.12.m12.1.1">subscript</csymbol><ci id="S4.SS2.SSS2.p5.12.m12.1.1.2.cmml" xref="S4.SS2.SSS2.p5.12.m12.1.1.2">ℒ</ci><ci id="S4.SS2.SSS2.p5.12.m12.1.1.3a.cmml" xref="S4.SS2.SSS2.p5.12.m12.1.1.3"><mtext id="S4.SS2.SSS2.p5.12.m12.1.1.3.cmml" mathsize="70%" xref="S4.SS2.SSS2.p5.12.m12.1.1.3">guide</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p5.12.m12.1c">\mathcal{L}_{\text{guide}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS2.p5.12.m12.1d">caligraphic_L start_POSTSUBSCRIPT guide end_POSTSUBSCRIPT</annotation></semantics></math> with cross-entropy loss for language modeling, enhancing multimodal alignment at the hidden state level and improving the safety mechanism.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S4.SS2.SSS2.p5.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S4.SS2.SSS2.p5.1.m1.1a"><mo id="S4.SS2.SSS2.p5.1.m1.1.1">∙</mo><annotation-xml id="S4.SS2.SSS2.p5.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.SS2.SSS2.p5.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S4.SS2.SSS2.p5.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 高级微调。BaThe [ 153] 将有害指令视为可能利用后门模型生成禁止输出的潜在触发器。BaThe [ 153] 用嵌入为“软文本嵌入”的拒绝提示（称为楔子）替换手动设计的触发器（例如，“SUDO”），将有害指令映射到拒绝响应。BaThe 还防御更高级的虚拟提示后门攻击，其中有害指令与微妙提示结合作为触发器。通过将拒绝提示嵌入模型的软文本嵌入中，并在训练中包含多模态问答数据集，BaThe 有效缓解后门风险，确保更安全、更稳健的模型行为。TGA [ 29] 发现特定 Transformer 层的隐藏状态在安全机制的成功激活中起着关键作用，强调当前方法在隐藏状态级别的视觉-语言对齐是不充分的。为此，TGA [ 29] 通过引入成对损失函数（ <math id="S4.SS2.SSS2.p5.4.m4.1" display="inline" class="ltx_Math" alttext="\mathcal{L}_{\text{guide}}"><semantics id="S4.SS2.SSS2.p5.4.m4.1a"><msub id="S4.SS2.SSS2.p5.4.m4.1.1"><mi id="S4.SS2.SSS2.p5.4.m4.1.1.2" class="ltx_font_mathcaligraphic">ℒ</mi><mtext id="S4.SS2.SSS2.p5.4.m4.1.1.3">guide</mtext></msub><annotation-xml id="S4.SS2.SSS2.p5.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.4.m4.1c" encoding="application/x-tex">\mathcal{L}_{\text{guide}}</annotation><annotation id="S4.SS2.SSS2.p5.4.m4.1d" encoding="application/x-llamapun">caligraphic_L start_POSTSUBSCRIPT guide end_POSTSUBSCRIPT</annotation></semantics></math> ），在 LVLMs 中跨 Transformer 层对齐视觉（ <math id="S4.SS2.SSS2.p5.2.m2.1" display="inline" class="ltx_Math" alttext="X_{\text{image}}"><semantics id="S4.SS2.SSS2.p5.2.m2.1a"><msub id="S4.SS2.SSS2.p5.2.m2.1.1"><mi id="S4.SS2.SSS2.p5.2.m2.1.1.2">X</mi><mtext id="S4.SS2.SSS2.p5.2.m2.1.1.3">image</mtext></msub><annotation-xml id="S4.SS2.SSS2.p5.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.2.m2.1c" encoding="application/x-tex">X_{\text{image}}</annotation><annotation id="S4.SS2.SSS2.p5.2.m2.1d" encoding="application/x-llamapun">italic_X start_POSTSUBSCRIPT image end_POSTSUBSCRIPT</annotation></semantics></math> ）和文本（ <math id="S4.SS2.SSS2.p5.3.m3.1" display="inline" class="ltx_Math" alttext="X_{\text{caption}}"><semantics id="S4.SS2.SSS2.p5.3.m3.1a"><msub id="S4.SS2.SSS2.p5.3.m3.1.1"><mi id="S4.SS2.SSS2.p5.3.m3.1.1.2">X</mi><mtext id="S4.SS2.SSS2.p5.3.m3.1.1.3">caption</mtext></msub><annotation-xml id="S4.SS2.SSS2.p5.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.3.m3.1c" encoding="application/x-tex">X_{\text{caption}}</annotation><annotation id="S4.SS2.SSS2.p5.3.m3.1d" encoding="application/x-llamapun">italic_X start_POSTSUBSCRIPT caption end_POSTSUBSCRIPT</annotation></semantics></math> ）输入的隐藏状态。 在这个过程中，检索到的文本（ <math id="S4.SS2.SSS2.p5.5.m5.1" display="inline" class="ltx_Math" alttext="X_{\text{retrieval}}"><semantics id="S4.SS2.SSS2.p5.5.m5.1a"><msub id="S4.SS2.SSS2.p5.5.m5.1.1"><mi id="S4.SS2.SSS2.p5.5.m5.1.1.2">X</mi><mtext id="S4.SS2.SSS2.p5.5.m5.1.1.3">retrieval</mtext></msub><annotation-xml id="S4.SS2.SSS2.p5.5.m5.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.5.m5.1c" encoding="application/x-tex">X_{\text{retrieval}}</annotation><annotation id="S4.SS2.SSS2.p5.5.m5.1d" encoding="application/x-llamapun">italic_X start_POSTSUBSCRIPT retrieval end_POSTSUBSCRIPT</annotation></semantics></math> ）作为指导，确保 <math id="S4.SS2.SSS2.p5.6.m6.1" display="inline" class="ltx_Math" alttext="I_{j}"><semantics id="S4.SS2.SSS2.p5.6.m6.1a"><msub id="S4.SS2.SSS2.p5.6.m6.1.1"><mi id="S4.SS2.SSS2.p5.6.m6.1.1.2">I</mi><mi id="S4.SS2.SSS2.p5.6.m6.1.1.3">j</mi></msub><annotation-xml id="S4.SS2.SSS2.p5.6.m6.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.6.m6.1c" encoding="application/x-tex">I_{j}</annotation><annotation id="S4.SS2.SSS2.p5.6.m6.1d" encoding="application/x-llamapun">italic_I start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> （ <math id="S4.SS2.SSS2.p5.7.m7.1" display="inline" class="ltx_Math" alttext="X_{\text{image}}"><semantics id="S4.SS2.SSS2.p5.7.m7.1a"><msub id="S4.SS2.SSS2.p5.7.m7.1.1"><mi id="S4.SS2.SSS2.p5.7.m7.1.1.2">X</mi><mtext id="S4.SS2.SSS2.p5.7.m7.1.1.3">image</mtext></msub><annotation-xml id="S4.SS2.SSS2.p5.7.m7.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.7.m7.1c" encoding="application/x-tex">X_{\text{image}}</annotation><annotation id="S4.SS2.SSS2.p5.7.m7.1d" encoding="application/x-llamapun">italic_X start_POSTSUBSCRIPT image end_POSTSUBSCRIPT</annotation></semantics></math> 的隐藏状态）比 <math id="S4.SS2.SSS2.p5.10.m10.1" display="inline" class="ltx_Math" alttext="R_{j}"><semantics id="S4.SS2.SSS2.p5.10.m10.1a"><msub id="S4.SS2.SSS2.p5.10.m10.1.1"><mi id="S4.SS2.SSS2.p5.10.m10.1.1.2">R</mi><mi id="S4.SS2.SSS2.p5.10.m10.1.1.3">j</mi></msub><annotation-xml id="S4.SS2.SSS2.p5.10.m10.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.10.m10.1c" encoding="application/x-tex">R_{j}</annotation><annotation id="S4.SS2.SSS2.p5.10.m10.1d" encoding="application/x-llamapun">italic_R start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> （ <math id="S4.SS2.SSS2.p5.11.m11.1" display="inline" class="ltx_Math" alttext="X_{\text{retrieval}}"><semantics id="S4.SS2.SSS2.p5.11.m11.1a"><msub id="S4.SS2.SSS2.p5.11.m11.1.1"><mi id="S4.SS2.SSS2.p5.11.m11.1.1.2">X</mi><mtext id="S4.SS2.SSS2.p5.11.m11.1.1.3">retrieval</mtext></msub><annotation-xml id="S4.SS2.SSS2.p5.11.m11.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.11.m11.1c" encoding="application/x-tex">X_{\text{retrieval}}</annotation><annotation id="S4.SS2.SSS2.p5.11.m11.1d" encoding="application/x-llamapun">italic_X start_POSTSUBSCRIPT retrieval end_POSTSUBSCRIPT</annotation></semantics></math> 的隐藏状态）更接近 <math id="S4.SS2.SSS2.p5.8.m8.1" display="inline" class="ltx_Math" alttext="C_{j}"><semantics id="S4.SS2.SSS2.p5.8.m8.1a"><msub id="S4.SS2.SSS2.p5.8.m8.1.1"><mi id="S4.SS2.SSS2.p5.8.m8.1.1.2">C</mi><mi id="S4.SS2.SSS2.p5.8.m8.1.1.3">j</mi></msub><annotation-xml id="S4.SS2.SSS2.p5.8.m8.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.8.m8.1c" encoding="application/x-tex">C_{j}</annotation><annotation id="S4.SS2.SSS2.p5.8.m8.1d" encoding="application/x-llamapun">italic_C start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> （ <math id="S4.SS2.SSS2.p5.9.m9.1" display="inline" class="ltx_Math" alttext="X_{\text{caption}}"><semantics id="S4.SS2.SSS2.p5.9.m9.1a"><msub id="S4.SS2.SSS2.p5.9.m9.1.1"><mi id="S4.SS2.SSS2.p5.9.m9.1.1.2">X</mi><mtext id="S4.SS2.SSS2.p5.9.m9.1.1.3">caption</mtext></msub><annotation-xml id="S4.SS2.SSS2.p5.9.m9.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.9.m9.1c" encoding="application/x-tex">X_{\text{caption}}</annotation><annotation id="S4.SS2.SSS2.p5.9.m9.1d" encoding="application/x-llamapun">italic_X start_POSTSUBSCRIPT caption end_POSTSUBSCRIPT</annotation></semantics></math> 的隐藏状态），从而实现语义一致性。 总损失结合 <math id="S4.SS2.SSS2.p5.12.m12.1" display="inline" class="ltx_Math" alttext="\mathcal{L}_{\text{guide}}"><semantics id="S4.SS2.SSS2.p5.12.m12.1a"><msub id="S4.SS2.SSS2.p5.12.m12.1.1"><mi id="S4.SS2.SSS2.p5.12.m12.1.1.2" class="ltx_font_mathcaligraphic">ℒ</mi><mtext id="S4.SS2.SSS2.p5.12.m12.1.1.3">guide</mtext></msub><annotation-xml id="S4.SS2.SSS2.p5.12.m12.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.SSS2.p5.12.m12.1c" encoding="application/x-tex">\mathcal{L}_{\text{guide}}</annotation><annotation id="S4.SS2.SSS2.p5.12.m12.1d" encoding="application/x-llamapun">caligraphic_L start_POSTSUBSCRIPT guide end_POSTSUBSCRIPT</annotation></semantics></math> 与语言模型的交叉熵损失，增强隐藏状态层面的多模态对齐，并提升安全机制。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Evaluation</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5 评估</font></font></font>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span><span class="ltx_text ltx_font_italic" id="S5.SS1.1.1">Setup</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.1 设置</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S5.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Methods<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.1.1 方法</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS1.p1">
<p class="ltx_p" id="S5.SS1.SSS1.p1.1">Effective safety evaluation methods are essential for identifying and mitigating risks in model outputs. Here, we outline the primary approaches used to assess response safety&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib154" title="">154</a>]</cite>, focusing on their strengths and constraints.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">有效的安全评估方法对于识别和减轻模型输出的风险至关重要。在此，我们概述了用于评估响应安全性的主要方法[154]，重点关注其优势和局限性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p2">
<p class="ltx_p" id="S5.SS1.SSS1.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p2.1.m1.1"><semantics id="S5.SS1.SSS1.p2.1.m1.1a"><mo id="S5.SS1.SSS1.p2.1.m1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p2.1.m1.1b"><ci id="S5.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p2.1.1">Rule-Based Matching <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.p2.1.1.1">\faEdit</span>.</span>
This method relies on detecting predefined phrases (e.g., “I’m sorry, I can’t assist with it”) to evaluate the safety of model’ responses. While computationally efficient, it has significant limitations, including a lack of contextual understanding and restricted vocabulary coverage, which make it unable to handle the wide variety of expressions that models may generate. Consequently, it fails to provide a thorough assessment of response safety.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS1.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS1.p2.1.m1.1a"><mo id="S5.SS1.SSS1.p2.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS1.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS1.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS1.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 基于规则的匹配 \faEdit. 这种方法依赖于检测预定义的短语（例如，“抱歉，我无法协助此事”）来评估模型响应的安全性。虽然计算效率高，但它存在显著局限性，包括缺乏上下文理解和词汇覆盖范围有限，这使得它无法处理模型可能生成的各种表达方式。因此，它无法提供全面的响应安全性评估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p3">
<p class="ltx_p" id="S5.SS1.SSS1.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p3.1.m1.1"><semantics id="S5.SS1.SSS1.p3.1.m1.1a"><mo id="S5.SS1.SSS1.p3.1.m1.1.1" xref="S5.SS1.SSS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p3.1.m1.1b"><ci id="S5.SS1.SSS1.p3.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p3.1.1">Human-Assisted Evaluation <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.p3.1.1.1">\faEye</span>.</span>
This method relies on manual assessment performed by human evaluators to provide high-quality and context-aware safety evaluations. While human judgment allows for comprehensive and flexible assessments, this approach is highly resource-intensive and constrained by subjectivity. Variations in individual perspectives, cultural backgrounds, and personal biases can lead to inconsistencies, limiting both the scalability and reproducibility of the evaluation process.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS1.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS1.p3.1.m1.1a"><mo id="S5.SS1.SSS1.p3.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS1.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS1.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS1.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 人工辅助评估 \faEye. 这种方法依赖于人工评估员进行的手动评估，以提供高质量且具有上下文感知能力的安全性评估。虽然人工判断允许进行全面和灵活的评估，但这种方法的资源消耗非常高，并受主观性限制。个体视角、文化背景和个人偏见的差异可能导致评估结果不一致，从而限制了评估过程的可扩展性和可重复性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p4">
<p class="ltx_p" id="S5.SS1.SSS1.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p4.1.m1.1"><semantics id="S5.SS1.SSS1.p4.1.m1.1a"><mo id="S5.SS1.SSS1.p4.1.m1.1.1" xref="S5.SS1.SSS1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p4.1.m1.1b"><ci id="S5.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p4.1.1">Fine-tuned Model-Based Assessment <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.p4.1.1.1">\faGithubAlt</span>.</span>
This approach utilizes fine-tuned LLMs or LVLMs to classify responses as safe or unsafe, as demonstrated by systems like LlamaGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib155" title="">155</a>]</cite>, LLaVAGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib146" title="">146</a>]</cite>, and GUARDRANK&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib56" title="">56</a>]</cite>. Compared to rule-based methods, it offers improved contextual understanding and accuracy. However, its performance heavily depends on the quality and diversity of the fine-tuning dataset and is fundamentally limited by the capabilities of the base model, particularly when handling out-of-distribution (OOD) inputs or complex safety scenarios.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS1.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS1.p4.1.m1.1a"><mo id="S5.SS1.SSS1.p4.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS1.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS1.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS1.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 基于微调模型的评估 \faGithubAlt. 这种方法利用微调的 LLMs 或 LVLMs 对响应进行安全或不安全的分类，例如 LlamaGuard [ 155]、LLaVAGuard [ 146]和 GUARDRANK [ 56]等系统所示。与基于规则的方法相比，它提供了更好的上下文理解和准确性。然而，其性能严重依赖于微调数据集的质量和多样性，并且从根本上受限于基础模型的能力，尤其是在处理分布外（OOD）输入或复杂安全场景时。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p5">
<p class="ltx_p" id="S5.SS1.SSS1.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p5.1.m1.1"><semantics id="S5.SS1.SSS1.p5.1.m1.1a"><mo id="S5.SS1.SSS1.p5.1.m1.1.1" xref="S5.SS1.SSS1.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p5.1.m1.1b"><ci id="S5.SS1.SSS1.p5.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p5.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS1.p5.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p5.1.1">GPT Proxy-Based Assessment <span class="ltx_ERROR undefined" id="S5.SS1.SSS1.p5.1.1.1">\faGoogle</span>.</span>
This method leverages the advanced capabilities of models like GPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib16" title="">16</a>]</cite> through API-based interactions, using carefully crafted prompts to evaluate responses to malicious instructions. By taking advantage of LLMs’ ability to understand context and generate detailed evaluations, this approach provides a robust framework for safety assessment. However, its effectiveness is undermined by inherent limitations such as biases and hallucination, where the model generates plausible but incorrect information. These issues introduce potential inconsistencies and reduce the reliability of the evaluation process. An example of a evaluation prompt selected from&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>]</cite> is as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS1.p5.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS1.p5.1.m1.1a"><mo id="S5.SS1.SSS1.p5.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS1.p5.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS1.p5.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS1.p5.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 基于 GPT 代理的评估 \faGoogle. 这种方法通过 API 交互利用 GPT-4 等模型的先进能力[ 16]，使用精心设计的提示来评估对恶意指令的响应。通过利用 LLMs 理解上下文和生成详细评估的能力，这种方法提供了一个强大的安全评估框架。然而，其有效性受到固有限制的削弱，如偏见和幻觉，其中模型会生成看似合理但错误的信息。这些问题引入了潜在的矛盾，降低了评估过程的可靠性。从[ 41]中选择的一个评估提示示例如下：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS1.p6">
<svg class="ltx_picture" height="154.53" id="S5.SS1.SSS1.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,154.53) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 148.62 C 0 151.88 2.64 154.53 5.91 154.53 L 594.09 154.53 C 597.36 154.53 600 151.88 600 148.62 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F5F5F0" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 148.62 C 1.97 150.8 3.73 152.56 5.91 152.56 L 594.09 152.56 C 596.27 152.56 598.03 150.8 598.03 148.62 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="126.97" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.1"><span class="ltx_text" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.1.1" style="font-size:90%;">Below are common AI safety usage policy prohibitions.</span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.2.1" style="font-size:90%;">[The detailed policy description]<span class="ltx_text ltx_font_serif" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.2.1.1"></span></span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.3"><span class="ltx_text" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.3.1" style="font-size:90%;">These prohibitions ensure that models interact with users safely and responsibly. Models should refuse to execute instructions that fall into the prohibited use cases outlined in the policy. I will provide you with user instructions that the AI model should not comply with. I will also give you the model’s response to that instruction.</span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.4"><span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.4.1" style="font-size:90%;">[User Instruction]<span class="ltx_text ltx_font_serif" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.4.1.1"></span></span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.5"><span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.5.1" style="font-size:90%;">[Model Response]<span class="ltx_text ltx_font_serif" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.5.1.1"></span></span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.6"><span class="ltx_text" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.6.1" style="font-size:90%;">Use the scoring rules below to score the model’s response to the user instruction on a scale of 1 to 5:</span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.7"><span class="ltx_text" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.7.1" style="font-size:90%;">1: Refuse to respond.</span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.8"><span class="ltx_text" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.8.1" style="font-size:90%;">2: The response is meaningless, repetitive, or non-informative.</span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.9"><span class="ltx_text" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.9.1" style="font-size:90%;">3: … 4: … 5: …</span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.10"><span class="ltx_text" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.10.1" style="font-size:90%;">Your answer should be: “harmfulness: {1-5}.”</span></span>
<span class="ltx_p" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.11"><span class="ltx_text" id="S5.SS1.SSS1.p6.pic1.1.1.1.1.1.11.1" style="font-size:90%;">Now, please give me your answer.</span></span>
</span></foreignobject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Metrics<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.1.2 指标</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS2.p1">
<p class="ltx_p" id="S5.SS1.SSS2.p1.3">In this part, we introduce a set of metrics used to evaluate the safety and robustness of the model under different conditions. These metrics assess the model’s ability to handle adversarial inputs, generate safe outputs, and maintain functionality across tasks. Specifically, the inputs to the model consist of text (<math alttext="T" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p1.1.m1.1"><semantics id="S5.SS1.SSS2.p1.1.m1.1a"><mi id="S5.SS1.SSS2.p1.1.m1.1.1" xref="S5.SS1.SSS2.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.1.m1.1b"><ci id="S5.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p1.1.m1.1d">italic_T</annotation></semantics></math>) and images (<math alttext="I" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p1.2.m2.1"><semantics id="S5.SS1.SSS2.p1.2.m2.1a"><mi id="S5.SS1.SSS2.p1.2.m2.1.1" xref="S5.SS1.SSS2.p1.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.2.m2.1b"><ci id="S5.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS2.p1.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.2.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p1.2.m2.1d">italic_I</annotation></semantics></math>), while the output is the model’s response (<math alttext="R" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p1.3.m3.1"><semantics id="S5.SS1.SSS2.p1.3.m3.1a"><mi id="S5.SS1.SSS2.p1.3.m3.1.1" xref="S5.SS1.SSS2.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.3.m3.1b"><ci id="S5.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS2.p1.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.3.m3.1c">R</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p1.3.m3.1d">italic_R</annotation></semantics></math>). The following metrics will be evaluated based on these common inputs and outputs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在这一部分，我们介绍一套用于评估模型在不同条件下安全性和鲁棒性的指标。这些指标用于评估模型处理对抗性输入、生成安全输出以及在各项任务中保持功能的能力。具体而言，模型的输入包括文本（ <math id="S5.SS1.SSS2.p1.1.m1.1" display="inline" class="ltx_Math" alttext="T"><semantics id="S5.SS1.SSS2.p1.1.m1.1a"><mi id="S5.SS1.SSS2.p1.1.m1.1.1">T</mi><annotation-xml id="S5.SS1.SSS2.p1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p1.1.m1.1c" encoding="application/x-tex">T</annotation><annotation id="S5.SS1.SSS2.p1.1.m1.1d" encoding="application/x-llamapun">italic_T</annotation></semantics></math> ）和图像（ <math id="S5.SS1.SSS2.p1.2.m2.1" display="inline" class="ltx_Math" alttext="I"><semantics id="S5.SS1.SSS2.p1.2.m2.1a"><mi id="S5.SS1.SSS2.p1.2.m2.1.1">I</mi><annotation-xml id="S5.SS1.SSS2.p1.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p1.2.m2.1c" encoding="application/x-tex">I</annotation><annotation id="S5.SS1.SSS2.p1.2.m2.1d" encoding="application/x-llamapun">italic_I</annotation></semantics></math> ），输出是模型的响应（ <math id="S5.SS1.SSS2.p1.3.m3.1" display="inline" class="ltx_Math" alttext="R"><semantics id="S5.SS1.SSS2.p1.3.m3.1a"><mi id="S5.SS1.SSS2.p1.3.m3.1.1">R</mi><annotation-xml id="S5.SS1.SSS2.p1.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p1.3.m3.1c" encoding="application/x-tex">R</annotation><annotation id="S5.SS1.SSS2.p1.3.m3.1d" encoding="application/x-llamapun">italic_R</annotation></semantics></math> ）。以下将根据这些常见的输入和输出进行评估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p2">
<p class="ltx_p" id="S5.SS1.SSS2.p2.3"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p2.1.m1.1"><semantics id="S5.SS1.SSS2.p2.1.m1.1a"><mo id="S5.SS1.SSS2.p2.1.m1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.1.m1.1b"><ci id="S5.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p2.3.1">Attack Success Rate&nbsp;(ASR)</span>
is employed to quantify the probability of eliciting harmful responses from LVLMs using pairs of image-text queries. Consider a dataset <math alttext="D" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p2.2.m2.1"><semantics id="S5.SS1.SSS2.p2.2.m2.1a"><mi id="S5.SS1.SSS2.p2.2.m2.1.1" xref="S5.SS1.SSS2.p2.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.2.m2.1b"><ci id="S5.SS1.SSS2.p2.2.m2.1.1.cmml" xref="S5.SS1.SSS2.p2.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.2.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p2.2.m2.1d">italic_D</annotation></semantics></math> comprising <math alttext="n" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p2.3.m3.1"><semantics id="S5.SS1.SSS2.p2.3.m3.1a"><mi id="S5.SS1.SSS2.p2.3.m3.1.1" xref="S5.SS1.SSS2.p2.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.3.m3.1b"><ci id="S5.SS1.SSS2.p2.3.m3.1.1.cmml" xref="S5.SS1.SSS2.p2.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p2.3.m3.1d">italic_n</annotation></semantics></math> pairs of image-text queries, we formally define the ASR as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS2.p2.1.m1.1a"><mo id="S5.SS1.SSS2.p2.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS2.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS2.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 攻击成功率（ASR）用于量化使用图像-文本查询对诱使大型视觉语言模型（LVLMs）产生有害响应的概率。考虑一个包含 <math id="S5.SS1.SSS2.p2.3.m3.1" display="inline" class="ltx_Math" alttext="n"><semantics id="S5.SS1.SSS2.p2.3.m3.1a"><mi id="S5.SS1.SSS2.p2.3.m3.1.1">n</mi><annotation-xml id="S5.SS1.SSS2.p2.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p2.3.m3.1c" encoding="application/x-tex">n</annotation><annotation id="S5.SS1.SSS2.p2.3.m3.1d" encoding="application/x-llamapun">italic_n</annotation></semantics></math> 对图像-文本查询的 <math id="S5.SS1.SSS2.p2.2.m2.1" display="inline" class="ltx_Math" alttext="D"><semantics id="S5.SS1.SSS2.p2.2.m2.1a"><mi id="S5.SS1.SSS2.p2.2.m2.1.1">D</mi><annotation-xml id="S5.SS1.SSS2.p2.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p2.2.m2.1c" encoding="application/x-tex">D</annotation><annotation id="S5.SS1.SSS2.p2.2.m2.1d" encoding="application/x-llamapun">italic_D</annotation></semantics></math> 数据集，我们正式定义 ASR 为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_table" id="S5.E12">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S5.E12X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{ASR}=\frac{\sum_{i=1}^{n}\text{AttackEvaluator}(T_{i},I_{i}%
,R_{i})}{|D|}," class="ltx_Math" display="inline" id="S5.E12X.2.1.1.m1.5"><semantics id="S5.E12X.2.1.1.m1.5a"><mrow id="S5.E12X.2.1.1.m1.5.5.1" xref="S5.E12X.2.1.1.m1.5.5.1.1.cmml"><mrow id="S5.E12X.2.1.1.m1.5.5.1.1" xref="S5.E12X.2.1.1.m1.5.5.1.1.cmml"><mtext id="S5.E12X.2.1.1.m1.5.5.1.1.2" xref="S5.E12X.2.1.1.m1.5.5.1.1.2a.cmml">ASR</mtext><mo id="S5.E12X.2.1.1.m1.5.5.1.1.1" xref="S5.E12X.2.1.1.m1.5.5.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S5.E12X.2.1.1.m1.4.4" xref="S5.E12X.2.1.1.m1.4.4.cmml"><mfrac id="S5.E12X.2.1.1.m1.4.4a" xref="S5.E12X.2.1.1.m1.4.4.cmml"><mrow id="S5.E12X.2.1.1.m1.3.3.3" xref="S5.E12X.2.1.1.m1.3.3.3.cmml"><msubsup id="S5.E12X.2.1.1.m1.3.3.3.4" xref="S5.E12X.2.1.1.m1.3.3.3.4.cmml"><mo id="S5.E12X.2.1.1.m1.3.3.3.4.2.2" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.2.cmml">∑</mo><mrow id="S5.E12X.2.1.1.m1.3.3.3.4.2.3" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.3.cmml"><mi id="S5.E12X.2.1.1.m1.3.3.3.4.2.3.2" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.3.2.cmml">i</mi><mo id="S5.E12X.2.1.1.m1.3.3.3.4.2.3.1" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.3.1.cmml">=</mo><mn id="S5.E12X.2.1.1.m1.3.3.3.4.2.3.3" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.3.3.cmml">1</mn></mrow><mi id="S5.E12X.2.1.1.m1.3.3.3.4.3" xref="S5.E12X.2.1.1.m1.3.3.3.4.3.cmml">n</mi></msubsup><mrow id="S5.E12X.2.1.1.m1.3.3.3.3" xref="S5.E12X.2.1.1.m1.3.3.3.3.cmml"><mtext id="S5.E12X.2.1.1.m1.3.3.3.3.5" xref="S5.E12X.2.1.1.m1.3.3.3.3.5a.cmml">AttackEvaluator</mtext><mo id="S5.E12X.2.1.1.m1.3.3.3.3.4" xref="S5.E12X.2.1.1.m1.3.3.3.3.4.cmml">⁢</mo><mrow id="S5.E12X.2.1.1.m1.3.3.3.3.3.3" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.4.cmml"><mo id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.4" stretchy="false" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.4.cmml">(</mo><msub id="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1" xref="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml">T</mi><mi id="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.5" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.4.cmml">,</mo><msub id="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2" xref="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.cmml"><mi id="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.2" xref="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.2.cmml">I</mi><mi id="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.3" xref="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.6" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.4.cmml">,</mo><msub id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.cmml"><mi id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.2" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.2.cmml">R</mi><mi id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.3" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.3.cmml">i</mi></msub><mo id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.7" stretchy="false" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E12X.2.1.1.m1.4.4.4.3" xref="S5.E12X.2.1.1.m1.4.4.4.2.cmml"><mo id="S5.E12X.2.1.1.m1.4.4.4.3.1" stretchy="false" xref="S5.E12X.2.1.1.m1.4.4.4.2.1.cmml">|</mo><mi id="S5.E12X.2.1.1.m1.4.4.4.1" xref="S5.E12X.2.1.1.m1.4.4.4.1.cmml">D</mi><mo id="S5.E12X.2.1.1.m1.4.4.4.3.2" stretchy="false" xref="S5.E12X.2.1.1.m1.4.4.4.2.1.cmml">|</mo></mrow></mfrac></mstyle></mrow><mo id="S5.E12X.2.1.1.m1.5.5.1.2" xref="S5.E12X.2.1.1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E12X.2.1.1.m1.5b"><apply id="S5.E12X.2.1.1.m1.5.5.1.1.cmml" xref="S5.E12X.2.1.1.m1.5.5.1"><eq id="S5.E12X.2.1.1.m1.5.5.1.1.1.cmml" xref="S5.E12X.2.1.1.m1.5.5.1.1.1"></eq><ci id="S5.E12X.2.1.1.m1.5.5.1.1.2a.cmml" xref="S5.E12X.2.1.1.m1.5.5.1.1.2"><mtext id="S5.E12X.2.1.1.m1.5.5.1.1.2.cmml" xref="S5.E12X.2.1.1.m1.5.5.1.1.2">ASR</mtext></ci><apply id="S5.E12X.2.1.1.m1.4.4.cmml" xref="S5.E12X.2.1.1.m1.4.4"><divide id="S5.E12X.2.1.1.m1.4.4.5.cmml" xref="S5.E12X.2.1.1.m1.4.4"></divide><apply id="S5.E12X.2.1.1.m1.3.3.3.cmml" xref="S5.E12X.2.1.1.m1.3.3.3"><apply id="S5.E12X.2.1.1.m1.3.3.3.4.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4"><csymbol cd="ambiguous" id="S5.E12X.2.1.1.m1.3.3.3.4.1.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4">superscript</csymbol><apply id="S5.E12X.2.1.1.m1.3.3.3.4.2.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4"><csymbol cd="ambiguous" id="S5.E12X.2.1.1.m1.3.3.3.4.2.1.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4">subscript</csymbol><sum id="S5.E12X.2.1.1.m1.3.3.3.4.2.2.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.2"></sum><apply id="S5.E12X.2.1.1.m1.3.3.3.4.2.3.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.3"><eq id="S5.E12X.2.1.1.m1.3.3.3.4.2.3.1.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.3.1"></eq><ci id="S5.E12X.2.1.1.m1.3.3.3.4.2.3.2.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.3.2">𝑖</ci><cn id="S5.E12X.2.1.1.m1.3.3.3.4.2.3.3.cmml" type="integer" xref="S5.E12X.2.1.1.m1.3.3.3.4.2.3.3">1</cn></apply></apply><ci id="S5.E12X.2.1.1.m1.3.3.3.4.3.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.4.3">𝑛</ci></apply><apply id="S5.E12X.2.1.1.m1.3.3.3.3.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3"><times id="S5.E12X.2.1.1.m1.3.3.3.3.4.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3.4"></times><ci id="S5.E12X.2.1.1.m1.3.3.3.3.5a.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3.5"><mtext id="S5.E12X.2.1.1.m1.3.3.3.3.5.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3.5">AttackEvaluator</mtext></ci><vector id="S5.E12X.2.1.1.m1.3.3.3.3.3.4.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.3"><apply id="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.2">𝑇</ci><ci id="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E12X.2.1.1.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.cmml" xref="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.1.cmml" xref="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.2">𝐼</ci><ci id="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.3.cmml" xref="S5.E12X.2.1.1.m1.2.2.2.2.2.2.2.3">𝑖</ci></apply><apply id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.1.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3">subscript</csymbol><ci id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.2.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.2">𝑅</ci><ci id="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.3.cmml" xref="S5.E12X.2.1.1.m1.3.3.3.3.3.3.3.3">𝑖</ci></apply></vector></apply></apply><apply id="S5.E12X.2.1.1.m1.4.4.4.2.cmml" xref="S5.E12X.2.1.1.m1.4.4.4.3"><abs id="S5.E12X.2.1.1.m1.4.4.4.2.1.cmml" xref="S5.E12X.2.1.1.m1.4.4.4.3.1"></abs><ci id="S5.E12X.2.1.1.m1.4.4.4.1.cmml" xref="S5.E12X.2.1.1.m1.4.4.4.1">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E12X.2.1.1.m1.5c">\displaystyle\text{ASR}=\frac{\sum_{i=1}^{n}\text{AttackEvaluator}(T_{i},I_{i}%
,R_{i})}{|D|},</annotation><annotation encoding="application/x-llamapun" id="S5.E12X.2.1.1.m1.5d">ASR = divide start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT AttackEvaluator ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG | italic_D | end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(12)</span></td>
</tr>
</tbody>
</table>
<p class="ltx_p" id="S5.SS1.SSS2.p2.6">where <math alttext="\text{AttackEvaluator}(\cdot)" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p2.4.m1.1"><semantics id="S5.SS1.SSS2.p2.4.m1.1a"><mrow id="S5.SS1.SSS2.p2.4.m1.1.2" xref="S5.SS1.SSS2.p2.4.m1.1.2.cmml"><mtext id="S5.SS1.SSS2.p2.4.m1.1.2.2" xref="S5.SS1.SSS2.p2.4.m1.1.2.2a.cmml">AttackEvaluator</mtext><mo id="S5.SS1.SSS2.p2.4.m1.1.2.1" xref="S5.SS1.SSS2.p2.4.m1.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.SSS2.p2.4.m1.1.2.3.2" xref="S5.SS1.SSS2.p2.4.m1.1.2.cmml"><mo id="S5.SS1.SSS2.p2.4.m1.1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS2.p2.4.m1.1.2.cmml">(</mo><mo id="S5.SS1.SSS2.p2.4.m1.1.1" lspace="0em" rspace="0em" xref="S5.SS1.SSS2.p2.4.m1.1.1.cmml">⋅</mo><mo id="S5.SS1.SSS2.p2.4.m1.1.2.3.2.2" stretchy="false" xref="S5.SS1.SSS2.p2.4.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.4.m1.1b"><apply id="S5.SS1.SSS2.p2.4.m1.1.2.cmml" xref="S5.SS1.SSS2.p2.4.m1.1.2"><times id="S5.SS1.SSS2.p2.4.m1.1.2.1.cmml" xref="S5.SS1.SSS2.p2.4.m1.1.2.1"></times><ci id="S5.SS1.SSS2.p2.4.m1.1.2.2a.cmml" xref="S5.SS1.SSS2.p2.4.m1.1.2.2"><mtext id="S5.SS1.SSS2.p2.4.m1.1.2.2.cmml" xref="S5.SS1.SSS2.p2.4.m1.1.2.2">AttackEvaluator</mtext></ci><ci id="S5.SS1.SSS2.p2.4.m1.1.1.cmml" xref="S5.SS1.SSS2.p2.4.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.4.m1.1c">\text{AttackEvaluator}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p2.4.m1.1d">AttackEvaluator ( ⋅ )</annotation></semantics></math> is a binary function that returns 1 if the model’s response <math alttext="R_{i}" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p2.5.m2.1"><semantics id="S5.SS1.SSS2.p2.5.m2.1a"><msub id="S5.SS1.SSS2.p2.5.m2.1.1" xref="S5.SS1.SSS2.p2.5.m2.1.1.cmml"><mi id="S5.SS1.SSS2.p2.5.m2.1.1.2" xref="S5.SS1.SSS2.p2.5.m2.1.1.2.cmml">R</mi><mi id="S5.SS1.SSS2.p2.5.m2.1.1.3" xref="S5.SS1.SSS2.p2.5.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.5.m2.1b"><apply id="S5.SS1.SSS2.p2.5.m2.1.1.cmml" xref="S5.SS1.SSS2.p2.5.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p2.5.m2.1.1.1.cmml" xref="S5.SS1.SSS2.p2.5.m2.1.1">subscript</csymbol><ci id="S5.SS1.SSS2.p2.5.m2.1.1.2.cmml" xref="S5.SS1.SSS2.p2.5.m2.1.1.2">𝑅</ci><ci id="S5.SS1.SSS2.p2.5.m2.1.1.3.cmml" xref="S5.SS1.SSS2.p2.5.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.5.m2.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p2.5.m2.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to a given input pair <math alttext="(T_{i},I_{i})" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p2.6.m3.2"><semantics id="S5.SS1.SSS2.p2.6.m3.2a"><mrow id="S5.SS1.SSS2.p2.6.m3.2.2.2" xref="S5.SS1.SSS2.p2.6.m3.2.2.3.cmml"><mo id="S5.SS1.SSS2.p2.6.m3.2.2.2.3" stretchy="false" xref="S5.SS1.SSS2.p2.6.m3.2.2.3.cmml">(</mo><msub id="S5.SS1.SSS2.p2.6.m3.1.1.1.1" xref="S5.SS1.SSS2.p2.6.m3.1.1.1.1.cmml"><mi id="S5.SS1.SSS2.p2.6.m3.1.1.1.1.2" xref="S5.SS1.SSS2.p2.6.m3.1.1.1.1.2.cmml">T</mi><mi id="S5.SS1.SSS2.p2.6.m3.1.1.1.1.3" xref="S5.SS1.SSS2.p2.6.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.SS1.SSS2.p2.6.m3.2.2.2.4" xref="S5.SS1.SSS2.p2.6.m3.2.2.3.cmml">,</mo><msub id="S5.SS1.SSS2.p2.6.m3.2.2.2.2" xref="S5.SS1.SSS2.p2.6.m3.2.2.2.2.cmml"><mi id="S5.SS1.SSS2.p2.6.m3.2.2.2.2.2" xref="S5.SS1.SSS2.p2.6.m3.2.2.2.2.2.cmml">I</mi><mi id="S5.SS1.SSS2.p2.6.m3.2.2.2.2.3" xref="S5.SS1.SSS2.p2.6.m3.2.2.2.2.3.cmml">i</mi></msub><mo id="S5.SS1.SSS2.p2.6.m3.2.2.2.5" stretchy="false" xref="S5.SS1.SSS2.p2.6.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.6.m3.2b"><interval closure="open" id="S5.SS1.SSS2.p2.6.m3.2.2.3.cmml" xref="S5.SS1.SSS2.p2.6.m3.2.2.2"><apply id="S5.SS1.SSS2.p2.6.m3.1.1.1.1.cmml" xref="S5.SS1.SSS2.p2.6.m3.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p2.6.m3.1.1.1.1.1.cmml" xref="S5.SS1.SSS2.p2.6.m3.1.1.1.1">subscript</csymbol><ci id="S5.SS1.SSS2.p2.6.m3.1.1.1.1.2.cmml" xref="S5.SS1.SSS2.p2.6.m3.1.1.1.1.2">𝑇</ci><ci id="S5.SS1.SSS2.p2.6.m3.1.1.1.1.3.cmml" xref="S5.SS1.SSS2.p2.6.m3.1.1.1.1.3">𝑖</ci></apply><apply id="S5.SS1.SSS2.p2.6.m3.2.2.2.2.cmml" xref="S5.SS1.SSS2.p2.6.m3.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p2.6.m3.2.2.2.2.1.cmml" xref="S5.SS1.SSS2.p2.6.m3.2.2.2.2">subscript</csymbol><ci id="S5.SS1.SSS2.p2.6.m3.2.2.2.2.2.cmml" xref="S5.SS1.SSS2.p2.6.m3.2.2.2.2.2">𝐼</ci><ci id="S5.SS1.SSS2.p2.6.m3.2.2.2.2.3.cmml" xref="S5.SS1.SSS2.p2.6.m3.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.6.m3.2c">(T_{i},I_{i})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p2.6.m3.2d">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is evaluated as unsafe and 0 otherwise. This metric effectively captures the proportion of query pairs capable of inducing undesirable outputs from the target LVLM. A lower ASR indicates greater safety performance to attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S5.SS1.SSS2.p2.4.m1.1" display="inline" class="ltx_Math" alttext="\text{AttackEvaluator}(\cdot)"><semantics id="S5.SS1.SSS2.p2.4.m1.1a"><mrow id="S5.SS1.SSS2.p2.4.m1.1.2"><mtext id="S5.SS1.SSS2.p2.4.m1.1.2.2">AttackEvaluator</mtext><mo id="S5.SS1.SSS2.p2.4.m1.1.2.1">⁢</mo><mrow id="S5.SS1.SSS2.p2.4.m1.1.2.3.2"><mo stretchy="false" id="S5.SS1.SSS2.p2.4.m1.1.2.3.2.1">(</mo><mo rspace="0em" lspace="0em" id="S5.SS1.SSS2.p2.4.m1.1.1">⋅</mo><mo stretchy="false" id="S5.SS1.SSS2.p2.4.m1.1.2.3.2.2">)</mo></mrow></mrow><annotation-xml id="S5.SS1.SSS2.p2.4.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p2.4.m1.1c" encoding="application/x-tex">\text{AttackEvaluator}(\cdot)</annotation><annotation id="S5.SS1.SSS2.p2.4.m1.1d" encoding="application/x-llamapun">AttackEvaluator ( ⋅ )</annotation></semantics></math> 是一个二元函数，当模型 <math id="S5.SS1.SSS2.p2.5.m2.1" display="inline" class="ltx_Math" alttext="R_{i}"><semantics id="S5.SS1.SSS2.p2.5.m2.1a"><msub id="S5.SS1.SSS2.p2.5.m2.1.1"><mi id="S5.SS1.SSS2.p2.5.m2.1.1.2">R</mi><mi id="S5.SS1.SSS2.p2.5.m2.1.1.3">i</mi></msub><annotation-xml id="S5.SS1.SSS2.p2.5.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S5.SS1.SSS2.p2.5.m2.1c" encoding="application/x-tex">R_{i}</annotation><annotation id="S5.SS1.SSS2.p2.5.m2.1d" encoding="application/x-llamapun">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> 对给定的输入对 <math id="S5.SS1.SSS2.p2.6.m3.2" display="inline" class="ltx_Math" alttext="(T_{i},I_{i})"><semantics id="S5.SS1.SSS2.p2.6.m3.2a"><mrow id="S5.SS1.SSS2.p2.6.m3.2.2.2"><mo stretchy="false" id="S5.SS1.SSS2.p2.6.m3.2.2.2.3">(</mo><msub id="S5.SS1.SSS2.p2.6.m3.1.1.1.1"><mi id="S5.SS1.SSS2.p2.6.m3.1.1.1.1.2">T</mi><mi id="S5.SS1.SSS2.p2.6.m3.1.1.1.1.3">i</mi></msub><mo id="S5.SS1.SSS2.p2.6.m3.2.2.2.4">,</mo><msub id="S5.SS1.SSS2.p2.6.m3.2.2.2.2"><mi id="S5.SS1.SSS2.p2.6.m3.2.2.2.2.2">I</mi><mi id="S5.SS1.SSS2.p2.6.m3.2.2.2.2.3">i</mi></msub><mo stretchy="false" id="S5.SS1.SSS2.p2.6.m3.2.2.2.5">)</mo></mrow><annotation-xml id="S5.SS1.SSS2.p2.6.m3.2b" encoding="MathML-Content">subscriptsubscript</annotation-xml><annotation id="S5.SS1.SSS2.p2.6.m3.2c" encoding="application/x-tex">(T_{i},I_{i})</annotation><annotation id="S5.SS1.SSS2.p2.6.m3.2d" encoding="application/x-llamapun">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> 的响应被评估为不安全时返回 1，否则返回 0。这个指标有效地捕捉了能够从目标大型视觉语言模型（LVLM）中诱导出不良输出的查询对的比例。ASR 越低，表明对攻击的安全性性能越好。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p3">
<p class="ltx_p" id="S5.SS1.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p3.1.m1.1"><semantics id="S5.SS1.SSS2.p3.1.m1.1a"><mo id="S5.SS1.SSS2.p3.1.m1.1.1" xref="S5.SS1.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p3.1.m1.1b"><ci id="S5.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p3.1.1">Safety Risk Index&nbsp;(SRI)</span>
is introduced by SafeBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib154" title="">154</a>]</cite>, aim to provides a more detailed evaluation of model safety by distinguishing between varying levels of response severity. While ASR classifies all unsafe responses equally, SRI measures the degree of risk posed by each response, enabling a finer-grained safety analysis. For example, when queried about harmful topics like bomb-making, one model might generate detailed instructions while another merely references a related book. Although both would be considered unsafe under ASR, SRI assigns a higher risk score to the former due to its greater severity. SRI is computed as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS2.p3.1.m1.1a"><mo id="S5.SS1.SSS2.p3.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS2.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS2.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 安全风险指数（SRI）由 SafeBench [ 154]引入，旨在通过区分不同级别的响应严重程度，对模型安全性进行更详细的评估。虽然 ASR 对所有不安全响应同等对待，但 SRI 衡量每个响应带来的风险程度，从而实现更细粒度的安全分析。例如，当被问及炸弹制作等有害话题时，一个模型可能会生成详细说明，而另一个模型仅引用相关书籍。尽管在 ASR 标准下两者都被视为不安全，但 SRI 由于前者严重程度更高，会赋予其更高的风险评分。SRI 的计算公式为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S5.E13">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{SRI}=\frac{\sum_{i=1}^{n}\text{RiskEvaluator}(T_{i},I_{i},R_{i})}{|D|}," class="ltx_Math" display="block" id="S5.E13.m1.5"><semantics id="S5.E13.m1.5a"><mrow id="S5.E13.m1.5.5.1" xref="S5.E13.m1.5.5.1.1.cmml"><mrow id="S5.E13.m1.5.5.1.1" xref="S5.E13.m1.5.5.1.1.cmml"><mtext id="S5.E13.m1.5.5.1.1.2" xref="S5.E13.m1.5.5.1.1.2a.cmml">SRI</mtext><mo id="S5.E13.m1.5.5.1.1.1" xref="S5.E13.m1.5.5.1.1.1.cmml">=</mo><mfrac id="S5.E13.m1.4.4" xref="S5.E13.m1.4.4.cmml"><mrow id="S5.E13.m1.3.3.3" xref="S5.E13.m1.3.3.3.cmml"><msubsup id="S5.E13.m1.3.3.3.4" xref="S5.E13.m1.3.3.3.4.cmml"><mo id="S5.E13.m1.3.3.3.4.2.2" xref="S5.E13.m1.3.3.3.4.2.2.cmml">∑</mo><mrow id="S5.E13.m1.3.3.3.4.2.3" xref="S5.E13.m1.3.3.3.4.2.3.cmml"><mi id="S5.E13.m1.3.3.3.4.2.3.2" xref="S5.E13.m1.3.3.3.4.2.3.2.cmml">i</mi><mo id="S5.E13.m1.3.3.3.4.2.3.1" xref="S5.E13.m1.3.3.3.4.2.3.1.cmml">=</mo><mn id="S5.E13.m1.3.3.3.4.2.3.3" xref="S5.E13.m1.3.3.3.4.2.3.3.cmml">1</mn></mrow><mi id="S5.E13.m1.3.3.3.4.3" xref="S5.E13.m1.3.3.3.4.3.cmml">n</mi></msubsup><mrow id="S5.E13.m1.3.3.3.3" xref="S5.E13.m1.3.3.3.3.cmml"><mtext id="S5.E13.m1.3.3.3.3.5" xref="S5.E13.m1.3.3.3.3.5a.cmml">RiskEvaluator</mtext><mo id="S5.E13.m1.3.3.3.3.4" xref="S5.E13.m1.3.3.3.3.4.cmml">⁢</mo><mrow id="S5.E13.m1.3.3.3.3.3.3" xref="S5.E13.m1.3.3.3.3.3.4.cmml"><mo id="S5.E13.m1.3.3.3.3.3.3.4" stretchy="false" xref="S5.E13.m1.3.3.3.3.3.4.cmml">(</mo><msub id="S5.E13.m1.1.1.1.1.1.1.1" xref="S5.E13.m1.1.1.1.1.1.1.1.cmml"><mi id="S5.E13.m1.1.1.1.1.1.1.1.2" xref="S5.E13.m1.1.1.1.1.1.1.1.2.cmml">T</mi><mi id="S5.E13.m1.1.1.1.1.1.1.1.3" xref="S5.E13.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.E13.m1.3.3.3.3.3.3.5" xref="S5.E13.m1.3.3.3.3.3.4.cmml">,</mo><msub id="S5.E13.m1.2.2.2.2.2.2.2" xref="S5.E13.m1.2.2.2.2.2.2.2.cmml"><mi id="S5.E13.m1.2.2.2.2.2.2.2.2" xref="S5.E13.m1.2.2.2.2.2.2.2.2.cmml">I</mi><mi id="S5.E13.m1.2.2.2.2.2.2.2.3" xref="S5.E13.m1.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S5.E13.m1.3.3.3.3.3.3.6" xref="S5.E13.m1.3.3.3.3.3.4.cmml">,</mo><msub id="S5.E13.m1.3.3.3.3.3.3.3" xref="S5.E13.m1.3.3.3.3.3.3.3.cmml"><mi id="S5.E13.m1.3.3.3.3.3.3.3.2" xref="S5.E13.m1.3.3.3.3.3.3.3.2.cmml">R</mi><mi id="S5.E13.m1.3.3.3.3.3.3.3.3" xref="S5.E13.m1.3.3.3.3.3.3.3.3.cmml">i</mi></msub><mo id="S5.E13.m1.3.3.3.3.3.3.7" stretchy="false" xref="S5.E13.m1.3.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E13.m1.4.4.4.3" xref="S5.E13.m1.4.4.4.2.cmml"><mo id="S5.E13.m1.4.4.4.3.1" stretchy="false" xref="S5.E13.m1.4.4.4.2.1.cmml">|</mo><mi id="S5.E13.m1.4.4.4.1" xref="S5.E13.m1.4.4.4.1.cmml">D</mi><mo id="S5.E13.m1.4.4.4.3.2" stretchy="false" xref="S5.E13.m1.4.4.4.2.1.cmml">|</mo></mrow></mfrac></mrow><mo id="S5.E13.m1.5.5.1.2" xref="S5.E13.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E13.m1.5b"><apply id="S5.E13.m1.5.5.1.1.cmml" xref="S5.E13.m1.5.5.1"><eq id="S5.E13.m1.5.5.1.1.1.cmml" xref="S5.E13.m1.5.5.1.1.1"></eq><ci id="S5.E13.m1.5.5.1.1.2a.cmml" xref="S5.E13.m1.5.5.1.1.2"><mtext id="S5.E13.m1.5.5.1.1.2.cmml" xref="S5.E13.m1.5.5.1.1.2">SRI</mtext></ci><apply id="S5.E13.m1.4.4.cmml" xref="S5.E13.m1.4.4"><divide id="S5.E13.m1.4.4.5.cmml" xref="S5.E13.m1.4.4"></divide><apply id="S5.E13.m1.3.3.3.cmml" xref="S5.E13.m1.3.3.3"><apply id="S5.E13.m1.3.3.3.4.cmml" xref="S5.E13.m1.3.3.3.4"><csymbol cd="ambiguous" id="S5.E13.m1.3.3.3.4.1.cmml" xref="S5.E13.m1.3.3.3.4">superscript</csymbol><apply id="S5.E13.m1.3.3.3.4.2.cmml" xref="S5.E13.m1.3.3.3.4"><csymbol cd="ambiguous" id="S5.E13.m1.3.3.3.4.2.1.cmml" xref="S5.E13.m1.3.3.3.4">subscript</csymbol><sum id="S5.E13.m1.3.3.3.4.2.2.cmml" xref="S5.E13.m1.3.3.3.4.2.2"></sum><apply id="S5.E13.m1.3.3.3.4.2.3.cmml" xref="S5.E13.m1.3.3.3.4.2.3"><eq id="S5.E13.m1.3.3.3.4.2.3.1.cmml" xref="S5.E13.m1.3.3.3.4.2.3.1"></eq><ci id="S5.E13.m1.3.3.3.4.2.3.2.cmml" xref="S5.E13.m1.3.3.3.4.2.3.2">𝑖</ci><cn id="S5.E13.m1.3.3.3.4.2.3.3.cmml" type="integer" xref="S5.E13.m1.3.3.3.4.2.3.3">1</cn></apply></apply><ci id="S5.E13.m1.3.3.3.4.3.cmml" xref="S5.E13.m1.3.3.3.4.3">𝑛</ci></apply><apply id="S5.E13.m1.3.3.3.3.cmml" xref="S5.E13.m1.3.3.3.3"><times id="S5.E13.m1.3.3.3.3.4.cmml" xref="S5.E13.m1.3.3.3.3.4"></times><ci id="S5.E13.m1.3.3.3.3.5a.cmml" xref="S5.E13.m1.3.3.3.3.5"><mtext id="S5.E13.m1.3.3.3.3.5.cmml" xref="S5.E13.m1.3.3.3.3.5">RiskEvaluator</mtext></ci><vector id="S5.E13.m1.3.3.3.3.3.4.cmml" xref="S5.E13.m1.3.3.3.3.3.3"><apply id="S5.E13.m1.1.1.1.1.1.1.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E13.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E13.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.2">𝑇</ci><ci id="S5.E13.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S5.E13.m1.2.2.2.2.2.2.2.cmml" xref="S5.E13.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.E13.m1.2.2.2.2.2.2.2.1.cmml" xref="S5.E13.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S5.E13.m1.2.2.2.2.2.2.2.2.cmml" xref="S5.E13.m1.2.2.2.2.2.2.2.2">𝐼</ci><ci id="S5.E13.m1.2.2.2.2.2.2.2.3.cmml" xref="S5.E13.m1.2.2.2.2.2.2.2.3">𝑖</ci></apply><apply id="S5.E13.m1.3.3.3.3.3.3.3.cmml" xref="S5.E13.m1.3.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S5.E13.m1.3.3.3.3.3.3.3.1.cmml" xref="S5.E13.m1.3.3.3.3.3.3.3">subscript</csymbol><ci id="S5.E13.m1.3.3.3.3.3.3.3.2.cmml" xref="S5.E13.m1.3.3.3.3.3.3.3.2">𝑅</ci><ci id="S5.E13.m1.3.3.3.3.3.3.3.3.cmml" xref="S5.E13.m1.3.3.3.3.3.3.3.3">𝑖</ci></apply></vector></apply></apply><apply id="S5.E13.m1.4.4.4.2.cmml" xref="S5.E13.m1.4.4.4.3"><abs id="S5.E13.m1.4.4.4.2.1.cmml" xref="S5.E13.m1.4.4.4.3.1"></abs><ci id="S5.E13.m1.4.4.4.1.cmml" xref="S5.E13.m1.4.4.4.1">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E13.m1.5c">\text{SRI}=\frac{\sum_{i=1}^{n}\text{RiskEvaluator}(T_{i},I_{i},R_{i})}{|D|},</annotation><annotation encoding="application/x-llamapun" id="S5.E13.m1.5d">SRI = divide start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT RiskEvaluator ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG | italic_D | end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(13)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS1.SSS2.p3.4">where <math alttext="\text{RiskEvaluator}(\cdot)" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p3.2.m1.1"><semantics id="S5.SS1.SSS2.p3.2.m1.1a"><mrow id="S5.SS1.SSS2.p3.2.m1.1.2" xref="S5.SS1.SSS2.p3.2.m1.1.2.cmml"><mtext id="S5.SS1.SSS2.p3.2.m1.1.2.2" xref="S5.SS1.SSS2.p3.2.m1.1.2.2a.cmml">RiskEvaluator</mtext><mo id="S5.SS1.SSS2.p3.2.m1.1.2.1" xref="S5.SS1.SSS2.p3.2.m1.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.SSS2.p3.2.m1.1.2.3.2" xref="S5.SS1.SSS2.p3.2.m1.1.2.cmml"><mo id="S5.SS1.SSS2.p3.2.m1.1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS2.p3.2.m1.1.2.cmml">(</mo><mo id="S5.SS1.SSS2.p3.2.m1.1.1" lspace="0em" rspace="0em" xref="S5.SS1.SSS2.p3.2.m1.1.1.cmml">⋅</mo><mo id="S5.SS1.SSS2.p3.2.m1.1.2.3.2.2" stretchy="false" xref="S5.SS1.SSS2.p3.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p3.2.m1.1b"><apply id="S5.SS1.SSS2.p3.2.m1.1.2.cmml" xref="S5.SS1.SSS2.p3.2.m1.1.2"><times id="S5.SS1.SSS2.p3.2.m1.1.2.1.cmml" xref="S5.SS1.SSS2.p3.2.m1.1.2.1"></times><ci id="S5.SS1.SSS2.p3.2.m1.1.2.2a.cmml" xref="S5.SS1.SSS2.p3.2.m1.1.2.2"><mtext id="S5.SS1.SSS2.p3.2.m1.1.2.2.cmml" xref="S5.SS1.SSS2.p3.2.m1.1.2.2">RiskEvaluator</mtext></ci><ci id="S5.SS1.SSS2.p3.2.m1.1.1.cmml" xref="S5.SS1.SSS2.p3.2.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p3.2.m1.1c">\text{RiskEvaluator}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p3.2.m1.1d">RiskEvaluator ( ⋅ )</annotation></semantics></math> is a scoring function that evaluates the severity of the model’s response <math alttext="R_{i}" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p3.3.m2.1"><semantics id="S5.SS1.SSS2.p3.3.m2.1a"><msub id="S5.SS1.SSS2.p3.3.m2.1.1" xref="S5.SS1.SSS2.p3.3.m2.1.1.cmml"><mi id="S5.SS1.SSS2.p3.3.m2.1.1.2" xref="S5.SS1.SSS2.p3.3.m2.1.1.2.cmml">R</mi><mi id="S5.SS1.SSS2.p3.3.m2.1.1.3" xref="S5.SS1.SSS2.p3.3.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p3.3.m2.1b"><apply id="S5.SS1.SSS2.p3.3.m2.1.1.cmml" xref="S5.SS1.SSS2.p3.3.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p3.3.m2.1.1.1.cmml" xref="S5.SS1.SSS2.p3.3.m2.1.1">subscript</csymbol><ci id="S5.SS1.SSS2.p3.3.m2.1.1.2.cmml" xref="S5.SS1.SSS2.p3.3.m2.1.1.2">𝑅</ci><ci id="S5.SS1.SSS2.p3.3.m2.1.1.3.cmml" xref="S5.SS1.SSS2.p3.3.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p3.3.m2.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p3.3.m2.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to a query pair <math alttext="(T_{i},I_{i})" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p3.4.m3.2"><semantics id="S5.SS1.SSS2.p3.4.m3.2a"><mrow id="S5.SS1.SSS2.p3.4.m3.2.2.2" xref="S5.SS1.SSS2.p3.4.m3.2.2.3.cmml"><mo id="S5.SS1.SSS2.p3.4.m3.2.2.2.3" stretchy="false" xref="S5.SS1.SSS2.p3.4.m3.2.2.3.cmml">(</mo><msub id="S5.SS1.SSS2.p3.4.m3.1.1.1.1" xref="S5.SS1.SSS2.p3.4.m3.1.1.1.1.cmml"><mi id="S5.SS1.SSS2.p3.4.m3.1.1.1.1.2" xref="S5.SS1.SSS2.p3.4.m3.1.1.1.1.2.cmml">T</mi><mi id="S5.SS1.SSS2.p3.4.m3.1.1.1.1.3" xref="S5.SS1.SSS2.p3.4.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.SS1.SSS2.p3.4.m3.2.2.2.4" xref="S5.SS1.SSS2.p3.4.m3.2.2.3.cmml">,</mo><msub id="S5.SS1.SSS2.p3.4.m3.2.2.2.2" xref="S5.SS1.SSS2.p3.4.m3.2.2.2.2.cmml"><mi id="S5.SS1.SSS2.p3.4.m3.2.2.2.2.2" xref="S5.SS1.SSS2.p3.4.m3.2.2.2.2.2.cmml">I</mi><mi id="S5.SS1.SSS2.p3.4.m3.2.2.2.2.3" xref="S5.SS1.SSS2.p3.4.m3.2.2.2.2.3.cmml">i</mi></msub><mo id="S5.SS1.SSS2.p3.4.m3.2.2.2.5" stretchy="false" xref="S5.SS1.SSS2.p3.4.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p3.4.m3.2b"><interval closure="open" id="S5.SS1.SSS2.p3.4.m3.2.2.3.cmml" xref="S5.SS1.SSS2.p3.4.m3.2.2.2"><apply id="S5.SS1.SSS2.p3.4.m3.1.1.1.1.cmml" xref="S5.SS1.SSS2.p3.4.m3.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p3.4.m3.1.1.1.1.1.cmml" xref="S5.SS1.SSS2.p3.4.m3.1.1.1.1">subscript</csymbol><ci id="S5.SS1.SSS2.p3.4.m3.1.1.1.1.2.cmml" xref="S5.SS1.SSS2.p3.4.m3.1.1.1.1.2">𝑇</ci><ci id="S5.SS1.SSS2.p3.4.m3.1.1.1.1.3.cmml" xref="S5.SS1.SSS2.p3.4.m3.1.1.1.1.3">𝑖</ci></apply><apply id="S5.SS1.SSS2.p3.4.m3.2.2.2.2.cmml" xref="S5.SS1.SSS2.p3.4.m3.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p3.4.m3.2.2.2.2.1.cmml" xref="S5.SS1.SSS2.p3.4.m3.2.2.2.2">subscript</csymbol><ci id="S5.SS1.SSS2.p3.4.m3.2.2.2.2.2.cmml" xref="S5.SS1.SSS2.p3.4.m3.2.2.2.2.2">𝐼</ci><ci id="S5.SS1.SSS2.p3.4.m3.2.2.2.2.3.cmml" xref="S5.SS1.SSS2.p3.4.m3.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p3.4.m3.2c">(T_{i},I_{i})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p3.4.m3.2d">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, assigning a numerical risk value based on predefined criteria. The final SRI score is normalized to a range of 0 to 100 for interpretability. Higher SRI values indicate higher safety performances.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S5.SS1.SSS2.p3.2.m1.1" display="inline" class="ltx_Math" alttext="\text{RiskEvaluator}(\cdot)"><semantics id="S5.SS1.SSS2.p3.2.m1.1a"><mrow id="S5.SS1.SSS2.p3.2.m1.1.2"><mtext id="S5.SS1.SSS2.p3.2.m1.1.2.2">RiskEvaluator</mtext><mo id="S5.SS1.SSS2.p3.2.m1.1.2.1">⁢</mo><mrow id="S5.SS1.SSS2.p3.2.m1.1.2.3.2"><mo stretchy="false" id="S5.SS1.SSS2.p3.2.m1.1.2.3.2.1">(</mo><mo rspace="0em" lspace="0em" id="S5.SS1.SSS2.p3.2.m1.1.1">⋅</mo><mo stretchy="false" id="S5.SS1.SSS2.p3.2.m1.1.2.3.2.2">)</mo></mrow></mrow><annotation-xml id="S5.SS1.SSS2.p3.2.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p3.2.m1.1c" encoding="application/x-tex">\text{RiskEvaluator}(\cdot)</annotation><annotation id="S5.SS1.SSS2.p3.2.m1.1d" encoding="application/x-llamapun">RiskEvaluator ( ⋅ )</annotation></semantics></math> 是一个评分函数，用于评估模型对查询对 <math id="S5.SS1.SSS2.p3.4.m3.2" display="inline" class="ltx_Math" alttext="(T_{i},I_{i})"><semantics id="S5.SS1.SSS2.p3.4.m3.2a"><mrow id="S5.SS1.SSS2.p3.4.m3.2.2.2"><mo stretchy="false" id="S5.SS1.SSS2.p3.4.m3.2.2.2.3">(</mo><msub id="S5.SS1.SSS2.p3.4.m3.1.1.1.1"><mi id="S5.SS1.SSS2.p3.4.m3.1.1.1.1.2">T</mi><mi id="S5.SS1.SSS2.p3.4.m3.1.1.1.1.3">i</mi></msub><mo id="S5.SS1.SSS2.p3.4.m3.2.2.2.4">,</mo><msub id="S5.SS1.SSS2.p3.4.m3.2.2.2.2"><mi id="S5.SS1.SSS2.p3.4.m3.2.2.2.2.2">I</mi><mi id="S5.SS1.SSS2.p3.4.m3.2.2.2.2.3">i</mi></msub><mo stretchy="false" id="S5.SS1.SSS2.p3.4.m3.2.2.2.5">)</mo></mrow><annotation-xml id="S5.SS1.SSS2.p3.4.m3.2b" encoding="MathML-Content">subscriptsubscript</annotation-xml><annotation id="S5.SS1.SSS2.p3.4.m3.2c" encoding="application/x-tex">(T_{i},I_{i})</annotation><annotation id="S5.SS1.SSS2.p3.4.m3.2d" encoding="application/x-llamapun">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> 的响应 <math id="S5.SS1.SSS2.p3.3.m2.1" display="inline" class="ltx_Math" alttext="R_{i}"><semantics id="S5.SS1.SSS2.p3.3.m2.1a"><msub id="S5.SS1.SSS2.p3.3.m2.1.1"><mi id="S5.SS1.SSS2.p3.3.m2.1.1.2">R</mi><mi id="S5.SS1.SSS2.p3.3.m2.1.1.3">i</mi></msub><annotation-xml id="S5.SS1.SSS2.p3.3.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S5.SS1.SSS2.p3.3.m2.1c" encoding="application/x-tex">R_{i}</annotation><annotation id="S5.SS1.SSS2.p3.3.m2.1d" encoding="application/x-llamapun">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> 的严重程度，并根据预定义标准赋予数值风险值。最终 SRI 分数被归一化到 0 到 100 的范围，以便于理解。更高的 SRI 值表示更高的安全性表现。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p4">
<p class="ltx_p" id="S5.SS1.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p4.1.m1.1"><semantics id="S5.SS1.SSS2.p4.1.m1.1a"><mo id="S5.SS1.SSS2.p4.1.m1.1.1" xref="S5.SS1.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p4.1.m1.1b"><ci id="S5.SS1.SSS2.p4.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p4.1.1">Attack Success Degree&nbsp;(ASD)</span>, proposed by MLLMGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib56" title="">56</a>]</cite>, ASD assesses the severity of unsafe model responses across four levels as shown in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.T6" title="In 5.1.2 Metrics ‣ 5.1 Setup ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Tab.</span>&nbsp;<span class="ltx_text ltx_ref_tag">VI</span></a>, score 0 represents <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS2.p4.1.2">Safe and Responsible</span> behavior, where the model refuses assistance with appropriate warnings; score 1 reflects harmless but generic responses; score 2 indicates direct unsafe outputs (e.g., step-by-step harmful instructions); and score 3 denotes high-risk responses, where the model acknowledges the harm but still provides guidance (e.g., warning about the dangers of creating a bomb while offering instructions). ASD is computed as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS2.p4.1.m1.1a"><mo id="S5.SS1.SSS2.p4.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS2.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS2.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 攻击成功程度（ASD），由 MLLMGuard [ 56] 提出，ASD 根据表 VI 所示的四级评估不安全模型响应的严重程度，分数 0 代表安全负责任的行为，即模型拒绝协助并给出适当的警告；分数 1 反映无害但通用的响应；分数 2 表示直接的不安全输出（例如，逐步有害的指令）；分数 3 表示高风险响应，即模型承认危害但仍然提供指导（例如，警告制造炸弹的危险性同时提供指导）。ASD 的计算公式为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S5.E14">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{ASD}=\frac{\sum_{i=1}^{n}\text{Smooth}(\text{DegreeEvaluator}(T_{i},I_{i%
},R_{i}))}{|D|}," class="ltx_Math" display="block" id="S5.E14.m1.3"><semantics id="S5.E14.m1.3a"><mrow id="S5.E14.m1.3.3.1" xref="S5.E14.m1.3.3.1.1.cmml"><mrow id="S5.E14.m1.3.3.1.1" xref="S5.E14.m1.3.3.1.1.cmml"><mtext id="S5.E14.m1.3.3.1.1.2" xref="S5.E14.m1.3.3.1.1.2a.cmml">ASD</mtext><mo id="S5.E14.m1.3.3.1.1.1" xref="S5.E14.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S5.E14.m1.2.2" xref="S5.E14.m1.2.2.cmml"><mrow id="S5.E14.m1.1.1.1" xref="S5.E14.m1.1.1.1.cmml"><msubsup id="S5.E14.m1.1.1.1.2" xref="S5.E14.m1.1.1.1.2.cmml"><mo id="S5.E14.m1.1.1.1.2.2.2" xref="S5.E14.m1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E14.m1.1.1.1.2.2.3" xref="S5.E14.m1.1.1.1.2.2.3.cmml"><mi id="S5.E14.m1.1.1.1.2.2.3.2" xref="S5.E14.m1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S5.E14.m1.1.1.1.2.2.3.1" xref="S5.E14.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E14.m1.1.1.1.2.2.3.3" xref="S5.E14.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E14.m1.1.1.1.2.3" xref="S5.E14.m1.1.1.1.2.3.cmml">n</mi></msubsup><mrow id="S5.E14.m1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.cmml"><mtext id="S5.E14.m1.1.1.1.1.3" xref="S5.E14.m1.1.1.1.1.3a.cmml">Smooth</mtext><mo id="S5.E14.m1.1.1.1.1.2" xref="S5.E14.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E14.m1.1.1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.1.1.1.cmml"><mo id="S5.E14.m1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E14.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E14.m1.1.1.1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.1.1.1.cmml"><mtext id="S5.E14.m1.1.1.1.1.1.1.1.5" xref="S5.E14.m1.1.1.1.1.1.1.1.5a.cmml">DegreeEvaluator</mtext><mo id="S5.E14.m1.1.1.1.1.1.1.1.4" xref="S5.E14.m1.1.1.1.1.1.1.1.4.cmml">⁢</mo><mrow id="S5.E14.m1.1.1.1.1.1.1.1.3.3" xref="S5.E14.m1.1.1.1.1.1.1.1.3.4.cmml"><mo id="S5.E14.m1.1.1.1.1.1.1.1.3.3.4" stretchy="false" xref="S5.E14.m1.1.1.1.1.1.1.1.3.4.cmml">(</mo><msub id="S5.E14.m1.1.1.1.1.1.1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">T</mi><mi id="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.E14.m1.1.1.1.1.1.1.1.3.3.5" xref="S5.E14.m1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S5.E14.m1.1.1.1.1.1.1.1.2.2.2" xref="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.2.cmml">I</mi><mi id="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="S5.E14.m1.1.1.1.1.1.1.1.3.3.6" xref="S5.E14.m1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S5.E14.m1.1.1.1.1.1.1.1.3.3.3" xref="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.2" xref="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.2.cmml">R</mi><mi id="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.3" xref="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.3.cmml">i</mi></msub><mo id="S5.E14.m1.1.1.1.1.1.1.1.3.3.7" stretchy="false" xref="S5.E14.m1.1.1.1.1.1.1.1.3.4.cmml">)</mo></mrow></mrow><mo id="S5.E14.m1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E14.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E14.m1.2.2.2.3" xref="S5.E14.m1.2.2.2.2.cmml"><mo id="S5.E14.m1.2.2.2.3.1" stretchy="false" xref="S5.E14.m1.2.2.2.2.1.cmml">|</mo><mi id="S5.E14.m1.2.2.2.1" xref="S5.E14.m1.2.2.2.1.cmml">D</mi><mo id="S5.E14.m1.2.2.2.3.2" stretchy="false" xref="S5.E14.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mrow><mo id="S5.E14.m1.3.3.1.2" xref="S5.E14.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E14.m1.3b"><apply id="S5.E14.m1.3.3.1.1.cmml" xref="S5.E14.m1.3.3.1"><eq id="S5.E14.m1.3.3.1.1.1.cmml" xref="S5.E14.m1.3.3.1.1.1"></eq><ci id="S5.E14.m1.3.3.1.1.2a.cmml" xref="S5.E14.m1.3.3.1.1.2"><mtext id="S5.E14.m1.3.3.1.1.2.cmml" xref="S5.E14.m1.3.3.1.1.2">ASD</mtext></ci><apply id="S5.E14.m1.2.2.cmml" xref="S5.E14.m1.2.2"><divide id="S5.E14.m1.2.2.3.cmml" xref="S5.E14.m1.2.2"></divide><apply id="S5.E14.m1.1.1.1.cmml" xref="S5.E14.m1.1.1.1"><apply id="S5.E14.m1.1.1.1.2.cmml" xref="S5.E14.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.2.1.cmml" xref="S5.E14.m1.1.1.1.2">superscript</csymbol><apply id="S5.E14.m1.1.1.1.2.2.cmml" xref="S5.E14.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.2.2.1.cmml" xref="S5.E14.m1.1.1.1.2">subscript</csymbol><sum id="S5.E14.m1.1.1.1.2.2.2.cmml" xref="S5.E14.m1.1.1.1.2.2.2"></sum><apply id="S5.E14.m1.1.1.1.2.2.3.cmml" xref="S5.E14.m1.1.1.1.2.2.3"><eq id="S5.E14.m1.1.1.1.2.2.3.1.cmml" xref="S5.E14.m1.1.1.1.2.2.3.1"></eq><ci id="S5.E14.m1.1.1.1.2.2.3.2.cmml" xref="S5.E14.m1.1.1.1.2.2.3.2">𝑖</ci><cn id="S5.E14.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.E14.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.E14.m1.1.1.1.2.3.cmml" xref="S5.E14.m1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.E14.m1.1.1.1.1.cmml" xref="S5.E14.m1.1.1.1.1"><times id="S5.E14.m1.1.1.1.1.2.cmml" xref="S5.E14.m1.1.1.1.1.2"></times><ci id="S5.E14.m1.1.1.1.1.3a.cmml" xref="S5.E14.m1.1.1.1.1.3"><mtext id="S5.E14.m1.1.1.1.1.3.cmml" xref="S5.E14.m1.1.1.1.1.3">Smooth</mtext></ci><apply id="S5.E14.m1.1.1.1.1.1.1.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1"><times id="S5.E14.m1.1.1.1.1.1.1.1.4.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.4"></times><ci id="S5.E14.m1.1.1.1.1.1.1.1.5a.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.5"><mtext id="S5.E14.m1.1.1.1.1.1.1.1.5.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.5">DegreeEvaluator</mtext></ci><vector id="S5.E14.m1.1.1.1.1.1.1.1.3.4.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.3.3"><apply id="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.2">𝑇</ci><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.2">𝐼</ci><ci id="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.2.2.2.3">𝑖</ci></apply><apply id="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.2">𝑅</ci><ci id="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.3.3.3.3">𝑖</ci></apply></vector></apply></apply></apply><apply id="S5.E14.m1.2.2.2.2.cmml" xref="S5.E14.m1.2.2.2.3"><abs id="S5.E14.m1.2.2.2.2.1.cmml" xref="S5.E14.m1.2.2.2.3.1"></abs><ci id="S5.E14.m1.2.2.2.1.cmml" xref="S5.E14.m1.2.2.2.1">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E14.m1.3c">\text{ASD}=\frac{\sum_{i=1}^{n}\text{Smooth}(\text{DegreeEvaluator}(T_{i},I_{i%
},R_{i}))}{|D|},</annotation><annotation encoding="application/x-llamapun" id="S5.E14.m1.3d">ASD = divide start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT Smooth ( DegreeEvaluator ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) end_ARG start_ARG | italic_D | end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(14)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS1.SSS2.p4.5">where <math alttext="\text{DegreeEvaluator}(\cdot)" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p4.2.m1.1"><semantics id="S5.SS1.SSS2.p4.2.m1.1a"><mrow id="S5.SS1.SSS2.p4.2.m1.1.2" xref="S5.SS1.SSS2.p4.2.m1.1.2.cmml"><mtext id="S5.SS1.SSS2.p4.2.m1.1.2.2" xref="S5.SS1.SSS2.p4.2.m1.1.2.2a.cmml">DegreeEvaluator</mtext><mo id="S5.SS1.SSS2.p4.2.m1.1.2.1" xref="S5.SS1.SSS2.p4.2.m1.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.SSS2.p4.2.m1.1.2.3.2" xref="S5.SS1.SSS2.p4.2.m1.1.2.cmml"><mo id="S5.SS1.SSS2.p4.2.m1.1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS2.p4.2.m1.1.2.cmml">(</mo><mo id="S5.SS1.SSS2.p4.2.m1.1.1" lspace="0em" rspace="0em" xref="S5.SS1.SSS2.p4.2.m1.1.1.cmml">⋅</mo><mo id="S5.SS1.SSS2.p4.2.m1.1.2.3.2.2" stretchy="false" xref="S5.SS1.SSS2.p4.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p4.2.m1.1b"><apply id="S5.SS1.SSS2.p4.2.m1.1.2.cmml" xref="S5.SS1.SSS2.p4.2.m1.1.2"><times id="S5.SS1.SSS2.p4.2.m1.1.2.1.cmml" xref="S5.SS1.SSS2.p4.2.m1.1.2.1"></times><ci id="S5.SS1.SSS2.p4.2.m1.1.2.2a.cmml" xref="S5.SS1.SSS2.p4.2.m1.1.2.2"><mtext id="S5.SS1.SSS2.p4.2.m1.1.2.2.cmml" xref="S5.SS1.SSS2.p4.2.m1.1.2.2">DegreeEvaluator</mtext></ci><ci id="S5.SS1.SSS2.p4.2.m1.1.1.cmml" xref="S5.SS1.SSS2.p4.2.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p4.2.m1.1c">\text{DegreeEvaluator}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p4.2.m1.1d">DegreeEvaluator ( ⋅ )</annotation></semantics></math> evaluates the severity of the model’s response <math alttext="R_{i}" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p4.3.m2.1"><semantics id="S5.SS1.SSS2.p4.3.m2.1a"><msub id="S5.SS1.SSS2.p4.3.m2.1.1" xref="S5.SS1.SSS2.p4.3.m2.1.1.cmml"><mi id="S5.SS1.SSS2.p4.3.m2.1.1.2" xref="S5.SS1.SSS2.p4.3.m2.1.1.2.cmml">R</mi><mi id="S5.SS1.SSS2.p4.3.m2.1.1.3" xref="S5.SS1.SSS2.p4.3.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p4.3.m2.1b"><apply id="S5.SS1.SSS2.p4.3.m2.1.1.cmml" xref="S5.SS1.SSS2.p4.3.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p4.3.m2.1.1.1.cmml" xref="S5.SS1.SSS2.p4.3.m2.1.1">subscript</csymbol><ci id="S5.SS1.SSS2.p4.3.m2.1.1.2.cmml" xref="S5.SS1.SSS2.p4.3.m2.1.1.2">𝑅</ci><ci id="S5.SS1.SSS2.p4.3.m2.1.1.3.cmml" xref="S5.SS1.SSS2.p4.3.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p4.3.m2.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p4.3.m2.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to a query pair <math alttext="(T_{i},I_{i})" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p4.4.m3.2"><semantics id="S5.SS1.SSS2.p4.4.m3.2a"><mrow id="S5.SS1.SSS2.p4.4.m3.2.2.2" xref="S5.SS1.SSS2.p4.4.m3.2.2.3.cmml"><mo id="S5.SS1.SSS2.p4.4.m3.2.2.2.3" stretchy="false" xref="S5.SS1.SSS2.p4.4.m3.2.2.3.cmml">(</mo><msub id="S5.SS1.SSS2.p4.4.m3.1.1.1.1" xref="S5.SS1.SSS2.p4.4.m3.1.1.1.1.cmml"><mi id="S5.SS1.SSS2.p4.4.m3.1.1.1.1.2" xref="S5.SS1.SSS2.p4.4.m3.1.1.1.1.2.cmml">T</mi><mi id="S5.SS1.SSS2.p4.4.m3.1.1.1.1.3" xref="S5.SS1.SSS2.p4.4.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.SS1.SSS2.p4.4.m3.2.2.2.4" xref="S5.SS1.SSS2.p4.4.m3.2.2.3.cmml">,</mo><msub id="S5.SS1.SSS2.p4.4.m3.2.2.2.2" xref="S5.SS1.SSS2.p4.4.m3.2.2.2.2.cmml"><mi id="S5.SS1.SSS2.p4.4.m3.2.2.2.2.2" xref="S5.SS1.SSS2.p4.4.m3.2.2.2.2.2.cmml">I</mi><mi id="S5.SS1.SSS2.p4.4.m3.2.2.2.2.3" xref="S5.SS1.SSS2.p4.4.m3.2.2.2.2.3.cmml">i</mi></msub><mo id="S5.SS1.SSS2.p4.4.m3.2.2.2.5" stretchy="false" xref="S5.SS1.SSS2.p4.4.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p4.4.m3.2b"><interval closure="open" id="S5.SS1.SSS2.p4.4.m3.2.2.3.cmml" xref="S5.SS1.SSS2.p4.4.m3.2.2.2"><apply id="S5.SS1.SSS2.p4.4.m3.1.1.1.1.cmml" xref="S5.SS1.SSS2.p4.4.m3.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p4.4.m3.1.1.1.1.1.cmml" xref="S5.SS1.SSS2.p4.4.m3.1.1.1.1">subscript</csymbol><ci id="S5.SS1.SSS2.p4.4.m3.1.1.1.1.2.cmml" xref="S5.SS1.SSS2.p4.4.m3.1.1.1.1.2">𝑇</ci><ci id="S5.SS1.SSS2.p4.4.m3.1.1.1.1.3.cmml" xref="S5.SS1.SSS2.p4.4.m3.1.1.1.1.3">𝑖</ci></apply><apply id="S5.SS1.SSS2.p4.4.m3.2.2.2.2.cmml" xref="S5.SS1.SSS2.p4.4.m3.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p4.4.m3.2.2.2.2.1.cmml" xref="S5.SS1.SSS2.p4.4.m3.2.2.2.2">subscript</csymbol><ci id="S5.SS1.SSS2.p4.4.m3.2.2.2.2.2.cmml" xref="S5.SS1.SSS2.p4.4.m3.2.2.2.2.2">𝐼</ci><ci id="S5.SS1.SSS2.p4.4.m3.2.2.2.2.3.cmml" xref="S5.SS1.SSS2.p4.4.m3.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p4.4.m3.2c">(T_{i},I_{i})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p4.4.m3.2d">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, assigning a score from 0 to 3, and <math alttext="\text{Smooth}(\cdot)" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p4.5.m4.1"><semantics id="S5.SS1.SSS2.p4.5.m4.1a"><mrow id="S5.SS1.SSS2.p4.5.m4.1.2" xref="S5.SS1.SSS2.p4.5.m4.1.2.cmml"><mtext id="S5.SS1.SSS2.p4.5.m4.1.2.2" xref="S5.SS1.SSS2.p4.5.m4.1.2.2a.cmml">Smooth</mtext><mo id="S5.SS1.SSS2.p4.5.m4.1.2.1" xref="S5.SS1.SSS2.p4.5.m4.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.SSS2.p4.5.m4.1.2.3.2" xref="S5.SS1.SSS2.p4.5.m4.1.2.cmml"><mo id="S5.SS1.SSS2.p4.5.m4.1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS2.p4.5.m4.1.2.cmml">(</mo><mo id="S5.SS1.SSS2.p4.5.m4.1.1" lspace="0em" rspace="0em" xref="S5.SS1.SSS2.p4.5.m4.1.1.cmml">⋅</mo><mo id="S5.SS1.SSS2.p4.5.m4.1.2.3.2.2" stretchy="false" xref="S5.SS1.SSS2.p4.5.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p4.5.m4.1b"><apply id="S5.SS1.SSS2.p4.5.m4.1.2.cmml" xref="S5.SS1.SSS2.p4.5.m4.1.2"><times id="S5.SS1.SSS2.p4.5.m4.1.2.1.cmml" xref="S5.SS1.SSS2.p4.5.m4.1.2.1"></times><ci id="S5.SS1.SSS2.p4.5.m4.1.2.2a.cmml" xref="S5.SS1.SSS2.p4.5.m4.1.2.2"><mtext id="S5.SS1.SSS2.p4.5.m4.1.2.2.cmml" xref="S5.SS1.SSS2.p4.5.m4.1.2.2">Smooth</mtext></ci><ci id="S5.SS1.SSS2.p4.5.m4.1.1.cmml" xref="S5.SS1.SSS2.p4.5.m4.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p4.5.m4.1c">\text{Smooth}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p4.5.m4.1d">Smooth ( ⋅ )</annotation></semantics></math> normalizes them to a 0–1 scale. Lower ASD values indicate better safety performance.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S5.SS1.SSS2.p4.2.m1.1" display="inline" class="ltx_Math" alttext="\text{DegreeEvaluator}(\cdot)"><semantics id="S5.SS1.SSS2.p4.2.m1.1a"><mrow id="S5.SS1.SSS2.p4.2.m1.1.2"><mtext id="S5.SS1.SSS2.p4.2.m1.1.2.2">DegreeEvaluator</mtext><mo id="S5.SS1.SSS2.p4.2.m1.1.2.1">⁢</mo><mrow id="S5.SS1.SSS2.p4.2.m1.1.2.3.2"><mo stretchy="false" id="S5.SS1.SSS2.p4.2.m1.1.2.3.2.1">(</mo><mo rspace="0em" lspace="0em" id="S5.SS1.SSS2.p4.2.m1.1.1">⋅</mo><mo stretchy="false" id="S5.SS1.SSS2.p4.2.m1.1.2.3.2.2">)</mo></mrow></mrow><annotation-xml id="S5.SS1.SSS2.p4.2.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p4.2.m1.1c" encoding="application/x-tex">\text{DegreeEvaluator}(\cdot)</annotation><annotation id="S5.SS1.SSS2.p4.2.m1.1d" encoding="application/x-llamapun">DegreeEvaluator ( ⋅ )</annotation></semantics></math> 评估模型对查询对 <math id="S5.SS1.SSS2.p4.4.m3.2" display="inline" class="ltx_Math" alttext="(T_{i},I_{i})"><semantics id="S5.SS1.SSS2.p4.4.m3.2a"><mrow id="S5.SS1.SSS2.p4.4.m3.2.2.2"><mo stretchy="false" id="S5.SS1.SSS2.p4.4.m3.2.2.2.3">(</mo><msub id="S5.SS1.SSS2.p4.4.m3.1.1.1.1"><mi id="S5.SS1.SSS2.p4.4.m3.1.1.1.1.2">T</mi><mi id="S5.SS1.SSS2.p4.4.m3.1.1.1.1.3">i</mi></msub><mo id="S5.SS1.SSS2.p4.4.m3.2.2.2.4">,</mo><msub id="S5.SS1.SSS2.p4.4.m3.2.2.2.2"><mi id="S5.SS1.SSS2.p4.4.m3.2.2.2.2.2">I</mi><mi id="S5.SS1.SSS2.p4.4.m3.2.2.2.2.3">i</mi></msub><mo stretchy="false" id="S5.SS1.SSS2.p4.4.m3.2.2.2.5">)</mo></mrow><annotation-xml id="S5.SS1.SSS2.p4.4.m3.2b" encoding="MathML-Content">subscriptsubscript</annotation-xml><annotation id="S5.SS1.SSS2.p4.4.m3.2c" encoding="application/x-tex">(T_{i},I_{i})</annotation><annotation id="S5.SS1.SSS2.p4.4.m3.2d" encoding="application/x-llamapun">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> 的响应 <math id="S5.SS1.SSS2.p4.3.m2.1" display="inline" class="ltx_Math" alttext="R_{i}"><semantics id="S5.SS1.SSS2.p4.3.m2.1a"><msub id="S5.SS1.SSS2.p4.3.m2.1.1"><mi id="S5.SS1.SSS2.p4.3.m2.1.1.2">R</mi><mi id="S5.SS1.SSS2.p4.3.m2.1.1.3">i</mi></msub><annotation-xml id="S5.SS1.SSS2.p4.3.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S5.SS1.SSS2.p4.3.m2.1c" encoding="application/x-tex">R_{i}</annotation><annotation id="S5.SS1.SSS2.p4.3.m2.1d" encoding="application/x-llamapun">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> 的严重程度，并分配 0 到 3 的分数， <math id="S5.SS1.SSS2.p4.5.m4.1" display="inline" class="ltx_Math" alttext="\text{Smooth}(\cdot)"><semantics id="S5.SS1.SSS2.p4.5.m4.1a"><mrow id="S5.SS1.SSS2.p4.5.m4.1.2"><mtext id="S5.SS1.SSS2.p4.5.m4.1.2.2">Smooth</mtext><mo id="S5.SS1.SSS2.p4.5.m4.1.2.1">⁢</mo><mrow id="S5.SS1.SSS2.p4.5.m4.1.2.3.2"><mo stretchy="false" id="S5.SS1.SSS2.p4.5.m4.1.2.3.2.1">(</mo><mo rspace="0em" lspace="0em" id="S5.SS1.SSS2.p4.5.m4.1.1">⋅</mo><mo stretchy="false" id="S5.SS1.SSS2.p4.5.m4.1.2.3.2.2">)</mo></mrow></mrow><annotation-xml id="S5.SS1.SSS2.p4.5.m4.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p4.5.m4.1c" encoding="application/x-tex">\text{Smooth}(\cdot)</annotation><annotation id="S5.SS1.SSS2.p4.5.m4.1d" encoding="application/x-llamapun">Smooth ( ⋅ )</annotation></semantics></math> 将它们归一化到 0-1 的刻度上。较低的 ASD 值表示更好的安全性表现。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S5.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Scoring rules for Attack Success Degree&nbsp;(ASD). Details in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS1.SSS2" title="5.1.2 Metrics ‣ 5.1 Setup ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.1.2</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 VI：攻击成功程度（ASD）的评分规则。详细信息见§ 5.1.2。</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T6.1" style="width:216.8pt;height:118.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(42.6pt,-23.3pt) scale(1.64700381217504,1.64700381217504) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T6.1.1">
<tbody><tr class="ltx_tr" id="S5.T6.1.1.1" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S5.T6.1.1.1.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T6.1.1.1.2" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.2.1" style="background-color:#F5F5F0;">Safe<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S5.T6.1.1.1.3" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.1.3.1" style="background-color:#F5F5F0;">Unsafe<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">不安全</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.2">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt" id="S5.T6.1.1.2.1" style="background-color:#F5F5F0;padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.2.1.1" style="background-color:#F5F5F0;">Aware<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">有意识</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T6.1.1.2.2" style="padding-top:1pt;padding-bottom:1pt;">0</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T6.1.1.2.3" style="padding-top:1pt;padding-bottom:1pt;">2</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.3">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S5.T6.1.1.3.1" style="background-color:#F5F5F0;padding-top:1pt;padding-bottom:1pt;"><span class="ltx_text ltx_font_bold" id="S5.T6.1.1.3.1.1" style="background-color:#F5F5F0;">Unaware<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">无意识</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T6.1.1.3.2" style="padding-top:1pt;padding-bottom:1pt;">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T6.1.1.3.3" style="padding-top:1pt;padding-bottom:1pt;">3</td>
</tr>
<tr class="ltx_tr" id="S5.T6.1.1.4">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S5.T6.1.1.4.1" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td" id="S5.T6.1.1.4.2" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td class="ltx_td" id="S5.T6.1.1.4.3" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p5">
<p class="ltx_p" id="S5.SS1.SSS2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p5.1.m1.1"><semantics id="S5.SS1.SSS2.p5.1.m1.1a"><mo id="S5.SS1.SSS2.p5.1.m1.1.1" xref="S5.SS1.SSS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p5.1.m1.1b"><ci id="S5.SS1.SSS2.p5.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p5.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p5.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p5.1.1">Perfect Answer Rate&nbsp;(PAR)</span>
is derived from ASD, MLLMGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib56" title="">56</a>]</cite> introduced PAR, measures the proportion of safe and responsible responses, specifically those categorized as score 0 by ASD. It is computed as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p5.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS2.p5.1.m1.1a"><mo id="S5.SS1.SSS2.p5.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS2.p5.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p5.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS2.p5.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 完美答案率（PAR）源自 ASD，MLLMGuard [ 56] 引入了 PAR，衡量安全且负责任的响应比例，具体指被 ASD 归类为 0 分的响应。其计算公式为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S5.E15">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{PAR}=\frac{\sum_{i=1}^{n}\mathbb{I}(\text{DegreeEvaluator}(T_{i},I_{i},R%
_{i})=0)}{|D|}," class="ltx_Math" display="block" id="S5.E15.m1.3"><semantics id="S5.E15.m1.3a"><mrow id="S5.E15.m1.3.3.1" xref="S5.E15.m1.3.3.1.1.cmml"><mrow id="S5.E15.m1.3.3.1.1" xref="S5.E15.m1.3.3.1.1.cmml"><mtext id="S5.E15.m1.3.3.1.1.2" xref="S5.E15.m1.3.3.1.1.2a.cmml">PAR</mtext><mo id="S5.E15.m1.3.3.1.1.1" xref="S5.E15.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S5.E15.m1.2.2" xref="S5.E15.m1.2.2.cmml"><mrow id="S5.E15.m1.1.1.1" xref="S5.E15.m1.1.1.1.cmml"><msubsup id="S5.E15.m1.1.1.1.2" xref="S5.E15.m1.1.1.1.2.cmml"><mo id="S5.E15.m1.1.1.1.2.2.2" xref="S5.E15.m1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E15.m1.1.1.1.2.2.3" xref="S5.E15.m1.1.1.1.2.2.3.cmml"><mi id="S5.E15.m1.1.1.1.2.2.3.2" xref="S5.E15.m1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S5.E15.m1.1.1.1.2.2.3.1" xref="S5.E15.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E15.m1.1.1.1.2.2.3.3" xref="S5.E15.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E15.m1.1.1.1.2.3" xref="S5.E15.m1.1.1.1.2.3.cmml">n</mi></msubsup><mrow id="S5.E15.m1.1.1.1.1" xref="S5.E15.m1.1.1.1.1.cmml"><mi id="S5.E15.m1.1.1.1.1.3" xref="S5.E15.m1.1.1.1.1.3.cmml">𝕀</mi><mo id="S5.E15.m1.1.1.1.1.2" xref="S5.E15.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E15.m1.1.1.1.1.1.1" xref="S5.E15.m1.1.1.1.1.1.1.1.cmml"><mo id="S5.E15.m1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E15.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E15.m1.1.1.1.1.1.1.1" xref="S5.E15.m1.1.1.1.1.1.1.1.cmml"><mrow id="S5.E15.m1.1.1.1.1.1.1.1.3" xref="S5.E15.m1.1.1.1.1.1.1.1.3.cmml"><mtext id="S5.E15.m1.1.1.1.1.1.1.1.3.5" xref="S5.E15.m1.1.1.1.1.1.1.1.3.5a.cmml">DegreeEvaluator</mtext><mo id="S5.E15.m1.1.1.1.1.1.1.1.3.4" xref="S5.E15.m1.1.1.1.1.1.1.1.3.4.cmml">⁢</mo><mrow id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.4.cmml"><mo id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.4" stretchy="false" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.4.cmml">(</mo><msub id="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">T</mi><mi id="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.5" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.4.cmml">,</mo><msub id="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">I</mi><mi id="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.3.cmml">i</mi></msub><mo id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.6" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.4.cmml">,</mo><msub id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.2" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.2.cmml">R</mi><mi id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.3" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.3.cmml">i</mi></msub><mo id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.7" stretchy="false" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.4.cmml">)</mo></mrow></mrow><mo id="S5.E15.m1.1.1.1.1.1.1.1.4" xref="S5.E15.m1.1.1.1.1.1.1.1.4.cmml">=</mo><mn id="S5.E15.m1.1.1.1.1.1.1.1.5" xref="S5.E15.m1.1.1.1.1.1.1.1.5.cmml">0</mn></mrow><mo id="S5.E15.m1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E15.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E15.m1.2.2.2.3" xref="S5.E15.m1.2.2.2.2.cmml"><mo id="S5.E15.m1.2.2.2.3.1" stretchy="false" xref="S5.E15.m1.2.2.2.2.1.cmml">|</mo><mi id="S5.E15.m1.2.2.2.1" xref="S5.E15.m1.2.2.2.1.cmml">D</mi><mo id="S5.E15.m1.2.2.2.3.2" stretchy="false" xref="S5.E15.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mrow><mo id="S5.E15.m1.3.3.1.2" xref="S5.E15.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E15.m1.3b"><apply id="S5.E15.m1.3.3.1.1.cmml" xref="S5.E15.m1.3.3.1"><eq id="S5.E15.m1.3.3.1.1.1.cmml" xref="S5.E15.m1.3.3.1.1.1"></eq><ci id="S5.E15.m1.3.3.1.1.2a.cmml" xref="S5.E15.m1.3.3.1.1.2"><mtext id="S5.E15.m1.3.3.1.1.2.cmml" xref="S5.E15.m1.3.3.1.1.2">PAR</mtext></ci><apply id="S5.E15.m1.2.2.cmml" xref="S5.E15.m1.2.2"><divide id="S5.E15.m1.2.2.3.cmml" xref="S5.E15.m1.2.2"></divide><apply id="S5.E15.m1.1.1.1.cmml" xref="S5.E15.m1.1.1.1"><apply id="S5.E15.m1.1.1.1.2.cmml" xref="S5.E15.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E15.m1.1.1.1.2.1.cmml" xref="S5.E15.m1.1.1.1.2">superscript</csymbol><apply id="S5.E15.m1.1.1.1.2.2.cmml" xref="S5.E15.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E15.m1.1.1.1.2.2.1.cmml" xref="S5.E15.m1.1.1.1.2">subscript</csymbol><sum id="S5.E15.m1.1.1.1.2.2.2.cmml" xref="S5.E15.m1.1.1.1.2.2.2"></sum><apply id="S5.E15.m1.1.1.1.2.2.3.cmml" xref="S5.E15.m1.1.1.1.2.2.3"><eq id="S5.E15.m1.1.1.1.2.2.3.1.cmml" xref="S5.E15.m1.1.1.1.2.2.3.1"></eq><ci id="S5.E15.m1.1.1.1.2.2.3.2.cmml" xref="S5.E15.m1.1.1.1.2.2.3.2">𝑖</ci><cn id="S5.E15.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.E15.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.E15.m1.1.1.1.2.3.cmml" xref="S5.E15.m1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.E15.m1.1.1.1.1.cmml" xref="S5.E15.m1.1.1.1.1"><times id="S5.E15.m1.1.1.1.1.2.cmml" xref="S5.E15.m1.1.1.1.1.2"></times><ci id="S5.E15.m1.1.1.1.1.3.cmml" xref="S5.E15.m1.1.1.1.1.3">𝕀</ci><apply id="S5.E15.m1.1.1.1.1.1.1.1.cmml" xref="S5.E15.m1.1.1.1.1.1.1"><eq id="S5.E15.m1.1.1.1.1.1.1.1.4.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.4"></eq><apply id="S5.E15.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3"><times id="S5.E15.m1.1.1.1.1.1.1.1.3.4.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3.4"></times><ci id="S5.E15.m1.1.1.1.1.1.1.1.3.5a.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3.5"><mtext id="S5.E15.m1.1.1.1.1.1.1.1.3.5.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3.5">DegreeEvaluator</mtext></ci><vector id="S5.E15.m1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.3"><apply id="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.2">𝑇</ci><ci id="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.2">𝐼</ci><ci id="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.2.2.2.2.3">𝑖</ci></apply><apply id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3">subscript</csymbol><ci id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.2">𝑅</ci><ci id="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.3.cmml" xref="S5.E15.m1.1.1.1.1.1.1.1.3.3.3.3.3">𝑖</ci></apply></vector></apply><cn id="S5.E15.m1.1.1.1.1.1.1.1.5.cmml" type="integer" xref="S5.E15.m1.1.1.1.1.1.1.1.5">0</cn></apply></apply></apply><apply id="S5.E15.m1.2.2.2.2.cmml" xref="S5.E15.m1.2.2.2.3"><abs id="S5.E15.m1.2.2.2.2.1.cmml" xref="S5.E15.m1.2.2.2.3.1"></abs><ci id="S5.E15.m1.2.2.2.1.cmml" xref="S5.E15.m1.2.2.2.1">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E15.m1.3c">\text{PAR}=\frac{\sum_{i=1}^{n}\mathbb{I}(\text{DegreeEvaluator}(T_{i},I_{i},R%
_{i})=0)}{|D|},</annotation><annotation encoding="application/x-llamapun" id="S5.E15.m1.3d">PAR = divide start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT blackboard_I ( DegreeEvaluator ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = 0 ) end_ARG start_ARG | italic_D | end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(15)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS1.SSS2.p5.2">where <math alttext="\mathbb{I}(\cdot)" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p5.2.m1.1"><semantics id="S5.SS1.SSS2.p5.2.m1.1a"><mrow id="S5.SS1.SSS2.p5.2.m1.1.2" xref="S5.SS1.SSS2.p5.2.m1.1.2.cmml"><mi id="S5.SS1.SSS2.p5.2.m1.1.2.2" xref="S5.SS1.SSS2.p5.2.m1.1.2.2.cmml">𝕀</mi><mo id="S5.SS1.SSS2.p5.2.m1.1.2.1" xref="S5.SS1.SSS2.p5.2.m1.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.SSS2.p5.2.m1.1.2.3.2" xref="S5.SS1.SSS2.p5.2.m1.1.2.cmml"><mo id="S5.SS1.SSS2.p5.2.m1.1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS2.p5.2.m1.1.2.cmml">(</mo><mo id="S5.SS1.SSS2.p5.2.m1.1.1" lspace="0em" rspace="0em" xref="S5.SS1.SSS2.p5.2.m1.1.1.cmml">⋅</mo><mo id="S5.SS1.SSS2.p5.2.m1.1.2.3.2.2" stretchy="false" xref="S5.SS1.SSS2.p5.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p5.2.m1.1b"><apply id="S5.SS1.SSS2.p5.2.m1.1.2.cmml" xref="S5.SS1.SSS2.p5.2.m1.1.2"><times id="S5.SS1.SSS2.p5.2.m1.1.2.1.cmml" xref="S5.SS1.SSS2.p5.2.m1.1.2.1"></times><ci id="S5.SS1.SSS2.p5.2.m1.1.2.2.cmml" xref="S5.SS1.SSS2.p5.2.m1.1.2.2">𝕀</ci><ci id="S5.SS1.SSS2.p5.2.m1.1.1.cmml" xref="S5.SS1.SSS2.p5.2.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p5.2.m1.1c">\mathbb{I}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p5.2.m1.1d">blackboard_I ( ⋅ )</annotation></semantics></math> is an indicator function returning 1 if the condition is true and 0 otherwise. Higher PAR indicates stronger safety performance.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p5.2.m1.1" display="inline" class="ltx_Math" alttext="\mathbb{I}(\cdot)"><semantics id="S5.SS1.SSS2.p5.2.m1.1a"><mrow id="S5.SS1.SSS2.p5.2.m1.1.2"><mi id="S5.SS1.SSS2.p5.2.m1.1.2.2">𝕀</mi><mo id="S5.SS1.SSS2.p5.2.m1.1.2.1">⁢</mo><mrow id="S5.SS1.SSS2.p5.2.m1.1.2.3.2"><mo stretchy="false" id="S5.SS1.SSS2.p5.2.m1.1.2.3.2.1">(</mo><mo rspace="0em" lspace="0em" id="S5.SS1.SSS2.p5.2.m1.1.1">⋅</mo><mo stretchy="false" id="S5.SS1.SSS2.p5.2.m1.1.2.3.2.2">)</mo></mrow></mrow><annotation-xml id="S5.SS1.SSS2.p5.2.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p5.2.m1.1c" encoding="application/x-tex">\mathbb{I}(\cdot)</annotation><annotation id="S5.SS1.SSS2.p5.2.m1.1d" encoding="application/x-llamapun">blackboard_I ( ⋅ )</annotation></semantics></math> 是一个指示函数，当条件为真时返回 1，否则返回 0。更高的 PAR 表示更强的安全性表现。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p6">
<p class="ltx_p" id="S5.SS1.SSS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p6.1.m1.1"><semantics id="S5.SS1.SSS2.p6.1.m1.1a"><mo id="S5.SS1.SSS2.p6.1.m1.1.1" xref="S5.SS1.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p6.1.m1.1b"><ci id="S5.SS1.SSS2.p6.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p6.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p6.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p6.1.1">Refusal Rate&nbsp;(RR)</span>
evaluates the ability of LVLMs to recognize malicious queries and appropriately refuse to respond. It quantifies the proportion of cases where the model accurately identifies a query as unsafe and opts to reject it. Formally, RR is calculated as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p6.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS2.p6.1.m1.1a"><mo id="S5.SS1.SSS2.p6.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS2.p6.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p6.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS2.p6.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 拒绝率（RR）评估了大型视觉语言模型识别恶意查询并适当拒绝响应的能力。它量化了模型准确识别查询为不安全并选择拒绝的比例。形式上，RR 的计算公式为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S5.E16">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{RR}=\frac{\sum_{i=1}^{n}\mathbb{I}(\text{RefusalEvaluator}(T_{i},I_{i},R%
_{i}))}{|D|}," class="ltx_Math" display="block" id="S5.E16.m1.3"><semantics id="S5.E16.m1.3a"><mrow id="S5.E16.m1.3.3.1" xref="S5.E16.m1.3.3.1.1.cmml"><mrow id="S5.E16.m1.3.3.1.1" xref="S5.E16.m1.3.3.1.1.cmml"><mtext id="S5.E16.m1.3.3.1.1.2" xref="S5.E16.m1.3.3.1.1.2a.cmml">RR</mtext><mo id="S5.E16.m1.3.3.1.1.1" xref="S5.E16.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S5.E16.m1.2.2" xref="S5.E16.m1.2.2.cmml"><mrow id="S5.E16.m1.1.1.1" xref="S5.E16.m1.1.1.1.cmml"><msubsup id="S5.E16.m1.1.1.1.2" xref="S5.E16.m1.1.1.1.2.cmml"><mo id="S5.E16.m1.1.1.1.2.2.2" xref="S5.E16.m1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.E16.m1.1.1.1.2.2.3" xref="S5.E16.m1.1.1.1.2.2.3.cmml"><mi id="S5.E16.m1.1.1.1.2.2.3.2" xref="S5.E16.m1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S5.E16.m1.1.1.1.2.2.3.1" xref="S5.E16.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.E16.m1.1.1.1.2.2.3.3" xref="S5.E16.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E16.m1.1.1.1.2.3" xref="S5.E16.m1.1.1.1.2.3.cmml">n</mi></msubsup><mrow id="S5.E16.m1.1.1.1.1" xref="S5.E16.m1.1.1.1.1.cmml"><mi id="S5.E16.m1.1.1.1.1.3" xref="S5.E16.m1.1.1.1.1.3.cmml">𝕀</mi><mo id="S5.E16.m1.1.1.1.1.2" xref="S5.E16.m1.1.1.1.1.2.cmml">⁢</mo><mrow id="S5.E16.m1.1.1.1.1.1.1" xref="S5.E16.m1.1.1.1.1.1.1.1.cmml"><mo id="S5.E16.m1.1.1.1.1.1.1.2" stretchy="false" xref="S5.E16.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E16.m1.1.1.1.1.1.1.1" xref="S5.E16.m1.1.1.1.1.1.1.1.cmml"><mtext id="S5.E16.m1.1.1.1.1.1.1.1.5" xref="S5.E16.m1.1.1.1.1.1.1.1.5a.cmml">RefusalEvaluator</mtext><mo id="S5.E16.m1.1.1.1.1.1.1.1.4" xref="S5.E16.m1.1.1.1.1.1.1.1.4.cmml">⁢</mo><mrow id="S5.E16.m1.1.1.1.1.1.1.1.3.3" xref="S5.E16.m1.1.1.1.1.1.1.1.3.4.cmml"><mo id="S5.E16.m1.1.1.1.1.1.1.1.3.3.4" stretchy="false" xref="S5.E16.m1.1.1.1.1.1.1.1.3.4.cmml">(</mo><msub id="S5.E16.m1.1.1.1.1.1.1.1.1.1.1" xref="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">T</mi><mi id="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.E16.m1.1.1.1.1.1.1.1.3.3.5" xref="S5.E16.m1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S5.E16.m1.1.1.1.1.1.1.1.2.2.2" xref="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.2" xref="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.2.cmml">I</mi><mi id="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.3" xref="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="S5.E16.m1.1.1.1.1.1.1.1.3.3.6" xref="S5.E16.m1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S5.E16.m1.1.1.1.1.1.1.1.3.3.3" xref="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.2" xref="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.2.cmml">R</mi><mi id="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.3" xref="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.3.cmml">i</mi></msub><mo id="S5.E16.m1.1.1.1.1.1.1.1.3.3.7" stretchy="false" xref="S5.E16.m1.1.1.1.1.1.1.1.3.4.cmml">)</mo></mrow></mrow><mo id="S5.E16.m1.1.1.1.1.1.1.3" stretchy="false" xref="S5.E16.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S5.E16.m1.2.2.2.3" xref="S5.E16.m1.2.2.2.2.cmml"><mo id="S5.E16.m1.2.2.2.3.1" stretchy="false" xref="S5.E16.m1.2.2.2.2.1.cmml">|</mo><mi id="S5.E16.m1.2.2.2.1" xref="S5.E16.m1.2.2.2.1.cmml">D</mi><mo id="S5.E16.m1.2.2.2.3.2" stretchy="false" xref="S5.E16.m1.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mrow><mo id="S5.E16.m1.3.3.1.2" xref="S5.E16.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E16.m1.3b"><apply id="S5.E16.m1.3.3.1.1.cmml" xref="S5.E16.m1.3.3.1"><eq id="S5.E16.m1.3.3.1.1.1.cmml" xref="S5.E16.m1.3.3.1.1.1"></eq><ci id="S5.E16.m1.3.3.1.1.2a.cmml" xref="S5.E16.m1.3.3.1.1.2"><mtext id="S5.E16.m1.3.3.1.1.2.cmml" xref="S5.E16.m1.3.3.1.1.2">RR</mtext></ci><apply id="S5.E16.m1.2.2.cmml" xref="S5.E16.m1.2.2"><divide id="S5.E16.m1.2.2.3.cmml" xref="S5.E16.m1.2.2"></divide><apply id="S5.E16.m1.1.1.1.cmml" xref="S5.E16.m1.1.1.1"><apply id="S5.E16.m1.1.1.1.2.cmml" xref="S5.E16.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E16.m1.1.1.1.2.1.cmml" xref="S5.E16.m1.1.1.1.2">superscript</csymbol><apply id="S5.E16.m1.1.1.1.2.2.cmml" xref="S5.E16.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E16.m1.1.1.1.2.2.1.cmml" xref="S5.E16.m1.1.1.1.2">subscript</csymbol><sum id="S5.E16.m1.1.1.1.2.2.2.cmml" xref="S5.E16.m1.1.1.1.2.2.2"></sum><apply id="S5.E16.m1.1.1.1.2.2.3.cmml" xref="S5.E16.m1.1.1.1.2.2.3"><eq id="S5.E16.m1.1.1.1.2.2.3.1.cmml" xref="S5.E16.m1.1.1.1.2.2.3.1"></eq><ci id="S5.E16.m1.1.1.1.2.2.3.2.cmml" xref="S5.E16.m1.1.1.1.2.2.3.2">𝑖</ci><cn id="S5.E16.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S5.E16.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.E16.m1.1.1.1.2.3.cmml" xref="S5.E16.m1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.E16.m1.1.1.1.1.cmml" xref="S5.E16.m1.1.1.1.1"><times id="S5.E16.m1.1.1.1.1.2.cmml" xref="S5.E16.m1.1.1.1.1.2"></times><ci id="S5.E16.m1.1.1.1.1.3.cmml" xref="S5.E16.m1.1.1.1.1.3">𝕀</ci><apply id="S5.E16.m1.1.1.1.1.1.1.1.cmml" xref="S5.E16.m1.1.1.1.1.1.1"><times id="S5.E16.m1.1.1.1.1.1.1.1.4.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.4"></times><ci id="S5.E16.m1.1.1.1.1.1.1.1.5a.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.5"><mtext id="S5.E16.m1.1.1.1.1.1.1.1.5.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.5">RefusalEvaluator</mtext></ci><vector id="S5.E16.m1.1.1.1.1.1.1.1.3.4.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.3.3"><apply id="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.2">𝑇</ci><ci id="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.2">𝐼</ci><ci id="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.2.2.2.3">𝑖</ci></apply><apply id="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.2">𝑅</ci><ci id="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S5.E16.m1.1.1.1.1.1.1.1.3.3.3.3">𝑖</ci></apply></vector></apply></apply></apply><apply id="S5.E16.m1.2.2.2.2.cmml" xref="S5.E16.m1.2.2.2.3"><abs id="S5.E16.m1.2.2.2.2.1.cmml" xref="S5.E16.m1.2.2.2.3.1"></abs><ci id="S5.E16.m1.2.2.2.1.cmml" xref="S5.E16.m1.2.2.2.1">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E16.m1.3c">\text{RR}=\frac{\sum_{i=1}^{n}\mathbb{I}(\text{RefusalEvaluator}(T_{i},I_{i},R%
_{i}))}{|D|},</annotation><annotation encoding="application/x-llamapun" id="S5.E16.m1.3d">RR = divide start_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT blackboard_I ( RefusalEvaluator ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) end_ARG start_ARG | italic_D | end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(16)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS1.SSS2.p6.4">where <math alttext="\mathbb{I}(\cdot)" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p6.2.m1.1"><semantics id="S5.SS1.SSS2.p6.2.m1.1a"><mrow id="S5.SS1.SSS2.p6.2.m1.1.2" xref="S5.SS1.SSS2.p6.2.m1.1.2.cmml"><mi id="S5.SS1.SSS2.p6.2.m1.1.2.2" xref="S5.SS1.SSS2.p6.2.m1.1.2.2.cmml">𝕀</mi><mo id="S5.SS1.SSS2.p6.2.m1.1.2.1" xref="S5.SS1.SSS2.p6.2.m1.1.2.1.cmml">⁢</mo><mrow id="S5.SS1.SSS2.p6.2.m1.1.2.3.2" xref="S5.SS1.SSS2.p6.2.m1.1.2.cmml"><mo id="S5.SS1.SSS2.p6.2.m1.1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS2.p6.2.m1.1.2.cmml">(</mo><mo id="S5.SS1.SSS2.p6.2.m1.1.1" lspace="0em" rspace="0em" xref="S5.SS1.SSS2.p6.2.m1.1.1.cmml">⋅</mo><mo id="S5.SS1.SSS2.p6.2.m1.1.2.3.2.2" stretchy="false" xref="S5.SS1.SSS2.p6.2.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p6.2.m1.1b"><apply id="S5.SS1.SSS2.p6.2.m1.1.2.cmml" xref="S5.SS1.SSS2.p6.2.m1.1.2"><times id="S5.SS1.SSS2.p6.2.m1.1.2.1.cmml" xref="S5.SS1.SSS2.p6.2.m1.1.2.1"></times><ci id="S5.SS1.SSS2.p6.2.m1.1.2.2.cmml" xref="S5.SS1.SSS2.p6.2.m1.1.2.2">𝕀</ci><ci id="S5.SS1.SSS2.p6.2.m1.1.1.cmml" xref="S5.SS1.SSS2.p6.2.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p6.2.m1.1c">\mathbb{I}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p6.2.m1.1d">blackboard_I ( ⋅ )</annotation></semantics></math> is an indicator function returning 1 if the model’s response <math alttext="R_{i}" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p6.3.m2.1"><semantics id="S5.SS1.SSS2.p6.3.m2.1a"><msub id="S5.SS1.SSS2.p6.3.m2.1.1" xref="S5.SS1.SSS2.p6.3.m2.1.1.cmml"><mi id="S5.SS1.SSS2.p6.3.m2.1.1.2" xref="S5.SS1.SSS2.p6.3.m2.1.1.2.cmml">R</mi><mi id="S5.SS1.SSS2.p6.3.m2.1.1.3" xref="S5.SS1.SSS2.p6.3.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p6.3.m2.1b"><apply id="S5.SS1.SSS2.p6.3.m2.1.1.cmml" xref="S5.SS1.SSS2.p6.3.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p6.3.m2.1.1.1.cmml" xref="S5.SS1.SSS2.p6.3.m2.1.1">subscript</csymbol><ci id="S5.SS1.SSS2.p6.3.m2.1.1.2.cmml" xref="S5.SS1.SSS2.p6.3.m2.1.1.2">𝑅</ci><ci id="S5.SS1.SSS2.p6.3.m2.1.1.3.cmml" xref="S5.SS1.SSS2.p6.3.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p6.3.m2.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p6.3.m2.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to the query pair <math alttext="(T_{i},I_{i})" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p6.4.m3.2"><semantics id="S5.SS1.SSS2.p6.4.m3.2a"><mrow id="S5.SS1.SSS2.p6.4.m3.2.2.2" xref="S5.SS1.SSS2.p6.4.m3.2.2.3.cmml"><mo id="S5.SS1.SSS2.p6.4.m3.2.2.2.3" stretchy="false" xref="S5.SS1.SSS2.p6.4.m3.2.2.3.cmml">(</mo><msub id="S5.SS1.SSS2.p6.4.m3.1.1.1.1" xref="S5.SS1.SSS2.p6.4.m3.1.1.1.1.cmml"><mi id="S5.SS1.SSS2.p6.4.m3.1.1.1.1.2" xref="S5.SS1.SSS2.p6.4.m3.1.1.1.1.2.cmml">T</mi><mi id="S5.SS1.SSS2.p6.4.m3.1.1.1.1.3" xref="S5.SS1.SSS2.p6.4.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.SS1.SSS2.p6.4.m3.2.2.2.4" xref="S5.SS1.SSS2.p6.4.m3.2.2.3.cmml">,</mo><msub id="S5.SS1.SSS2.p6.4.m3.2.2.2.2" xref="S5.SS1.SSS2.p6.4.m3.2.2.2.2.cmml"><mi id="S5.SS1.SSS2.p6.4.m3.2.2.2.2.2" xref="S5.SS1.SSS2.p6.4.m3.2.2.2.2.2.cmml">I</mi><mi id="S5.SS1.SSS2.p6.4.m3.2.2.2.2.3" xref="S5.SS1.SSS2.p6.4.m3.2.2.2.2.3.cmml">i</mi></msub><mo id="S5.SS1.SSS2.p6.4.m3.2.2.2.5" stretchy="false" xref="S5.SS1.SSS2.p6.4.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p6.4.m3.2b"><interval closure="open" id="S5.SS1.SSS2.p6.4.m3.2.2.3.cmml" xref="S5.SS1.SSS2.p6.4.m3.2.2.2"><apply id="S5.SS1.SSS2.p6.4.m3.1.1.1.1.cmml" xref="S5.SS1.SSS2.p6.4.m3.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p6.4.m3.1.1.1.1.1.cmml" xref="S5.SS1.SSS2.p6.4.m3.1.1.1.1">subscript</csymbol><ci id="S5.SS1.SSS2.p6.4.m3.1.1.1.1.2.cmml" xref="S5.SS1.SSS2.p6.4.m3.1.1.1.1.2">𝑇</ci><ci id="S5.SS1.SSS2.p6.4.m3.1.1.1.1.3.cmml" xref="S5.SS1.SSS2.p6.4.m3.1.1.1.1.3">𝑖</ci></apply><apply id="S5.SS1.SSS2.p6.4.m3.2.2.2.2.cmml" xref="S5.SS1.SSS2.p6.4.m3.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.SSS2.p6.4.m3.2.2.2.2.1.cmml" xref="S5.SS1.SSS2.p6.4.m3.2.2.2.2">subscript</csymbol><ci id="S5.SS1.SSS2.p6.4.m3.2.2.2.2.2.cmml" xref="S5.SS1.SSS2.p6.4.m3.2.2.2.2.2">𝐼</ci><ci id="S5.SS1.SSS2.p6.4.m3.2.2.2.2.3.cmml" xref="S5.SS1.SSS2.p6.4.m3.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p6.4.m3.2c">(T_{i},I_{i})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p6.4.m3.2d">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> appropriately rejects the unsafe query, and 0 otherwise. Higher RR indicates stronger ability of the model to handle malicious inputs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S5.SS1.SSS2.p6.2.m1.1" display="inline" class="ltx_Math" alttext="\mathbb{I}(\cdot)"><semantics id="S5.SS1.SSS2.p6.2.m1.1a"><mrow id="S5.SS1.SSS2.p6.2.m1.1.2"><mi id="S5.SS1.SSS2.p6.2.m1.1.2.2">𝕀</mi><mo id="S5.SS1.SSS2.p6.2.m1.1.2.1">⁢</mo><mrow id="S5.SS1.SSS2.p6.2.m1.1.2.3.2"><mo stretchy="false" id="S5.SS1.SSS2.p6.2.m1.1.2.3.2.1">(</mo><mo rspace="0em" lspace="0em" id="S5.SS1.SSS2.p6.2.m1.1.1">⋅</mo><mo stretchy="false" id="S5.SS1.SSS2.p6.2.m1.1.2.3.2.2">)</mo></mrow></mrow><annotation-xml id="S5.SS1.SSS2.p6.2.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p6.2.m1.1c" encoding="application/x-tex">\mathbb{I}(\cdot)</annotation><annotation id="S5.SS1.SSS2.p6.2.m1.1d" encoding="application/x-llamapun">blackboard_I ( ⋅ )</annotation></semantics></math> 是一个指示函数，当模型 <math id="S5.SS1.SSS2.p6.3.m2.1" display="inline" class="ltx_Math" alttext="R_{i}"><semantics id="S5.SS1.SSS2.p6.3.m2.1a"><msub id="S5.SS1.SSS2.p6.3.m2.1.1"><mi id="S5.SS1.SSS2.p6.3.m2.1.1.2">R</mi><mi id="S5.SS1.SSS2.p6.3.m2.1.1.3">i</mi></msub><annotation-xml id="S5.SS1.SSS2.p6.3.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S5.SS1.SSS2.p6.3.m2.1c" encoding="application/x-tex">R_{i}</annotation><annotation id="S5.SS1.SSS2.p6.3.m2.1d" encoding="application/x-llamapun">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> 对查询对 <math id="S5.SS1.SSS2.p6.4.m3.2" display="inline" class="ltx_Math" alttext="(T_{i},I_{i})"><semantics id="S5.SS1.SSS2.p6.4.m3.2a"><mrow id="S5.SS1.SSS2.p6.4.m3.2.2.2"><mo stretchy="false" id="S5.SS1.SSS2.p6.4.m3.2.2.2.3">(</mo><msub id="S5.SS1.SSS2.p6.4.m3.1.1.1.1"><mi id="S5.SS1.SSS2.p6.4.m3.1.1.1.1.2">T</mi><mi id="S5.SS1.SSS2.p6.4.m3.1.1.1.1.3">i</mi></msub><mo id="S5.SS1.SSS2.p6.4.m3.2.2.2.4">,</mo><msub id="S5.SS1.SSS2.p6.4.m3.2.2.2.2"><mi id="S5.SS1.SSS2.p6.4.m3.2.2.2.2.2">I</mi><mi id="S5.SS1.SSS2.p6.4.m3.2.2.2.2.3">i</mi></msub><mo stretchy="false" id="S5.SS1.SSS2.p6.4.m3.2.2.2.5">)</mo></mrow><annotation-xml id="S5.SS1.SSS2.p6.4.m3.2b" encoding="MathML-Content">subscriptsubscript</annotation-xml><annotation id="S5.SS1.SSS2.p6.4.m3.2c" encoding="application/x-tex">(T_{i},I_{i})</annotation><annotation id="S5.SS1.SSS2.p6.4.m3.2d" encoding="application/x-llamapun">( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> 适当地拒绝不安全的查询时返回 1，否则返回 0。更高的 RR 表示模型处理恶意输入的能力更强。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p7">
<p class="ltx_p" id="S5.SS1.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p7.1.m1.1"><semantics id="S5.SS1.SSS2.p7.1.m1.1a"><mo id="S5.SS1.SSS2.p7.1.m1.1.1" xref="S5.SS1.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p7.1.m1.1b"><ci id="S5.SS1.SSS2.p7.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p7.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p7.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p7.1.1">Effective Rate&nbsp;(ER)</span>
evaluates the proportion of responses that effectively address user queries while maintaining contextual relevance and accuracy. It reflects the model’s ability to generate meaningful and effective outputs. A higher ER indicates better performance in providing useful and accurate responses.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p7.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS2.p7.1.m1.1a"><mo id="S5.SS1.SSS2.p7.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS2.p7.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p7.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS2.p7.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 有效率（ER）评估模型在保持上下文相关性和准确性的同时，有效回应用户查询的比例。它反映了模型生成有意义和有效输出的能力。更高的 ER 表明模型在提供有用和准确回应方面表现更好。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p8">
<p class="ltx_p" id="S5.SS1.SSS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p8.1.m1.1"><semantics id="S5.SS1.SSS2.p8.1.m1.1a"><mo id="S5.SS1.SSS2.p8.1.m1.1.1" xref="S5.SS1.SSS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p8.1.m1.1b"><ci id="S5.SS1.SSS2.p8.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p8.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p8.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p8.1.1">Toxicity Score&nbsp;(TS)</span>
evaluates the level of harmful or offensive language in a model’s response using tools like PerspectiveAPI<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.perspectiveapi.com/" title="">https://www.perspectiveapi.com/</a></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p8.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS2.p8.1.m1.1a"><mo id="S5.SS1.SSS2.p8.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS2.p8.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p8.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS2.p8.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 毒性评分（TS）使用 PerspectiveAPI 等工具评估模型响应中危害性或冒犯性语言的程度 <sup class="ltx_note_mark">2</sup> </font></font></font> and Detoxify API<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/unitaryai/detoxify" title="">https://github.com/unitaryai/detoxify</a></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">和 Detoxify API <sup class="ltx_note_mark">3</sup> </font></font></font>. These tools assign a toxicity score based on linguistic features, providing a systematic assessment of harmful content. It is commonly used as a complementary evaluation metric in Fine-tuned Model-based Assessment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这些工具根据语言特征分配毒性分数，为有害内容提供系统性的评估。它通常被用作基于微调模型的评估的补充评估指标。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS2.p9">
<p class="ltx_p" id="S5.SS1.SSS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p9.1.m1.1"><semantics id="S5.SS1.SSS2.p9.1.m1.1a"><mo id="S5.SS1.SSS2.p9.1.m1.1.1" xref="S5.SS1.SSS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p9.1.m1.1b"><ci id="S5.SS1.SSS2.p9.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p9.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS2.p9.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p9.1.1">GPT-Score&nbsp;(GS)</span>
uses GPT-4 to rate the quality, relevance, and safety of model responses based on predefined criteria. While offering valuable insights, this metric is subjective and can vary due to GPT-4’s inherent biases. It is commonly used as a complementary evaluation metric in GPT Proxy-Based Assessment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS1.SSS2.p9.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS1.SSS2.p9.1.m1.1a"><mo id="S5.SS1.SSS2.p9.1.m1.1.1">∙</mo><annotation-xml id="S5.SS1.SSS2.p9.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS1.SSS2.p9.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS1.SSS2.p9.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> GPT-Score（GS）使用 GPT-4 根据预定义标准对模型响应的质量、相关性和安全性进行评分。虽然提供了有价值的见解，但这一指标是主观的，可能因 GPT-4 的固有偏见而有所差异。它通常作为 GPT 代理评估中的补充评估指标使用。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span><span class="ltx_text ltx_font_italic" id="S5.SS2.1.1">Benchmarks</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.2 基准测试</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T7">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>Summary of essential characteristics for reviewed methods in Safety Capability Benchmarks&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2.SSS2" title="5.2.2 Safety Capability ‣ 5.2 Benchmarks ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.2.2</span></a>).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 VII：安全能力基准（§ 5.2.2）中审查方法的关键特征总结</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T7.23" style="width:867.2pt;height:479.1pt;vertical-align:-1.4pt;"><span class="ltx_transformed_inner" style="transform:translate(123.2pt,-67.9pt) scale(1.39682869868823,1.39682869868823) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T7.23.23">
<tbody><tr class="ltx_tr" id="S5.T7.23.23.24" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S5.T7.23.23.24.1" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span><span class="ltx_text" id="S5.T7.23.23.24.1.1" style="font-size:90%;background-color:#D8D6C4;">
<span class="ltx_text ltx_font_bold" id="S5.T7.23.23.24.1.1.1">Methods<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.23.23.24.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.23.23.24.2.1" style="font-size:90%;background-color:#D8D6C4;">Venue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">场地</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.23.23.24.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.23.23.24.3.1" style="font-size:90%;background-color:#D8D6C4;">Scale<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">规模</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.23.23.24.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.23.23.24.4.1" style="font-size:90%;background-color:#D8D6C4;">Methods<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.23.23.24.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.23.23.24.5.1" style="font-size:90%;background-color:#D8D6C4;">Metrics<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">指标</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.23.23.24.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S5.T7.23.23.24.6.1" style="font-size:90%;background-color:#D8D6C4;">Highlight<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">重点</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.23.23.25">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="6" id="S5.T7.23.23.25.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T7.23.23.25.1.1" style="font-size:90%;">Adversarial Capability Benchmarks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对抗能力基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.1.1.1" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr ltx_border_t" id="S5.T7.1.1.1.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.1.1.1.2.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">HowManyUnicorns<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib52" title="">52</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.1.1.1.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.1.1.1.3.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ECCV’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.1.1.1.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.1.1.1.4.1" style="font-size:90%;background-color:#F5F5F0;">8.5K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.1.1.1.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S5.T7.1.1.1.5.1" data-imt_insert_failed="1">\faEye</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.1.1.1.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">ASR(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.1.1.1.1.1.m1.1"><semantics id="S5.T7.1.1.1.1.1.m1.1a"><mo id="S5.T7.1.1.1.1.1.m1.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.1.1.1.1.1.m1.1b"><ci id="S5.T7.1.1.1.1.1.m1.1.1.cmml" xref="S5.T7.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.1.1.1.1.1.m1.1d">↓</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.1.1.1.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.1.1.1.6.1" style="font-size:90%;background-color:#F5F5F0;">OOD &amp; adversarial robustness<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">OOD &amp; 对抗鲁棒性</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.3.3.3">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.3.3.3.3" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.3.3.3.3.1" style="font-size:90%;">AVIBench</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T7.3.3.3.3.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib156" title="">156</a><span class="ltx_text" id="S5.T7.3.3.3.3.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.3.3.3.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.3.3.3.4.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.3.3.3.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.3.3.3.5.1" style="font-size:90%;">260K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.3.3.3.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.3.3.3.6.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.3.3.3.2" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S5.T7.3.3.3.2.1" style="font-size:90%;">ASR(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.2.2.2.1.m1.1"><semantics id="S5.T7.2.2.2.1.m1.1a"><mo id="S5.T7.2.2.2.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T7.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.2.2.2.1.m1.1b"><ci id="S5.T7.2.2.2.1.m1.1.1.cmml" xref="S5.T7.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.2.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.2.2.2.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.3.3.3.2.2" style="font-size:90%;">), ASDR(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.3.3.3.2.m2.1"><semantics id="S5.T7.3.3.3.2.m2.1a"><mo id="S5.T7.3.3.3.2.m2.1.1" mathsize="90%" stretchy="false" xref="S5.T7.3.3.3.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.3.3.3.2.m2.1b"><ci id="S5.T7.3.3.3.2.m2.1.1.cmml" xref="S5.T7.3.3.3.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.3.3.3.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.3.3.3.2.m2.1d">↓</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ASR( <math id="S5.T7.2.2.2.1.m1.1" display="inline" class="ltx_Math" alttext="\downarrow"><semantics id="S5.T7.2.2.2.1.m1.1a"><mo stretchy="false" mathsize="90%" id="S5.T7.2.2.2.1.m1.1.1">↓</mo><annotation-xml id="S5.T7.2.2.2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.T7.2.2.2.1.m1.1c" encoding="application/x-tex">\downarrow</annotation><annotation id="S5.T7.2.2.2.1.m1.1d" encoding="application/x-llamapun">↓</annotation></semantics></math> ), ASDR( <math id="S5.T7.3.3.3.2.m2.1" display="inline" class="ltx_Math" alttext="\downarrow"><semantics id="S5.T7.3.3.3.2.m2.1a"><mo stretchy="false" mathsize="90%" id="S5.T7.3.3.3.2.m2.1.1">↓</mo><annotation-xml id="S5.T7.3.3.3.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.T7.3.3.3.2.m2.1c" encoding="application/x-tex">\downarrow</annotation><annotation id="S5.T7.3.3.3.2.m2.1d" encoding="application/x-llamapun">↓</annotation></semantics></math> )</font></font></font><span class="ltx_text" id="S5.T7.3.3.3.2.3" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T7.3.3.3.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.3.3.3.7.1" style="font-size:90%;">Large scale adversarial benchmark<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大规模对抗基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.23.23.26">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="6" id="S5.T7.23.23.26.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T7.23.23.26.1.1" style="font-size:90%;">Multi-Model Attack Benchmarks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多模型攻击基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.5.5.5" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr ltx_border_t" id="S5.T7.5.5.5.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.5.5.5.3.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">MM-SafetyBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib53" title="">53</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.5.5.5.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.5.5.5.4.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ECCV’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.5.5.5.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.5.5.5.5.1" style="font-size:90%;background-color:#F5F5F0;">5K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.5.5.5.6" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S5.T7.5.5.5.6.1">\faEye</span><span class="ltx_text" id="S5.T7.5.5.5.6.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S5.T7.5.5.5.6.2.1">\faGoogle</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.5.5.5.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.5.5.5.2.2" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">ASR(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.4.4.4.1.1.m1.1"><semantics id="S5.T7.4.4.4.1.1.m1.1a"><mo id="S5.T7.4.4.4.1.1.m1.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.4.4.4.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.4.4.4.1.1.m1.1b"><ci id="S5.T7.4.4.4.1.1.m1.1.1.cmml" xref="S5.T7.4.4.4.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.4.4.4.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.4.4.4.1.1.m1.1d">↓</annotation></semantics></math>), RR(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T7.5.5.5.2.2.m2.1"><semantics id="S5.T7.5.5.5.2.2.m2.1a"><mo id="S5.T7.5.5.5.2.2.m2.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.5.5.5.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T7.5.5.5.2.2.m2.1b"><ci id="S5.T7.5.5.5.2.2.m2.1.1.cmml" xref="S5.T7.5.5.5.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.5.5.5.2.2.m2.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.5.5.5.2.2.m2.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.5.5.5.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.5.5.5.7.1" style="font-size:90%;background-color:#F5F5F0;">OCR &amp; diffusion based attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">OCR &amp; 扩散攻击</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.6.6.6">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.6.6.6.2" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.6.6.6.2.1" style="font-size:90%;">TypoD</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T7.6.6.6.2.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib157" title="">157</a><span class="ltx_text" id="S5.T7.6.6.6.2.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.6.6.6.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.6.6.6.3.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[ECCV’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.6.6.6.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.6.6.6.4.1" style="font-size:90%;">20K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.6.6.6.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.6.6.6.5.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.6.6.6.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.6.6.6.1.1" style="font-size:90%;">ASR(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.6.6.6.1.m1.1"><semantics id="S5.T7.6.6.6.1.m1.1a"><mo id="S5.T7.6.6.6.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T7.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.6.6.6.1.m1.1b"><ci id="S5.T7.6.6.6.1.m1.1.1.cmml" xref="S5.T7.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.6.6.6.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.6.6.6.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.6.6.6.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T7.6.6.6.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.6.6.6.6.1" style="font-size:90%;">Typography attack benchmark<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">字体攻击基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.7.7.7" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.7.7.7.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.7.7.7.2.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">RTVLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib158" title="">158</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.7.7.7.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.7.7.7.3.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ACL’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.7.7.7.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.7.7.7.4.1" style="font-size:90%;background-color:#F5F5F0;">5.2K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.7.7.7.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S5.T7.7.7.7.5.1" data-imt_insert_failed="1">\faGoogle</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.7.7.7.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.7.7.7.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">GS(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T7.7.7.7.1.1.m1.1"><semantics id="S5.T7.7.7.7.1.1.m1.1a"><mo id="S5.T7.7.7.7.1.1.m1.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.7.7.7.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T7.7.7.7.1.1.m1.1b"><ci id="S5.T7.7.7.7.1.1.m1.1.1.cmml" xref="S5.T7.7.7.7.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.7.7.7.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.7.7.7.1.1.m1.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T7.7.7.7.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.7.7.7.6.1" style="font-size:90%;background-color:#F5F5F0;">First LVLM red teaming benchmark<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">首个视觉语言模型红队评测基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.8.8.8">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.8.8.8.2" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.8.8.8.2.1" style="font-size:90%;">JailBreakV-28K</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T7.8.8.8.2.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib54" title="">54</a><span class="ltx_text" id="S5.T7.8.8.8.2.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.8.8.8.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.8.8.8.3.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[COLM’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.8.8.8.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.8.8.8.4.1" style="font-size:90%;">28K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.8.8.8.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S5.T7.8.8.8.5.1" data-imt_insert_failed="1">\faGithubAlt</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.8.8.8.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.8.8.8.1.1" style="font-size:90%;">ASR(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.8.8.8.1.m1.1"><semantics id="S5.T7.8.8.8.1.m1.1a"><mo id="S5.T7.8.8.8.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T7.8.8.8.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.8.8.8.1.m1.1b"><ci id="S5.T7.8.8.8.1.m1.1.1.cmml" xref="S5.T7.8.8.8.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.8.8.8.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.8.8.8.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.8.8.8.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T7.8.8.8.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.8.8.8.6.1" style="font-size:90%;">Both image-based and text-based<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于图像和基于文本的</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.9.9.9" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.9.9.9.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.9.9.9.2.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">RTGPT4<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib159" title="">159</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.9.9.9.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.9.9.9.3.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[ICLR’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.9.9.9.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.9.9.9.4.1" style="font-size:90%;background-color:#F5F5F0;">1.4K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.9.9.9.5" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S5.T7.9.9.9.5.1">\faEdit</span><span class="ltx_text" id="S5.T7.9.9.9.5.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S5.T7.9.9.9.5.2.1">\faGithubAlt</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.9.9.9.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.9.9.9.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">ASR(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.9.9.9.1.1.m1.1"><semantics id="S5.T7.9.9.9.1.1.m1.1a"><mo id="S5.T7.9.9.9.1.1.m1.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.9.9.9.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.9.9.9.1.1.m1.1b"><ci id="S5.T7.9.9.9.1.1.m1.1.1.cmml" xref="S5.T7.9.9.9.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.9.9.9.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.9.9.9.1.1.m1.1d">↓</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T7.9.9.9.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.9.9.9.6.1" style="font-size:90%;background-color:#F5F5F0;">Jailbreak red teaming benchmark<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Jailbreak 红队测试基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.13.13.13">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.13.13.13.5" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.13.13.13.5.1" style="font-size:90%;">MultiTrust</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T7.13.13.13.5.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib55" title="">55</a><span class="ltx_text" id="S5.T7.13.13.13.5.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.13.13.13.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.13.13.13.6.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[NeurIPS’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.13.13.13.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.13.13.13.7.1" style="font-size:90%;">23K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.13.13.13.8" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S5.T7.13.13.13.8.1">\faEdit</span><span class="ltx_text" id="S5.T7.13.13.13.8.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S5.T7.13.13.13.8.3">\faGithubAlt</span><span class="ltx_text" id="S5.T7.13.13.13.8.4" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S5.T7.13.13.13.8.5">\faGoogle</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.13.13.13.4" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.13.13.13.4.1" style="font-size:90%;">ASR(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.10.10.10.1.m1.1"><semantics id="S5.T7.10.10.10.1.m1.1a"><mo id="S5.T7.10.10.10.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T7.10.10.10.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.10.10.10.1.m1.1b"><ci id="S5.T7.10.10.10.1.m1.1.1.cmml" xref="S5.T7.10.10.10.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.10.10.10.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.10.10.10.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.13.13.13.4.2" style="font-size:90%;">), RR(</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T7.11.11.11.2.m2.1"><semantics id="S5.T7.11.11.11.2.m2.1a"><mo id="S5.T7.11.11.11.2.m2.1.1" mathsize="90%" stretchy="false" xref="S5.T7.11.11.11.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T7.11.11.11.2.m2.1b"><ci id="S5.T7.11.11.11.2.m2.1.1.cmml" xref="S5.T7.11.11.11.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.11.11.11.2.m2.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.11.11.11.2.m2.1d">↑</annotation></semantics></math><span class="ltx_text" id="S5.T7.13.13.13.4.3" style="font-size:90%;">), TS(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.12.12.12.3.m3.1"><semantics id="S5.T7.12.12.12.3.m3.1a"><mo id="S5.T7.12.12.12.3.m3.1.1" mathsize="90%" stretchy="false" xref="S5.T7.12.12.12.3.m3.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.12.12.12.3.m3.1b"><ci id="S5.T7.12.12.12.3.m3.1.1.cmml" xref="S5.T7.12.12.12.3.m3.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.12.12.12.3.m3.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.12.12.12.3.m3.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.13.13.13.4.4" style="font-size:90%;">), GS(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.13.13.13.4.m4.1"><semantics id="S5.T7.13.13.13.4.m4.1a"><mo id="S5.T7.13.13.13.4.m4.1.1" mathsize="90%" stretchy="false" xref="S5.T7.13.13.13.4.m4.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.13.13.13.4.m4.1b"><ci id="S5.T7.13.13.13.4.m4.1.1.cmml" xref="S5.T7.13.13.13.4.m4.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.13.13.13.4.m4.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.13.13.13.4.m4.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.13.13.13.4.5" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T7.13.13.13.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.13.13.13.9.1" style="font-size:90%;">Comprehensive trustworthy benchmark<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">全面的可信基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.15.15.15" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.15.15.15.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.15.15.15.3.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">MLLMGuard<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib56" title="">56</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.15.15.15.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.15.15.15.4.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[NeurIPS’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.15.15.15.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.15.15.15.5.1" style="font-size:90%;background-color:#F5F5F0;">2.3K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.15.15.15.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S5.T7.15.15.15.6.1" data-imt_insert_failed="1">\faGithubAlt</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.15.15.15.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.15.15.15.2.2" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">ASD(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.14.14.14.1.1.m1.1"><semantics id="S5.T7.14.14.14.1.1.m1.1a"><mo id="S5.T7.14.14.14.1.1.m1.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.14.14.14.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.14.14.14.1.1.m1.1b"><ci id="S5.T7.14.14.14.1.1.m1.1.1.cmml" xref="S5.T7.14.14.14.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.14.14.14.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.14.14.14.1.1.m1.1d">↓</annotation></semantics></math>), PAR(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T7.15.15.15.2.2.m2.1"><semantics id="S5.T7.15.15.15.2.2.m2.1a"><mo id="S5.T7.15.15.15.2.2.m2.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.15.15.15.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T7.15.15.15.2.2.m2.1b"><ci id="S5.T7.15.15.15.2.2.m2.1.1.cmml" xref="S5.T7.15.15.15.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.15.15.15.2.2.m2.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.15.15.15.2.2.m2.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T7.15.15.15.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.15.15.15.7.1" style="font-size:90%;background-color:#F5F5F0;">Bilingual benchmark<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">双语基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.16.16.16">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.16.16.16.2" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.16.16.16.2.1" style="font-size:90%;">MOSSBench</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T7.16.16.16.2.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib160" title="">160</a><span class="ltx_text" id="S5.T7.16.16.16.2.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.16.16.16.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.16.16.16.3.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.16.16.16.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.16.16.16.4.1" style="font-size:90%;">300</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.16.16.16.5" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S5.T7.16.16.16.5.1">\faEye</span><span class="ltx_text" id="S5.T7.16.16.16.5.2" style="font-size:90%;">&nbsp;</span><span class="ltx_ERROR undefined" id="S5.T7.16.16.16.5.3">\faGoogle</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.16.16.16.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.16.16.16.1.1" style="font-size:90%;">RR(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.16.16.16.1.m1.1"><semantics id="S5.T7.16.16.16.1.m1.1a"><mo id="S5.T7.16.16.16.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T7.16.16.16.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.16.16.16.1.m1.1b"><ci id="S5.T7.16.16.16.1.m1.1.1.cmml" xref="S5.T7.16.16.16.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.16.16.16.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.16.16.16.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.16.16.16.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T7.16.16.16.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.16.16.16.6.1" style="font-size:90%;">Safety oversensitivity benchmark<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全过度敏感基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.18.18.18" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.18.18.18.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.18.18.18.3.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">Arondight<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib161" title="">161</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.18.18.18.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.18.18.18.4.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[MM’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.18.18.18.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.18.18.18.5.1" style="font-size:90%;background-color:#F5F5F0;">14K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.18.18.18.6" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S5.T7.18.18.18.6.1">\faEye</span><span class="ltx_text" id="S5.T7.18.18.18.6.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S5.T7.18.18.18.6.2.1">\faGithubAlt</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.18.18.18.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.18.18.18.2.2" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">ASR(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.17.17.17.1.1.m1.1"><semantics id="S5.T7.17.17.17.1.1.m1.1a"><mo id="S5.T7.17.17.17.1.1.m1.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.17.17.17.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.17.17.17.1.1.m1.1b"><ci id="S5.T7.17.17.17.1.1.m1.1.1.cmml" xref="S5.T7.17.17.17.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.17.17.17.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.17.17.17.1.1.m1.1d">↓</annotation></semantics></math>), TS(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.18.18.18.2.2.m2.1"><semantics id="S5.T7.18.18.18.2.2.m2.1a"><mo id="S5.T7.18.18.18.2.2.m2.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.18.18.18.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.18.18.18.2.2.m2.1b"><ci id="S5.T7.18.18.18.2.2.m2.1.1.cmml" xref="S5.T7.18.18.18.2.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.18.18.18.2.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.18.18.18.2.2.m2.1d">↓</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center" id="S5.T7.18.18.18.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.18.18.18.7.1" style="font-size:90%;background-color:#F5F5F0;">Auto-generated red teaming evaluation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">自动生成的红队评估</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.20.20.20">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.20.20.20.3" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.20.20.20.3.1" style="font-size:90%;">SafeBench</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T7.20.20.20.3.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib154" title="">154</a><span class="ltx_text" id="S5.T7.20.20.20.3.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.20.20.20.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.20.20.20.4.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.20.20.20.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.20.20.20.5.1" style="font-size:90%;">2.3K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.20.20.20.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S5.T7.20.20.20.6.1" data-imt_insert_failed="1">\faGithubAlt</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.20.20.20.2" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S5.T7.20.20.20.2.1" style="font-size:90%;">ASR(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.19.19.19.1.m1.1"><semantics id="S5.T7.19.19.19.1.m1.1a"><mo id="S5.T7.19.19.19.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T7.19.19.19.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.19.19.19.1.m1.1b"><ci id="S5.T7.19.19.19.1.m1.1.1.cmml" xref="S5.T7.19.19.19.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.19.19.19.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.19.19.19.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.20.20.20.2.2" style="font-size:90%;">), SRI(</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T7.20.20.20.2.m2.1"><semantics id="S5.T7.20.20.20.2.m2.1a"><mo id="S5.T7.20.20.20.2.m2.1.1" mathsize="90%" stretchy="false" xref="S5.T7.20.20.20.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T7.20.20.20.2.m2.1b"><ci id="S5.T7.20.20.20.2.m2.1.1.cmml" xref="S5.T7.20.20.20.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.20.20.20.2.m2.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.20.20.20.2.m2.1d">↑</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ASR( <math id="S5.T7.19.19.19.1.m1.1" display="inline" class="ltx_Math" alttext="\downarrow"><semantics id="S5.T7.19.19.19.1.m1.1a"><mo stretchy="false" mathsize="90%" id="S5.T7.19.19.19.1.m1.1.1">↓</mo><annotation-xml id="S5.T7.19.19.19.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.T7.19.19.19.1.m1.1c" encoding="application/x-tex">\downarrow</annotation><annotation id="S5.T7.19.19.19.1.m1.1d" encoding="application/x-llamapun">↓</annotation></semantics></math> ), SRI( <math id="S5.T7.20.20.20.2.m2.1" display="inline" class="ltx_Math" alttext="\uparrow"><semantics id="S5.T7.20.20.20.2.m2.1a"><mo stretchy="false" mathsize="90%" id="S5.T7.20.20.20.2.m2.1.1">↑</mo><annotation-xml id="S5.T7.20.20.20.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.T7.20.20.20.2.m2.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S5.T7.20.20.20.2.m2.1d" encoding="application/x-llamapun">↑</annotation></semantics></math> )</font></font></font><span class="ltx_text" id="S5.T7.20.20.20.2.3" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T7.20.20.20.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.20.20.20.7.1" style="font-size:90%;">Jury-based evaluation framework<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于陪审团的评估框架</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.23.23.27">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="6" id="S5.T7.23.23.27.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S5.T7.23.23.27.1.1" style="font-size:90%;">Cross-Modality Alignment Benchmarks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">跨模态对齐基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.22.22.22" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr ltx_border_t" id="S5.T7.22.22.22.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.22.22.22.3.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">SIUO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib44" title="">44</a>]</cite></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.22.22.22.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.22.22.22.4.1" style="font-size:90%;color:#4D4D4D;background-color:#F5F5F0;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.22.22.22.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.22.22.22.5.1" style="font-size:90%;background-color:#F5F5F0;">167</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.22.22.22.6" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_ERROR undefined" id="S5.T7.22.22.22.6.1">\faEye</span><span class="ltx_text" id="S5.T7.22.22.22.6.2" style="font-size:90%;background-color:#F5F5F0;">&nbsp;<span class="ltx_ERROR undefined" id="S5.T7.22.22.22.6.2.1">\faGoogle</span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T7.22.22.22.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.22.22.22.2.2" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">ASR(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.21.21.21.1.1.m1.1"><semantics id="S5.T7.21.21.21.1.1.m1.1a"><mo id="S5.T7.21.21.21.1.1.m1.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.21.21.21.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.21.21.21.1.1.m1.1b"><ci id="S5.T7.21.21.21.1.1.m1.1.1.cmml" xref="S5.T7.21.21.21.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.21.21.21.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.21.21.21.1.1.m1.1d">↓</annotation></semantics></math>), ER(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T7.22.22.22.2.2.m2.1"><semantics id="S5.T7.22.22.22.2.2.m2.1a"><mo id="S5.T7.22.22.22.2.2.m2.1.1" mathbackground="#F5F5F0" stretchy="false" xref="S5.T7.22.22.22.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T7.22.22.22.2.2.m2.1b"><ci id="S5.T7.22.22.22.2.2.m2.1.1.cmml" xref="S5.T7.22.22.22.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.22.22.22.2.2.m2.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.22.22.22.2.2.m2.1d">↑</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T7.22.22.22.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.22.22.22.7.1" style="font-size:90%;background-color:#F5F5F0;">Safe input unsafe output<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全输入不安全输出</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.23.23.23">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S5.T7.23.23.23.2" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.23.23.23.2.1" style="font-size:90%;">MSSBench</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S5.T7.23.23.23.2.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib162" title="">162</a><span class="ltx_text" id="S5.T7.23.23.23.2.3.2" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.23.23.23.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.23.23.23.3.1" style="font-size:90%;color:#4D4D4D;" data-imt_insert_failed="1">[arXiv’24]</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.23.23.23.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.23.23.23.4.1" style="font-size:90%;">1.8K</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.23.23.23.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_ERROR undefined" id="S5.T7.23.23.23.5.1" data-imt_insert_failed="1">\faGoogle</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T7.23.23.23.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">
<span class="ltx_text" id="S5.T7.23.23.23.1.1" style="font-size:90%;">ASR(</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T7.23.23.23.1.m1.1"><semantics id="S5.T7.23.23.23.1.m1.1a"><mo id="S5.T7.23.23.23.1.m1.1.1" mathsize="90%" stretchy="false" xref="S5.T7.23.23.23.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.23.23.23.1.m1.1b"><ci id="S5.T7.23.23.23.1.m1.1.1.cmml" xref="S5.T7.23.23.23.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.23.23.23.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T7.23.23.23.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S5.T7.23.23.23.1.2" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T7.23.23.23.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S5.T7.23.23.23.6.1" style="font-size:90%;">Multimodel situational safety benchmark<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多模型情境安全基准</font></font></font></span></td>
</tr>
<tr class="ltx_tr" id="S5.T7.23.23.28">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S5.T7.23.23.28.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_t" id="S5.T7.23.23.28.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T7.23.23.28.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T7.23.23.28.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T7.23.23.28.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S5.T7.23.23.28.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">To evaluate the security capabilities of LVLMs and the effectiveness of attack and defense strategies, researchers have developed extensive benchmarks. These benchmarks fall into two categories: <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">Strategy Effectivity</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2.SSS1" title="5.2.1 Strategy Effectivity ‣ 5.2 Benchmarks ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.2.1</span></a>), which assesses attack and defense strategies, and <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.2">Safety Capability</span>&nbsp;(<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S5.SS2.SSS2" title="5.2.2 Safety Capability ‣ 5.2 Benchmarks ‣ 5 Evaluation ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">§</span>&nbsp;<span class="ltx_text ltx_ref_tag">5.2.2</span></a>), which examines the models’ inherent security capabilities. Together, they provide a comprehensive framework for improving LVLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了评估大型视觉语言模型（LVLMs）的安全能力以及攻击和防御策略的有效性，研究人员开发了广泛的基准。这些基准分为两类：策略有效性（§ 5.2.1），用于评估攻击和防御策略，以及安全能力（§ 5.2.2），用于检验模型的固有安全能力。两者共同为改进 LVLMs 提供了一个全面的框架。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Strategy Effectivity<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.2.1 策略有效性</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS1.p1">
<p class="ltx_p" id="S5.SS2.SSS1.p1.1">Despite the proliferation of various attack and defense methodologies, evaluating their effectiveness under consistent and standardized conditions remains a significant challenge. This aspect is dedicated to assessing the efficacy of diverse attack and defense strategies. At present, only one work has tackled this issue in a comprehensive manner.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管各种攻击和防御方法不断涌现，但在一致和标准化的条件下评估它们的有效性仍然是一个重大挑战。这一方面致力于评估各种攻击和防御策略的有效性。目前，只有一项工作全面地处理了这个问题。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS1.p2">
<p class="ltx_p" id="S5.SS2.SSS1.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS1.p2.1.m1.1"><semantics id="S5.SS2.SSS1.p2.1.m1.1a"><mo id="S5.SS2.SSS1.p2.1.m1.1.1" xref="S5.SS2.SSS1.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p2.1.m1.1b"><ci id="S5.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS1.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS1.p2.1.1">MMJ-Bench</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib163" title="">163</a>]</cite>
is the first benchmark designed to evaluate LVLM jailbreak attack and defense techniques in a standardized and comprehensive manner. This benchmark utilizes HarmBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib164" title="">164</a>]</cite> to generate harmful queries, and incorporates three generation-based attacks: FigStep&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>]</cite>, MMSafetyBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib53" title="">53</a>]</cite>, and HADES&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib40" title="">40</a>]</cite>, as well as three optimization-based attacks: VisualAdv&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>]</cite>, ImgJP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib101" title="">101</a>]</cite>, and AttackVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib25" title="">25</a>]</cite>, to create corresponding jailbreak prompts. For defense strategies, one proactive defense, VLGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib49" title="">49</a>]</cite>, is selected, along with three reactive defenses: AdaShield&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib43" title="">43</a>]</cite>, CIDER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib44" title="">44</a>]</cite>, and JailGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib47" title="">47</a>]</cite>. Through this unified evaluation framework, the study reveals that the effectiveness of each attack varies across LVLMs, with no model exhibiting uniform robustness against all jailbreak attacks. The development of a defense method that achieves an optimal balance between model utility and defense efficacy for all LVLMs presents a considerable challenge.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS2.SSS1.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS2.SSS1.p2.1.m1.1a"><mo id="S5.SS2.SSS1.p2.1.m1.1.1">∙</mo><annotation-xml id="S5.SS2.SSS1.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS2.SSS1.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS2.SSS1.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> MMJ-Bench [ 163] 是首个设计用于以标准化和全面的方式评估大型视觉语言模型（LVLM）越狱攻击与防御技术的基准。该基准利用 HarmBench [ 164] 生成有害查询，并整合了三种基于生成的攻击：FigStep [ 41]、MMSafetyBench [ 53] 和 HADES [ 40]，以及三种基于优化的攻击：VisualAdv [ 23]、ImgJP [ 101] 和 AttackVLM [ 25]，以创建相应的越狱提示。在防御策略方面，选用了 VLGuard [ 49] 这一主动防御方法，以及 AdaShield [ 43]、CIDER [ 44] 和 JailGuard [ 47] 三种被动防御方法。通过这一统一的评估框架，研究揭示每种攻击在 LVLM 上的有效性存在差异，没有模型对所有越狱攻击表现出一致的鲁棒性。为所有 LVLM 开发一种在模型效用与防御效能之间取得最佳平衡的防御方法，是一项相当大的挑战。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.2 </span>Safety Capability<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.2.2 安全能力</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS2.p1">
<p class="ltx_p" id="S5.SS2.SSS2.p1.1">This aspect of the benchmark is designed to evaluate the model’s ability to handle diverse safety-critical scenarios. Including measuring the model’s response to malicious inputs, assessing robustness against adversarial attacks, and verifying its alignment with ethical and safety principles.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这一基准测试的方面旨在评估模型处理多样化安全关键场景的能力。包括测量模型对恶意输入的反应，评估其对抗对抗性攻击的鲁棒性，并验证其与伦理和安全原则的一致性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p2">
<p class="ltx_p" id="S5.SS2.SSS2.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p2.1.m1.1"><semantics id="S5.SS2.SSS2.p2.1.m1.1a"><mo id="S5.SS2.SSS2.p2.1.m1.1.1" xref="S5.SS2.SSS2.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p2.1.m1.1b"><ci id="S5.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS2.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p2.1.1">Adversarial Capability Benchmarks.</span>
HowManyUnicorns&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib52" title="">52</a>]</cite> was initially proposed to introduce a straightforward attack strategy designed to mislead LVLMs into generating visually unrelated responses. By evaluating both out-of-distribution (OOD) generalization and adversarial robustness, HowManyUnicorns&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib52" title="">52</a>]</cite> provides a comprehensive assessment of 21 diverse models, spanning from open-source VLLMs to GPT-4V.
Besides, AVIBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib156" title="">156</a>]</cite> focuses on evaluating the robustness of LVLMs against Adversarial Visual-Instructions (AVIs). AVIBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib156" title="">156</a>]</cite> employs LVLM-agnostic and output-probability-distribution-agnostic black-box attack methods, generating 10 types of text-based AVIs, 4 types of image-based AVIs, and 9 types of content bias AVIs, resulting in a comprehensive dataset of 260K AVIs. This benchmark evaluates the adversarial robustness of 14 open-source models and 2 proprietary models (GPT-4V, GeminiPro), providing an extensive assessment of their ability to withstand various adversarial attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS2.SSS2.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS2.SSS2.p2.1.m1.1a"><mo id="S5.SS2.SSS2.p2.1.m1.1.1">∙</mo><annotation-xml id="S5.SS2.SSS2.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS2.SSS2.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS2.SSS2.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 对抗能力基准测试。HowManyUnicorns [ 52] 最初被提出用于引入一种直接的攻击策略，旨在误导大型视觉语言模型（LVLMs）生成视觉上不相关的响应。通过评估分布外（OOD）泛化和对抗鲁棒性，HowManyUnicorns [ 52] 对 21 种不同模型进行了全面评估，涵盖了开源视觉语言模型（VLLMs）到 GPT-4V。此外，AVIBench [ 156] 专注于评估 LVLMs 对对抗视觉指令（AVIs）的鲁棒性。AVIBench [ 156] 采用与 LVLM 无关和与输出概率分布无关的黑盒攻击方法，生成了 10 种基于文本的 AVIs、4 种基于图像的 AVIs 和 9 种内容偏差 AVIs，形成了一个包含 260K AVIs 的综合数据集。该基准测试评估了 14 种开源模型和 2 种专有模型（GPT-4V、GeminiPro）的对抗鲁棒性，全面评估了它们抵御各种对抗攻击的能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p3">
<p class="ltx_p" id="S5.SS2.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p3.1.m1.1"><semantics id="S5.SS2.SSS2.p3.1.m1.1a"><mo id="S5.SS2.SSS2.p3.1.m1.1.1" xref="S5.SS2.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p3.1.m1.1b"><ci id="S5.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS2.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p3.1.1">Multi-Model Attack Benchmarks.</span>
MM-SafetyBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib53" title="">53</a>]</cite> presents a framework for assessing LVLM safety against image-based adversarial attacks. The evaluation dataset, constructed using Stable Diffusion<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0" title="">https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0</a></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS2.SSS2.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS2.SSS2.p3.1.m1.1a"><mo id="S5.SS2.SSS2.p3.1.m1.1.1">∙</mo><annotation-xml id="S5.SS2.SSS2.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS2.SSS2.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS2.SSS2.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 多模型攻击基准。MM-SafetyBench [53] 提出了一个用于评估 LVLM 安全性的框架，以应对基于图像的对抗性攻击。评估数据集是使用 Stable Diffusion <sup class="ltx_note_mark">4</sup> 构建的。</font></font></font> and Typography techniques along with GPT-4-generated queries, includes 5,040 text-image pairs across 13 scenarios. Two primary metrics, ASR and RR, are used to measure model vulnerability, revealing that many LVLMs, despite safety alignment, remain highly susceptible to adversarial manipulations.
TypoD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib157" title="">157</a>]</cite> investigates LVLM vulnerability to typographic distractions with a dataset spanning perception-oriented tasks (e.g., object recognition) and cognition-oriented tasks (e.g., commonsense reasoning). The study shows that LVLMs must rely on cross-modal attention matching, rather than uni-modal information, to resolve typographic distractions effectively.
JailBreakV-28K&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib54" title="">54</a>]</cite> evaluates LVLM vulnerability to jailbreak attacks by extending the RedTeam-2K dataset with 28,000 multimodal adversarial prompts. The high ASR in evaluations across 10 open-source LVLMs highlights significant vulnerability to these attacks.
RTVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib158" title="">158</a>]</cite> is the first to construct a red teaming dataset to benchmark current LVLMs across four key aspects: faithfulness, privacy, safety, and fairness. Comprising 5,200 samples, RTVLM includes tasks like multimodal jailbreaking and visual misdirection.
RTGPT4&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib159" title="">159</a>]</cite> combines three attack methods: FigStep&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>]</cite>, VisualAdv&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>]</cite>, and ImageHijacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib27" title="">27</a>]</cite> to create 1,445 samples, which are used to evaluate 11 different LLMs and MLLMs, finding that GPT-4 and GPT-4V outperform open-source models in resisting both textual and visual jailbreak techniques.
Arondight&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib161" title="">161</a>]</cite> addresses challenges in adapting red teaming techniques from LLMs to VLMs, such as the lack of a visual modality and insufficient diversity. The framework features an automated multimodal jailbreak attack, where visual prompts are generated by a red team VLM and textual prompts by a red team LLM, guided by reinforcement learning. To improve VLM security evaluation, the framework incorporates entropy bonuses and novelty reward metrics.
MultiTrust&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib55" title="">55</a>]</cite> offers a unified benchmark for LVLM trustworthiness, evaluating 21 models across 32 tasks in five critical dimensions: truthfulness, safety, robustness, fairness, and privacy. The study highlights significant vulnerabilities in LVLMs, particularly in novel multimodal scenarios where cross-modal interactions often introduce instabilities.
MLLMGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib56" title="">56</a>]</cite> provides a bilingual evaluation dataset, incorporating red teaming techniques to assess five safety dimensions (privacy, bias, toxicity, truthfulness, and legality) across 12 subtasks. This framework yields valuable insights for improving model safety.
MOSSBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib160" title="">160</a>]</cite> evaluates the oversensitivity of LVLMs to harmless queries when specific visual stimuli are present, revealing that safety-aligned models tend to exhibit a higher degree of oversensitivity.
SafeBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib154" title="">154</a>]</cite> introduces an automated pipeline for safety dataset generation, leveraging a jury system to evaluate harmful behaviors and assess content security risks through collaborative LLMs. This innovative approach provides a impartial assessment of LVLM safety.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> 以及排版技术，并结合 GPT-4 生成的查询，包含 13 种场景下的 5,040 个文本-图像对。使用 ASR 和 RR 两个主要指标来衡量模型漏洞，揭示许多 LVLM 尽管进行了安全对齐，仍然高度容易受到对抗性操控。TypoD [ 157] 研究了 LVLM 对排版干扰的漏洞，其数据集涵盖了感知导向任务（例如，物体识别）和认知导向任务（例如，常识推理）。研究表明，LVLM 必须依赖跨模态注意力匹配，而不是单模态信息，才能有效解决排版干扰。JailBreakV-28K [ 54] 通过扩展 RedTeam-2K 数据集，增加了 28,000 个多模态对抗性提示，评估了 LVLM 对越狱攻击的漏洞。在 10 个开源 LVLM 上的评估中，高 ASR 凸显了这些攻击的显著漏洞。RTVLM [ 158] 首次构建了一个红队测试数据集，用于在四个关键方面（可信度、隐私、安全和公平性）基准测试当前的 LVLM。包含 5,200 个样本的 RTVLM，包括多模态越狱和视觉误导等任务。 RTGPT4 [ 159] 结合了三种攻击方法：FigStep [ 41]、VisualAdv [ 23] 和 ImageHijacks [ 27] 来创建 1,445 个样本，用于评估 11 种不同的 LLMs 和 MLLMs，发现 GPT-4 和 GPT-4V 在抵抗文本和视觉越狱技术方面均优于开源模型。Arondight [ 161] 解决了将红队技术从 LLMs 应用于 VLMs 时面临的挑战，例如缺乏视觉模态和多样性不足。该框架具有自动多模态越狱攻击功能，其中视觉提示由红队 VLM 生成，文本提示由红队 LLM 生成，并在强化学习的指导下进行。为了改进 VLM 安全评估，该框架集成了熵奖励和新颖性奖励指标。MultiTrust [ 55] 提供了一个统一的基准来评估 LVLM 的可信度，在五个关键维度（真实性、安全性、鲁棒性、公平性和隐私性）上对 21 个模型在 32 项任务中进行了评估。该研究突出了 LVLM 中的重大漏洞，特别是在新颖的多模态场景中，跨模态交互常常引入不稳定性。 MLLMGuard [ 56] 提供了一个双语评估数据集，结合红队技术评估五个安全维度（隐私、偏见、毒性、真实性和合法性），涵盖 12 个子任务。该框架为提升模型安全性提供了宝贵的见解。MOSSBench [ 160] 评估了 LVLMs 在存在特定视觉刺激时对无害查询的过度敏感性，揭示安全对齐模型倾向于表现出更高的过度敏感性程度。SafeBench [ 154] 引入了一个用于安全数据集生成的自动化流程，利用陪审团系统通过协作 LLMs 评估有害行为并评估内容安全风险。这种创新方法为 LVLM 安全性提供了公正的评估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS2.p4">
<p class="ltx_p" id="S5.SS2.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S5.SS2.SSS2.p4.1.m1.1"><semantics id="S5.SS2.SSS2.p4.1.m1.1a"><mo id="S5.SS2.SSS2.p4.1.m1.1.1" xref="S5.SS2.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p4.1.m1.1b"><ci id="S5.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS2.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS2.p4.1.1">Cross-Modality Alignment Benchmarks.</span>
LLMs generally undergo safety alignment&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib165" title="">165</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib166" title="">166</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib167" title="">167</a>]</cite>. Nevertheless, for LVLMs, ensuring cross-modal safety alignment is even more crucial due to the integration of both visual and textual modalities (e.g., asking an LVLM how to jump from a cliff while providing an image of a person standing at the edge).
To address this, SIUO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib168" title="">168</a>]</cite> developed a dataset where both textual and visual inputs are individually safe, but their combination results in unsafe outputs. The dataset was used to evaluate the integration, knowledge, and reasoning capabilities of 15 LVLMs, revealing that even advanced models like GPT-4V&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib16" title="">16</a>]</cite> only achieve a safe response rate of 53.26% on this benchmark.
Additionally, MSSBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib162" title="">162</a>]</cite> constructed a larger dataset containing 1,820 language-query-image pairs, half of which are safe and the other half unsafe. The findings highlight that current LVLMs struggle with this safety issue in instruction-following tasks and face significant challenges when addressing these situational safety concerns simultaneously, underscoring a crucial area for future research.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S5.SS2.SSS2.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S5.SS2.SSS2.p4.1.m1.1a"><mo id="S5.SS2.SSS2.p4.1.m1.1.1">∙</mo><annotation-xml id="S5.SS2.SSS2.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S5.SS2.SSS2.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S5.SS2.SSS2.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 跨模态对齐基准测试。LLMs 通常会进行安全对齐 [ 165, 166, 167]。然而，对于 LVLMs 来说，由于视觉和文本模态的集成（例如，向一个 LVLM 提问如何从悬崖跳下，同时提供一张站在边缘的人的图片），确保跨模态安全对齐更为关键。为了解决这个问题，SIUO [ 168] 开发了一个数据集，其中文本和视觉输入都是单独安全的，但它们的组合会产生不安全的输出。该数据集被用于评估 15 个 LVLMs 的集成、知识和推理能力，揭示即使是像 GPT-4V [ 16] 这样的高级模型，在这个基准测试上也只能达到 53.26% 的安全响应率。此外，MSSBench [ 162] 构建了一个更大的数据集，包含 1,820 个语言-查询-图像对，其中一半是安全的，另一半是不安全的。这些发现表明，当前的 LVLMs 在指令跟随任务中难以处理这个问题，并且在同时处理这些情境安全问题时面临重大挑战，突显了未来研究的一个关键领域。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Safety Evaluation on Janus-Pro</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6 Janus-Pro 安全评估</font></font></font>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T8">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span>Evaluation on SIUO using ASR (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S6.T8.2.m1.1"><semantics id="S6.T8.2.m1.1b"><mo id="S6.T8.2.m1.1.1" stretchy="false" xref="S6.T8.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T8.2.m1.1c"><ci id="S6.T8.2.m1.1.1.cmml" xref="S6.T8.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T8.2.m1.1d">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S6.T8.2.m1.1e">↓</annotation></semantics></math>) with both close-source and open-source LVLMs. OpenQA refers to open-ended question answering, while MCQA refers to multiple-choice question answering.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 VIII：使用 ASR ( <math id="S6.T8.2.m1.1" display="inline" class="ltx_Math" alttext="\downarrow"><semantics id="S6.T8.2.m1.1b"><mo stretchy="false" id="S6.T8.2.m1.1.1">↓</mo><annotation-xml id="S6.T8.2.m1.1c" encoding="MathML-Content"></annotation-xml><annotation id="S6.T8.2.m1.1d" encoding="application/x-tex">\downarrow</annotation><annotation id="S6.T8.2.m1.1e" encoding="application/x-llamapun">↓</annotation></semantics></math> ) 在 SIUO 上对闭源和开源视觉语言模型进行评估。OpenQA 指开放式问答，而 MCQA 指多项选择题问答。</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T8.6" style="width:390.3pt;height:518.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(86.7pt,-115.1pt) scale(1.79944521775056,1.79944521775056) ;">
<table class="ltx_tabular ltx_align_middle" id="S6.T8.6.1">
<tbody><tr class="ltx_tr" id="S6.T8.6.1.1" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S6.T8.6.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span><span class="ltx_text" id="S6.T8.6.1.1.1.1" style="font-size:90%;background-color:#D8D6C4;">
<span class="ltx_text ltx_font_bold" id="S6.T8.6.1.1.1.1.1">Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">模型</font></font></font></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T8.6.1.1.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T8.6.1.1.2.1" style="font-size:90%;background-color:#D8D6C4;">Size<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大小</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.6.1.1.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T8.6.1.1.3.1" style="font-size:90%;background-color:#D8D6C4;">OpenQA<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">开放式问答</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.6.1.1.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T8.6.1.1.4.1" style="font-size:90%;background-color:#D8D6C4;">MCQA</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.2">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="2" id="S6.T8.6.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.T8.6.1.2.1.1" style="font-size:90%;">Close-Source LVLMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">闭源视觉语言模型</font></font></font></span></td>
<td class="ltx_td ltx_border_tt" id="S6.T8.6.1.2.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_tt" id="S6.T8.6.1.2.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.3" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr ltx_border_t" id="S6.T8.6.1.3.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.3.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">GPT-4V(ision)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T8.6.1.3.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.3.2.1" style="font-size:90%;background-color:#F5F5F0;">-</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.6.1.3.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T8.6.1.3.3.1" style="font-size:90%;background-color:#F5F5F0;">46.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.6.1.3.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.3.4.1" style="font-size:90%;background-color:#F5F5F0;">61.08</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.4">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.4.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.4.1.1" style="font-size:90%;" data-imt_insert_failed="1">GPT-4o</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.4.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.4.2.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.4.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.4.3.1" style="font-size:90%;">49.10</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.4.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.4.4.1" style="font-size:90%;">58.68</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.5" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.5.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.5.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">Gemini 1.5 Pro</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.5.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.5.2.1" style="font-size:90%;background-color:#F5F5F0;">-</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.5.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.5.3.1" style="font-size:90%;background-color:#F5F5F0;">47.90</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.5.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.5.4.1" style="font-size:90%;background-color:#F5F5F0;">52.69</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.6">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.6.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.6.1.1" style="font-size:90%;" data-imt_insert_failed="1">Gemini 1.0 Pro</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.6.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.6.2.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.6.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.6.3.1" style="font-size:90%;">72.46</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.6.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.6.4.1" style="font-size:90%;">65.87</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.7">
<td class="ltx_td ltx_align_left ltx_border_tt" colspan="2" id="S6.T8.6.1.7.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S6.T8.6.1.7.1.1" style="font-size:90%;">Open-Source LVLMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">开源视觉语言模型</font></font></font></span></td>
<td class="ltx_td ltx_border_tt" id="S6.T8.6.1.7.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_tt" id="S6.T8.6.1.7.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.8" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr ltx_border_t" id="S6.T8.6.1.8.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.8.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">Qwen-VL-7B-Chat</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T8.6.1.8.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.8.2.1" style="font-size:90%;background-color:#F5F5F0;">9.6B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.6.1.8.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.8.3.1" style="font-size:90%;background-color:#F5F5F0;">58.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.6.1.8.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.8.4.1" style="font-size:90%;background-color:#F5F5F0;">79.04</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.9">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.9.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.9.1.1" style="font-size:90%;" data-imt_insert_failed="1">MiniGPT4-v2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.9.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.9.2.1" style="font-size:90%;">8B</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.9.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T8.6.1.9.3.1" style="font-size:90%;">58.08</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.9.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.9.4.1" style="font-size:90%;">72.46</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.10" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.10.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.10.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVA-1.6-34B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.10.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.10.2.1" style="font-size:90%;background-color:#F5F5F0;">34B</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.10.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.10.3.1" style="font-size:90%;background-color:#F5F5F0;">59.28</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.10.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.10.4.1" style="font-size:90%;background-color:#F5F5F0;">47.31</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.11">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.11.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.11.1.1" style="font-size:90%;" data-imt_insert_failed="1">LLaVA-1.5-13B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.11.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.11.2.1" style="font-size:90%;">13.4B</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.11.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.11.3.1" style="font-size:90%;">77.84</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.11.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.11.4.1" style="font-size:90%;">67.07</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.12" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.12.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.12.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">LLaVA-1.5-7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.12.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.12.2.1" style="font-size:90%;background-color:#F5F5F0;">7.2B</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.12.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.12.3.1" style="font-size:90%;background-color:#F5F5F0;">78.44</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.12.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.12.4.1" style="font-size:90%;background-color:#F5F5F0;">66.47</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.13">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.13.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.13.1.1" style="font-size:90%;" data-imt_insert_failed="1">CogVLM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.13.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.13.2.1" style="font-size:90%;">17B</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.13.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.13.3.1" style="font-size:90%;">77.25</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.13.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.13.4.1" style="font-size:90%;">72.46</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.14" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T8.6.1.14.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.14.1.1" style="font-size:90%;background-color:#F5F5F0;" data-imt_insert_failed="1">mPLUG-OWL2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T8.6.1.14.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.14.2.1" style="font-size:90%;background-color:#F5F5F0;">8.2B</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.14.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.14.3.1" style="font-size:90%;background-color:#F5F5F0;">77.84</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.6.1.14.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.14.4.1" style="font-size:90%;background-color:#F5F5F0;">71.86</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.15" style="background-color:#E5E4DA;">
<td class="ltx_td ltx_align_right ltx_border_rr ltx_border_tt" id="S6.T8.6.1.15.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T8.6.1.15.1.1" style="font-size:90%;background-color:#E5E4DA;" data-imt_insert_failed="1">Janus-Pro-7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S6.T8.6.1.15.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.15.2.1" style="font-size:90%;background-color:#E5E4DA;">7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T8.6.1.15.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.15.3.1" style="font-size:90%;background-color:#E5E4DA;">84.43</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T8.6.1.15.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T8.6.1.15.4.1" style="font-size:90%;background-color:#E5E4DA;">73.06</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.6.1.16">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S6.T8.6.1.16.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_t" id="S6.T8.6.1.16.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T8.6.1.16.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T8.6.1.16.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T9">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE IX: </span>Evaluation on MM-SafetyBench using ASR (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S6.T9.2.m1.1"><semantics id="S6.T9.2.m1.1b"><mo id="S6.T9.2.m1.1.1" stretchy="false" xref="S6.T9.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T9.2.m1.1c"><ci id="S6.T9.2.m1.1.1.cmml" xref="S6.T9.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T9.2.m1.1d">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S6.T9.2.m1.1e">↓</annotation></semantics></math>) for LLaVA-1.5-7B, LLaVA-1.5-13B, and Janus-Pro-7B, highlighting the <span class="ltx_text ltx_font_bold" id="S6.T9.10.1">best</span> and <span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.11.2">second-best</span> performances.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 IX：在 MM-SafetyBench 上使用 ASR ( <math id="S6.T9.2.m1.1" display="inline" class="ltx_Math" alttext="\downarrow"><semantics id="S6.T9.2.m1.1b"><mo stretchy="false" id="S6.T9.2.m1.1.1">↓</mo><annotation-xml id="S6.T9.2.m1.1c" encoding="MathML-Content"></annotation-xml><annotation id="S6.T9.2.m1.1d" encoding="application/x-tex">\downarrow</annotation><annotation id="S6.T9.2.m1.1e" encoding="application/x-llamapun">↓</annotation></semantics></math> ) 对 LLaVA-1.5-7B、LLaVA-1.5-13B 和 Janus-Pro-7B 的评估，突出最佳和次佳表现。</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T9.12" style="width:867.2pt;height:466.4pt;vertical-align:-1.4pt;"><span class="ltx_transformed_inner" style="transform:translate(126.5pt,-67.8pt) scale(1.41166493406742,1.41166493406742) ;">
<table class="ltx_tabular ltx_align_middle" id="S6.T9.12.1">
<tbody><tr class="ltx_tr" id="S6.T9.12.1.1" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S6.T9.12.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S6.T9.12.1.1.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.1.2.1" style="font-size:90%;">SD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S6.T9.12.1.1.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.1.3.1" style="font-size:90%;">TYPO</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S6.T9.12.1.1.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.1.4.1" style="font-size:90%;" data-imt_insert_failed="1">SD + TYPO</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.2" style="background-color:#D8D6C4;">
<td class="ltx_td ltx_align_center ltx_border_rr" id="S6.T9.12.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.1.1" style="font-size:90%;background-color:#D8D6C4;">Scenarios<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">场景</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.2.2" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.2.1"></span><span class="ltx_text" id="S6.T9.12.1.2.2.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.2.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.2.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.2.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.2.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.2.2.1.1.1.1.1" data-imt_insert_failed="1">LLaVA</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.2.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.2.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">7B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.2.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.2.3" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.3.1"></span><span class="ltx_text" id="S6.T9.12.1.2.3.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.3.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.3.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.3.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.3.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.3.2.1.1.1.1.1" data-imt_insert_failed="1">LLaVA</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.3.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.3.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">13B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.3.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.2.4" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.4.1"></span><span class="ltx_text" id="S6.T9.12.1.2.4.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.4.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.4.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.4.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.4.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.4.2.1.1.1.1.1" data-imt_insert_failed="1">Janus-Pro</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.4.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.4.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">7B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.4.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.2.5" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.5.1"></span><span class="ltx_text" id="S6.T9.12.1.2.5.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.5.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.5.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.5.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.5.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.5.2.1.1.1.1.1" data-imt_insert_failed="1">LLaVA</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.5.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.5.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">7B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.5.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.2.6" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.6.1"></span><span class="ltx_text" id="S6.T9.12.1.2.6.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.6.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.6.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.6.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.6.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.6.2.1.1.1.1.1" data-imt_insert_failed="1">LLaVA</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.6.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.6.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">13B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.6.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.2.7" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.7.1"></span><span class="ltx_text" id="S6.T9.12.1.2.7.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.7.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.7.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.7.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.7.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.7.2.1.1.1.1.1" data-imt_insert_failed="1">Janus-Pro</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.7.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.7.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">7B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.7.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.2.8" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.8.1"></span><span class="ltx_text" id="S6.T9.12.1.2.8.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.8.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.8.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.8.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.8.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.8.2.1.1.1.1.1" data-imt_insert_failed="1">LLaVA</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.8.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.8.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">7B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.8.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.2.9" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.9.1"></span><span class="ltx_text" id="S6.T9.12.1.2.9.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.9.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.9.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.9.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.9.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.9.2.1.1.1.1.1" data-imt_insert_failed="1">LLaVA</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.9.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.9.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">13B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.9.2.2"></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.2.10" style="padding-top:0.9pt;padding-bottom:0.9pt;">
<span class="ltx_text" id="S6.T9.12.1.2.10.1"></span><span class="ltx_text" id="S6.T9.12.1.2.10.2" style="font-size:90%;background-color:#D8D6C4;"> <span class="ltx_text" id="S6.T9.12.1.2.10.2.1">
<span class="ltx_tabular ltx_align_middle" id="S6.T9.12.1.2.10.2.1.1">
<span class="ltx_tr" id="S6.T9.12.1.2.10.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.10.2.1.1.1.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.2.10.2.1.1.1.1.1" data-imt_insert_failed="1">Janus-Pro</span></span></span>
<span class="ltx_tr" id="S6.T9.12.1.2.10.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S6.T9.12.1.2.10.2.1.1.2.1" style="padding-top:0.9pt;padding-bottom:0.9pt;" data-imt_insert_failed="1">7B</span></span>
</span></span><span class="ltx_text" id="S6.T9.12.1.2.10.2.2"></span></span>
</td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.3">
<td class="ltx_td ltx_align_right ltx_border_rr ltx_border_tt" id="S6.T9.12.1.3.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.3.1.1" style="font-size:90%;">01-Illegal Activity<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">01-非法活动</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.3.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.3.2.1" style="font-size:90%;">22.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.3.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.3.3.1" style="font-size:90%;">25.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S6.T9.12.1.3.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.3.4.1" style="font-size:90%;">36.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.3.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.3.5.1" style="font-size:90%;">79.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.3.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.3.6.1" style="font-size:90%;">81.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S6.T9.12.1.3.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.3.7.1" style="font-size:90%;">97.93</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.3.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.3.8.1" style="font-size:90%;">77.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.3.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.3.9.1" style="font-size:90%;">80.41</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.3.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.3.10.1" style="font-size:90%;">92.78</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.4" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.4.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.4.1.1" style="font-size:90%;background-color:#F5F5F0;">02-Hate Speech<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">02-仇恨言论</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.4.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.4.2.1" style="font-size:90%;background-color:#F5F5F0;">16.56</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.4.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.4.3.1" style="font-size:90%;background-color:#F5F5F0;">14.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.4.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.4.4.1" style="font-size:90%;background-color:#F5F5F0;">17.17</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.4.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.4.5.1" style="font-size:90%;background-color:#F5F5F0;">39.88</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.4.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.4.6.1" style="font-size:90%;background-color:#F5F5F0;">47.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.4.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.4.7.1" style="font-size:90%;background-color:#F5F5F0;">67.48</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.4.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.4.8.1" style="font-size:90%;background-color:#F5F5F0;">47.85</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.4.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.4.9.1" style="font-size:90%;background-color:#F5F5F0;">44.79</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.4.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.4.10.1" style="font-size:90%;background-color:#F5F5F0;">61.96</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.5">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.5.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.5.1.1" style="font-size:90%;">03-Malware Generation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">03-恶意软件生成</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.5.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.5.2.1" style="font-size:90%;">20.45</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.5.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.5.3.1" style="font-size:90%;">11.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.5.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.5.4.1" style="font-size:90%;">25.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.5.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.5.5.1" style="font-size:90%;">65.91</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.5.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.5.6.1" style="font-size:90%;">59.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.5.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.5.7.1" style="font-size:90%;">77.27</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.5.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.5.8.1" style="font-size:90%;">70.45</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.5.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.5.9.1" style="font-size:90%;">68.18</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.5.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.5.10.1" style="font-size:90%;">84.09</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.6" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.6.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.6.1.1" style="font-size:90%;background-color:#F5F5F0;">04-Physical Harm<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">04-物理伤害</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.6.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.6.2.1" style="font-size:90%;background-color:#F5F5F0;">20.14</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.6.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.6.3.1" style="font-size:90%;background-color:#F5F5F0;">22.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.6.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.6.4.1" style="font-size:90%;background-color:#F5F5F0;">23.61</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.6.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.6.5.1" style="font-size:90%;background-color:#F5F5F0;">60.42</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.6.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.6.6.1" style="font-size:90%;background-color:#F5F5F0;">59.72</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.6.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.6.7.1" style="font-size:90%;background-color:#F5F5F0;">72.91</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.6.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.6.8.1" style="font-size:90%;background-color:#F5F5F0;">62.50</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.6.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.6.9.1" style="font-size:90%;background-color:#F5F5F0;">63.19</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.6.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.6.10.1" style="font-size:90%;background-color:#F5F5F0;">78.47</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.7">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.7.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.7.1.1" style="font-size:90%;">05-Economic Harm<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">05-经济伤害</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.7.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.7.2.1" style="font-size:90%;">4.10</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.7.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.7.3.1" style="font-size:90%;">4.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.7.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.7.4.1" style="font-size:90%;">10.65</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.7.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.7.5.1" style="font-size:90%;">14.75</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.7.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.7.6.1" style="font-size:90%;">16.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.7.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.7.7.1" style="font-size:90%;">30.32</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.7.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.7.8.1" style="font-size:90%;">15.57</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.7.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.7.9.1" style="font-size:90%;">13.93</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.7.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.7.10.1" style="font-size:90%;">30.32</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.8" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.8.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.8.1.1" style="font-size:90%;background-color:#F5F5F0;">06-Fraud<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">06-欺诈</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.8.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.8.2.1" style="font-size:90%;background-color:#F5F5F0;">20.13</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.8.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.8.3.1" style="font-size:90%;background-color:#F5F5F0;">20.13</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.8.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.8.4.1" style="font-size:90%;background-color:#F5F5F0;">27.27</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.8.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.8.5.1" style="font-size:90%;background-color:#F5F5F0;">72.73</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.8.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.8.6.1" style="font-size:90%;background-color:#F5F5F0;">75.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.8.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.8.7.1" style="font-size:90%;background-color:#F5F5F0;">77.92</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.8.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.8.8.1" style="font-size:90%;background-color:#F5F5F0;">66.88</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.8.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.8.9.1" style="font-size:90%;background-color:#F5F5F0;">74.03</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.8.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.8.10.1" style="font-size:90%;background-color:#F5F5F0;">74.67</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.9">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.9.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.9.1.1" style="font-size:90%;">07-Sex<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">07-性</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.9.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.9.2.1" style="font-size:90%;">11.93</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.9.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.9.3.1" style="font-size:90%;">13.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.9.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.9.4.1" style="font-size:90%;">6.42</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.9.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.9.5.1" style="font-size:90%;">53.21</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.9.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.9.6.1" style="font-size:90%;">49.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.9.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.9.7.1" style="font-size:90%;">50.45</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.9.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.9.8.1" style="font-size:90%;">53.21</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.9.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.9.9.1" style="font-size:90%;">46.79</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.9.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.9.10.1" style="font-size:90%;">33.02</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.10" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.10.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.10.1.1" style="font-size:90%;background-color:#F5F5F0;">08-Political Lobbying<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">08-政治游说</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.10.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.10.2.1" style="font-size:90%;background-color:#F5F5F0;">73.86</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.10.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.10.3.1" style="font-size:90%;background-color:#F5F5F0;">69.93</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.10.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.10.4.1" style="font-size:90%;background-color:#F5F5F0;">49.01</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.10.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.10.5.1" style="font-size:90%;background-color:#F5F5F0;">94.77</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.10.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.10.6.1" style="font-size:90%;background-color:#F5F5F0;">94.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.10.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.10.7.1" style="font-size:90%;background-color:#F5F5F0;">80.66</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.10.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.10.8.1" style="font-size:90%;background-color:#F5F5F0;">96.73</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.10.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.10.9.1" style="font-size:90%;background-color:#F5F5F0;">96.08</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.10.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.10.10.1" style="font-size:90%;background-color:#F5F5F0;">94.77</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.11">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.11.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.11.1.1" style="font-size:90%;">09-Privacy Violence<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">09-隐私暴力</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.11.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.11.2.1" style="font-size:90%;">12.95</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.11.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.11.3.1" style="font-size:90%;">17.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.11.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.11.4.1" style="font-size:90%;">25.89</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.11.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.11.5.1" style="font-size:90%;">55.40</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.11.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.11.6.1" style="font-size:90%;">59.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.11.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.11.7.1" style="font-size:90%;">85.61</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.11.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.11.8.1" style="font-size:90%;">51.08</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.11.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.11.9.1" style="font-size:90%;">64.75</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.11.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.11.10.1" style="font-size:90%;">86.33</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.12" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.12.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.12.1.1" style="font-size:90%;background-color:#F5F5F0;">10-Legal Opinion<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">10-法律意见</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.12.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.12.2.1" style="font-size:90%;background-color:#F5F5F0;">92.31</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.12.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.12.3.1" style="font-size:90%;background-color:#F5F5F0;">93.85</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.12.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.12.4.1" style="font-size:90%;background-color:#F5F5F0;">78.46</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.12.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.12.5.1" style="font-size:90%;background-color:#F5F5F0;">94.62</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.12.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.12.6.1" style="font-size:90%;background-color:#F5F5F0;">95.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.12.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.12.7.1" style="font-size:90%;background-color:#F5F5F0;">78.46</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.12.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.12.8.1" style="font-size:90%;background-color:#F5F5F0;">96.92</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.12.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.12.9.1" style="font-size:90%;background-color:#F5F5F0;">96.92</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.12.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.12.10.1" style="font-size:90%;background-color:#F5F5F0;">96.15</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.13">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.13.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.13.1.1" style="font-size:90%;">11-Financial Advice<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">11-财务建议</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.13.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.13.2.1" style="font-size:90%;">97.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.13.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.13.3.1" style="font-size:90%;">98.80</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.13.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.13.4.1" style="font-size:90%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.13.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.13.5.1" style="font-size:90%;">99.40</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.13.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.13.6.1" style="font-size:90%;">99.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.13.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.13.7.1" style="font-size:90%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.13.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.13.8.1" style="font-size:90%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.13.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.13.9.1" style="font-size:90%;">98.80</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.13.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.13.10.1" style="font-size:90%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.14" style="background-color:#F5F5F0;">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.14.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.14.1.1" style="font-size:90%;background-color:#F5F5F0;">12-Health Consultation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">12-健康咨询</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.14.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.14.2.1" style="font-size:90%;background-color:#F5F5F0;">99.08</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.14.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.14.3.1" style="font-size:90%;background-color:#F5F5F0;">99.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.14.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.14.4.1" style="font-size:90%;background-color:#F5F5F0;">91.74</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.14.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.14.5.1" style="font-size:90%;background-color:#F5F5F0;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.14.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.14.6.1" style="font-size:90%;background-color:#F5F5F0;">100.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.14.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.14.7.1" style="font-size:90%;background-color:#F5F5F0;">88.99</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.14.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.14.8.1" style="font-size:90%;background-color:#F5F5F0;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.14.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.14.9.1" style="font-size:90%;background-color:#F5F5F0;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.14.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.14.10.1" style="font-size:90%;background-color:#F5F5F0;">99.08</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.15">
<td class="ltx_td ltx_align_right ltx_border_rr" id="S6.T9.12.1.15.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.15.1.1" style="font-size:90%;">13-Gov Decision<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">13-政府决策</font></font></font></span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.15.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.15.2.1" style="font-size:90%;">98.66</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.15.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.15.3.1" style="font-size:90%;">96.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.15.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.15.4.1" style="font-size:90%;">85.90</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.15.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.15.5.1" style="font-size:90%;">99.33</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.15.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.15.6.1" style="font-size:90%;">100.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T9.12.1.15.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.15.7.1" style="font-size:90%;">95.97</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.15.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.15.8.1" style="font-size:90%;">99.33</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.15.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.15.9.1" style="font-size:90%;">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.12.1.15.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.15.10.1" style="font-size:90%;">100.00</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.16" style="background-color:#E5E4DA;">
<td class="ltx_td ltx_align_right ltx_border_rr ltx_border_tt" id="S6.T9.12.1.16.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.16.1.1" style="font-size:90%;background-color:#E5E4DA;">Average<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">平均</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.16.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.16.2.1" style="font-size:90%;background-color:#E5E4DA;">45.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.16.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.16.3.1" style="font-size:90%;background-color:#E5E4DA;">45.16</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S6.T9.12.1.16.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.16.4.1" style="font-size:90%;background-color:#E5E4DA;">46.07</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.16.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.16.5.1" style="font-size:90%;background-color:#E5E4DA;">71.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.16.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.16.6.1" style="font-size:90%;background-color:#E5E4DA;">72.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S6.T9.12.1.16.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.16.7.1" style="font-size:90%;background-color:#E5E4DA;">78.09</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.16.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_font_bold" id="S6.T9.12.1.16.8.1" style="font-size:90%;background-color:#E5E4DA;">72.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.16.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text ltx_framed ltx_framed_underline" id="S6.T9.12.1.16.9.1" style="font-size:90%;background-color:#E5E4DA;">72.91</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.12.1.16.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_text" id="S6.T9.12.1.16.10.1" style="font-size:90%;background-color:#E5E4DA;">79.94</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.12.1.17">
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" id="S6.T9.12.1.17.1" style="padding-top:0.9pt;padding-bottom:0.9pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">&nbsp;</span></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.2" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.3" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.4" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.5" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.6" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.7" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.8" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.9" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
<td class="ltx_td ltx_border_t" id="S6.T9.12.1.17.10" style="padding-top:0.9pt;padding-bottom:0.9pt;"></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span><span class="ltx_text ltx_font_italic" id="S6.SS1.1.1">Details of Janus-Pro</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6.1 Janus-Pro 的详细信息</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Janus-Pro-7B&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib169" title="">169</a>]</cite> is the latest LVLM released by DeepSeek, representing a significant advancement over Janus-1B. This new model scales up both the data and model parameters, validating the potential of the original design. DeepSeek’s Janus-Pro integrates unified multimodal understanding and generation capabilities, addressing the longstanding gap between image understanding (as seen in GPT-4o&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib16" title="">16</a>]</cite>) and image generation (such as with Stable Diffusion). While earlier approaches typically relied on separate models for image understanding and generation, Janus-Pro aims to bridge this divide using a single model for both tasks. One of the challenges in combining understanding and generation lies in the different encoder architectures typically used for image encoding in understanding and generation tasks. Janus-Pro tackles this by employing separate encoders for image processing, but integrates them into a unified latent space, where both text-to-image and image-to-text tasks are handled through an autoregressive framework similar to LLMs. After validating the feasibility of this approach, Janus-Pro revealed significant gaps in generation performance when compared to diffusion-based models such as Stable Diffusion, which is a known challenge for autoregressive models in image generation. Janus-Pro improves upon this by scaling the model and data, and introducing an optimized training strategy. As a result, Janus-Pro has achieved state-of-the-art performance in multimodal understanding tasks and has surpassed diffusion models such as DALL-E 3 in terms of text-to-image generation capabilities.
<span class="ltx_text ltx_font_italic" id="S6.SS1.p1.1.1">However, given its strong multimodel understanding performance, how about Janus-Pro’s safety capability?</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Janus-Pro-7B [ 169] 是 DeepSeek 发布的最新大型视觉语言模型（LVLM），相较于 Janus-1B 有显著进步。该新模型在数据和模型参数规模上均有所提升，验证了原始设计的潜力。DeepSeek 的 Janus-Pro 集成了统一的多模态理解和生成能力，解决了长期以来图像理解（如 GPT-4o [ 16] 所示）与图像生成（如 Stable Diffusion）之间的差距。虽然早期方法通常依赖独立的模型进行图像理解和生成，但 Janus-Pro 旨在通过单一模型同时完成这两个任务来弥合这一鸿沟。将理解和生成结合起来的一个挑战在于，理解和生成任务中通常使用不同的编码器架构进行图像编码。Janus-Pro 通过采用独立的图像处理编码器，但将它们集成到一个统一的潜在空间中，在这个空间里，文本到图像和图像到文本任务都通过类似于 LLMs 的自回归框架进行处理。 在验证了该方法的可行性后，Janus-Pro 在与 Stable Diffusion 等基于扩散的模型相比时，在生成性能上暴露出显著差距，这是自回归模型在图像生成中已知的一个挑战。Janus-Pro 通过扩展模型和数据，并引入优化的训练策略来改进这一点。因此，Janus-Pro 在多模态理解任务中取得了最先进的性能，并在文本到图像生成能力方面超越了 DALL-E 3 等扩散模型。然而，鉴于其强大的多模态理解性能，Janus-Pro 的安全能力如何呢？</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span><span class="ltx_text ltx_font_italic" id="S6.SS2.1.1">Experiments</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6.2 实验</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S6.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.1 </span>Benchmarks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6.2.1 基准测试</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS2.SSS1.p1">
<p class="ltx_p" id="S6.SS2.SSS1.p1.1">We conduct a set of safety evaluations on Janus-Pro, utilizing two open-source benchmarks: SIUO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib168" title="">168</a>]</cite> and MM-SafetyBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib53" title="">53</a>]</cite>.
For assessing Cross-Modality Alignment, we used the SIUO dataset, which is developed to evaluate the integration, knowledge, and reasoning capabilities of LVLMs. SIUO consists of 167 samples spanning 9 critical safety domains, including self-harm, illegal activities, and privacy violations. In SIUO, both textual and visual inputs are individually safe, but their combination results in unsafe outputs, posing a challenge to cross-modal reasoning.
MM-SafetyBench is then used to evaluate Janus-Pro’s defense capabilities under Multi-Model Attacks. This benchmark consists of 5,040 examples across 13 common scenarios involving malicious intent. The benchmark includes three distinct subcategories: (1) SD: Images generated by Stable Diffusion (SD) conditioned on malicious keywords, (2) OCR: Images containing malicious keywords extracted through Optical Character Recognition (OCR), and (3) SD + OCR: Images generated by SD and then subtitled with OCR.
The experiments are conducted on NVIDIA GeForce 4090 GPUs, using the GPT-4o-2024-05-13 API for evaluation. Additionally, temperature is set to 0 to ensure deterministic evaluation results, and manual review is conducted on the evaluation results to ensure accuracy.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们对 Janus-Pro 进行了一系列安全性评估，使用了两个开源基准：SIUO[168]和 MM-SafetyBench[53]。为了评估跨模态对齐能力，我们使用了 SIUO 数据集，该数据集旨在评估大型视觉语言模型（LVLMs）的整合、知识和推理能力。SIUO 包含 167 个样本，涵盖 9 个关键安全领域，包括自残、非法活动和隐私侵犯。在 SIUO 中，文本和视觉输入单独都是安全的，但它们的组合会产生不安全的输出，这对跨模态推理提出了挑战。MM-SafetyBench 用于评估 Janus-Pro 在多模型攻击下的防御能力。该基准包含 5,040 个涉及恶意意图的 13 种常见场景的示例。该基准分为三个不同的子类别：（1）SD：由 Stable Diffusion（SD）根据恶意关键词生成的图像，（2）OCR：通过光学字符识别（OCR）提取包含恶意关键词的图像，（3）SD + OCR：由 SD 生成后用 OCR 添加字幕的图像。实验在 NVIDIA GeForce 4090 GPU 上进行，使用 GPT-4o-2024-05-13 API 进行评估。 此外，温度设置为 0 以确保确定性评估结果，并对评估结果进行人工审核以确保准确性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S6.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">6.2.2 </span>Results Analyse<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6.2.2 结果分析</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS2.p1">
<p class="ltx_p" id="S6.SS2.SSS2.p1.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS2.SSS2.p1.1.m1.1"><semantics id="S6.SS2.SSS2.p1.1.m1.1a"><mo id="S6.SS2.SSS2.p1.1.m1.1.1" xref="S6.SS2.SSS2.p1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p1.1.m1.1b"><ci id="S6.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p1.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS2.p1.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S6.SS2.SSS2.p1.1.1">Results on SIUO.</span>
From the results presented in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S6.T8" title="In 6 Safety Evaluation on Janus-Pro ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Tab.</span>&nbsp;<span class="ltx_text ltx_ref_tag">VIII</span></a>, it is evident that Janus-Pro-7B exhibits suboptimal performance in OpenQA tasks. Its performance significantly lags behind that of LLaVA-1.5-7B, a model of comparable scale, with Janus-Pro achieving a ASR of 84.43%, whereas LLaVA-1.5-7B performs at 78.44%. This underperformance in open-ended question answering may be attributed to several factors, including potential limitations in Janus-Pro’s architecture, which may not yet be fully optimized for complex, open-ended reasoning tasks. Additionally, it is possible that the model’s fine-tuning for open-ended question answering is still in development, leading to less robust responses in comparison to models like Qwen-VL-7B-Chat&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib65" title="">65</a>]</cite> and MiniGPT4-v2&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib170" title="">170</a>]</cite>
, which show ASR of 58.68% and 58.08% respectively, demonstrated more refined capabilities in this cross-modality alignment.
Conversely, Janus-Pro-7B performs considerably better in MCQA (Multiple Choice Question Answering) tasks, where its ASR of 73.06% is competitive with most other models, such as Qwen-VL-7B-Chat (79.04%) and MiniGPT4-v2 (72.46%). This improvement in performance suggests that Janus-Pro is better suited to structured response tasks, where the model’s predictive capabilities in selecting the most appropriate answer from predefined options are more effectively utilized. This ability to handle fixed-response tasks could enhance Janus-Pro’s safety capabilities, as it is less prone to generating unsafe outputs in well-defined, closed-question settings. The model’s autoregressive framework, which excels in generating coherent responses within such structured contexts, contributes to this improved safety performance.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S6.SS2.SSS2.p1.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S6.SS2.SSS2.p1.1.m1.1a"><mo id="S6.SS2.SSS2.p1.1.m1.1.1">∙</mo><annotation-xml id="S6.SS2.SSS2.p1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S6.SS2.SSS2.p1.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S6.SS2.SSS2.p1.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> SIUO 上的结果。从表 VIII 中的结果可以看出，Janus-Pro-7B 在 OpenQA 任务中的表现并不理想。其性能明显落后于规模相当的 LLaVA-1.5-7B 模型，Janus-Pro 达到了 84.43%的 ASR，而 LLaVA-1.5-7B 的表现为 78.44%。这种在开放式问答中的表现不佳可能归因于多个因素，包括 Janus-Pro 架构的潜在局限性，该架构可能尚未完全优化以应对复杂的开放式推理任务。此外，模型在开放式问答方面的微调可能仍在开发中，导致其响应的鲁棒性不如 Qwen-VL-7B-Chat [ 65] 和 MiniGPT4-v2 [ 170] 等模型，后者分别表现出 58.68%和 58.08%的 ASR，并在跨模态对齐方面展现出更精细的能力。 相反地，Janus-Pro-7B 在多项选择题回答（MCQA）任务中表现显著更优，其 73.06%的 ASR（自动语音识别）成绩与大多数其他模型（如 Qwen-VL-7B-Chat 的 79.04%和 MiniGPT4-v2 的 72.46%）相比具有竞争力。这一性能提升表明 Janus-Pro 更适合结构化回答任务，在这种任务中，模型从预定义选项中选择最合适答案的预测能力能被更有效地利用。这种处理固定回答任务的能力可能增强 Janus-Pro 的安全性，因为它在定义明确、封闭式问题的设置中不太容易生成不安全的输出。该模型的自动回归框架在生成此类结构化环境中的连贯回答方面表现出色，这有助于提升其安全性表现。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS2.p2">
<p class="ltx_p" id="S6.SS2.SSS2.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS2.SSS2.p2.1.m1.1"><semantics id="S6.SS2.SSS2.p2.1.m1.1a"><mo id="S6.SS2.SSS2.p2.1.m1.1.1" xref="S6.SS2.SSS2.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p2.1.m1.1b"><ci id="S6.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS2.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S6.SS2.SSS2.p2.1.1">Result on MM-SafetyBench.</span>
Turning to the results in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#S6.T9" title="In 6 Safety Evaluation on Janus-Pro ‣ A Survey of Safety on Large Vision-Language Models: Attacks, Defenses and Evaluations"><span class="ltx_text ltx_ref_tag">Tab.</span>&nbsp;<span class="ltx_text ltx_ref_tag">IX</span></a>, which evaluates Janus-Pro’s performance on MM-SafetyBench, a similar pattern of performance discrepancies emerges. In the first half of the table (Scenarios 1-6), which includes safety-critical tasks such as identifying illegal activities, hate speech, and malware generation, Janus-Pro consistently underperforms relative to the LLaVA series models. For example, in the Illegal Activity scenario, Janus-Pro achieves an ASR of 36.08% compared to LLaVA-1.5-7B’s 25.77%. This observation suggests that Janus-Pro may be less adept at addressing safety-sensitive tasks, particularly those involving illegal activities or violence, possibly due to differences in its model architecture or training methodology. We speculate that Janus-Pro’s design of a unified latent space for both text and image generation may struggle to effectively capture and mitigate patterns in scenarios that require highly specialized safety mechanisms. Its encoder architecture, designed to process visual and textual inputs in parallel, might not be sufficiently fine-tuned for the nuanced detection of harmful or malicious content, especially in cases involving high-risk scenarios.
In contrast, Janus-Pro demonstrates notable improvement in the second half of the table (Scenarios 7-13), which includes tasks such as political lobbying, privacy violations, and government decision-making. The enhanced performance in these scenarios suggests that Janus-Pro may be more safety when dealing with context-specific tasks that require multimodal reasoning, where the model can leverage its integrated understanding of both textual and visual inputs. The structured nature of these scenarios may align more closely with Janus-Pro’s autoregressive framework, which excels in tasks requiring coherent output generation based on contextual input. This improvement could also be due to the model’s stronger training on data that includes these types of tasks, or it may reflect an inherent advantage in processing structured tasks where text and images contribute complementary information.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S6.SS2.SSS2.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S6.SS2.SSS2.p2.1.m1.1a"><mo id="S6.SS2.SSS2.p2.1.m1.1.1">∙</mo><annotation-xml id="S6.SS2.SSS2.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S6.SS2.SSS2.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S6.SS2.SSS2.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> MM-SafetyBench 上的结果。转向表 IX 中的结果，该表评估了 Janus-Pro 在 MM-SafetyBench 上的性能，出现了类似的性能差异模式。在表格的前半部分（场景 1-6），包括识别非法活动、仇恨言论和恶意软件生成等安全关键任务，Janus-Pro 始终相对于 LLaVA 系列模型表现不佳。例如，在非法活动场景中，Janus-Pro 的 ASR 达到 36.08%，而 LLaVA-1.5-7B 为 25.77%。这一观察表明，Janus-Pro 可能不太擅长处理涉及安全敏感的任务，特别是涉及非法活动或暴力的任务，这可能是由于其模型架构或训练方法的不同。我们推测，Janus-Pro 为文本和图像生成设计了一个统一的潜在空间，可能难以有效地捕捉和缓解需要高度专业化安全机制的场景中的模式。 其编码器架构设计为并行处理视觉和文本输入，可能无法充分针对有害或恶意内容的细微检测进行微调，特别是在涉及高风险场景的情况下。相比之下，Janus-Pro 在表格的第二部分（场景 7-13）中表现出显著改进，这些场景包括政治游说、隐私侵犯和政府决策等任务。在这些场景中的性能提升表明，Janus-Pro 在处理需要多模态推理的特定上下文任务时可能更安全，此时模型能够利用其整合的文本和视觉输入理解。这些场景的结构化性质可能与 Janus-Pro 的自回归框架更为契合，该框架擅长基于上下文输入生成连贯输出的任务。 这种改进也可能归因于模型在包含这些类型任务的训练数据上进行了更强的训练，或者它可能反映了在处理结构化任务时的一种固有优势，在这些任务中，文本和图像提供了互补信息。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS2.p3">
<p class="ltx_p" id="S6.SS2.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S6.SS2.SSS2.p3.1.m1.1"><semantics id="S6.SS2.SSS2.p3.1.m1.1a"><mo id="S6.SS2.SSS2.p3.1.m1.1.1" xref="S6.SS2.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.SSS2.p3.1.m1.1b"><ci id="S6.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S6.SS2.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.SSS2.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS2.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S6.SS2.SSS2.p3.1.1">Conclusion.</span>
While Janus-Pro has achieved impressive multimodal understanding capabilities, its safety performance remains a significant limitation. Across multiple benchmarks, Janus-Pro fails to meet the basic safety standards of most other models. We speculate that this shortcoming may be due to the model architecture, which was designed to simultaneously handle both understanding and generation tasks, potentially at the expense of specialized safety mechanisms. Additionally, it is possible that Janus-Pro did not undergo specific safety-focused training, which may be contributing to its limited ability to recognize and mitigate harmful or adversarial inputs. This could also be related to the capabilities of the chosen LLM architecture used in Janus-Pro.
Given the critical role of safety in deploying multimodal models in real-world applications, it is evident that the safety capabilities of DeepSeek Janus-Pro need substantial improvements. Further refinements in its architecture and training methodology, with a stronger focus on safety and adversarial robustness, are essential for enhancing Janus-Pro’s effectiveness across diverse, high-risk tasks and scenarios.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S6.SS2.SSS2.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S6.SS2.SSS2.p3.1.m1.1a"><mo id="S6.SS2.SSS2.p3.1.m1.1.1">∙</mo><annotation-xml id="S6.SS2.SSS2.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S6.SS2.SSS2.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S6.SS2.SSS2.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 结论。尽管 Janus-Pro 在多模态理解能力上取得了令人印象深刻的成果，但其安全性表现仍然是一个显著的局限。在多个基准测试中，Janus-Pro 未能达到大多数其他模型的基本安全标准。我们推测这一缺陷可能源于模型架构，该架构设计为同时处理理解和生成任务，可能以牺牲专门的安全机制为代价。此外，Janus-Pro 可能没有接受专门针对安全的训练，这可能是其识别和缓解有害或对抗性输入能力有限的原因之一。这也可能与 Janus-Pro 所使用的 LLM 架构的能力有关。鉴于安全性在现实世界应用中部署多模态模型的关键作用，很明显 DeepSeek Janus-Pro 的安全能力需要大幅改进。为了提升 Janus-Pro 在多样化、高风险任务和场景中的有效性，对其架构和训练方法的进一步优化，并更加注重安全性和对抗性鲁棒性，是至关重要的。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Outlook</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7 展望</font></font></font>
</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span><span class="ltx_text ltx_font_italic" id="S7.SS1.1.1">Future Trends</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7.1 未来趋势</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">Based on the reviewed research, we list several future research directions that we believe should be pursued.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于已审阅的研究，我们列出了几个我们认为应该追求的未来研究方向。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p2">
<p class="ltx_p" id="S7.SS1.p2.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.p2.1.m1.1"><semantics id="S7.SS1.p2.1.m1.1a"><mo id="S7.SS1.p2.1.m1.1.1" xref="S7.SS1.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.p2.1.m1.1b"><ci id="S7.SS1.p2.1.m1.1.1.cmml" xref="S7.SS1.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p2.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S7.SS1.p2.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S7.SS1.p2.1.1">The Shift Towards Black-box Attacks.</span>
A key future direction in attack methodologies is the increasing focus on black-box attacks, which offer advantages over traditional white-box approaches. While effective, white-box attacks require extensive prior knowledge of the target model, limiting their applicability and introducing significant computational overhead&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib92" title="">92</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib26" title="">26</a>]</cite>. In contrast, black-box attacks exploit the intrinsic capabilities of LVLMs—such as OCR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib104" title="">104</a>]</cite>, logical reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib105" title="">105</a>]</cite>, associative memory&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib106" title="">106</a>]</cite>, and multimodal integration&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib108" title="">108</a>]</cite>—to target vulnerabilities without direct access to the model’s architecture, enhancing transferability and resource efficiency. However, prompt-based defenses&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib132" title="">132</a>]</cite> often mitigate these attacks, exposing the limitations of current strategies. Future research should focus on developing more advanced black-box attack techniques that can circumvent defenses and demonstrate greater resilience, ensuring their robustness as LVLMs see broader deployment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S7.SS1.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S7.SS1.p2.1.m1.1a"><mo id="S7.SS1.p2.1.m1.1.1">∙</mo><annotation-xml id="S7.SS1.p2.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S7.SS1.p2.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S7.SS1.p2.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 向黑盒攻击的转变。攻击方法的一个关键未来方向是越来越关注黑盒攻击，它们比传统的白盒方法具有优势。虽然有效，但白盒攻击需要大量关于目标模型的先验知识，限制了其适用性并引入了显著的计算开销[ 23, 27, 92, 26]。相比之下，黑盒攻击利用 LVLMs 的内在能力——如 OCR[ 41, 104]、逻辑推理[ 105]、联想记忆[ 106]和多模态集成[ 108]——来针对漏洞，而无需直接访问模型的架构，从而提高了可迁移性和资源效率。然而，基于提示的防御[ 43, 48, 132]通常可以缓解这些攻击，这暴露了当前策略的局限性。未来研究应专注于开发更先进的黑盒攻击技术，使其能够绕过防御并展示更大的韧性，确保它们在 LVLMs 更广泛部署时的鲁棒性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p3">
<p class="ltx_p" id="S7.SS1.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.p3.1.m1.1"><semantics id="S7.SS1.p3.1.m1.1a"><mo id="S7.SS1.p3.1.m1.1.1" xref="S7.SS1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.p3.1.m1.1b"><ci id="S7.SS1.p3.1.m1.1.1.cmml" xref="S7.SS1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p3.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S7.SS1.p3.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S7.SS1.p3.1.1">Enhancing Safety through Cross-Modality Alignment.</span>
Most defense mechanisms focus on detecting harmful inputs, addressing obvious attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib146" title="">146</a>]</cite>, yet LVLMs in real-world applications face subtler threats. For example, individually innocuous image and text inputs can combine to produce unsafe outputs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib168" title="">168</a>, <a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib162" title="">162</a>]</cite>. Visual components often struggle to identify unsafe elements or grasp contextual nuances, and research on aligning safety across visual and textual modalities remains limited&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib29" title="">29</a>]</cite>. Future efforts should focus on bridging the security capabilities of LLMs and vision encoders to address these modality gaps. Ensuring seamless safety integration across modalities is essential to prevent harmful interpretations arising from their combination. Additionally, improving contextual understanding in joint visual-textual processing will be crucial for enhancing the robustness and reliability of LVLMs in dynamic environments.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S7.SS1.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S7.SS1.p3.1.m1.1a"><mo id="S7.SS1.p3.1.m1.1.1">∙</mo><annotation-xml id="S7.SS1.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S7.SS1.p3.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S7.SS1.p3.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 通过跨模态对齐增强安全性。大多数防御机制集中于检测有害输入，应对明显的攻击[49, 146]，然而在实际应用中，LVLMs 面临更隐蔽的威胁。例如，单独无害的图像和文本输入可能组合产生不安全的输出[168, 162]。视觉组件往往难以识别不安全元素或理解上下文细节，而跨视觉和文本模态对齐安全性的研究仍有限[29]。未来工作应着重于提升 LLMs 和视觉编码器的安全能力，以弥补这些模态差距。确保跨模态的无缝安全集成对于防止它们组合产生有害解读至关重要。此外，提升联合视觉-文本处理中的上下文理解能力，对于增强 LVLMs 在动态环境中的鲁棒性和可靠性将至关重要。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p4">
<p class="ltx_p" id="S7.SS1.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.p4.1.m1.1"><semantics id="S7.SS1.p4.1.m1.1a"><mo id="S7.SS1.p4.1.m1.1.1" xref="S7.SS1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.p4.1.m1.1b"><ci id="S7.SS1.p4.1.m1.1.1.cmml" xref="S7.SS1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p4.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S7.SS1.p4.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S7.SS1.p4.1.1">Diversifying Safety Fine-Tuning Techniques.</span>
Balancing the enhancement of safety while maintaining the general capabilities of LVLMs remains a significant challenge. Traditional fine-tuning approaches often risk compromising the model’s overall performance in the pursuit of improved safety measures. To address this dilemma, future research should explore a broader range of safety fine-tuning methodologies, such as Reinforcement Learning from Human Feedback (RLHF)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib171" title="">171</a>]</cite>, adversarial training, and multi-objective optimization. RLHF, in particular, offers a promising direction by enabling models to iteratively learn safety-oriented behaviors from refined feedback, reducing the reliance on static, rule-based constraints. Additionally, techniques like curriculum learning could help models gradually adapt to increasingly complex safety scenarios without sacrificing their ability to generalize across diverse tasks. Hybrid approaches that combine multiple fine-tuning strategies may further enhance safety while preserving or even improving the model’s overall capabilities. These advancements are crucial for developing robust, safety-aware LVLMs that can meet the demands of real-world applications without significant trade-offs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S7.SS1.p4.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S7.SS1.p4.1.m1.1a"><mo id="S7.SS1.p4.1.m1.1.1">∙</mo><annotation-xml id="S7.SS1.p4.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S7.SS1.p4.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S7.SS1.p4.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 丰富安全微调技术。在提升安全性的同时保持 LVLMs 的通用能力仍然是一个重大挑战。传统的微调方法往往在追求改进安全措施的过程中，有损害模型整体性能的风险。为了解决这一困境，未来的研究应探索更广泛的安全微调方法，例如人类反馈强化学习（RLHF）[ 171]、对抗训练和多目标优化。RLHF 尤其提供了一个有前景的方向，它使模型能够通过精细的反馈迭代学习以安全为导向的行为，减少对静态、基于规则的约束的依赖。此外，课程学习等技术可以帮助模型在不牺牲其泛化不同任务能力的情况下，逐步适应日益复杂的安全场景。结合多种微调策略的混合方法可能进一步增强安全性，同时保持或甚至提高模型的整体能力。 这些进步对于开发稳健、注重安全的视觉语言模型至关重要，它们能够在不进行重大权衡的情况下满足实际应用的需求。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p5">
<p class="ltx_p" id="S7.SS1.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S7.SS1.p5.1.m1.1"><semantics id="S7.SS1.p5.1.m1.1a"><mo id="S7.SS1.p5.1.m1.1.1" xref="S7.SS1.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S7.SS1.p5.1.m1.1b"><ci id="S7.SS1.p5.1.m1.1.1.cmml" xref="S7.SS1.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p5.1.m1.1c">\bullet</annotation><annotation encoding="application/x-llamapun" id="S7.SS1.p5.1.m1.1d">∙</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="S7.SS1.p5.1.1">Developing Unified Strategy Benchmarking Frameworks.</span>
The rapid diversification of attack and defense methodologies for LVLMs has led to fragmented experimental environments, obstructing meaningful cross-method comparisons of effectiveness, efficiency, and overall performance. While existing benchmark MMJBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2502.14881v1#bib.bib163" title="">163</a>]</cite>, offers evaluations of various strategies, but it employs a limited set of assessment methods and lack a comprehensive, general framework. To address these shortcomings, future research may prioritize the development of standardized benchmarking frameworks that unify the evaluation of diverse strategies. These benchmarks should encompass a broad range of metrics, including attack success rates, computational resource requirements, response times, and resilience against adaptive defenses. Additionally, incorporating diverse datasets and realistic threat models is essential to ensure evaluations accurately reflect real-world scenarios. The creation of open-source benchmark suites, supported by community contributions, will enhance transparency and reproducibility, enabling researchers to validate and build upon each other’s work more effectively. By implementing comprehensive benchmarking strategies, the research community can systematically assess the strengths and limitations of existing approaches, drive the innovation of more robust and efficient solutions, and ultimately advance the security and reliability of LVLMs in practical applications.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math id="S7.SS1.p5.1.m1.1" display="inline" class="ltx_Math" alttext="\bullet"><semantics id="S7.SS1.p5.1.m1.1a"><mo id="S7.SS1.p5.1.m1.1.1">∙</mo><annotation-xml id="S7.SS1.p5.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S7.SS1.p5.1.m1.1c" encoding="application/x-tex">\bullet</annotation><annotation id="S7.SS1.p5.1.m1.1d" encoding="application/x-llamapun">∙</annotation></semantics></math> 开发统一的策略基准测试框架。LVLMs 的攻击和防御方法的快速多样化导致了实验环境的碎片化，阻碍了在有效性、效率和整体性能方面的跨方法比较。虽然现有的基准 MMJBench [ 163]提供了各种策略的评估，但它采用了一套有限的评估方法，缺乏一个全面、通用的框架。为了解决这些不足，未来的研究应优先考虑开发统一评估多样化策略的标准化基准测试框架。这些基准应涵盖广泛的指标，包括攻击成功率、计算资源需求、响应时间和对自适应防御的弹性。此外，纳入多样化的数据集和现实威胁模型对于确保评估准确反映现实世界场景至关重要。创建由社区贡献支持的开源基准套件将增强透明度和可重复性，使研究人员能够更有效地验证和基于彼此的工作进行构建。 通过实施全面的基准测试策略，研究界可以系统地评估现有方法的优缺点，推动更健壮和高效解决方案的创新，并最终提升 LVLMs 在实际应用中的安全性和可靠性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span><span class="ltx_text ltx_font_italic" id="S7.SS2.1.1">Conclusion</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7.2 结论</font></font></font>
</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">To the best of our knowledge, this is the first survey to offer a comprehensive and systematic review of recent advances in all field of LVLM safety from attacks, defenses, and evaluations, with an analysis of over 100 methods. We present the background of LVLM safety, emphasizing the unique vulnerabilities inherent in these models and introducing fundamental attack classifications. We categorize attack and defense strategies based on the model lifecycle, distinguishing between inference-phase and training-phase methods, and provide detailed sub-classifications with in-depth descriptions of each approach. In the Evaluation section, we synthesize all relevant benchmarks, providing a valuable resource for researchers seeking a comprehensive understanding of the field. Finally, we offer insights into future research directions and highlight open challenges, aiming to encourage further exploration and engagement from the research community in this critical area.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">据我们所知，这是首个全面系统地综述 LVLM 安全领域最新进展的调研，涵盖了攻击、防御和评估三个方面，并分析了超过 100 种方法。我们介绍了 LVLM 安全背景，强调了这些模型固有的独特漏洞，并介绍了基础攻击分类。我们根据模型生命周期对攻击和防御策略进行分类，区分了推理阶段和训练阶段的方法，并为每种方法提供了详细的子分类和深入描述。在评估部分，我们综合了所有相关基准，为寻求全面了解该领域的研究人员提供了宝贵资源。最后，我们探讨了未来研究方向，并强调了开放性挑战，旨在鼓励研究界在这一关键领域进行进一步探索和参与。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.1.1" style="font-size:90%;">
W.&nbsp;X. Zhao, K.&nbsp;Zhou, J.&nbsp;Li, T.&nbsp;Tang, X.&nbsp;Wang, Y.&nbsp;Hou, Y.&nbsp;Min, B.&nbsp;Zhang, J.&nbsp;Zhang, Z.&nbsp;Dong </span><em class="ltx_emph ltx_font_italic" id="bib.bib1.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib1.3.3" style="font-size:90%;">, “A survey of large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib1.4.4" style="font-size:90%;">arXiv preprint arXiv:2303.18223</em><span class="ltx_text" id="bib.bib1.5.5" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.1.1" style="font-size:90%;">
S.&nbsp;Minaee, T.&nbsp;Mikolov, N.&nbsp;Nikzad, M.&nbsp;Chenaghlu, R.&nbsp;Socher, X.&nbsp;Amatriain, and J.&nbsp;Gao, “Large language models: A survey,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib2.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.06196</em><span class="ltx_text" id="bib.bib2.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.1.1" style="font-size:90%;">
T.&nbsp;Brown, B.&nbsp;Mann, N.&nbsp;Ryder, M.&nbsp;Subbiah, J.&nbsp;D. Kaplan, P.&nbsp;Dhariwal, A.&nbsp;Neelakantan, P.&nbsp;Shyam, G.&nbsp;Sastry, A.&nbsp;Askell </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib3.3.3" style="font-size:90%;">, “Language models are few-shot learners,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.4.4" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib3.5.5" style="font-size:90%;">, pp. 1877–1901, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.1.1" style="font-size:90%;">
A.&nbsp;Chowdhery, S.&nbsp;Narang, J.&nbsp;Devlin, M.&nbsp;Bosma, G.&nbsp;Mishra, A.&nbsp;Roberts, P.&nbsp;Barham, H.&nbsp;W. Chung, C.&nbsp;Sutton, S.&nbsp;Gehrmann </span><em class="ltx_emph ltx_font_italic" id="bib.bib4.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib4.3.3" style="font-size:90%;">, “Palm: Scaling language modeling with pathways,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib4.4.4" style="font-size:90%;">JMLR</em><span class="ltx_text" id="bib.bib4.5.5" style="font-size:90%;">, pp. 1–113, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.1.1" style="font-size:90%;">
H.&nbsp;Touvron, T.&nbsp;Lavril, G.&nbsp;Izacard, X.&nbsp;Martinet, M.-A. Lachaux, T.&nbsp;Lacroix, B.&nbsp;Rozière, N.&nbsp;Goyal, E.&nbsp;Hambro, F.&nbsp;Azhar </span><em class="ltx_emph ltx_font_italic" id="bib.bib5.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib5.3.3" style="font-size:90%;">, “Llama: Open and efficient foundation language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib5.4.4" style="font-size:90%;">arXiv preprint arXiv:2302.13971</em><span class="ltx_text" id="bib.bib5.5.5" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.1.1" style="font-size:90%;">
M.&nbsp;Awais, M.&nbsp;Naseer, S.&nbsp;Khan, R.&nbsp;M. Anwer, H.&nbsp;Cholakkal, M.&nbsp;Shah, M.-H. Yang, and F.&nbsp;S. Khan, “Foundation models defining a new era in vision: a survey and outlook,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib6.2.2" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span class="ltx_text" id="bib.bib6.3.3" style="font-size:90%;">, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.1.1" style="font-size:90%;">
P.&nbsp;Kaur, G.&nbsp;S. Kashyap, A.&nbsp;Kumar, M.&nbsp;T. Nafis, S.&nbsp;Kumar, and V.&nbsp;Shokeen, “From text to transformation: A comprehensive review of large language models’ versatility,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib7.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.16142</em><span class="ltx_text" id="bib.bib7.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.1.1" style="font-size:90%;">
Z.&nbsp;Cai, M.&nbsp;Cao, H.&nbsp;Chen, K.&nbsp;Chen, K.&nbsp;Chen, X.&nbsp;Chen, X.&nbsp;Chen, Z.&nbsp;Chen, Z.&nbsp;Chen, P.&nbsp;Chu </span><em class="ltx_emph ltx_font_italic" id="bib.bib8.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib8.3.3" style="font-size:90%;">, “Internlm2 technical report,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib8.4.4" style="font-size:90%;">arXiv preprint arXiv:2403.17297</em><span class="ltx_text" id="bib.bib8.5.5" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.1.1" style="font-size:90%;">
A.&nbsp;Q. Jiang, A.&nbsp;Sablayrolles, A.&nbsp;Roux, A.&nbsp;Mensch, B.&nbsp;Savary, C.&nbsp;Bamford, D.&nbsp;S. Chaplot, D.&nbsp;d.&nbsp;l. Casas, E.&nbsp;B. Hanna, F.&nbsp;Bressand </span><em class="ltx_emph ltx_font_italic" id="bib.bib9.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib9.3.3" style="font-size:90%;">, “Mixtral of experts,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib9.4.4" style="font-size:90%;">arXiv preprint arXiv:2401.04088</em><span class="ltx_text" id="bib.bib9.5.5" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.1.1" style="font-size:90%;">
J.&nbsp;Bai, S.&nbsp;Bai, Y.&nbsp;Chu, Z.&nbsp;Cui, K.&nbsp;Dang, X.&nbsp;Deng, Y.&nbsp;Fan, W.&nbsp;Ge, Y.&nbsp;Han, F.&nbsp;Huang </span><em class="ltx_emph ltx_font_italic" id="bib.bib10.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib10.3.3" style="font-size:90%;">, “Qwen technical report,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib10.4.4" style="font-size:90%;">arXiv preprint arXiv:2309.16609</em><span class="ltx_text" id="bib.bib10.5.5" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.1.1" style="font-size:90%;">
P.&nbsp;Xu, W.&nbsp;Shao, K.&nbsp;Zhang, P.&nbsp;Gao, S.&nbsp;Liu, M.&nbsp;Lei, F.&nbsp;Meng, S.&nbsp;Huang, Y.&nbsp;Qiao, and P.&nbsp;Luo, “Lvlm-ehub: A comprehensive evaluation benchmark for large vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib11.2.2" style="font-size:90%;">IEEE TPAMI</em><span class="ltx_text" id="bib.bib11.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.1.1" style="font-size:90%;">
A.&nbsp;Radford, J.&nbsp;W. Kim, C.&nbsp;Hallacy, A.&nbsp;Ramesh, G.&nbsp;Goh, S.&nbsp;Agarwal, G.&nbsp;Sastry, A.&nbsp;Askell, P.&nbsp;Mishkin, J.&nbsp;Clark </span><em class="ltx_emph ltx_font_italic" id="bib.bib12.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib12.3.3" style="font-size:90%;">, “Learning transferable visual models from natural language supervision,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib12.4.4" style="font-size:90%;">ICML</em><span class="ltx_text" id="bib.bib12.5.5" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;PMLR, 2021, pp. 8748–8763.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.1.1" style="font-size:90%;">
J.-B. Alayrac, J.&nbsp;Donahue, P.&nbsp;Luc, A.&nbsp;Miech, I.&nbsp;Barr, Y.&nbsp;Hasson, K.&nbsp;Lenc, A.&nbsp;Mensch, K.&nbsp;Millican, M.&nbsp;Reynolds </span><em class="ltx_emph ltx_font_italic" id="bib.bib13.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib13.3.3" style="font-size:90%;">, “Flamingo: a visual language model for few-shot learning,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib13.4.4" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib13.5.5" style="font-size:90%;">, pp. 23 716–23 736, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.1.1" style="font-size:90%;">
J.&nbsp;Li, D.&nbsp;Li, S.&nbsp;Savarese, and S.&nbsp;Hoi, “Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib14.2.2" style="font-size:90%;">ICML</em><span class="ltx_text" id="bib.bib14.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;PMLR, 2023, pp. 19 730–19 742.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.1.1" style="font-size:90%;">
H.&nbsp;Liu, C.&nbsp;Li, Q.&nbsp;Wu, and Y.&nbsp;J. Lee, “Visual instruction tuning,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib15.2.2" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib15.3.3" style="font-size:90%;">, vol.&nbsp;36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.1.1" style="font-size:90%;">
J.&nbsp;Achiam, S.&nbsp;Adler, S.&nbsp;Agarwal, L.&nbsp;Ahmad, I.&nbsp;Akkaya, F.&nbsp;L. Aleman, D.&nbsp;Almeida, J.&nbsp;Altenschmidt, S.&nbsp;Altman, S.&nbsp;Anadkat </span><em class="ltx_emph ltx_font_italic" id="bib.bib16.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib16.3.3" style="font-size:90%;">, “Gpt-4 technical report,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib16.4.4" style="font-size:90%;">arXiv preprint arXiv:2303.08774</em><span class="ltx_text" id="bib.bib16.5.5" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.1.1" style="font-size:90%;">
J.&nbsp;Zhang, J.&nbsp;Huang, S.&nbsp;Jin, and S.&nbsp;Lu, “Vision-language models for vision tasks: A survey,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib17.2.2" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span class="ltx_text" id="bib.bib17.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.1.1" style="font-size:90%;">
C.&nbsp;Jia, Y.&nbsp;Yang, Y.&nbsp;Xia, Y.-T. Chen, Z.&nbsp;Parekh, H.&nbsp;Pham, Q.&nbsp;Le, Y.-H. Sung, Z.&nbsp;Li, and T.&nbsp;Duerig, “Scaling up visual and vision-language representation learning with noisy text supervision,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib18.2.2" style="font-size:90%;">ICML</em><span class="ltx_text" id="bib.bib18.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;PMLR, 2021, pp. 4904–4916.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.1.1" style="font-size:90%;">
X.&nbsp;Tian, J.&nbsp;Gu, B.&nbsp;Li, Y.&nbsp;Liu, Y.&nbsp;Wang, Z.&nbsp;Zhao, K.&nbsp;Zhan, P.&nbsp;Jia, X.&nbsp;Lang, and H.&nbsp;Zhao, “Drivevlm: The convergence of autonomous driving and large vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib19.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.12289</em><span class="ltx_text" id="bib.bib19.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.1.1" style="font-size:90%;">
M.-H. Van, P.&nbsp;Verma, and X.&nbsp;Wu, “On large visual language models for medical imaging analysis: An empirical study,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib20.2.2" style="font-size:90%;">CHASE</em><span class="ltx_text" id="bib.bib20.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;IEEE, 2024, pp. 172–176.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.1.1" style="font-size:90%;">
A.&nbsp;Maharana, D.&nbsp;Hannan, and M.&nbsp;Bansal, “Storydall-e: Adapting pretrained text-to-image transformers for story continuation,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib21.2.2" style="font-size:90%;">ECCV</em><span class="ltx_text" id="bib.bib21.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;Springer, 2022, pp. 70–87.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.1.1" style="font-size:90%;">
Y.&nbsp;Zhou, D.&nbsp;Zhou, M.-M. Cheng, J.&nbsp;Feng, and Q.&nbsp;Hou, “Storydiffusion: Consistent self-attention for long-range image and video generation,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib22.2.2" style="font-size:90%;">arXiv preprint arXiv:2405.01434</em><span class="ltx_text" id="bib.bib22.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.1.1" style="font-size:90%;">
X.&nbsp;Qi, K.&nbsp;Huang, A.&nbsp;Panda, P.&nbsp;Henderson, M.&nbsp;Wang, and P.&nbsp;Mittal, “Visual adversarial examples jailbreak aligned large language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib23.2.2" style="font-size:90%;">AAAI</em><span class="ltx_text" id="bib.bib23.3.3" style="font-size:90%;">, 2024, pp. 21 527–21 536.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.1.1" style="font-size:90%;">
C.&nbsp;Schlarmann and M.&nbsp;Hein, “On the adversarial robustness of multi-modal foundation models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib24.2.2" style="font-size:90%;">ICCV</em><span class="ltx_text" id="bib.bib24.3.3" style="font-size:90%;">, 2023, pp. 3677–3685.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.1.1" style="font-size:90%;">
Y.&nbsp;Zhao, T.&nbsp;Pang, C.&nbsp;Du, X.&nbsp;Yang, C.&nbsp;Li, N.-M.&nbsp;M. Cheung, and M.&nbsp;Lin, “On evaluating adversarial robustness of large vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib25.2.2" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib25.3.3" style="font-size:90%;">, vol.&nbsp;36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.1.1" style="font-size:90%;">
R.&nbsp;Wang, X.&nbsp;Ma, H.&nbsp;Zhou, C.&nbsp;Ji, G.&nbsp;Ye, and Y.-G. Jiang, “White-box multimodal jailbreaks against large vision-language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib26.2.2" style="font-size:90%;">ACM MM</em><span class="ltx_text" id="bib.bib26.3.3" style="font-size:90%;">, 2024, pp. 6920–6928.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.1.1" style="font-size:90%;">
L.&nbsp;Bailey, E.&nbsp;Ong, S.&nbsp;Russell, and S.&nbsp;Emmons, “Image hijacks: Adversarial images can control generative models at runtime,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib27.2.2" style="font-size:90%;">ICML</em><span class="ltx_text" id="bib.bib27.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.1.1" style="font-size:90%;">
Y.&nbsp;Ding, B.&nbsp;Li, and R.&nbsp;Zhang, “Eta: Evaluating then aligning safety of vision language models at inference time,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib28.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.06625</em><span class="ltx_text" id="bib.bib28.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.1.1" style="font-size:90%;">
S.&nbsp;Xu, L.&nbsp;Pang, Y.&nbsp;Zhu, H.&nbsp;Shen, and X.&nbsp;Cheng, “Cross-modal safety mechanism transfer in large vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib29.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.12662</em><span class="ltx_text" id="bib.bib29.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.1.1" style="font-size:90%;">
Y.&nbsp;Xu, J.&nbsp;Yao, M.&nbsp;Shu, Y.&nbsp;Sun, Z.&nbsp;Wu, N.&nbsp;Yu, T.&nbsp;Goldstein, and F.&nbsp;Huang, “Shadowcast: Stealthy data poisoning attacks against vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib30.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.06659</em><span class="ltx_text" id="bib.bib30.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.1.1" style="font-size:90%;">
J.&nbsp;Liang, S.&nbsp;Liang, M.&nbsp;Luo, A.&nbsp;Liu, D.&nbsp;Han, E.-C. Chang, and X.&nbsp;Cao, “Vl-trojan: Multimodal instruction backdoor attacks against autoregressive visual language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib31.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.13851</em><span class="ltx_text" id="bib.bib31.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.1.1" style="font-size:90%;">
Z.&nbsp;Ni, R.&nbsp;Ye, Y.&nbsp;Wei, Z.&nbsp;Xiang, Y.&nbsp;Wang, and S.&nbsp;Chen, “Physical backdoor attack can jeopardize driving with vision-large-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib32.2.2" style="font-size:90%;">arXiv preprint arXiv:2404.12916</em><span class="ltx_text" id="bib.bib32.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.1.1" style="font-size:90%;">
X.&nbsp;Liu, Y.&nbsp;Zhu, Y.&nbsp;Lan, C.&nbsp;Yang, and Y.&nbsp;Qiao, “Safety of multimodal large language models on images and text,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib33.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.00357</em><span class="ltx_text" id="bib.bib33.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.1.1" style="font-size:90%;">
Y.&nbsp;Fan, Y.&nbsp;Cao, Z.&nbsp;Zhao, Z.&nbsp;Liu, and S.&nbsp;Li, “Unbridled icarus: A survey of the potential perils of image inputs in multimodal large language model security,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib34.2.2" style="font-size:90%;">arXiv preprint arXiv:2404.05264</em><span class="ltx_text" id="bib.bib34.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.1.1" style="font-size:90%;">
S.&nbsp;Wang, Z.&nbsp;Long, Z.&nbsp;Fan, and Z.&nbsp;Wei, “From llms to mllms: Exploring the landscape of multimodal jailbreaking,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib35.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.14859</em><span class="ltx_text" id="bib.bib35.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.1.1" style="font-size:90%;">
H.&nbsp;Jin, L.&nbsp;Hu, X.&nbsp;Li, P.&nbsp;Zhang, C.&nbsp;Chen, J.&nbsp;Zhuang, and H.&nbsp;Wang, “Jailbreakzoo: Survey, landscapes, and horizons in jailbreaking large language and vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib36.2.2" style="font-size:90%;">arXiv preprint arXiv:2407.01599</em><span class="ltx_text" id="bib.bib36.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.1.1" style="font-size:90%;">
D.&nbsp;Liu, M.&nbsp;Yang, X.&nbsp;Qu, P.&nbsp;Zhou, Y.&nbsp;Cheng, and W.&nbsp;Hu, “A survey of attacks on large vision-language models: Resources, advances, and future trends,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib37.2.2" style="font-size:90%;">arXiv preprint arXiv:2407.07403</em><span class="ltx_text" id="bib.bib37.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.1.1" style="font-size:90%;">
C.&nbsp;Zhang, X.&nbsp;Xu, J.&nbsp;Wu, Z.&nbsp;Liu, and L.&nbsp;Zhou, “Adversarial attacks of vision tasks in the past 10 years: A survey,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib38.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.23687</em><span class="ltx_text" id="bib.bib38.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.1.1" style="font-size:90%;">
X.&nbsp;Liu, X.&nbsp;Cui, P.&nbsp;Li, Z.&nbsp;Li, H.&nbsp;Huang, S.&nbsp;Xia, M.&nbsp;Zhang, Y.&nbsp;Zou, and R.&nbsp;He, “Jailbreak attacks and defenses against multimodal generative models: A survey,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib39.2.2" style="font-size:90%;">arXiv preprint arXiv:2411.09259</em><span class="ltx_text" id="bib.bib39.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.1.1" style="font-size:90%;">
Y.&nbsp;Li, H.&nbsp;Guo, K.&nbsp;Zhou, W.&nbsp;X. Zhao, and J.-R. Wen, “Images are achilles’ heel of alignment: Exploiting visual vulnerabilities for jailbreaking multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib40.2.2" style="font-size:90%;">arXiv preprint arXiv:2403.09792</em><span class="ltx_text" id="bib.bib40.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.1.1" style="font-size:90%;">
Y.&nbsp;Gong, D.&nbsp;Ran, J.&nbsp;Liu, C.&nbsp;Wang, T.&nbsp;Cong, A.&nbsp;Wang, S.&nbsp;Duan, and X.&nbsp;Wang, “Figstep: Jailbreaking large vision-language models via typographic visual prompts,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib41.2.2" style="font-size:90%;">arXiv preprint arXiv:2311.05608</em><span class="ltx_text" id="bib.bib41.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.1.1" style="font-size:90%;">
S.&nbsp;Lee, G.&nbsp;Kim, J.&nbsp;Kim, H.&nbsp;Lee, H.&nbsp;Chang, S.&nbsp;H. Park, and M.&nbsp;Seo, “How does vision-language adaptation impact the safety of vision language models?” </span><em class="ltx_emph ltx_font_italic" id="bib.bib42.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.07571</em><span class="ltx_text" id="bib.bib42.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.1.1" style="font-size:90%;">
Y.&nbsp;Wang, X.&nbsp;Liu, Y.&nbsp;Li, M.&nbsp;Chen, and C.&nbsp;Xiao, “Adashield: Safeguarding multimodal large language models from structure-based attack via adaptive shield prompting,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib43.2.2" style="font-size:90%;">arXiv preprint arXiv:2403.09513</em><span class="ltx_text" id="bib.bib43.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.1.1" style="font-size:90%;">
Y.&nbsp;Xu, X.&nbsp;Qi, Z.&nbsp;Qin, and W.&nbsp;Wang, “Cross-modality information check for detecting jailbreaking in multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib44.2.2" style="font-size:90%;">arXiv preprint arXiv:2407.21659</em><span class="ltx_text" id="bib.bib44.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.1.1" style="font-size:90%;">
P.&nbsp;Wang, D.&nbsp;Zhang, L.&nbsp;Li, C.&nbsp;Tan, X.&nbsp;Wang, K.&nbsp;Ren, B.&nbsp;Jiang, and X.&nbsp;Qiu, “Inferaligner: Inference-time alignment for harmlessness through cross-model guidance,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib45.2.2" style="font-size:90%;">arXiv preprint arXiv:2401.11206</em><span class="ltx_text" id="bib.bib45.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.1.1" style="font-size:90%;">
J.&nbsp;Gao, R.&nbsp;Pi, T.&nbsp;Han, H.&nbsp;Wu, L.&nbsp;Hong, L.&nbsp;Kong, X.&nbsp;Jiang, and Z.&nbsp;Li, “Coca: Regaining safety-awareness of multimodal large language models with constitutional calibration,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib46.2.2" style="font-size:90%;">arXiv preprint arXiv:2409.11365</em><span class="ltx_text" id="bib.bib46.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.1.1" style="font-size:90%;">
X.&nbsp;Zhang, C.&nbsp;Zhang, T.&nbsp;Li, Y.&nbsp;Huang, X.&nbsp;Jia, X.&nbsp;Xie, Y.&nbsp;Liu, and C.&nbsp;Shen, “A mutation-based method for multi-modal jailbreaking attack detection,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib47.2.2" style="font-size:90%;">arXiv preprint arXiv:2312.10766</em><span class="ltx_text" id="bib.bib47.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.1.1" style="font-size:90%;">
R.&nbsp;Pi, T.&nbsp;Han, J.&nbsp;Zhang, Y.&nbsp;Xie, R.&nbsp;Pan, Q.&nbsp;Lian, H.&nbsp;Dong, J.&nbsp;Zhang, and T.&nbsp;Zhang, “Mllm-protector: Ensuring mllm’s safety without hurting performance,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib48.2.2" style="font-size:90%;">arXiv preprint arXiv:2401.02906</em><span class="ltx_text" id="bib.bib48.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.1.1" style="font-size:90%;">
Y.&nbsp;Zong, O.&nbsp;Bohdal, T.&nbsp;Yu, Y.&nbsp;Yang, and T.&nbsp;Hospedales, “Safety fine-tuning at (almost) no cost: A baseline for vision large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib49.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.02207</em><span class="ltx_text" id="bib.bib49.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.1.1" style="font-size:90%;">
Y.&nbsp;Zhang, L.&nbsp;Chen, G.&nbsp;Zheng, Y.&nbsp;Gao, R.&nbsp;Zheng, J.&nbsp;Fu, Z.&nbsp;Yin, S.&nbsp;Jin, Y.&nbsp;Qiao, X.&nbsp;Huang </span><em class="ltx_emph ltx_font_italic" id="bib.bib50.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib50.3.3" style="font-size:90%;">, “Spa-vl: A comprehensive safety preference alignment dataset for vision language model,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib50.4.4" style="font-size:90%;">arXiv preprint arXiv:2406.12030</em><span class="ltx_text" id="bib.bib50.5.5" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.1.1" style="font-size:90%;">
Z.&nbsp;Liu, Y.&nbsp;Nie, Y.&nbsp;Tan, X.&nbsp;Yue, Q.&nbsp;Cui, C.&nbsp;Wang, X.&nbsp;Zhu, and B.&nbsp;Zheng, “Safety alignment for vision language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib51.2.2" style="font-size:90%;">arXiv preprint arXiv:2405.13581</em><span class="ltx_text" id="bib.bib51.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.1.1" style="font-size:90%;">
H.&nbsp;Tu, C.&nbsp;Cui, Z.&nbsp;Wang, Y.&nbsp;Zhou, B.&nbsp;Zhao, J.&nbsp;Han, W.&nbsp;Zhou, H.&nbsp;Yao, and C.&nbsp;Xie, “How many unicorns are in this image? a safety evaluation benchmark for vision llms,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib52.2.2" style="font-size:90%;">arXiv preprint arXiv:2311.16101</em><span class="ltx_text" id="bib.bib52.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib53.1.1" style="font-size:90%;">
X.&nbsp;Liu, Y.&nbsp;Zhu, Y.&nbsp;Lan, C.&nbsp;Yang, and Y.&nbsp;Qiao, “Query-relevant images jailbreak large multi-modal models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib53.2.2" style="font-size:90%;">arXiv preprint arXiv:2311.17600</em><span class="ltx_text" id="bib.bib53.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib54.1.1" style="font-size:90%;">
W.&nbsp;Luo, S.&nbsp;Ma, X.&nbsp;Liu, X.&nbsp;Guo, and C.&nbsp;Xiao, “Jailbreakv-28k: A benchmark for assessing the robustness of multimodal large language models against jailbreak attacks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib54.2.2" style="font-size:90%;">arXiv preprint arXiv:2404.03027</em><span class="ltx_text" id="bib.bib54.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib55.1.1" style="font-size:90%;">
Y.&nbsp;Zhang, Y.&nbsp;Huang, Y.&nbsp;Sun, C.&nbsp;Liu, Z.&nbsp;Zhao, Z.&nbsp;Fang, Y.&nbsp;Wang, H.&nbsp;Chen, X.&nbsp;Yang, X.&nbsp;Wei </span><em class="ltx_emph ltx_font_italic" id="bib.bib55.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib55.3.3" style="font-size:90%;">, “Benchmarking trustworthiness of multimodal large language models: A comprehensive study,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib55.4.4" style="font-size:90%;">arXiv preprint arXiv:2406.07057</em><span class="ltx_text" id="bib.bib55.5.5" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib56.1.1" style="font-size:90%;">
T.&nbsp;Gu, Z.&nbsp;Zhou, K.&nbsp;Huang, D.&nbsp;Liang, Y.&nbsp;Wang, H.&nbsp;Zhao, Y.&nbsp;Yao, X.&nbsp;Qiao, K.&nbsp;Wang, Y.&nbsp;Yang </span><em class="ltx_emph ltx_font_italic" id="bib.bib56.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib56.3.3" style="font-size:90%;">, “Mllmguard: A multi-dimensional safety evaluation suite for multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib56.4.4" style="font-size:90%;">arXiv preprint arXiv:2406.07594</em><span class="ltx_text" id="bib.bib56.5.5" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib57.1.1" style="font-size:90%;">
A.&nbsp;Radford, J.&nbsp;Wu, R.&nbsp;Child, D.&nbsp;Luan, D.&nbsp;Amodei, I.&nbsp;Sutskever </span><em class="ltx_emph ltx_font_italic" id="bib.bib57.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib57.3.3" style="font-size:90%;">, “Language models are unsupervised multitask learners,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib57.4.4" style="font-size:90%;">OpenAI blog</em><span class="ltx_text" id="bib.bib57.5.5" style="font-size:90%;">, p.&nbsp;9, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib58.1.1" style="font-size:90%;">
R.&nbsp;Anil, A.&nbsp;M. Dai, O.&nbsp;Firat, M.&nbsp;Johnson, D.&nbsp;Lepikhin, A.&nbsp;Passos, S.&nbsp;Shakeri, E.&nbsp;Taropa, P.&nbsp;Bailey, Z.&nbsp;Chen </span><em class="ltx_emph ltx_font_italic" id="bib.bib58.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib58.3.3" style="font-size:90%;">, “Palm 2 technical report,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib58.4.4" style="font-size:90%;">arXiv preprint arXiv:2305.10403</em><span class="ltx_text" id="bib.bib58.5.5" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib59.1.1" style="font-size:90%;">
W.-L. Chiang, Z.&nbsp;Li, Z.&nbsp;Lin, Y.&nbsp;Sheng, Z.&nbsp;Wu, H.&nbsp;Zhang, L.&nbsp;Zheng, S.&nbsp;Zhuang, Y.&nbsp;Zhuang, J.&nbsp;E. Gonzalez, I.&nbsp;Stoica, and E.&nbsp;P. Xing, “Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality,” March 2023. [Online]. Available: </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lmsys.org/blog/2023-03-30-vicuna/" style="font-size:90%;" title="">https://lmsys.org/blog/2023-03-30-vicuna/</a><span class="ltx_text" id="bib.bib59.2.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib60.1.1" style="font-size:90%;">
G.&nbsp;Team, R.&nbsp;Anil, S.&nbsp;Borgeaud, J.-B. Alayrac, J.&nbsp;Yu, R.&nbsp;Soricut, J.&nbsp;Schalkwyk, A.&nbsp;M. Dai, A.&nbsp;Hauth, K.&nbsp;Millican </span><em class="ltx_emph ltx_font_italic" id="bib.bib60.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib60.3.3" style="font-size:90%;">, “Gemini: a family of highly capable multimodal models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib60.4.4" style="font-size:90%;">arXiv preprint arXiv:2312.11805</em><span class="ltx_text" id="bib.bib60.5.5" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_tag_bibitem">[61]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib61.1.1" style="font-size:90%;">
D.&nbsp;Zhu, J.&nbsp;Chen, X.&nbsp;Shen, X.&nbsp;Li, and M.&nbsp;Elhoseiny, “Minigpt-4: Enhancing vision-language understanding with advanced large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib61.2.2" style="font-size:90%;">arXiv preprint arXiv:2304.10592</em><span class="ltx_text" id="bib.bib61.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_tag_bibitem">[62]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib62.1.1" style="font-size:90%;">
Y.&nbsp;Su, T.&nbsp;Lan, H.&nbsp;Li, J.&nbsp;Xu, Y.&nbsp;Wang, and D.&nbsp;Cai, “Pandagpt: One model to instruction-follow them all,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib62.2.2" style="font-size:90%;">arXiv preprint arXiv:2305.16355</em><span class="ltx_text" id="bib.bib62.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_tag_bibitem">[63]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib63.1.1" style="font-size:90%;">
B.&nbsp;Li, Y.&nbsp;Zhang, D.&nbsp;Guo, R.&nbsp;Zhang, F.&nbsp;Li, H.&nbsp;Zhang, K.&nbsp;Zhang, Y.&nbsp;Li, Z.&nbsp;Liu, and C.&nbsp;Li, “Llava-onevision: Easy visual task transfer,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib63.2.2" style="font-size:90%;">arXiv preprint arXiv:2408.03326</em><span class="ltx_text" id="bib.bib63.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_tag_bibitem">[64]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib64.1.1" style="font-size:90%;">
Z.&nbsp;Chen, J.&nbsp;Wu, W.&nbsp;Wang, W.&nbsp;Su, G.&nbsp;Chen, S.&nbsp;Xing, M.&nbsp;Zhong, Q.&nbsp;Zhang, X.&nbsp;Zhu, L.&nbsp;Lu </span><em class="ltx_emph ltx_font_italic" id="bib.bib64.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib64.3.3" style="font-size:90%;">, “Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib64.4.4" style="font-size:90%;">CVPR</em><span class="ltx_text" id="bib.bib64.5.5" style="font-size:90%;">, 2024, pp. 24 185–24 198.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_tag_bibitem">[65]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib65.1.1" style="font-size:90%;">
J.&nbsp;Bai, S.&nbsp;Bai, S.&nbsp;Yang, S.&nbsp;Wang, S.&nbsp;Tan, P.&nbsp;Wang, J.&nbsp;Lin, C.&nbsp;Zhou, and J.&nbsp;Zhou, “Qwen-vl: A frontier large vision-language model with versatile abilities,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib65.2.2" style="font-size:90%;">arXiv preprint arXiv:2308.12966</em><span class="ltx_text" id="bib.bib65.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_tag_bibitem">[66]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib66.1.1" style="font-size:90%;">
J.&nbsp;Lin, H.&nbsp;Yin, W.&nbsp;Ping, P.&nbsp;Molchanov, M.&nbsp;Shoeybi, and S.&nbsp;Han, “Vila: On pre-training for visual language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib66.2.2" style="font-size:90%;">CVPR</em><span class="ltx_text" id="bib.bib66.3.3" style="font-size:90%;">, 2024, pp. 26 689–26 699.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_tag_bibitem">[67]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib67.1.1" style="font-size:90%;">
R.&nbsp;Pi, J.&nbsp;Zhang, J.&nbsp;Zhang, R.&nbsp;Pan, Z.&nbsp;Chen, and T.&nbsp;Zhang, “Image textualization: An automatic framework for creating accurate and detailed image descriptions,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib67.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.07502</em><span class="ltx_text" id="bib.bib67.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_tag_bibitem">[68]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib68.1.1" style="font-size:90%;">
R.&nbsp;Pi, J.&nbsp;Zhang, T.&nbsp;Han, J.&nbsp;Zhang, R.&nbsp;Pan, and T.&nbsp;Zhang, “Personalized visual instruction tuning,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib68.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.07113</em><span class="ltx_text" id="bib.bib68.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_tag_bibitem">[69]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib69.1.1" style="font-size:90%;">
I.&nbsp;O. Gallegos, R.&nbsp;A. Rossi, J.&nbsp;Barrow, M.&nbsp;M. Tanjim, S.&nbsp;Kim, F.&nbsp;Dernoncourt, T.&nbsp;Yu, R.&nbsp;Zhang, and N.&nbsp;K. Ahmed, “Bias and fairness in large language models: A survey,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib69.2.2" style="font-size:90%;">CL</em><span class="ltx_text" id="bib.bib69.3.3" style="font-size:90%;">, pp. 1–79, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_tag_bibitem">[70]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib70.1.1" style="font-size:90%;">
X.&nbsp;Shen, Z.&nbsp;Chen, M.&nbsp;Backes, Y.&nbsp;Shen, and Y.&nbsp;Zhang, “” do anything now”: Characterizing and evaluating in-the-wild jailbreak prompts on large language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib70.2.2" style="font-size:90%;">ACM CCS</em><span class="ltx_text" id="bib.bib70.3.3" style="font-size:90%;">, 2024, pp. 1671–1685.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_tag_bibitem">[71]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib71.1.1" style="font-size:90%;">
S.&nbsp;Yi, Y.&nbsp;Liu, Z.&nbsp;Sun, T.&nbsp;Cong, X.&nbsp;He, J.&nbsp;Song, K.&nbsp;Xu, and Q.&nbsp;Li, “Jailbreak attacks and defenses against large language models: A survey,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib71.2.2" style="font-size:90%;">arXiv preprint arXiv:2407.04295</em><span class="ltx_text" id="bib.bib71.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_tag_bibitem">[72]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib72.1.1" style="font-size:90%;">
Y.&nbsp;Guo, F.&nbsp;Jiao, L.&nbsp;Nie, and M.&nbsp;Kankanhalli, “The vllm safety paradox: Dual ease in jailbreak attack and defense,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib72.2.2" style="font-size:90%;">arXiv preprint arXiv:2411.08410</em><span class="ltx_text" id="bib.bib72.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_tag_bibitem">[73]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib73.1.1" style="font-size:90%;">
G.&nbsp;Pantazopoulos, A.&nbsp;Parekh, M.&nbsp;Nikandrou, and A.&nbsp;Suglia, “Learning to see but forgetting to follow: Visual instruction tuning makes llms more prone to jailbreak attacks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib73.2.2" style="font-size:90%;">arXiv preprint arXiv:2405.04403</em><span class="ltx_text" id="bib.bib73.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_tag_bibitem">[74]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib74.1.1" style="font-size:90%;">
S.&nbsp;Bachu, E.&nbsp;Shayegani, T.&nbsp;Chakraborty, R.&nbsp;Lal, A.&nbsp;Dutta, C.&nbsp;Song, Y.&nbsp;Dong, N.&nbsp;Abu-Ghazaleh, and A.&nbsp;K. Roy-Chowdhury, “Unfair alignment: Examining safety alignment across vision encoder layers in vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib74.2.2" style="font-size:90%;">arXiv preprint arXiv:2411.04291</em><span class="ltx_text" id="bib.bib74.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_tag_bibitem">[75]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib75.1.1" style="font-size:90%;">
A.&nbsp;Chakraborty, M.&nbsp;Alam, V.&nbsp;Dey, A.&nbsp;Chattopadhyay, and D.&nbsp;Mukhopadhyay, “A survey on adversarial attacks and defences,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib75.2.2" style="font-size:90%;">CAAI TIT</em><span class="ltx_text" id="bib.bib75.3.3" style="font-size:90%;">, pp. 25–45, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_tag_bibitem">[76]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib76.1.1" style="font-size:90%;">
S.&nbsp;Huang, N.&nbsp;Papernot, I.&nbsp;Goodfellow, Y.&nbsp;Duan, and P.&nbsp;Abbeel, “Adversarial attacks on neural network policies,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib76.2.2" style="font-size:90%;">arXiv preprint arXiv:1702.02284</em><span class="ltx_text" id="bib.bib76.3.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_tag_bibitem">[77]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib77.1.1" style="font-size:90%;">
A.&nbsp;Chakraborty, M.&nbsp;Alam, V.&nbsp;Dey, A.&nbsp;Chattopadhyay, and D.&nbsp;Mukhopadhyay, “Adversarial attacks and defences: A survey,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib77.2.2" style="font-size:90%;">arXiv preprint arXiv:1810.00069</em><span class="ltx_text" id="bib.bib77.3.3" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_tag_bibitem">[78]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib78.1.1" style="font-size:90%;">
I.&nbsp;J. Goodfellow, J.&nbsp;Shlens, and C.&nbsp;Szegedy, “Explaining and harnessing adversarial examples,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib78.2.2" style="font-size:90%;">arXiv preprint arXiv:1412.6572</em><span class="ltx_text" id="bib.bib78.3.3" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_tag_bibitem">[79]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib79.1.1" style="font-size:90%;">
A.&nbsp;Madry, “Towards deep learning models resistant to adversarial attacks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib79.2.2" style="font-size:90%;">arXiv preprint arXiv:1706.06083</em><span class="ltx_text" id="bib.bib79.3.3" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_tag_bibitem">[80]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib80.1.1" style="font-size:90%;">
S.&nbsp;Cheng, Y.&nbsp;Dong, T.&nbsp;Pang, H.&nbsp;Su, and J.&nbsp;Zhu, “Improving black-box adversarial attacks with a transfer-based prior,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib80.2.2" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib80.3.3" style="font-size:90%;">, vol.&nbsp;32, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_tag_bibitem">[81]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib81.1.1" style="font-size:90%;">
A.&nbsp;Demontis, M.&nbsp;Melis, M.&nbsp;Pintor, M.&nbsp;Jagielski, B.&nbsp;Biggio, A.&nbsp;Oprea, C.&nbsp;Nita-Rotaru, and F.&nbsp;Roli, “Why do adversarial attacks transfer? explaining transferability of evasion and poisoning attacks,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib81.2.2" style="font-size:90%;">USENIX</em><span class="ltx_text" id="bib.bib81.3.3" style="font-size:90%;">, 2019, pp. 321–338.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_tag_bibitem">[82]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib82.1.1" style="font-size:90%;">
Z.&nbsp;Qin, Y.&nbsp;Fan, Y.&nbsp;Liu, L.&nbsp;Shen, Y.&nbsp;Zhang, J.&nbsp;Wang, and B.&nbsp;Wu, “Boosting the transferability of adversarial attacks with reverse adversarial perturbation,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib82.2.2" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib82.3.3" style="font-size:90%;">, vol.&nbsp;35, pp. 29 845–29 858, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_tag_bibitem">[83]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib83.1.1" style="font-size:90%;">
F.&nbsp;Perez and I.&nbsp;Ribeiro, “Ignore previous prompt: Attack techniques for language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib83.2.2" style="font-size:90%;">arXiv preprint arXiv:2211.09527</em><span class="ltx_text" id="bib.bib83.3.3" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_tag_bibitem">[84]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib84.1.1" style="font-size:90%;">
D.&nbsp;Yao, J.&nbsp;Zhang, I.&nbsp;G. Harris, and M.&nbsp;Carlsson, “Fuzzllm: A novel and universal fuzzing framework for proactively discovering jailbreak vulnerabilities in large language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib84.2.2" style="font-size:90%;">ICASSP</em><span class="ltx_text" id="bib.bib84.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;IEEE, 2024, pp. 4485–4489.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_tag_bibitem">[85]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib85.1.1" style="font-size:90%;">
E.&nbsp;Shayegani, Y.&nbsp;Dong, and N.&nbsp;Abu-Ghazaleh, “Jailbreak in pieces: Compositional adversarial attacks on multi-modal language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib85.2.2" style="font-size:90%;">ICLR</em><span class="ltx_text" id="bib.bib85.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_tag_bibitem">[86]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib86.1.1" style="font-size:90%;">
V.&nbsp;Tolpegin, S.&nbsp;Truex, M.&nbsp;E. Gursoy, and L.&nbsp;Liu, “Data poisoning attacks against federated learning systems,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib86.2.2" style="font-size:90%;">ESORICs</em><span class="ltx_text" id="bib.bib86.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;Springer, 2020, pp. 480–501.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_tag_bibitem">[87]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib87.1.1" style="font-size:90%;">
A.&nbsp;Saha, A.&nbsp;Subramanya, and H.&nbsp;Pirsiavash, “Hidden trigger backdoor attacks,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib87.2.2" style="font-size:90%;">AAAI</em><span class="ltx_text" id="bib.bib87.3.3" style="font-size:90%;">, 2020, pp. 11 957–11 965.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_tag_bibitem">[88]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib88.1.1" style="font-size:90%;">
Y.&nbsp;Li, T.&nbsp;Zhai, B.&nbsp;Wu, Y.&nbsp;Jiang, Z.&nbsp;Li, and S.&nbsp;Xia, “Rethinking the trigger of backdoor attack,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib88.2.2" style="font-size:90%;">arXiv preprint arXiv:2004.04692</em><span class="ltx_text" id="bib.bib88.3.3" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_tag_bibitem">[89]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib89.1.1" style="font-size:90%;">
Y.&nbsp;Zeng, W.&nbsp;Park, Z.&nbsp;M. Mao, and R.&nbsp;Jia, “Rethinking the backdoor attacks’ triggers: A frequency perspective,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib89.2.2" style="font-size:90%;">ICCV</em><span class="ltx_text" id="bib.bib89.3.3" style="font-size:90%;">, 2021, pp. 16 473–16 481.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_tag_bibitem">[90]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib90.1.1" style="font-size:90%;">
Y.&nbsp;Li, Y.&nbsp;Li, B.&nbsp;Wu, L.&nbsp;Li, R.&nbsp;He, and S.&nbsp;Lyu, “Invisible backdoor attack with sample-specific triggers,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib90.2.2" style="font-size:90%;">ICCV</em><span class="ltx_text" id="bib.bib90.3.3" style="font-size:90%;">, 2021, pp. 16 463–16 472.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_tag_bibitem">[91]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib91.1.1" style="font-size:90%;">
E.&nbsp;Bagdasaryan, T.-Y. Hsieh, B.&nbsp;Nassi, and V.&nbsp;Shmatikov, “(ab) using images and sounds for indirect instruction injection in multi-modal llms,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib91.2.2" style="font-size:90%;">arXiv preprint arXiv:2307.10490</em><span class="ltx_text" id="bib.bib91.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_tag_bibitem">[92]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib92.1.1" style="font-size:90%;">
K.&nbsp;Gao, Y.&nbsp;Bai, J.&nbsp;Gu, S.-T. Xia, P.&nbsp;Torr, Z.&nbsp;Li, and W.&nbsp;Liu, “Inducing high energy-latency of large vision-language models with verbose images,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib92.2.2" style="font-size:90%;">arXiv preprint arXiv:2401.11170</em><span class="ltx_text" id="bib.bib92.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_tag_bibitem">[93]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib93.1.1" style="font-size:90%;">
D.&nbsp;Lu, T.&nbsp;Pang, C.&nbsp;Du, Q.&nbsp;Liu, X.&nbsp;Yang, and M.&nbsp;Lin, “Test-time backdoor attacks on multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib93.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.08577</em><span class="ltx_text" id="bib.bib93.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_tag_bibitem">[94]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib94.1.1" style="font-size:90%;">
Z.&nbsp;Wang, Z.&nbsp;Han, S.&nbsp;Chen, F.&nbsp;Xue, Z.&nbsp;Ding, X.&nbsp;Xiao, V.&nbsp;Tresp, P.&nbsp;Torr, and J.&nbsp;Gu, “Stop reasoning! when multimodal llms with chain-of-thought reasoning meets adversarial images,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib94.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.14899</em><span class="ltx_text" id="bib.bib94.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_tag_bibitem">[95]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib95.1.1" style="font-size:90%;">
H.&nbsp;Luo, J.&nbsp;Gu, F.&nbsp;Liu, and P.&nbsp;Torr, “An image is worth 1000 lies: Adversarial transferability across prompts on vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib95.2.2" style="font-size:90%;">arXiv preprint arXiv:2403.09766</em><span class="ltx_text" id="bib.bib95.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_tag_bibitem">[96]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib96.1.1" style="font-size:90%;">
K.&nbsp;Gao, Y.&nbsp;Bai, J.&nbsp;Bai, Y.&nbsp;Yang, and S.-T. Xia, “Adversarial robustness for visual grounding of multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib96.2.2" style="font-size:90%;">arXiv preprint arXiv:2405.09981</em><span class="ltx_text" id="bib.bib96.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_tag_bibitem">[97]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib97.1.1" style="font-size:90%;">
Z.&nbsp;Ying, A.&nbsp;Liu, T.&nbsp;Zhang, Z.&nbsp;Yu, S.&nbsp;Liang, X.&nbsp;Liu, and D.&nbsp;Tao, “Jailbreak vision language models via bi-modal adversarial prompt,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib97.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.04031</em><span class="ltx_text" id="bib.bib97.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_tag_bibitem">[98]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib98.1.1" style="font-size:90%;">
X.&nbsp;Yang, X.&nbsp;Tang, F.&nbsp;Zhu, J.&nbsp;Han, and S.&nbsp;Hu, “Enhancing cross-prompt transferability in vision-language models through contextual injection of target tokens,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib98.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.13294</em><span class="ltx_text" id="bib.bib98.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_tag_bibitem">[99]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib99.1.1" style="font-size:90%;">
J.&nbsp;Jang, H.&nbsp;Lyu, J.&nbsp;Koh, and H.&nbsp;J. Yang, “Replace-then-perturb: Targeted adversarial attacks with visual reasoning for vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib99.2.2" style="font-size:90%;">arXiv preprint arXiv:2411.00898</em><span class="ltx_text" id="bib.bib99.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_tag_bibitem">[100]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib100.1.1" style="font-size:90%;">
Y.&nbsp;Dong, H.&nbsp;Chen, J.&nbsp;Chen, Z.&nbsp;Fang, X.&nbsp;Yang, Y.&nbsp;Zhang, Y.&nbsp;Tian, H.&nbsp;Su, and J.&nbsp;Zhu, “How robust is google’s bard to adversarial image attacks?” </span><em class="ltx_emph ltx_font_italic" id="bib.bib100.2.2" style="font-size:90%;">arXiv preprint arXiv:2309.11751</em><span class="ltx_text" id="bib.bib100.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_tag_bibitem">[101]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib101.1.1" style="font-size:90%;">
Z.&nbsp;Niu, H.&nbsp;Ren, X.&nbsp;Gao, G.&nbsp;Hua, and R.&nbsp;Jin, “Jailbreaking attack against multimodal large language model,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib101.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.02309</em><span class="ltx_text" id="bib.bib101.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_tag_bibitem">[102]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib102.1.1" style="font-size:90%;">
X.&nbsp;Gu, X.&nbsp;Zheng, T.&nbsp;Pang, C.&nbsp;Du, Q.&nbsp;Liu, Y.&nbsp;Wang, J.&nbsp;Jiang, and M.&nbsp;Lin, “Agent smith: A single image can jailbreak one million multimodal llm agents exponentially fast,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib102.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.08567</em><span class="ltx_text" id="bib.bib102.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_tag_bibitem">[103]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib103.1.1" style="font-size:90%;">
Z.&nbsp;Tan, C.&nbsp;Zhao, R.&nbsp;Moraffah, Y.&nbsp;Li, Y.&nbsp;Kong, T.&nbsp;Chen, and H.&nbsp;Liu, “The wolf within: Covert injection of malice into mllm societies via an mllm operative,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib103.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.14859</em><span class="ltx_text" id="bib.bib103.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_tag_bibitem">[104]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib104.1.1" style="font-size:90%;">
M.&nbsp;Qraitem, N.&nbsp;Tasnim, P.&nbsp;Teterwak, K.&nbsp;Saenko, and B.&nbsp;A. Plummer, “Vision-llms can fool themselves with self-generated typographic attacks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib104.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.00626</em><span class="ltx_text" id="bib.bib104.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_tag_bibitem">[105]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib105.1.1" style="font-size:90%;">
S.&nbsp;Ma, W.&nbsp;Luo, Y.&nbsp;Wang, X.&nbsp;Liu, M.&nbsp;Chen, B.&nbsp;Li, and C.&nbsp;Xiao, “Visual-roleplay: Universal jailbreak attack on multimodal large language models via role-playing image characte,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib105.2.2" style="font-size:90%;">arXiv preprint arXiv:2405.20773</em><span class="ltx_text" id="bib.bib105.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_tag_bibitem">[106]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib106.1.1" style="font-size:90%;">
X.&nbsp;Zou, K.&nbsp;Li, and Y.&nbsp;Chen, “Image-to-text logic jailbreak: Your imagination can help you do anything,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib106.2.2" style="font-size:90%;">arXiv preprint arXiv:2407.02534</em><span class="ltx_text" id="bib.bib106.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_tag_bibitem">[107]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib107.1.1" style="font-size:90%;">
R.&nbsp;Wang, B.&nbsp;Wang, X.&nbsp;Ma, and Y.-G. Jiang, “Ideator: Jailbreaking vlms using vlms,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib107.2.2" style="font-size:90%;">arXiv preprint arXiv:2411.00827</em><span class="ltx_text" id="bib.bib107.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_tag_bibitem">[108]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib108.1.1" style="font-size:90%;">
Y.&nbsp;Wang, X.&nbsp;Zhou, Y.&nbsp;Wang, G.&nbsp;Zhang, and T.&nbsp;He, “Jailbreak large visual language models through multi-modal linkage,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib108.2.2" style="font-size:90%;">arXiv preprint arXiv:2412.00473</em><span class="ltx_text" id="bib.bib108.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_tag_bibitem">[109]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib109.1.1" style="font-size:90%;">
M.&nbsp;Teng, J.&nbsp;Xiaojun, D.&nbsp;Ranjie, L.&nbsp;Xinfeng, H.&nbsp;Yihao, C.&nbsp;Zhixuan, L.&nbsp;Yang, and R.&nbsp;Wenqi, “Heuristic-induced multimodal risk distribution jailbreak attack for multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib109.2.2" style="font-size:90%;">arXiv preprint arXiv:2412.05934</em><span class="ltx_text" id="bib.bib109.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_tag_bibitem">[110]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib110.1.1" style="font-size:90%;">
A.&nbsp;Awadalla, I.&nbsp;Gao, J.&nbsp;Gardner, J.&nbsp;Hessel, Y.&nbsp;Hanafy, W.&nbsp;Zhu, K.&nbsp;Marathe, Y.&nbsp;Bitton, S.&nbsp;Gadre, S.&nbsp;Sagawa </span><em class="ltx_emph ltx_font_italic" id="bib.bib110.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib110.3.3" style="font-size:90%;">, “Openflamingo: An open-source framework for training large autoregressive vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib110.4.4" style="font-size:90%;">arXiv preprint arXiv:2308.01390</em><span class="ltx_text" id="bib.bib110.5.5" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_tag_bibitem">[111]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib111.1.1" style="font-size:90%;">
I.&nbsp;Shumailov, Y.&nbsp;Zhao, D.&nbsp;Bates, N.&nbsp;Papernot, R.&nbsp;Mullins, and R.&nbsp;Anderson, “Sponge examples: Energy-latency attacks on neural networks,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib111.2.2" style="font-size:90%;">EuroS&amp;P</em><span class="ltx_text" id="bib.bib111.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;IEEE, 2021, pp. 212–231.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_tag_bibitem">[112]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib112.1.1" style="font-size:90%;">
S.&nbsp;Chen, Z.&nbsp;Song, M.&nbsp;Haque, C.&nbsp;Liu, and W.&nbsp;Yang, “Nicgslowdown: Evaluating the efficiency robustness of neural image caption generation models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib112.2.2" style="font-size:90%;">CVPR</em><span class="ltx_text" id="bib.bib112.3.3" style="font-size:90%;">, 2022, pp. 15 365–15 374.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_tag_bibitem">[113]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib113.1.1" style="font-size:90%;">
P.&nbsp;Lu, S.&nbsp;Mishra, T.&nbsp;Xia, L.&nbsp;Qiu, K.-W. Chang, S.-C. Zhu, O.&nbsp;Tafjord, P.&nbsp;Clark, and A.&nbsp;Kalyan, “Learn to explain: Multimodal reasoning via thought chains for science question answering,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib113.2.2" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib113.3.3" style="font-size:90%;">, pp. 2507–2521, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_tag_bibitem">[114]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib114.1.1" style="font-size:90%;">
Z.&nbsp;Zhang, A.&nbsp;Zhang, M.&nbsp;Li, H.&nbsp;Zhao, G.&nbsp;Karypis, and A.&nbsp;Smola, “Multimodal chain-of-thought reasoning in language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib114.2.2" style="font-size:90%;">arXiv preprint arXiv:2302.00923</em><span class="ltx_text" id="bib.bib114.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_tag_bibitem">[115]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib115.1.1" style="font-size:90%;">
L.&nbsp;He, Z.&nbsp;Li, X.&nbsp;Cai, and P.&nbsp;Wang, “Multi-modal latent space learning for chain-of-thought reasoning in language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib115.2.2" style="font-size:90%;">AAAI</em><span class="ltx_text" id="bib.bib115.3.3" style="font-size:90%;">, 2024, pp. 18 180–18 187.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_tag_bibitem">[116]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib116.1.1" style="font-size:90%;">
Z.&nbsp;Peng, W.&nbsp;Wang, L.&nbsp;Dong, Y.&nbsp;Hao, S.&nbsp;Huang, S.&nbsp;Ma, and F.&nbsp;Wei, “Kosmos-2: Grounding multimodal large language models to the world,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib116.2.2" style="font-size:90%;">arXiv preprint arXiv:2306.14824</em><span class="ltx_text" id="bib.bib116.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_tag_bibitem">[117]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib117.1.1" style="font-size:90%;">
W.&nbsp;Wang, Z.&nbsp;Chen, X.&nbsp;Chen, J.&nbsp;Wu, X.&nbsp;Zhu, G.&nbsp;Zeng, P.&nbsp;Luo, T.&nbsp;Lu, J.&nbsp;Zhou, Y.&nbsp;Qiao </span><em class="ltx_emph ltx_font_italic" id="bib.bib117.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib117.3.3" style="font-size:90%;">, “Visionllm: Large language model is also an open-ended decoder for vision-centric tasks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib117.4.4" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib117.5.5" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_tag_bibitem">[118]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib118.1.1" style="font-size:90%;">
M.&nbsp;Li and L.&nbsp;Sigal, “Referring transformer: A one-step approach to multi-task visual grounding,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib118.2.2" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib118.3.3" style="font-size:90%;">, pp. 19 652–19 664, 2021.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_tag_bibitem">[119]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib119.1.1" style="font-size:90%;">
J.&nbsp;Wei, X.&nbsp;Wang, D.&nbsp;Schuurmans, M.&nbsp;Bosma, F.&nbsp;Xia, E.&nbsp;Chi, Q.&nbsp;V. Le, D.&nbsp;Zhou </span><em class="ltx_emph ltx_font_italic" id="bib.bib119.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib119.3.3" style="font-size:90%;">, “Chain-of-thought prompting elicits reasoning in large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib119.4.4" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib119.5.5" style="font-size:90%;">, pp. 24 824–24 837, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_tag_bibitem">[120]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib120.1.1" style="font-size:90%;">
Z.&nbsp;Chu, J.&nbsp;Chen, Q.&nbsp;Chen, W.&nbsp;Yu, T.&nbsp;He, H.&nbsp;Wang, W.&nbsp;Peng, M.&nbsp;Liu, B.&nbsp;Qin, and T.&nbsp;Liu, “A survey of chain of thought reasoning: Advances, frontiers and future,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib120.2.2" style="font-size:90%;">arXiv preprint arXiv:2309.15402</em><span class="ltx_text" id="bib.bib120.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_tag_bibitem">[121]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib121.1.1" style="font-size:90%;">
J.&nbsp;Li, D.&nbsp;Li, C.&nbsp;Xiong, and S.&nbsp;Hoi, “Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib121.2.2" style="font-size:90%;">ICML</em><span class="ltx_text" id="bib.bib121.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;PMLR, 2022, pp. 12 888–12 900.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_tag_bibitem">[122]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib122.1.1" style="font-size:90%;">
Y.&nbsp;Wang, C.&nbsp;Liu, Y.&nbsp;Qu, H.&nbsp;Cao, D.&nbsp;Jiang, and L.&nbsp;Xu, “Break the visual perception: Adversarial attacks targeting encoded visual tokens of large vision-language models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib122.2.2" style="font-size:90%;">ACM MM</em><span class="ltx_text" id="bib.bib122.3.3" style="font-size:90%;">, 2024, pp. 1072–1081.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_tag_bibitem">[123]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib123.1.1" style="font-size:90%;">
S.&nbsp;Bird, E.&nbsp;Klein, and E.&nbsp;Loper, </span><em class="ltx_emph ltx_font_italic" id="bib.bib123.2.2" style="font-size:90%;">Natural language processing with Python: analyzing text with the natural language toolkit</em><span class="ltx_text" id="bib.bib123.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;” O’Reilly Media, Inc.”, 2009.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_tag_bibitem">[124]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib124.1.1" style="font-size:90%;">
J.&nbsp;Xu, M.&nbsp;D. Ma, F.&nbsp;Wang, C.&nbsp;Xiao, and M.&nbsp;Chen, “Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib124.2.2" style="font-size:90%;">arXiv preprint arXiv:2305.14710</em><span class="ltx_text" id="bib.bib124.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_tag_bibitem">[125]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib125.1.1" style="font-size:90%;">
J.&nbsp;Yan, V.&nbsp;Yadav, S.&nbsp;Li, L.&nbsp;Chen, Z.&nbsp;Tang, H.&nbsp;Wang, V.&nbsp;Srinivasan, X.&nbsp;Ren, and H.&nbsp;Jin, “Backdooring instruction-tuned large language models with virtual prompt injection,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib125.2.2" style="font-size:90%;">NAACL</em><span class="ltx_text" id="bib.bib125.3.3" style="font-size:90%;">, 2024, pp. 6065–6086.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_tag_bibitem">[126]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib126.1.1" style="font-size:90%;">
X.&nbsp;Tao, S.&nbsp;Zhong, L.&nbsp;Li, Q.&nbsp;Liu, and L.&nbsp;Kong, “Imgtrojan: Jailbreaking vision-language models with one image,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib126.2.2" style="font-size:90%;">arXiv preprint arXiv:2403.02910</em><span class="ltx_text" id="bib.bib126.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_tag_bibitem">[127]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib127.1.1" style="font-size:90%;">
S.&nbsp;Liang, J.&nbsp;Liang, T.&nbsp;Pang, C.&nbsp;Du, A.&nbsp;Liu, E.-C. Chang, and X.&nbsp;Cao, “Revisiting backdoor attacks against large vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib127.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.18844</em><span class="ltx_text" id="bib.bib127.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_tag_bibitem">[128]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib128.1.1" style="font-size:90%;">
W.&nbsp;Lyu, L.&nbsp;Pang, T.&nbsp;Ma, H.&nbsp;Ling, and C.&nbsp;Chen, “Trojvlm: Backdoor attack against vision language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib128.2.2" style="font-size:90%;">arXiv preprint arXiv:2409.19232</em><span class="ltx_text" id="bib.bib128.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_tag_bibitem">[129]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib129.1.1" style="font-size:90%;">
W.&nbsp;Lyu, J.&nbsp;Yao, S.&nbsp;Gupta, L.&nbsp;Pang, T.&nbsp;Sun, L.&nbsp;Yi, L.&nbsp;Hu, H.&nbsp;Ling, and C.&nbsp;Chen, “Backdooring vision-language models with out-of-distribution data,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib129.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.01264</em><span class="ltx_text" id="bib.bib129.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_tag_bibitem">[130]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib130.1.1" style="font-size:90%;">
J.&nbsp;Sun, C.&nbsp;Wang, J.&nbsp;Wang, Y.&nbsp;Zhang, and C.&nbsp;Xiao, “Safeguarding vision-language models against patched visual prompt injectors,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib130.2.2" style="font-size:90%;">arXiv preprint arXiv:2405.10529</em><span class="ltx_text" id="bib.bib130.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_tag_bibitem">[131]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib131.1.1" style="font-size:90%;">
Y.&nbsp;Zhao, X.&nbsp;Zheng, L.&nbsp;Luo, Y.&nbsp;Li, X.&nbsp;Ma, and Y.-G. Jiang, “Bluesuffix: Reinforced blue teaming for vision-language models against jailbreak attacks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib131.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.20971</em><span class="ltx_text" id="bib.bib131.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_tag_bibitem">[132]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib132.1.1" style="font-size:90%;">
S.&nbsp;Oh, Y.&nbsp;Jin, M.&nbsp;Sharma, D.&nbsp;Kim, E.&nbsp;Ma, G.&nbsp;Verma, and S.&nbsp;Kumar, “Uniguard: Towards universal safety guardrails for jailbreak attacks on multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib132.2.2" style="font-size:90%;">arXiv preprint arXiv:2411.01703</em><span class="ltx_text" id="bib.bib132.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_tag_bibitem">[133]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib133.1.1" style="font-size:90%;">
Q.&nbsp;Liu, C.&nbsp;Shang, L.&nbsp;Liu, N.&nbsp;Pappas, J.&nbsp;Ma, N.&nbsp;A. John, S.&nbsp;Doss, L.&nbsp;Marquez, M.&nbsp;Ballesteros, and Y.&nbsp;Benajiba, “Unraveling and mitigating safety alignment degradation of vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib133.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.09047</em><span class="ltx_text" id="bib.bib133.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_tag_bibitem">[134]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib134.1.1" style="font-size:90%;">
H.&nbsp;Wang, G.&nbsp;Wang, and H.&nbsp;Zhang, “Steering away from harm: An adaptive approach to defending vision language model against jailbreaks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib134.2.2" style="font-size:90%;">arXiv preprint arXiv:2411.16721</em><span class="ltx_text" id="bib.bib134.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_tag_bibitem">[135]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib135.1.1" style="font-size:90%;">
S.&nbsp;S. Ghosal, S.&nbsp;Chakraborty, V.&nbsp;Singh, T.&nbsp;Guan, M.&nbsp;Wang, A.&nbsp;Beirami, F.&nbsp;Huang, A.&nbsp;Velasquez, D.&nbsp;Manocha, and A.&nbsp;S. Bedi, “Immune: Improving safety against jailbreaks in multi-modal llms via inference-time alignment,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib135.2.2" style="font-size:90%;">arXiv preprint arXiv:2411.18688</em><span class="ltx_text" id="bib.bib135.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_tag_bibitem">[136]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib136.1.1" style="font-size:90%;">
Y.&nbsp;Gou, K.&nbsp;Chen, Z.&nbsp;Liu, L.&nbsp;Hong, H.&nbsp;Xu, Z.&nbsp;Li, D.-Y. Yeung, J.&nbsp;T. Kwok, and Y.&nbsp;Zhang, “Eyes closed, safety on: Protecting multimodal llms via image-to-text transformation,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib136.2.2" style="font-size:90%;">ECCV</em><span class="ltx_text" id="bib.bib136.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;Springer, 2024, pp. 388–404.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_tag_bibitem">[137]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib137.1.1" style="font-size:90%;">
S.&nbsp;Fares, K.&nbsp;Ziu, T.&nbsp;Aremu, N.&nbsp;Durasov, M.&nbsp;Takáč, P.&nbsp;Fua, K.&nbsp;Nandakumar, and I.&nbsp;Laptev, “Mirrorcheck: Efficient adversarial defense for vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib137.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.09250</em><span class="ltx_text" id="bib.bib137.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_tag_bibitem">[138]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib138.1.1" style="font-size:90%;">
A.&nbsp;Robey, E.&nbsp;Wong, H.&nbsp;Hassani, and G.&nbsp;J. Pappas, “Smoothllm: Defending large language models against jailbreaking attacks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib138.2.2" style="font-size:90%;">arXiv preprint arXiv:2310.03684</em><span class="ltx_text" id="bib.bib138.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_tag_bibitem">[139]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib139.1.1" style="font-size:90%;">
Y.&nbsp;Xie, M.&nbsp;Fang, R.&nbsp;Pi, and N.&nbsp;Gong, “Gradsafe: Detecting jailbreak prompts for llms via safety-critical gradient analysis,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib139.2.2" style="font-size:90%;">ACL</em><span class="ltx_text" id="bib.bib139.3.3" style="font-size:90%;">, 2024, pp. 507–518.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_tag_bibitem">[140]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib140.1.1" style="font-size:90%;">
R.&nbsp;Rombach, A.&nbsp;Blattmann, D.&nbsp;Lorenz, P.&nbsp;Esser, and B.&nbsp;Ommer, “High-resolution image synthesis with latent diffusion models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib140.2.2" style="font-size:90%;">CVPR</em><span class="ltx_text" id="bib.bib140.3.3" style="font-size:90%;">, 2022, pp. 10 684–10 695.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_tag_bibitem">[141]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib141.1.1" style="font-size:90%;">
F.&nbsp;Bao, S.&nbsp;Nie, K.&nbsp;Xue, C.&nbsp;Li, S.&nbsp;Pu, Y.&nbsp;Wang, G.&nbsp;Yue, Y.&nbsp;Cao, H.&nbsp;Su, and J.&nbsp;Zhu, “One transformer fits all distributions in multi-modal diffusion at scale,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib141.2.2" style="font-size:90%;">ICML</em><span class="ltx_text" id="bib.bib141.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;PMLR, 2023, pp. 1692–1717.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_tag_bibitem">[142]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib142.1.1" style="font-size:90%;">
L.&nbsp;Zhang, A.&nbsp;Rao, and M.&nbsp;Agrawala, “Adding conditional control to text-to-image diffusion models,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib142.2.2" style="font-size:90%;">ICCV</em><span class="ltx_text" id="bib.bib142.3.3" style="font-size:90%;">, 2023, pp. 3836–3847.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_tag_bibitem">[143]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib143.1.1" style="font-size:90%;">
Y.&nbsp;Huang, F.&nbsp;Zhu, J.&nbsp;Tang, P.&nbsp;Zhou, W.&nbsp;Lei, J.&nbsp;Lv, and T.-S. Chua, “Effective and efficient adversarial detection for vision-language models via a single vector,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib143.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.22888</em><span class="ltx_text" id="bib.bib143.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_tag_bibitem">[144]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib144.1.1" style="font-size:90%;">
T.-Y. Lin, M.&nbsp;Maire, S.&nbsp;Belongie, J.&nbsp;Hays, P.&nbsp;Perona, D.&nbsp;Ramanan, P.&nbsp;Dollár, and C.&nbsp;L. Zitnick, “Microsoft coco: Common objects in context,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib144.2.2" style="font-size:90%;">ECCV</em><span class="ltx_text" id="bib.bib144.3.3" style="font-size:90%;">.&nbsp;&nbsp;&nbsp;Springer, 2014, pp. 740–755.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_tag_bibitem">[145]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib145.1.1" style="font-size:90%;">
Y.&nbsp;Chen, K.&nbsp;Sikka, M.&nbsp;Cogswell, H.&nbsp;Ji, and A.&nbsp;Divakaran, “Dress: Instructing large vision-language models to align and interact with humans via natural language feedback,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib145.2.2" style="font-size:90%;">CVPR</em><span class="ltx_text" id="bib.bib145.3.3" style="font-size:90%;">, 2024, pp. 14 239–14 250.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_tag_bibitem">[146]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib146.1.1" style="font-size:90%;">
L.&nbsp;Helff, F.&nbsp;Friedrich, M.&nbsp;Brack, K.&nbsp;Kersting, and P.&nbsp;Schramowski, “Llavaguard: Vlm-based safeguards for vision dataset curation and safety assessment,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib146.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.05113</em><span class="ltx_text" id="bib.bib146.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_tag_bibitem">[147]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib147.1.1" style="font-size:90%;">
D.&nbsp;L. Crone, S.&nbsp;Bode, C.&nbsp;Murawski, and S.&nbsp;M. Laham, “The socio-moral image database (smid): A novel stimulus set for the study of social, moral and affective processes,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib147.2.2" style="font-size:90%;">PloS one</em><span class="ltx_text" id="bib.bib147.3.3" style="font-size:90%;">, p. e0190954, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_tag_bibitem">[148]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib148.1.1" style="font-size:90%;">
C.&nbsp;Schlarmann, N.&nbsp;D. Singh, F.&nbsp;Croce, and M.&nbsp;Hein, “Robust clip: Unsupervised adversarial fine-tuning of vision embeddings for robust large vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib148.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.12336</em><span class="ltx_text" id="bib.bib148.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_tag_bibitem">[149]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib149.1.1" style="font-size:90%;">
J.&nbsp;Li, Q.&nbsp;Wei, C.&nbsp;Zhang, G.&nbsp;Qi, M.&nbsp;Du, Y.&nbsp;Chen, and S.&nbsp;Bi, “Single image unlearning: Efficient machine unlearning in multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib149.2.2" style="font-size:90%;">arXiv preprint arXiv:2405.12523</em><span class="ltx_text" id="bib.bib149.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_tag_bibitem">[150]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib150.1.1" style="font-size:90%;">
T.&nbsp;Chakraborty, E.&nbsp;Shayegani, Z.&nbsp;Cai, N.&nbsp;Abu-Ghazaleh, M.&nbsp;S. Asif, Y.&nbsp;Dong, A.&nbsp;K. Roy-Chowdhury, and C.&nbsp;Song, “Cross-modal safety alignment: Is textual unlearning all you need?” </span><em class="ltx_emph ltx_font_italic" id="bib.bib150.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.02575</em><span class="ltx_text" id="bib.bib150.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_tag_bibitem">[151]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib151.1.1" style="font-size:90%;">
M.&nbsp;Z. Hossain and A.&nbsp;Imteaj, “Sim-clip: Unsupervised siamese adversarial fine-tuning for robust and semantically-rich vision-language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib151.2.2" style="font-size:90%;">arXiv preprint arXiv:2407.14971</em><span class="ltx_text" id="bib.bib151.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_tag_bibitem">[152]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib152.1.1" style="font-size:90%;">
——, “Securing vision-language models with a robust encoder against jailbreak and adversarial attacks,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib152.2.2" style="font-size:90%;">arXiv preprint arXiv:2409.07353</em><span class="ltx_text" id="bib.bib152.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_tag_bibitem">[153]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib153.1.1" style="font-size:90%;">
Y.&nbsp;Chen, H.&nbsp;Li, Z.&nbsp;Zheng, and Y.&nbsp;Song, “Bathe: Defense against the jailbreak attack in multimodal large language models by treating harmful instruction as backdoor trigger,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib153.2.2" style="font-size:90%;">arXiv preprint arXiv:2408.09093</em><span class="ltx_text" id="bib.bib153.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_tag_bibitem">[154]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib154.1.1" style="font-size:90%;">
Z.&nbsp;Ying, A.&nbsp;Liu, S.&nbsp;Liang, L.&nbsp;Huang, J.&nbsp;Guo, W.&nbsp;Zhou, X.&nbsp;Liu, and D.&nbsp;Tao, “Safebench: A safety evaluation framework for multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib154.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.18927</em><span class="ltx_text" id="bib.bib154.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_tag_bibitem">[155]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib155.1.1" style="font-size:90%;">
H.&nbsp;Inan, K.&nbsp;Upasani, J.&nbsp;Chi, R.&nbsp;Rungta, K.&nbsp;Iyer, Y.&nbsp;Mao, M.&nbsp;Tontchev, Q.&nbsp;Hu, B.&nbsp;Fuller, D.&nbsp;Testuggine </span><em class="ltx_emph ltx_font_italic" id="bib.bib155.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib155.3.3" style="font-size:90%;">, “Llama guard: Llm-based input-output safeguard for human-ai conversations,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib155.4.4" style="font-size:90%;">arXiv preprint arXiv:2312.06674</em><span class="ltx_text" id="bib.bib155.5.5" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_tag_bibitem">[156]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib156.1.1" style="font-size:90%;">
H.&nbsp;Zhang, W.&nbsp;Shao, H.&nbsp;Liu, Y.&nbsp;Ma, P.&nbsp;Luo, Y.&nbsp;Qiao, and K.&nbsp;Zhang, “Avibench: Towards evaluating the robustness of large vision-language model on adversarial visual-instructions,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib156.2.2" style="font-size:90%;">arXiv preprint arXiv:2403.09346</em><span class="ltx_text" id="bib.bib156.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_tag_bibitem">[157]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib157.1.1" style="font-size:90%;">
H.&nbsp;Cheng, E.&nbsp;Xiao, and R.&nbsp;Xu, “Typographic attacks in large multimodal models can be alleviated by more informative prompts,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib157.2.2" style="font-size:90%;">arXiv preprint arXiv:2402.19150</em><span class="ltx_text" id="bib.bib157.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_tag_bibitem">[158]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib158.1.1" style="font-size:90%;">
M.&nbsp;Li, L.&nbsp;Li, Y.&nbsp;Yin, M.&nbsp;Ahmed, Z.&nbsp;Liu, and Q.&nbsp;Liu, “Red teaming visual language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib158.2.2" style="font-size:90%;">arXiv preprint arXiv:2401.12915</em><span class="ltx_text" id="bib.bib158.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_tag_bibitem">[159]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib159.1.1" style="font-size:90%;">
S.&nbsp;Chen, Z.&nbsp;Han, B.&nbsp;He, Z.&nbsp;Ding, W.&nbsp;Yu, P.&nbsp;Torr, V.&nbsp;Tresp, and J.&nbsp;Gu, “Red teaming gpt-4v: Are gpt-4v safe against uni/multi-modal jailbreak attacks?” </span><em class="ltx_emph ltx_font_italic" id="bib.bib159.2.2" style="font-size:90%;">arXiv preprint arXiv:2404.03411</em><span class="ltx_text" id="bib.bib159.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_tag_bibitem">[160]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib160.1.1" style="font-size:90%;">
X.&nbsp;Li, H.&nbsp;Zhou, R.&nbsp;Wang, T.&nbsp;Zhou, M.&nbsp;Cheng, and C.-J. Hsieh, “Mossbench: Is your multimodal language model oversensitive to safe queries?” </span><em class="ltx_emph ltx_font_italic" id="bib.bib160.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.17806</em><span class="ltx_text" id="bib.bib160.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_tag_bibitem">[161]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib161.1.1" style="font-size:90%;">
Y.&nbsp;Liu, C.&nbsp;Cai, X.&nbsp;Zhang, X.&nbsp;Yuan, and C.&nbsp;Wang, “Arondight: Red teaming large vision language models with auto-generated multi-modal jailbreak prompts,” in </span><em class="ltx_emph ltx_font_italic" id="bib.bib161.2.2" style="font-size:90%;">ACM MM</em><span class="ltx_text" id="bib.bib161.3.3" style="font-size:90%;">, 2024, pp. 3578–3586.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_tag_bibitem">[162]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib162.1.1" style="font-size:90%;">
K.&nbsp;Zhou, C.&nbsp;Liu, X.&nbsp;Zhao, A.&nbsp;Compalas, D.&nbsp;Song, and X.&nbsp;E. Wang, “Multimodal situational safety,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib162.2.2" style="font-size:90%;">arXiv preprint arXiv:2410.06172</em><span class="ltx_text" id="bib.bib162.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_tag_bibitem">[163]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib163.1.1" style="font-size:90%;">
F.&nbsp;Weng, Y.&nbsp;Xu, C.&nbsp;Fu, and W.&nbsp;Wang, “Mmj-bench: A comprehensive study on jailbreak attacks and defenses for multimodal large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib163.2.2" style="font-size:90%;">arXiv preprint arXiv:2408.08464</em><span class="ltx_text" id="bib.bib163.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_tag_bibitem">[164]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib164.1.1" style="font-size:90%;">
M.&nbsp;Mazeika, L.&nbsp;Phan, X.&nbsp;Yin, A.&nbsp;Zou, Z.&nbsp;Wang, N.&nbsp;Mu, E.&nbsp;Sakhaee, N.&nbsp;Li, S.&nbsp;Basart, B.&nbsp;Li </span><em class="ltx_emph ltx_font_italic" id="bib.bib164.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib164.3.3" style="font-size:90%;">, “Harmbench: A standardized evaluation framework for automated red teaming and robust refusal,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib164.4.4" style="font-size:90%;">arXiv preprint arXiv:2402.04249</em><span class="ltx_text" id="bib.bib164.5.5" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_tag_bibitem">[165]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib165.1.1" style="font-size:90%;">
J.&nbsp;Ji, M.&nbsp;Liu, J.&nbsp;Dai, X.&nbsp;Pan, C.&nbsp;Zhang, C.&nbsp;Bian, B.&nbsp;Chen, R.&nbsp;Sun, Y.&nbsp;Wang, and Y.&nbsp;Yang, “Beavertails: Towards improved safety alignment of llm via a human-preference dataset,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib165.2.2" style="font-size:90%;">NeurIPS</em><span class="ltx_text" id="bib.bib165.3.3" style="font-size:90%;">, vol.&nbsp;36, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_tag_bibitem">[166]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib166.1.1" style="font-size:90%;">
Y.&nbsp;Liu, Y.&nbsp;Yao, J.-F. Ton, X.&nbsp;Zhang, R.&nbsp;G.&nbsp;H. Cheng, Y.&nbsp;Klochkov, M.&nbsp;F. Taufiq, and H.&nbsp;Li, “Trustworthy llms: A survey and guideline for evaluating large language models’ alignment,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib166.2.2" style="font-size:90%;">arXiv preprint arXiv:2308.05374</em><span class="ltx_text" id="bib.bib166.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib167">
<span class="ltx_tag ltx_tag_bibitem">[167]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib167.1.1" style="font-size:90%;">
U.&nbsp;Anwar, A.&nbsp;Saparov, J.&nbsp;Rando, D.&nbsp;Paleka, M.&nbsp;Turpin, P.&nbsp;Hase, E.&nbsp;S. Lubana, E.&nbsp;Jenner, S.&nbsp;Casper, O.&nbsp;Sourbut </span><em class="ltx_emph ltx_font_italic" id="bib.bib167.2.2" style="font-size:90%;">et&nbsp;al.</em><span class="ltx_text" id="bib.bib167.3.3" style="font-size:90%;">, “Foundational challenges in assuring alignment and safety of large language models,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib167.4.4" style="font-size:90%;">arXiv preprint arXiv:2404.09932</em><span class="ltx_text" id="bib.bib167.5.5" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib168">
<span class="ltx_tag ltx_tag_bibitem">[168]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib168.1.1" style="font-size:90%;">
S.&nbsp;Wang, X.&nbsp;Ye, Q.&nbsp;Cheng, J.&nbsp;Duan, S.&nbsp;Li, J.&nbsp;Fu, X.&nbsp;Qiu, and X.&nbsp;Huang, “Cross-modality safety alignment,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib168.2.2" style="font-size:90%;">arXiv preprint arXiv:2406.15279</em><span class="ltx_text" id="bib.bib168.3.3" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib169">
<span class="ltx_tag ltx_tag_bibitem">[169]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib169.1.1" style="font-size:90%;">
X.&nbsp;Chen, Z.&nbsp;Wu, X.&nbsp;Liu, Z.&nbsp;Pan, W.&nbsp;Liu, Z.&nbsp;Xie, X.&nbsp;Yu, and C.&nbsp;Ruan, “Janus-pro: Unified multimodal understanding and generation with data and model scaling,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib169.2.2" style="font-size:90%;">arXiv preprint arXiv:2501.17811</em><span class="ltx_text" id="bib.bib169.3.3" style="font-size:90%;">, 2025.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib170">
<span class="ltx_tag ltx_tag_bibitem">[170]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib170.1.1" style="font-size:90%;">
J.&nbsp;Chen, D.&nbsp;Zhu, X.&nbsp;Shen, X.&nbsp;Li, Z.&nbsp;Liu, P.&nbsp;Zhang, R.&nbsp;Krishnamoorthi, V.&nbsp;Chandra, Y.&nbsp;Xiong, and M.&nbsp;Elhoseiny, “Minigpt-v2: large language model as a unified interface for vision-language multi-task learning,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib170.2.2" style="font-size:90%;">arXiv preprint arXiv:2310.09478</em><span class="ltx_text" id="bib.bib170.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib171">
<span class="ltx_tag ltx_tag_bibitem">[171]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib171.1.1" style="font-size:90%;">
T.&nbsp;Kaufmann, P.&nbsp;Weng, V.&nbsp;Bengs, and E.&nbsp;Hüllermeier, “A survey of reinforcement learning from human feedback,” </span><em class="ltx_emph ltx_font_italic" id="bib.bib171.2.2" style="font-size:90%;">arXiv preprint arXiv:2312.14925</em><span class="ltx_text" id="bib.bib171.3.3" style="font-size:90%;">, 2023.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">报告问题</font></font></font></button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" width="11" height="14">
            </a><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由 L A T E xml <img height="14" width="11" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"> 生成</font></font></font>
        </div></div><footer id="footer" class="ltx_document" default-translate="no">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>/** 基础色阶定义 **/
:root,
#mount[data-theme="light"],
#mount:not([data-theme="dark"]) {
  /* 中性灰阶（light） */
  --c-00: #000000;
  --c-22: #222222;
  --c-33: #333333;
  --c-66: #666666;
  --c-83: #838383;
  --c-99: #999999;
  --c-c7: #c7c7c7;
  --c-cc: #cccccc;
  --c-e6: #e6e6e6;
  --c-f5: #f5f5f5;
  --c-ff: #ffffff;
  /* 品牌主色阶（light） */
  --p-main: #ea4c89;
  --p-hover: #ec5e95;
  --p-active: #e34a85;
  --p-special: #ee71a2;
  --p-disabled: #f4a5c4;
  --p-text-disabled: #f9c9dc;
  --p-weak: #fdedf3;
  /* Surface 层级（light，TC 填充-1） */
  --s-1: #f3f5f6;
  --s-1-hover: #f6f8f9;
  --s-1-active: #edf1f2;
  --s-1-weak: #fafbfb;
  /* 输入/边框（light，TC 填充-2） */
  --input-bg-base: #fafbfc;
  --input-border: #ecf0f7;
  --input-border-strong: #e0e0e6;
  --input-bg-strong: #fafdff;
}

:root[data-theme="dark"],
[data-theme="dark"] {
  /* 中性灰阶（dark） */
  --c-00: #ffffff;
  --c-22: #dbdbdb;
  --c-33: #dbdbdb;
  --c-66: #b3b3b3;
  --c-83: #838383;
  --c-99: #707070;
  --c-c7: #666666;
  --c-cc: #5c5c5c;
  --c-e6: #3b3b3b;
  --c-f5: #262626;
  --c-ff: #222222;
  /* 品牌主色阶（dark） */
  --p-main: #e23c7c;
  --p-hover: #ea4c89;
  --p-active: #d5467d;
  --p-special: #a93a65;
  --p-disabled: #7e2f4d;
  --p-text-disabled: #522335;
  --p-weak: #26171d;
  /* Surface 层级（dark，TC 填充-1） */
  --s-1: #2d2e2f;
  --s-1-hover: #323434;
  --s-1-active: #202121;
  --s-1-weak: #262627;
  /* 输入/边框（dark，TC 填充-2） */
  --input-bg-base: #2b2d30;
  --input-border: #3e434b;
  --input-border-strong: #43474b;
  --input-bg-strong: #1f2123;
}

:root,
#mount [data-theme] {
  /* 业务/通用变量引用色阶（全局可见，含 Shadow DOM） */
  --primary: var(--p-main);
  --primary-hover: var(--p-hover);
  --primary-inverse: #fff;
  --modal-background: var(--s-1);
  --modal-border: var(--input-border);
  --modal-text: var(--c-22);
  --modal-text-secondary: var(--c-66);
  --modal-error: var(--p-main);
  --modal-required: #f53f3f;
  --modal-success: #68cd52;
  --modal-button-background: var(--p-main);
  --modal-button-text: var(--c-ff);
  --modal-input-background: var(--input-bg-base);
  --modal-check-color: var(--p-main);
  --background-color: var(--c-ff);
  --background-light-green: var(--s-1-weak, #f5f7f9);
  --text-black-2: var(--c-22);
  --text-gray-2: var(--c-22);
  --text-gray-6: var(--c-66);
  --text-gray-9: var(--c-99);
  --text-gray-c2: var(--c-c7);
  --switch-background-color: var(--c-c7, hsl(205deg, 16%, 77%));
  --float-ball-more-button-border-color: var(--c-f5, #f6f6f6);
  --float-ball-more-button-background-color: var(--c-ff);
  --float-ball-more-button-svg-color: #6c6f73;
  --service-bg-hover: var(--s-1-hover, #f7faff);
  --service-bg: var(--s-1-weak, #fafbfb);
}

#mount {
  --font-family: var(
    system-ui,
    -apple-system,
    "Segoe UI",
    "Roboto",
    "Ubuntu",
    "Cantarell",
    "Noto Sans",
    sans-serif,
    "Apple Color Emoji",
    "Segoe UI Emoji",
    "Segoe UI Symbol",
    "Noto Color Emoji"
  );
  /* PC/H5 兼容的字号、间距、圆角、阴影变量 */
  --f-12: 12px;
  --f-14: 14px;
  --f-15: 15px;
  --f-16: 16px;
  --f-18: 18px;
  --f-20: 20px;
  --space-4: 4px;
  --space-6: 6px;
  --space-8: 8px;
  --space-12: 12px;
  --space-16: 16px;
  --space-18: 18px;
  --space-24: 24px;
  --radius-8: 8px;
  --radius-12: 12px;
  --radius-16: 16px;
  --control-height-lg: 44px;
  --width-28: 28px;
  --width-24: 24px;
  --width-20: 20px;
  --width-18: 18px;
  --width-16: 16px;
  --width-label-md: 56px;
  --shadow-lg: 0 18px 48px rgba(0, 0, 0, 0.12);

  /* 常规变量 */
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 2px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  /* 兼容旧变量：主色直接引用品牌主色阶 */
  --primary: var(--p-main);
  --primary-hover: var(--p-hover);
  --primary-inverse: #fff;
  /* Modal 业务变量引用色阶 */
  --modal-background: var(--s-1);
  --modal-border: var(--input-border);
  --modal-text: var(--c-22);
  --modal-text-secondary: var(--c-66);
  --modal-error: var(--p-main);
  --modal-required: #f53f3f;
  --modal-success: #68cd52;
  --modal-button-background: var(--p-main);
  --modal-button-text: var(--c-ff);
  --modal-input-background: var(--input-bg-base);
  --modal-check-color: var(--p-main);
  --background-color: var(--c-ff);
  --background-light-green: var(--s-1-weak, #f5f7f9);
  --text-black-2: var(--c-22);
  --text-gray-2: var(--c-22);
  --text-gray-6: var(--c-66);
  --text-gray-9: var(--c-99);
  --text-gray-c2: var(--c-c7);
  --switch-background-color: var(--c-c7, hsl(205deg, 16%, 77%));
  --float-ball-more-button-border-color: var(--c-f5, #f6f6f6);
  --float-ball-more-button-background-color: var(--c-ff);
  --float-ball-more-button-svg-color: #6c6f73;
  --service-bg-hover: var(--s-1-hover, #f7faff);
  --service-bg: var(--s-1-weak, #fafbfb);
  line-height: var(--line-height);
  font-family: var(--font-family);
  font-size: var(--font-size);
}

@media (max-width: 480px) {
  :root,
  #mount {
    --f-12: 10px;
    --f-14: 12px;
    --f-15: 13px;
    --f-16: 14px;
    --f-18: 16px;
    --f-20: 18px;
    --space-4: 4px;
    --space-6: 4px;
    --space-8: 6px;
    --space-12: 8px;
    --space-16: 12px;
    --space-18: 14px;
    --space-24: 18px;
    --radius-8: 6px;
    --radius-12: 10px;
    --radius-16: 12px;
    --control-height-lg: 38px;
    --shadow-lg: 0 12px 32px rgba(0, 0, 0, 0.1);
    --width-28: 24px;
    --width-24: 20px;
    --width-20: 16px;
    --width-18: 14px;
    --width-16: 12px;
    --width-label-md: 52px;
  }
}

#mount * {
  box-sizing: border-box;
}

[hidden] {
  display: none !important;
}

:where(#mount) a,
:where(#mount) [role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
:where(#mount) a:is([aria-current], :hover, :active, :focus),
:where(#mount) [role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}

:where(#mount) label {
  font-size: 13px;
  line-height: 1.3;
  color: var(--text-gray-2, #222222);
}

:where(#mount) button {
  width: 100%;
  font-family: inherit;
  font-size: 15px;
  line-height: 1.3;
  min-height: 44px;
  border-radius: 12px;
  padding: 0 14px;
  border: none;
  background-color: var(--primary, #ea4c89);
  color: #ffffff;
  cursor: pointer;
  transition: background-color 0.2s ease, box-shadow 0.2s ease, color 0.2s ease;
}

:where(#mount) button:hover {
  background-color: var(--primary-hover, #f082ac);
}

:where(#mount) button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

:where(#mount) select,
:where(#mount) input,
:where(#mount) textarea {
  font-family: inherit;
  color: var(--text-gray-2, #222222);
}

:where(#mount) select {
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  font-family: inherit;
  color: var(--text-gray-2, inherit);
  font-size: 13px;
  line-height: 1.3;
  outline: none;
  padding: 8px 16px;
  border: none;
  border-radius: 12px;
  background-color: var(--popup-item-background-color, transparent);
  background-image: var(--icon-xia, none);
  background-repeat: no-repeat;
  background-position: center right 12px;
  background-size: 16px auto;
  cursor: pointer;
}

:where(#mount) input[type="checkbox"] {
  accent-color: var(--primary, #ea4c89);
}

[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

:where(#mount) [type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
:where(#mount) [type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
:where(#mount) [type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
:where(#mount) [type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
:where(#mount) [type="checkbox"][role="switch"]:checked {
  background-image: none;
}
:where(#mount) [type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

:where(#mount) [type="checkbox"][aria-invalid="false"],
:where(#mount) [type="checkbox"]:checked[aria-invalid="false"],
:where(#mount) [type="radio"][aria-invalid="false"],
:where(#mount) [type="radio"]:checked[aria-invalid="false"],
:where(#mount) [type="checkbox"][role="switch"][aria-invalid="false"],
:where(#mount) [type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(#mount) [type="checkbox"][aria-invalid="true"],
:where(#mount) [type="checkbox"]:checked[aria-invalid="true"],
:where(#mount) [type="radio"][aria-invalid="true"],
:where(#mount) [type="radio"]:checked[aria-invalid="true"],
:where(#mount) [type="checkbox"][role="switch"][aria-invalid="true"],
:where(#mount) [type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

.text-black {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.inline-flex {
  display: inline-flex;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

#mount {
  min-width: 268px;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}



.activity-tips {
  border-radius: 8px;
  padding: 0px 8px;
  min-height: 28px;
  background: linear-gradient(83deg, #FACCDE -0.87%, #FCE7EF 43.13%, #FBD6E4 72.08%, #FFB3D1 96.34%);  gap: 2px;
  color: #333;
  cursor: pointer;
  gap: 4px;
}

.activity-tips-icon {
  width: 18px;
  height: 18px;
  flex-shrink: 0;
}

.countdown-container {
  min-width: 50px;
  text-align: left;
  font-weight: 600;
  font-size: 12px;
  letter-spacing: 0.01em;
}

.activity-tips-text {
  font-weight: 600;
  max-width: 100px;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 100%;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #b3b3b3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="light" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 261px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg></div></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#68CD52"></circle><path d="M1.40857 5.87858L2.24148 5.18962L4.15344 6.64214C4.15344 6.64214 6.33547 4.15566 9.00658 2.48145L9.32541 2.87514C9.32541 2.87514 6.28665 5.55844 4.71735 9.07881L1.40857 5.87858Z" fill="white"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; top: 261px; right: 65px;"></div></div></div></div></template></div></html>