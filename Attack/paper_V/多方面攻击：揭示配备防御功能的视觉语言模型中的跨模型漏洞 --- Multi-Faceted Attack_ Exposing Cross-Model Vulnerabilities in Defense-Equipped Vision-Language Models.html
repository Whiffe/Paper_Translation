<!DOCTYPE html>
<!-- saved from url=(0071)https://arxiv.org/html/2511.16110?_immersive_translate_auto_translate=1 -->
<html lang="en" imt-state="dual" imt-trans-position="after" data-theme="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models</title>
<!--Generated on Thu Nov 20 07:01:18 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/arxiv-html-papers-20250916.css" rel="stylesheet" type="text/css">
<script src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/bootstrap.bundle.min.js"></script><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-toast {
  display: flex;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  right: 0;
  top: 1%;
  width: fit-content;
  padding: 12px 20px;
  margin: auto;
  overflow: auto;
  background: #fef6f9;
  box-shadow: 0px 4px 10px 0px rgba(0, 10, 30, 0.06);
  font-size: 15px;
  border-radius: 8px;
  color: #333;
}

.immersive-translate-toast-content {
  display: flex;
  flex-direction: row;
  align-items: center;
}

.immersive-translate-toast-hidden {
  margin: 0 20px 0 72px;
  text-decoration: underline;
  cursor: pointer;
}

.immersive-translate-toast-close {
  color: #666666;
  font-size: 20px;
  font-weight: bold;
  padding: 0 10px;
  cursor: pointer;
}

@media screen and (max-width: 768px) {
  .immersive-translate-toast {
    top: 0;
    padding: 12px 0px 0 10px;
  }
  .immersive-translate-toast-content {
    flex-direction: column;
    text-align: center;
  }
  .immersive-translate-toast-hidden {
    margin: 10px auto;
  }
}

.immersive-translate-dialog {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  display: flex;
  width: 300px;
  flex-direction: column;
  align-items: center;
  font-size: 15px;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  margin: auto;
  height: fit-content;
  border-radius: 20px;
  background-color: #fff;
}

.immersive-translate-modal {
  display: none;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
  word-break: break-all;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style>
<script src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/html2canvas.min.js"></script>
<script src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/addons_new.js"></script>
<script src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/feedbackOverlay.js"></script>
<!--<base href="/html/2511.16110v1/">--><base href="."><link rel="stylesheet" href="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-default-injected-css">:root {
  --immersive-translate-theme-underline-borderColor: #72ece9;
  --immersive-translate-theme-nativeUnderline-borderColor: #72ece9;
  --immersive-translate-theme-nativeDashed-borderColor: #72ece9;
  --immersive-translate-theme-nativeDotted-borderColor: #72ece9;
  --immersive-translate-theme-highlight-backgroundColor: #ffff00;
  --immersive-translate-theme-dashed-borderColor: #59c1bd;
  --immersive-translate-theme-blockquote-borderColor: #cc3355;
  --immersive-translate-theme-thinDashed-borderColor: #ff374f;
  --immersive-translate-theme-dashedBorder-borderColor: #94a3b8;
  --immersive-translate-theme-dashedBorder-borderRadius: 0;
  --immersive-translate-theme-solidBorder-borderColor: #94a3b8;
  --immersive-translate-theme-solidBorder-borderRadius: 0;
  --immersive-translate-theme-dotted-borderColor: #94a3b8;
  --immersive-translate-theme-wavy-borderColor: #72ece9;
  --immersive-translate-theme-dividingLine-borderColor: #94a3b8;
  --immersive-translate-theme-grey-textColor: #2f4f4f;
  --immersive-translate-theme-marker-backgroundColor: #fbda41;
  --immersive-translate-theme-marker-backgroundColor-rgb: 251, 218, 65;
  --immersive-translate-theme-marker2-backgroundColor: #ffff00;
  --immersive-translate-theme-background-backgroundColor: #dbafaf;
  --immersive-translate-theme-background-backgroundColor-rgb: 219, 175, 175;
  --immersive-translate-theme-background-backgroundOpacity: 12;
  --immersive-translate-theme-opacity-opacity: 10;
}

[imt-state="dual"] .immersive-translate-target-translation-pre-whitespace {
  white-space: pre-wrap !important;
}

[imt-state="dual"] .immersive-translate-pdf-target-container {
  position: absolute;
  background-color: #fff;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica,
    sans-serif;
  top: 0;
  width: 600px;
  height: 100%;
  z-index: 2;
  line-height: 1.3;
  font-size: 16px;
}
[imt-state="dual"] .immersive-translate-target-wrapper[dir="rtl"] {
  text-align: right;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper {
  color: rgb(0, 0, 0);
  white-space: normal;
  position: absolute;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper
  font {
  color: inherit;
  white-space: inherit;
  position: unset;
}

[imt-state="translation"] .immersive-translate-target-wrapper > br {
  display: none;
}

[imt-state="translation"]
  .immersive-translate-target-translation-block-wrapper {
  margin: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-block-wrapper {
  margin: 8px 0 !important;
  display: inline-block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  display: block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  margin-top: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-pdf-block-wrapper {
  margin: 0 !important;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-grey-inner {
  color: var(--immersive-translate-theme-grey-textColor);
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-underline-inner {
  border-bottom: 1px solid
    var(--immersive-translate-theme-underline-borderColor) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeUnderline-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeUnderline-borderColor
  ) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDashed-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDashed-borderColor
  ) !important;
  text-decoration-style: dashed !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-thinDashed-inner {
  border-bottom: 1px dashed
    var(--immersive-translate-theme-thinDashed-borderColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dotted-inner {
  background-image: linear-gradient(
    to right,
    var(--immersive-translate-theme-dotted-borderColor) 30%,
    rgba(255, 255, 255, 0) 0%
  );
  background-position: bottom;
  background-size: 5px 1px;
  background-repeat: repeat-x;
  padding-bottom: 3px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDotted-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDotted-borderColor
  ) !important;
  text-decoration-style: dotted !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-wavy-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-wavy-borderColor
  ) !important;
  text-decoration-style: wavy !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dashed-inner {
  background: linear-gradient(
      to right,
      var(--immersive-translate-theme-dashed-borderColor) 0%,
      var(--immersive-translate-theme-dashed-borderColor) 50%,
      transparent 50%,
      transparent 100%
    )
    repeat-x left bottom;
  background-size: 8px 2px;
  padding-bottom: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {
  content: "";
  display: block;
  max-width: 80px;
  width: 10%;
  border-top: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  padding-top: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dividingLine::before {
  content: "";
  border-left: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  max-height: 16px;
  height: 16px;
  padding-left: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-highlight-inner {
  background: var(--immersive-translate-theme-highlight-backgroundColor);
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-marker {
  line-height: 1.5em;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker2-inner {
  font-weight: bold;
  text-shadow: 10px 0px 3px
      var(--immersive-translate-theme-marker2-backgroundColor),
    16px 3px 9px var(--immersive-translate-theme-marker2-backgroundColor),
    2px 0px 6px var(--immersive-translate-theme-marker2-backgroundColor),
    -12px 0px 12px var(--immersive-translate-theme-marker2-backgroundColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker-inner {
  /* TODO: add more texture */
  background: linear-gradient(
    to right,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.1),
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 3%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 35%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 70%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.8) 95%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.3)
  );
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-weakening {
  opacity: 0.618 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-italic {
  font-style: italic !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-bold {
  font-weight: bold !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-paper {
  margin: 8px 0;
  box-shadow: rgba(0, 0, 0, 0.24) 0px 3px 8px;
  padding: 16px 32px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-blockquote {
  border-left: 4px solid var(--immersive-translate-theme-blockquote-borderColor) !important;
  padding-left: 12px !important;
  margin-top: 4px;
  margin-bottom: 4px;
  padding-top: 4px;
  padding-bottom: 4px;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-mask-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-mask-inner {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

/* opacity theme start */

[imt-state="dual"] .immersive-translate-target-translation-theme-opacity-inner {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-opacity-inner {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner,
[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: none !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-mask-inner:hover {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

/* opacity theme end */

/* background theme start */
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-background {
  margin: 8px 0;
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  border-radius: 4px;
  box-shadow: unset !important;
  padding: 12px;
  display: inline-block;
}
[imt-state="dual"]
  .immersive-translate-target-translation-theme-background-inner {
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  padding-left: 6px;
  padding-right: 6px;
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper
  .immersive-translate-target-translation-theme-background-inner {
  background: unset;
  padding-left: unset;
  padding-right: unset;
}
/* background theme end */

/* vertical css , please remain it in the last one. */
.immersive-translate-target-translation-vertical-block-wrapper {
  margin: 0px 8px !important;
}

.immersive-translate-text {
  font-size: 15px !important;
}

.immersive-translate-error-toast {
  position: fixed;
  top: 5%;
  z-index: 99999999;
  left: 0;
  right: 0;
  margin: auto;
  max-width: 300px;
  padding: 16px;
  border-radius: 12px;
  background-color: rgba(0, 0, 0, 0.8);
  display: flex;
  flex-direction: row;
  justify-content: space-between;
}

@media all and (min-width: 750px) {
  .immersive-translate-error-toast {
    max-width: 400px;
  }
}

.immersive-translate-clickable-button {
  cursor: pointer;
}

.immersive-translate-help-button {
  cursor: pointer;
}

.immersive-translate-loading-text:before {
  content: "...";
}

/* dark mode for loading */

@media only screen and (prefers-color-scheme: dark) {
  .immersive-translate-loading {
    border: 2px rgba(255, 255, 255, 0.25) solid !important;
    border-top: 2px rgba(255, 255, 255, 1) solid !important;
  }
}

.immersive-translate-error-wrapper {
  position: relative;
  display: inline-flex;
  padding: 6px;
  margin: 0 12px;
  white-space: nowrap;
  font-size: 0.9em;
}
[lang="zh-CN"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}
[lang="zh-TW"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}

.immersive-translate-tooltip {
  position: relative;
  display: inline-flex;
  /* little indicater to indicate it's hoverable */
}

.immersive-translate-tooltip-content {
  /* here's the magic */
  position: absolute;
  z-index: 100000000000;

  left: 50%;
  bottom: 0;
  transform: translate(-50%, 110%);
  line-height: 1;
  /* and add a small left margin */

  /* basic styles */
  width: max-content;
  max-width: 250px;
  word-wrap: break-word;
  white-space: pre-line;
  padding: 10px;
  border-radius: 10px;
  background: #000c;
  color: #fff;
  text-align: center;
  font-size: 14px;
  display: none;
  /* hide by default */
}

.immersive-translate-tooltip:hover .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip:hover + .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip-content-table {
  left: unset !important;
  bottom: unset !important;
  transform: translate(-10%, 50%) !important;
}

.immersive-translate-tooltip:hover:before {
  display: inline-block;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5);
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--bg-2, #fff);
  font-size: 14px;
}
</style><style data-id="immersive-translate-user-custom-style">:root {

.immersive-translate-target-inner { font-family: inherit; }


.immersive-translate-target-inner { font-family: inherit; }
}
</style><style data-id="immersive-translate-dynamic-injected-css">.immersive-translate-target-wrapper[dir='rtl'] {text-align: right;display:block!important;}
[dir='rtl'] .immersive-translate-target-wrapper:not([dir]) {text-align:left;direction:ltr;}
.immersive-translate-target-wrapper {word-break:break-word; user-select:text;}
[imt-state=dual] .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {display:block;}
[imt-trans-position=before] .immersive-translate-target-translation-block-wrapper {display:block!important;}
</style></head><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>@charset "UTF-8";
/*!
 * Pico.css v1.5.6 (https://picocss.com)
 * Copyright 2019-2022 - Licensed under MIT
 */
/**
 * Theme: default
 */
#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 0.25rem;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 1rem;
  --typography-spacing-vertical: 1.5rem;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 0.75rem;
  --form-element-spacing-horizontal: 1rem;
  --nav-element-spacing-vertical: 1rem;
  --nav-element-spacing-horizontal: 0.5rem;
  --nav-link-spacing-vertical: 0.5rem;
  --nav-link-spacing-horizontal: 0.5rem;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(0.25rem);
}
@media (min-width: 576px) {
  #mount {
    --font-size: 17px;
  }
}
@media (min-width: 768px) {
  #mount {
    --font-size: 18px;
  }
}
@media (min-width: 992px) {
  #mount {
    --font-size: 19px;
  }
}
@media (min-width: 1200px) {
  #mount {
    --font-size: 20px;
  }
}

@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2);
  }
}
@media (min-width: 768px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3);
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3.5);
  }
}

@media (min-width: 576px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}
@media (min-width: 992px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.75);
  }
}
@media (min-width: 1200px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 2);
  }
}

dialog > article {
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
}
@media (min-width: 576px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 3);
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}

a {
  --text-decoration: none;
}
a.secondary,
a.contrast {
  --text-decoration: underline;
}

small {
  --font-size: 0.875em;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  --font-weight: 700;
}

h1 {
  --font-size: 2rem;
  --typography-spacing-vertical: 3rem;
}

h2 {
  --font-size: 1.75rem;
  --typography-spacing-vertical: 2.625rem;
}

h3 {
  --font-size: 1.5rem;
  --typography-spacing-vertical: 2.25rem;
}

h4 {
  --font-size: 1.25rem;
  --typography-spacing-vertical: 1.874rem;
}

h5 {
  --font-size: 1.125rem;
  --typography-spacing-vertical: 1.6875rem;
}

[type="checkbox"],
[type="radio"] {
  --border-width: 2px;
}

[type="checkbox"][role="switch"] {
  --border-width: 2px;
}

thead th,
thead td,
tfoot th,
tfoot td {
  --border-width: 3px;
}

:not(thead, tfoot) > * > td {
  --font-size: 0.875em;
}

pre,
code,
kbd,
samp {
  --font-family: "Menlo", "Consolas", "Roboto Mono", "Ubuntu Monospace",
    "Noto Mono", "Oxygen Mono", "Liberation Mono", monospace,
    "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
}

kbd {
  --font-weight: bolder;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --background-color: #fff;
  --background-light-green: #f5f7f9;
  --color: hsl(205deg, 20%, 32%);
  --h1-color: hsl(205deg, 30%, 15%);
  --h2-color: #24333e;
  --h3-color: hsl(205deg, 25%, 23%);
  --h4-color: #374956;
  --h5-color: hsl(205deg, 20%, 32%);
  --h6-color: #4d606d;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: hsl(205deg, 20%, 94%);
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 90%, 32%);
  --primary-focus: rgba(16, 149, 193, 0.125);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 20%, 32%);
  --secondary-focus: rgba(89, 107, 120, 0.125);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 30%, 15%);
  --contrast-hover: #000;
  --contrast-focus: rgba(89, 107, 120, 0.125);
  --contrast-inverse: #fff;
  --mark-background-color: #fff2ca;
  --mark-color: #543a26;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: transparent;
  --form-element-border-color: hsl(205deg, 14%, 68%);
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: transparent;
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 18%, 86%);
  --form-element-disabled-border-color: hsl(205deg, 14%, 68%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #c62828;
  --form-element-invalid-active-border-color: #d32f2f;
  --form-element-invalid-focus-color: rgba(211, 47, 47, 0.125);
  --form-element-valid-border-color: #388e3c;
  --form-element-valid-active-border-color: #43a047;
  --form-element-valid-focus-color: rgba(67, 160, 71, 0.125);
  --switch-background-color: hsl(205deg, 16%, 77%);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: hsl(205deg, 18%, 86%);
  --range-active-border-color: hsl(205deg, 16%, 77%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: #f6f8f9;
  --code-background-color: hsl(205deg, 20%, 94%);
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 40%, 50%);
  --code-property-color: hsl(185deg, 40%, 40%);
  --code-value-color: hsl(40deg, 20%, 50%);
  --code-comment-color: hsl(205deg, 14%, 68%);
  --accordion-border-color: var(--muted-border-color);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: var(--background-color);
  --card-border-color: var(--muted-border-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(27, 40, 50, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(27, 40, 50, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(27, 40, 50, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(27, 40, 50, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(27, 40, 50, 0.04302),
    0.5rem 1rem 6rem rgba(27, 40, 50, 0.06),
    0 0 0 0.0625rem rgba(27, 40, 50, 0.015);
  --card-sectionning-background-color: #fbfbfc;
  --dropdown-background-color: #fbfbfc;
  --dropdown-border-color: #e1e6eb;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: hsl(205deg, 20%, 94%);
  --modal-overlay-background-color: rgba(213, 220, 226, 0.7);
  --progress-background-color: hsl(205deg, 18%, 86%);
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(198, 40, 40)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(56, 142, 60)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  --float-ball-more-button-border-color: #f6f6f6;
  --float-ball-more-button-background-color: #ffffff;
  --float-ball-more-button-svg-color: #6c6f73;
  color-scheme: light;
  --service-bg-hover: #f7faff;
  --service-bg: #fafbfb;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --background-color: #11191f;
    --float-ball-more-button-background-color: #ffffff;
    --background-light-green: #141e26;
    --color: hsl(205deg, 16%, 77%);
    --h1-color: hsl(205deg, 20%, 94%);
    --h2-color: #e1e6eb;
    --h3-color: hsl(205deg, 18%, 86%);
    --h4-color: #c8d1d8;
    --h5-color: hsl(205deg, 16%, 77%);
    --h6-color: #afbbc4;
    --muted-color: hsl(205deg, 10%, 50%);
    --muted-border-color: #1f2d38;
    --primary: hsl(195deg, 85%, 41%);
    --primary-hover: hsl(195deg, 80%, 50%);
    --primary-focus: rgba(16, 149, 193, 0.25);
    --primary-inverse: #fff;
    --secondary: hsl(205deg, 15%, 41%);
    --secondary-hover: hsl(205deg, 10%, 50%);
    --secondary-focus: rgba(115, 130, 140, 0.25);
    --secondary-inverse: #fff;
    --contrast: hsl(205deg, 20%, 94%);
    --contrast-hover: #fff;
    --contrast-focus: rgba(115, 130, 140, 0.25);
    --contrast-inverse: #000;
    --mark-background-color: #d1c284;
    --mark-color: #11191f;
    --ins-color: #388e3c;
    --del-color: #c62828;
    --blockquote-border-color: var(--muted-border-color);
    --blockquote-footer-color: var(--muted-color);
    --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --form-element-background-color: #11191f;
    --form-element-border-color: #374956;
    --form-element-color: var(--color);
    --form-element-placeholder-color: var(--muted-color);
    --form-element-active-background-color: var(
      --form-element-background-color
    );
    --form-element-active-border-color: var(--primary);
    --form-element-focus-color: var(--primary-focus);
    --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
    --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
    --form-element-disabled-opacity: 0.5;
    --form-element-invalid-border-color: #b71c1c;
    --form-element-invalid-active-border-color: #c62828;
    --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
    --form-element-valid-border-color: #2e7d32;
    --form-element-valid-active-border-color: #388e3c;
    --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
    --switch-background-color: #374956;
    --switch-color: var(--primary-inverse);
    --switch-checked-background-color: var(--primary);
    --range-border-color: #24333e;
    --range-active-border-color: hsl(205deg, 25%, 23%);
    --range-thumb-border-color: var(--background-color);
    --range-thumb-color: var(--secondary);
    --range-thumb-hover-color: var(--secondary-hover);
    --range-thumb-active-color: var(--primary);
    --table-border-color: var(--muted-border-color);
    --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
    --code-background-color: #18232c;
    --code-color: var(--muted-color);
    --code-kbd-background-color: var(--contrast);
    --code-kbd-color: var(--contrast-inverse);
    --code-tag-color: hsl(330deg, 30%, 50%);
    --code-property-color: hsl(185deg, 30%, 50%);
    --code-value-color: hsl(40deg, 10%, 50%);
    --code-comment-color: #4d606d;
    --accordion-border-color: var(--muted-border-color);
    --accordion-active-summary-color: var(--primary);
    --accordion-close-summary-color: var(--color);
    --accordion-open-summary-color: var(--muted-color);
    --card-background-color: #141e26;
    --card-border-color: var(--card-background-color);
    --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
      0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
      0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
      0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
      0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
      0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
    --card-sectionning-background-color: #18232c;
    --dropdown-background-color: hsl(205deg, 30%, 15%);
    --dropdown-border-color: #24333e;
    --dropdown-box-shadow: var(--card-box-shadow);
    --dropdown-color: var(--color);
    --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
    --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
    --progress-background-color: #24333e;
    --progress-color: var(--primary);
    --loading-spinner-opacity: 0.5;
    --tooltip-background-color: var(--contrast);
    --tooltip-color: var(--contrast-inverse);
    --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
    --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
    --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
    --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
    --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
    --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
    color-scheme: dark;
    --service-bg-hover: #22292f;
    --service-bg: rgba(0, 0, 0, 0.1);
  }
}
[data-theme="dark"] {
  --background-color: #11191f;
  --float-ball-more-button-background-color: #191919;
  --background-light-green: #141e26;
  --color: hsl(205deg, 16%, 77%);
  --h1-color: hsl(205deg, 20%, 94%);
  --h2-color: #e1e6eb;
  --h3-color: hsl(205deg, 18%, 86%);
  --h4-color: #c8d1d8;
  --h5-color: hsl(205deg, 16%, 77%);
  --h6-color: #afbbc4;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: #1f2d38;
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 80%, 50%);
  --primary-focus: rgba(16, 149, 193, 0.25);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 10%, 50%);
  --secondary-focus: rgba(115, 130, 140, 0.25);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 20%, 94%);
  --contrast-hover: #fff;
  --contrast-focus: rgba(115, 130, 140, 0.25);
  --contrast-inverse: #000;
  --mark-background-color: #d1c284;
  --mark-color: #11191f;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: #11191f;
  --form-element-border-color: #374956;
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: var(--form-element-background-color);
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
  --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #b71c1c;
  --form-element-invalid-active-border-color: #c62828;
  --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
  --form-element-valid-border-color: #2e7d32;
  --form-element-valid-active-border-color: #388e3c;
  --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
  --switch-background-color: #374956;
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: #24333e;
  --range-active-border-color: hsl(205deg, 25%, 23%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
  --code-background-color: #18232c;
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 30%, 50%);
  --code-property-color: hsl(185deg, 30%, 50%);
  --code-value-color: hsl(40deg, 10%, 50%);
  --code-comment-color: #4d606d;
  --accordion-border-color: var(--muted-border-color);
  --accordion-active-summary-color: var(--primary);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: #141e26;
  --card-border-color: var(--card-background-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
    0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
  --card-sectionning-background-color: #18232c;
  --dropdown-background-color: hsl(205deg, 30%, 15%);
  --dropdown-border-color: #24333e;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
  --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
  --progress-background-color: #24333e;
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  color-scheme: dark;
  --service-bg: rgba(0, 0, 0, 0.1);
}

progress,
[type="checkbox"],
[type="radio"],
[type="range"] {
  accent-color: var(--primary);
}

/**
 * Document
 * Content-box & Responsive typography
 */
*,
*::before,
*::after {
  box-sizing: border-box;
  background-repeat: no-repeat;
}

::before,
::after {
  text-decoration: inherit;
  vertical-align: inherit;
}

:where(#mount) {
  -webkit-tap-highlight-color: transparent;
  -webkit-text-size-adjust: 100%;
  -moz-text-size-adjust: 100%;
  text-size-adjust: 100%;
  background-color: var(--background-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  line-height: var(--line-height);
  font-family: var(--font-family);
  text-rendering: optimizeLegibility;
  overflow-wrap: break-word;
  cursor: default;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
}

/**
 * Sectioning
 * Container and responsive spacings for header, main, footer
 */
main {
  display: block;
}

#mount {
  width: 100%;
  margin: 0;
}
#mount > header,
#mount > main,
#mount > footer {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
}
@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 2px !important;
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 12px !important;
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 24px !important;
  }
}

/**
* Container
*/
.container,
.container-fluid {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding-right: var(--spacing);
  padding-left: var(--spacing);
}
/*
@media (min-width: 576px) {
  .container {
    max-width: 510px;
    padding-right: 0;
    padding-left: 0;
  }
}
@media (min-width: 768px) {
  .container {
    max-width: 700px;
  }
} */
@media (min-width: 992px) {
  .container {
    max-width: 920px;
  }
}
@media (min-width: 1200px) {
  .container {
    max-width: 1130px;
  }
}

/**
 * Section
 * Responsive spacings for section
 */
section {
  margin-bottom: var(--block-spacing-vertical);
}

/**
* Grid
* Minimal grid system with auto-layout columns
*/
.grid {
  grid-column-gap: var(--grid-spacing-horizontal);
  grid-row-gap: var(--grid-spacing-vertical);
  display: grid;
  grid-template-columns: 1fr;
  margin: 0;
}
@media (min-width: 1280px) {
  .grid {
    grid-template-columns: repeat(auto-fit, minmax(0%, 1fr));
  }
}
.grid > * {
  min-width: 0;
}

/**
 * Horizontal scroller (<figure>)
 */
figure {
  display: block;
  margin: 0;
  padding: 0;
  overflow-x: auto;
}
figure figcaption {
  padding: calc(var(--spacing) * 0.5) 0;
  color: var(--muted-color);
}

/**
 * Typography
 */
b,
strong {
  font-weight: bolder;
}

sub,
sup {
  position: relative;
  font-size: 0.75em;
  line-height: 0;
  vertical-align: baseline;
}

sub {
  bottom: -0.25em;
}

sup {
  top: -0.5em;
}

address,
blockquote,
dl,
figure,
form,
ol,
p,
pre,
table,
ul {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: var(--font-size);
}

a,
[role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
a:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}
a:focus,
[role="link"]:focus {
  --background-color: var(--primary-focus);
}
a.secondary,
[role="link"].secondary {
  --color: var(--secondary);
}
a.secondary:is([aria-current], :hover, :active, :focus),
[role="link"].secondary:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}
a.secondary:focus,
[role="link"].secondary:focus {
  --background-color: var(--secondary-focus);
}
a.contrast,
[role="link"].contrast {
  --color: var(--contrast);
}
a.contrast:is([aria-current], :hover, :active, :focus),
[role="link"].contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}
a.contrast:focus,
[role="link"].contrast:focus {
  --background-color: var(--contrast-focus);
}

h1,
h2,
h3,
h4,
h5,
h6 {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  font-family: var(--font-family);
}

h1 {
  --color: var(--h1-color);
}

h2 {
  --color: var(--h2-color);
}

h3 {
  --color: var(--h3-color);
}

h4 {
  --color: var(--h4-color);
}

h5 {
  --color: var(--h5-color);
}

h6 {
  --color: var(--h6-color);
}

:where(address, blockquote, dl, figure, form, ol, p, pre, table, ul)
  ~ :is(h1, h2, h3, h4, h5, h6) {
  margin-top: var(--typography-spacing-vertical);
}

hgroup,
.headings {
  margin-bottom: var(--typography-spacing-vertical);
}
hgroup > *,
.headings > * {
  margin-bottom: 0;
}
hgroup > *:last-child,
.headings > *:last-child {
  --color: var(--muted-color);
  --font-weight: unset;
  font-size: 1rem;
  font-family: unset;
}

p {
  margin-bottom: var(--typography-spacing-vertical);
}

small {
  font-size: var(--font-size);
}

:where(dl, ol, ul) {
  padding-right: 0;
  padding-left: var(--spacing);
  -webkit-padding-start: var(--spacing);
  padding-inline-start: var(--spacing);
  -webkit-padding-end: 0;
  padding-inline-end: 0;
}
:where(dl, ol, ul) li {
  margin-bottom: calc(var(--typography-spacing-vertical) * 0.25);
}

:where(dl, ol, ul) :is(dl, ol, ul) {
  margin: 0;
  margin-top: calc(var(--typography-spacing-vertical) * 0.25);
}

ul li {
  list-style: square;
}

mark {
  padding: 0.125rem 0.25rem;
  background-color: var(--mark-background-color);
  color: var(--mark-color);
  vertical-align: baseline;
}

blockquote {
  display: block;
  margin: var(--typography-spacing-vertical) 0;
  padding: var(--spacing);
  border-right: none;
  border-left: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-start: 0.25rem solid var(--blockquote-border-color);
  border-inline-start: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-end: none;
  border-inline-end: none;
}
blockquote footer {
  margin-top: calc(var(--typography-spacing-vertical) * 0.5);
  color: var(--blockquote-footer-color);
}

abbr[title] {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}

ins {
  color: var(--ins-color);
  text-decoration: none;
}

del {
  color: var(--del-color);
}

::-moz-selection {
  background-color: var(--primary-focus);
}

::selection {
  background-color: var(--primary-focus);
}

/**
 * Embedded content
 */
:where(audio, canvas, iframe, img, svg, video) {
  vertical-align: middle;
}

audio,
video {
  display: inline-block;
}

audio:not([controls]) {
  display: none;
  height: 0;
}

:where(iframe) {
  border-style: none;
}

img {
  max-width: 100%;
  height: auto;
  border-style: none;
}

:where(svg:not([fill])) {
  fill: currentColor;
}

svg:not(#mount) {
  overflow: hidden;
}

/**
 * Button
 */
button {
  margin: 0;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

button,
[type="button"],
[type="reset"],
[type="submit"] {
  -webkit-appearance: button;
}

button {
  display: block;
  width: 100%;
  margin-bottom: var(--spacing);
}

[role="button"] {
  display: inline-block;
  text-decoration: none;
}

button,
input[type="submit"],
input[type="button"],
input[type="reset"],
[role="button"] {
  --background-color: var(--primary);
  --border-color: var(--primary);
  --color: var(--primary-inverse);
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
button:is([aria-current], :hover, :active, :focus),
input[type="submit"]:is([aria-current], :hover, :active, :focus),
input[type="button"]:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus),
[role="button"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--primary-hover);
  --border-color: var(--primary-hover);
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  --color: var(--primary-inverse);
}
button:focus,
input[type="submit"]:focus,
input[type="button"]:focus,
input[type="reset"]:focus,
[role="button"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--primary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary,
input[type="reset"] {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  cursor: pointer;
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:focus,
input[type="reset"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--secondary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast {
  --background-color: var(--contrast);
  --border-color: var(--contrast);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--contrast-hover);
  --border-color: var(--contrast-hover);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--contrast-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline,
input[type="reset"].outline {
  --background-color: transparent;
  --color: var(--primary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --background-color: transparent;
  --color: var(--primary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary,
input[type="reset"].outline {
  --color: var(--secondary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast {
  --color: var(--contrast);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}

:where(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  )[disabled],
:where(fieldset[disabled])
  :is(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  ),
a[role="button"]:not([href]) {
  opacity: 0.5;
  pointer-events: none;
}

/**
 * Form elements
 */
input,
optgroup,
select,
textarea {
  margin: 0;
  font-size: 1rem;
  line-height: var(--line-height);
  font-family: inherit;
  letter-spacing: inherit;
}

input {
  overflow: visible;
}

select {
  text-transform: none;
}

legend {
  max-width: 100%;
  padding: 0;
  color: inherit;
  white-space: normal;
}

textarea {
  overflow: auto;
}

[type="checkbox"],
[type="radio"] {
  padding: 0;
}

::-webkit-inner-spin-button,
::-webkit-outer-spin-button {
  height: auto;
}

[type="search"] {
  -webkit-appearance: textfield;
  outline-offset: -2px;
}

[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}

::-webkit-file-upload-button {
  -webkit-appearance: button;
  font: inherit;
}

::-moz-focus-inner {
  padding: 0;
  border-style: none;
}

:-moz-focusring {
  outline: none;
}

:-moz-ui-invalid {
  box-shadow: none;
}

::-ms-expand {
  display: none;
}

[type="file"],
[type="range"] {
  padding: 0;
  border-width: 0;
}

input:not([type="checkbox"], [type="radio"], [type="range"]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
}

fieldset {
  margin: 0;
  margin-bottom: var(--spacing);
  padding: 0;
  border: 0;
}

label,
fieldset legend {
  display: block;
  margin-bottom: calc(var(--spacing) * 0.25);
  font-weight: var(--form-label-font-weight, var(--font-weight));
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  width: 100%;
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]),
select,
textarea {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
}

input,
select,
textarea {
  --background-color: var(--form-element-background-color);
  --border-color: var(--form-element-border-color);
  --color: var(--form-element-color);
  --box-shadow: none;
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="checkbox"],
    [type="radio"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --background-color: var(--form-element-active-background-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="switch"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --border-color: var(--form-element-active-border-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="range"],
    [type="file"],
    [readonly]
  ):focus,
select:focus,
textarea:focus {
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}

input:not([type="submit"], [type="button"], [type="reset"])[disabled],
select[disabled],
textarea[disabled],
:where(fieldset[disabled])
  :is(
    input:not([type="submit"], [type="button"], [type="reset"]),
    select,
    textarea
  ) {
  --background-color: var(--form-element-disabled-background-color);
  --border-color: var(--form-element-disabled-border-color);
  opacity: var(--form-element-disabled-opacity);
  pointer-events: none;
}

:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid] {
  padding-right: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal) !important;
  padding-inline-start: var(--form-element-spacing-horizontal) !important;
  -webkit-padding-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-inline-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="false"] {
  background-image: var(--icon-valid);
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="true"] {
  background-image: var(--icon-invalid);
}
:where(input, select, textarea)[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(input, select, textarea)[aria-invalid="false"]:is(:active, :focus) {
  --border-color: var(--form-element-valid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-valid-focus-color) !important;
}
:where(input, select, textarea)[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}
:where(input, select, textarea)[aria-invalid="true"]:is(:active, :focus) {
  --border-color: var(--form-element-invalid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width)
    var(--form-element-invalid-focus-color) !important;
}

[dir="rtl"]
  :where(input, select, textarea):not([type="checkbox"], [type="radio"]):is(
    [aria-invalid],
    [aria-invalid="true"],
    [aria-invalid="false"]
  ) {
  background-position: center left 0.75rem;
}

input::placeholder,
input::-webkit-input-placeholder,
textarea::placeholder,
textarea::-webkit-input-placeholder,
select:invalid {
  color: var(--form-element-placeholder-color);
  opacity: 1;
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  margin-bottom: var(--spacing);
}

select::-ms-expand {
  border: 0;
  background-color: transparent;
}
select:not([multiple], [size]) {
  padding-right: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal);
  padding-inline-start: var(--form-element-spacing-horizontal);
  -webkit-padding-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-inline-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  background-image: var(--icon-chevron);
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}

[dir="rtl"] select:not([multiple], [size]) {
  background-position: center left 0.75rem;
}

:where(input, select, textarea) + small {
  display: block;
  width: 100%;
  margin-top: calc(var(--spacing) * -0.75);
  margin-bottom: var(--spacing);
  color: var(--muted-color);
}

label > :where(input, select, textarea) {
  margin-top: calc(var(--spacing) * 0.25);
}

/**
 * Form elements
 * Checkboxes & Radios
 */
[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

[type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
[type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
[type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
[type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
[type="checkbox"][role="switch"]:checked {
  background-image: none;
}
[type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

[type="checkbox"][aria-invalid="false"],
[type="checkbox"]:checked[aria-invalid="false"],
[type="radio"][aria-invalid="false"],
[type="radio"]:checked[aria-invalid="false"],
[type="checkbox"][role="switch"][aria-invalid="false"],
[type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
[type="checkbox"][aria-invalid="true"],
[type="checkbox"]:checked[aria-invalid="true"],
[type="radio"][aria-invalid="true"],
[type="radio"]:checked[aria-invalid="true"],
[type="checkbox"][role="switch"][aria-invalid="true"],
[type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

/**
 * Form elements
 * Alternatives input types (Not Checkboxes & Radios)
 */
[type="color"]::-webkit-color-swatch-wrapper {
  padding: 0;
}
[type="color"]::-moz-focus-inner {
  padding: 0;
}
[type="color"]::-webkit-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}
[type="color"]::-moz-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]):is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  --icon-position: 0.75rem;
  --icon-width: 1rem;
  padding-right: calc(var(--icon-width) + var(--icon-position));
  background-image: var(--icon-date);
  background-position: center right var(--icon-position);
  background-size: var(--icon-width) auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="time"] {
  background-image: var(--icon-time);
}

[type="date"]::-webkit-calendar-picker-indicator,
[type="datetime-local"]::-webkit-calendar-picker-indicator,
[type="month"]::-webkit-calendar-picker-indicator,
[type="time"]::-webkit-calendar-picker-indicator,
[type="week"]::-webkit-calendar-picker-indicator {
  width: var(--icon-width);
  margin-right: calc(var(--icon-width) * -1);
  margin-left: var(--icon-position);
  opacity: 0;
}

[dir="rtl"]
  :is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  text-align: right;
}

[type="file"] {
  --color: var(--muted-color);
  padding: calc(var(--form-element-spacing-vertical) * 0.5) 0;
  border: 0;
  border-radius: 0;
  background: none;
}
[type="file"]::file-selector-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::file-selector-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-webkit-file-upload-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-webkit-file-upload-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-ms-browse {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  margin-inline-start: 0;
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-ms-browse:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}

[type="range"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 100%;
  height: 1.25rem;
  background: none;
}
[type="range"]::-webkit-slider-runnable-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -webkit-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-moz-range-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -moz-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-ms-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -ms-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-webkit-slider-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-moz-range-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -moz-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-ms-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]:hover,
[type="range"]:focus {
  --range-border-color: var(--range-active-border-color);
  --range-thumb-color: var(--range-thumb-hover-color);
}
[type="range"]:active {
  --range-thumb-color: var(--range-thumb-active-color);
}
[type="range"]:active::-webkit-slider-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-moz-range-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-ms-thumb {
  transform: scale(1.25);
}

input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  -webkit-padding-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  padding-inline-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  border-radius: 5rem;
  background-image: var(--icon-search);
  background-position: center left 1.125rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  -webkit-padding-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  padding-inline-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  background-position: center left 1.125rem, center right 0.75rem;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="false"] {
  background-image: var(--icon-search), var(--icon-valid);
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="true"] {
  background-image: var(--icon-search), var(--icon-invalid);
}

[type="search"]::-webkit-search-cancel-button {
  -webkit-appearance: none;
  display: none;
}

[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  background-position: center right 1.125rem;
}
[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  background-position: center right 1.125rem, center left 0.75rem;
}

/**
 * Table
 */
:where(table) {
  width: 100%;
  border-collapse: collapse;
  border-spacing: 0;
  text-indent: 0;
}

th,
td {
  padding: calc(var(--spacing) / 2) var(--spacing);
  border-bottom: var(--border-width) solid var(--table-border-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  text-align: left;
  text-align: start;
}

tfoot th,
tfoot td {
  border-top: var(--border-width) solid var(--table-border-color);
  border-bottom: 0;
}

table[role="grid"] tbody tr:nth-child(odd) {
  background-color: var(--table-row-stripped-background-color);
}

/**
 * Code
 */
pre,
code,
kbd,
samp {
  font-size: 0.875em;
  font-family: var(--font-family);
}

pre {
  -ms-overflow-style: scrollbar;
  overflow: auto;
}

pre,
code,
kbd {
  border-radius: var(--border-radius);
  background: var(--code-background-color);
  color: var(--code-color);
  font-weight: var(--font-weight);
  line-height: initial;
}

code,
kbd {
  display: inline-block;
  padding: 0.375rem 0.5rem;
}

pre {
  display: block;
  margin-bottom: var(--spacing);
  overflow-x: auto;
}
pre > code {
  display: block;
  padding: var(--spacing);
  background: none;
  font-size: 14px;
  line-height: var(--line-height);
}

code b {
  color: var(--code-tag-color);
  font-weight: var(--font-weight);
}
code i {
  color: var(--code-property-color);
  font-style: normal;
}
code u {
  color: var(--code-value-color);
  text-decoration: none;
}
code em {
  color: var(--code-comment-color);
  font-style: normal;
}

kbd {
  background-color: var(--code-kbd-background-color);
  color: var(--code-kbd-color);
  vertical-align: baseline;
}

/**
 * Miscs
 */
hr {
  height: 0;
  border: 0;
  border-top: 1px solid var(--muted-border-color);
  color: inherit;
}

[hidden],
template {
  display: none !important;
}

canvas {
  display: inline-block;
}

/**
 * Accordion (<details>)
 */
details {
  display: block;
  margin-bottom: var(--spacing);
  padding-bottom: var(--spacing);
  border-bottom: var(--border-width) solid var(--accordion-border-color);
}
details summary {
  line-height: 1rem;
  list-style-type: none;
  cursor: pointer;
  transition: color var(--transition);
}
details summary:not([role]) {
  color: var(--accordion-close-summary-color);
}
details summary::-webkit-details-marker {
  display: none;
}
details summary::marker {
  display: none;
}
details summary::-moz-list-bullet {
  list-style-type: none;
}
details summary::after {
  display: block;
  width: 1rem;
  height: 1rem;
  -webkit-margin-start: calc(var(--spacing, 1rem) * 0.5);
  margin-inline-start: calc(var(--spacing, 1rem) * 0.5);
  float: right;
  transform: rotate(-90deg);
  background-image: var(--icon-chevron);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
  transition: transform var(--transition);
}
details summary:focus {
  outline: none;
}
details summary:focus:not([role="button"]) {
  color: var(--accordion-active-summary-color);
}
details summary[role="button"] {
  width: 100%;
  text-align: left;
}
details summary[role="button"]::after {
  height: calc(1rem * var(--line-height, 1.5));
  background-image: var(--icon-chevron-button);
}
details summary[role="button"]:not(.outline).contrast::after {
  background-image: var(--icon-chevron-button-inverse);
}
details[open] > summary {
  margin-bottom: calc(var(--spacing));
}
details[open] > summary:not([role]):not(:focus) {
  color: var(--accordion-open-summary-color);
}
details[open] > summary::after {
  transform: rotate(0);
}

[dir="rtl"] details summary {
  text-align: right;
}
[dir="rtl"] details summary::after {
  float: left;
  background-position: left center;
}

/**
 * Card (<article>)
 */
article {
  margin: var(--block-spacing-vertical) 0;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
  border-radius: var(--border-radius);
  background: var(--card-background-color);
  box-shadow: var(--card-box-shadow);
}
article > header,
article > footer {
  margin-right: calc(var(--block-spacing-horizontal) * -1);
  margin-left: calc(var(--block-spacing-horizontal) * -1);
  padding: calc(var(--block-spacing-vertical) * 0.66)
    var(--block-spacing-horizontal);
  background-color: var(--card-sectionning-background-color);
}
article > header {
  margin-top: calc(var(--block-spacing-vertical) * -1);
  margin-bottom: var(--block-spacing-vertical);
  border-bottom: var(--border-width) solid var(--card-border-color);
  border-top-right-radius: var(--border-radius);
  border-top-left-radius: var(--border-radius);
}
article > footer {
  margin-top: var(--block-spacing-vertical);
  margin-bottom: calc(var(--block-spacing-vertical) * -1);
  border-top: var(--border-width) solid var(--card-border-color);
  border-bottom-right-radius: var(--border-radius);
  border-bottom-left-radius: var(--border-radius);
}

/**
 * Modal (<dialog>)
 */
#mount {
  --scrollbar-width: 0px;
}

dialog {
  display: flex;
  z-index: 999;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  align-items: center;
  justify-content: center;
  width: inherit;
  min-width: 100%;
  height: inherit;
  min-height: 100%;
  padding: var(--spacing);
  border: 0;
  -webkit-backdrop-filter: var(--modal-overlay-backdrop-filter);
  backdrop-filter: var(--modal-overlay-backdrop-filter);
  background-color: var(--modal-overlay-background-color);
  color: var(--color);
}
dialog article {
  max-height: calc(100vh - var(--spacing) * 2);
  overflow: auto;
}
@media (min-width: 576px) {
  dialog article {
    max-width: 510px;
  }
}
@media (min-width: 768px) {
  dialog article {
    max-width: 700px;
  }
}
dialog article > header,
dialog article > footer {
  padding: calc(var(--block-spacing-vertical) * 0.5)
    var(--block-spacing-horizontal);
}
dialog article > header .close {
  margin: 0;
  margin-left: var(--spacing);
  float: right;
}
dialog article > footer {
  text-align: right;
}
dialog article > footer [role="button"] {
  margin-bottom: 0;
}
dialog article > footer [role="button"]:not(:first-of-type) {
  margin-left: calc(var(--spacing) * 0.5);
}
dialog article p:last-of-type {
  margin: 0;
}
dialog article .close {
  display: block;
  width: 1rem;
  height: 1rem;
  margin-top: calc(var(--block-spacing-vertical) * -0.5);
  margin-bottom: var(--typography-spacing-vertical);
  margin-left: auto;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}
dialog article .close:is([aria-current], :hover, :active, :focus) {
  opacity: 1;
}
dialog:not([open]),
dialog[open="false"] {
  display: none;
}

.modal-is-open {
  padding-right: var(--scrollbar-width, 0px);
  overflow: hidden;
  pointer-events: none;
}
.modal-is-open dialog {
  pointer-events: auto;
}

:where(.modal-is-opening, .modal-is-closing) dialog,
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-duration: 0.2s;
  animation-timing-function: ease-in-out;
  animation-fill-mode: both;
}
:where(.modal-is-opening, .modal-is-closing) dialog {
  animation-duration: 0.8s;
  animation-name: modal-overlay;
}
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-delay: 0.2s;
  animation-name: modal;
}

.modal-is-closing dialog,
.modal-is-closing dialog > article {
  animation-delay: 0s;
  animation-direction: reverse;
}

@keyframes modal-overlay {
  from {
    -webkit-backdrop-filter: none;
    backdrop-filter: none;
    background-color: transparent;
  }
}
@keyframes modal {
  from {
    transform: translateY(-100%);
    opacity: 0;
  }
}
/**
 * Nav
 */
:where(nav li)::before {
  float: left;
  content: "​";
}

nav,
nav ul {
  display: flex;
}

nav {
  justify-content: space-between;
}
nav ol,
nav ul {
  align-items: center;
  margin-bottom: 0;
  padding: 0;
  list-style: none;
}
nav ol:first-of-type,
nav ul:first-of-type {
  margin-left: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav ol:last-of-type,
nav ul:last-of-type {
  margin-right: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav li {
  display: inline-block;
  margin: 0;
  padding: var(--nav-element-spacing-vertical)
    var(--nav-element-spacing-horizontal);
}
nav li > * {
  --spacing: 0;
}
nav :where(a, [role="link"]) {
  display: inline-block;
  margin: calc(var(--nav-link-spacing-vertical) * -1)
    calc(var(--nav-link-spacing-horizontal) * -1);
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
  border-radius: var(--border-radius);
  text-decoration: none;
}
nav :where(a, [role="link"]):is([aria-current], :hover, :active, :focus) {
  text-decoration: none;
}
nav[aria-label="breadcrumb"] {
  align-items: center;
  justify-content: start;
}
nav[aria-label="breadcrumb"] ul li:not(:first-child) {
  -webkit-margin-start: var(--nav-link-spacing-horizontal);
  margin-inline-start: var(--nav-link-spacing-horizontal);
}
nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  position: absolute;
  width: calc(var(--nav-link-spacing-horizontal) * 2);
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) / 2);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) / 2);
  content: "/";
  color: var(--muted-color);
  text-align: center;
}
nav[aria-label="breadcrumb"] a[aria-current] {
  background-color: transparent;
  color: inherit;
  text-decoration: none;
  pointer-events: none;
}
nav [role="button"] {
  margin-right: inherit;
  margin-left: inherit;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}

aside nav,
aside ol,
aside ul,
aside li {
  display: block;
}
aside li {
  padding: calc(var(--nav-element-spacing-vertical) * 0.5)
    var(--nav-element-spacing-horizontal);
}
aside li a {
  display: block;
}
aside li [role="button"] {
  margin: inherit;
}

[dir="rtl"] nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  content: "\\";
}

/**
 * Progress
 */
progress {
  display: inline-block;
  vertical-align: baseline;
}

progress {
  -webkit-appearance: none;
  -moz-appearance: none;
  display: inline-block;
  appearance: none;
  width: 100%;
  height: 0.5rem;
  margin-bottom: calc(var(--spacing) * 0.5);
  overflow: hidden;
  border: 0;
  border-radius: var(--border-radius);
  background-color: var(--progress-background-color);
  color: var(--progress-color);
}
progress::-webkit-progress-bar {
  border-radius: var(--border-radius);
  background: none;
}
progress[value]::-webkit-progress-value {
  background-color: var(--progress-color);
}
progress::-moz-progress-bar {
  background-color: var(--progress-color);
}
@media (prefers-reduced-motion: no-preference) {
  progress:indeterminate {
    background: var(--progress-background-color)
      linear-gradient(
        to right,
        var(--progress-color) 30%,
        var(--progress-background-color) 30%
      )
      top left/150% 150% no-repeat;
    animation: progress-indeterminate 1s linear infinite;
  }
  progress:indeterminate[value]::-webkit-progress-value {
    background-color: transparent;
  }
  progress:indeterminate::-moz-progress-bar {
    background-color: transparent;
  }
}

@media (prefers-reduced-motion: no-preference) {
  [dir="rtl"] progress:indeterminate {
    animation-direction: reverse;
  }
}

@keyframes progress-indeterminate {
  0% {
    background-position: 200% 0;
  }
  100% {
    background-position: -200% 0;
  }
}
/**
 * Dropdown ([role="list"])
 */
details[role="list"],
li[role="list"] {
  position: relative;
}

details[role="list"] summary + ul,
li[role="list"] > ul {
  display: flex;
  z-index: 99;
  position: absolute;
  top: auto;
  right: 0;
  left: 0;
  flex-direction: column;
  margin: 0;
  padding: 0;
  border: var(--border-width) solid var(--dropdown-border-color);
  border-radius: var(--border-radius);
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  background-color: var(--dropdown-background-color);
  box-shadow: var(--card-box-shadow);
  color: var(--dropdown-color);
  white-space: nowrap;
}
details[role="list"] summary + ul li,
li[role="list"] > ul li {
  width: 100%;
  margin-bottom: 0;
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  list-style: none;
}
details[role="list"] summary + ul li:first-of-type,
li[role="list"] > ul li:first-of-type {
  margin-top: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li:last-of-type,
li[role="list"] > ul li:last-of-type {
  margin-bottom: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li a,
li[role="list"] > ul li a {
  display: block;
  margin: calc(var(--form-element-spacing-vertical) * -0.5)
    calc(var(--form-element-spacing-horizontal) * -1);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  overflow: hidden;
  color: var(--dropdown-color);
  text-decoration: none;
  text-overflow: ellipsis;
}
details[role="list"] summary + ul li a:hover,
li[role="list"] > ul li a:hover {
  background-color: var(--dropdown-hover-background-color);
}

details[role="list"] summary::after,
li[role="list"] > a::after {
  display: block;
  width: 1rem;
  height: calc(1rem * var(--line-height, 1.5));
  -webkit-margin-start: 0.5rem;
  margin-inline-start: 0.5rem;
  float: right;
  transform: rotate(0deg);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
}

details[role="list"] {
  padding: 0;
  border-bottom: none;
}
details[role="list"] summary {
  margin-bottom: 0;
}
details[role="list"] summary:not([role]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--form-element-border-color);
  border-radius: var(--border-radius);
  background-color: var(--form-element-background-color);
  color: var(--form-element-placeholder-color);
  line-height: inherit;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
details[role="list"] summary:not([role]):active,
details[role="list"] summary:not([role]):focus {
  border-color: var(--form-element-active-border-color);
  background-color: var(--form-element-active-background-color);
}
details[role="list"] summary:not([role]):focus {
  box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}
details[role="list"][open] summary {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
details[role="list"][open] summary::before {
  display: block;
  z-index: 1;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  background: none;
  content: "";
  cursor: default;
}

nav details[role="list"] summary,
nav li[role="list"] a {
  display: flex;
  direction: ltr;
}

nav details[role="list"] summary + ul,
nav li[role="list"] > ul {
  min-width: -moz-fit-content;
  min-width: fit-content;
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul li a,
nav li[role="list"] > ul li a {
  border-radius: 0;
}

nav details[role="list"] summary,
nav details[role="list"] summary:not([role]) {
  height: auto;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}
nav details[role="list"][open] summary {
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul {
  margin-top: var(--outline-width);
  -webkit-margin-start: 0;
  margin-inline-start: 0;
}
nav details[role="list"] summary[role="link"] {
  margin-bottom: calc(var(--nav-link-spacing-vertical) * -1);
  line-height: var(--line-height);
}
nav details[role="list"] summary[role="link"] + ul {
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) * -1);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) * -1);
}

li[role="list"]:hover > ul,
li[role="list"] a:active ~ ul,
li[role="list"] a:focus ~ ul {
  display: flex;
}
li[role="list"] > ul {
  display: none;
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
  margin-inline-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
}
li[role="list"] > a::after {
  background-image: var(--icon-chevron);
}

/**
 * Loading ([aria-busy=true])
 */
[aria-busy="true"] {
  cursor: progress;
}

[aria-busy="true"]:not(input, select, textarea)::before {
  display: inline-block;
  width: 1em;
  height: 1em;
  border: 0.1875em solid currentColor;
  border-radius: 1em;
  border-right-color: transparent;
  content: "";
  vertical-align: text-bottom;
  vertical-align: -0.125em;
  animation: spinner 0.75s linear infinite;
  opacity: var(--loading-spinner-opacity);
}
[aria-busy="true"]:not(input, select, textarea):not(:empty)::before {
  margin-right: calc(var(--spacing) * 0.5);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) * 0.5);
  margin-inline-end: calc(var(--spacing) * 0.5);
}
[aria-busy="true"]:not(input, select, textarea):empty {
  text-align: center;
}

button[aria-busy="true"],
input[type="submit"][aria-busy="true"],
input[type="button"][aria-busy="true"],
input[type="reset"][aria-busy="true"],
a[aria-busy="true"] {
  pointer-events: none;
}

@keyframes spinner {
  to {
    transform: rotate(360deg);
  }
}
/**
 * Tooltip ([data-tooltip])
 */
[data-tooltip] {
  position: relative;
}
[data-tooltip]:not(a, button, input) {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}
[data-tooltip][data-placement="top"]::before,
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::before,
[data-tooltip]::after {
  display: block;
  z-index: 99;
  position: absolute;
  bottom: 100%;
  left: 50%;
  padding: 0.25rem 0.5rem;
  overflow: hidden;
  transform: translate(-50%, -0.25rem);
  border-radius: var(--border-radius);
  background: var(--tooltip-background-color);
  content: attr(data-tooltip);
  color: var(--tooltip-color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: 0.875rem;
  text-decoration: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  opacity: 0;
  pointer-events: none;
}
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::after {
  padding: 0;
  transform: translate(-50%, 0rem);
  border-top: 0.3rem solid;
  border-right: 0.3rem solid transparent;
  border-left: 0.3rem solid transparent;
  border-radius: 0;
  background-color: transparent;
  content: "";
  color: var(--tooltip-background-color);
}
[data-tooltip][data-placement="bottom"]::before,
[data-tooltip][data-placement="bottom"]::after {
  top: 100%;
  bottom: auto;
  transform: translate(-50%, 0.25rem);
}
[data-tooltip][data-placement="bottom"]:after {
  transform: translate(-50%, -0.3rem);
  border: 0.3rem solid transparent;
  border-bottom: 0.3rem solid;
}
[data-tooltip][data-placement="left"]::before,
[data-tooltip][data-placement="left"]::after {
  top: 50%;
  right: 100%;
  bottom: auto;
  left: auto;
  transform: translate(-0.25rem, -50%);
}
[data-tooltip][data-placement="left"]:after {
  transform: translate(0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-left: 0.3rem solid;
}
[data-tooltip][data-placement="right"]::before,
[data-tooltip][data-placement="right"]::after {
  top: 50%;
  right: auto;
  bottom: auto;
  left: 100%;
  transform: translate(0.25rem, -50%);
}
[data-tooltip][data-placement="right"]:after {
  transform: translate(-0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-right: 0.3rem solid;
}
[data-tooltip]:focus::before,
[data-tooltip]:focus::after,
[data-tooltip]:hover::before,
[data-tooltip]:hover::after {
  opacity: 1;
}
@media (hover: hover) and (pointer: fine) {
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::before,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::before,
  [data-tooltip]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::after {
    animation-name: tooltip-caret-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::before,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-bottom;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-name: tooltip-caret-slide-bottom;
  }
  [data-tooltip][data-placement="left"]:focus::before,
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::before,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-left;
  }
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-name: tooltip-caret-slide-left;
  }
  [data-tooltip][data-placement="right"]:focus::before,
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::before,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-right;
  }
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-name: tooltip-caret-slide-right;
  }
}
@keyframes tooltip-slide-top {
  from {
    transform: translate(-50%, 0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-top {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.25rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-bottom {
  from {
    transform: translate(-50%, -0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-bottom {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.5rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.3rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-left {
  from {
    transform: translate(0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-left {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.3rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-slide-right {
  from {
    transform: translate(-0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-right {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.3rem, -50%);
    opacity: 1;
  }
}

/**
 * Accessibility & User interaction
 */
[aria-controls] {
  cursor: pointer;
}

[aria-disabled="true"],
[disabled] {
  cursor: not-allowed;
}

[aria-hidden="false"][hidden] {
  display: initial;
}

[aria-hidden="false"][hidden]:not(:focus) {
  clip: rect(0, 0, 0, 0);
  position: absolute;
}

a,
area,
button,
input,
label,
select,
summary,
textarea,
[tabindex] {
  -ms-touch-action: manipulation;
}

[dir="rtl"] {
  direction: rtl;
}

/**
* Reduce Motion Features
*/
@media (prefers-reduced-motion: reduce) {
  *:not([aria-busy="true"]),
  :not([aria-busy="true"])::before,
  :not([aria-busy="true"])::after {
    background-attachment: initial !important;
    animation-duration: 1ms !important;
    animation-delay: -1ms !important;
    animation-iteration-count: 1 !important;
    scroll-behavior: auto !important;
    transition-delay: 0s !important;
    transition-duration: 0s !important;
  }
}

#mount {
  /* --primary: rgb(227, 59, 126); */
  --primary: #ea4c89;
  --primary-hover: #f082ac;
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  --switch-checked-background-color: var(--primary);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="dark"] {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="light"] {
  --primary: #ea4c89;
  --primary-hover: #f082ac;
}

li.select-link.select-link:hover > ul {
  display: none;
}
li.select-link.select-link > ul {
  display: none;
}
li.select-link.select-link a:focus ~ ul {
  display: none;
}

li.select-link.select-link a:active ~ ul {
  display: none;
}
li.select-link-active.select-link-active > ul {
  display: flex;
}
li.select-link-active.select-link-active:hover > ul {
  display: flex;
}

li.select-link-active.select-link-active a:focus ~ ul {
  display: flex;
}

li.select-link-active.select-link-active a:active ~ ul {
  display: flex;
}
ul.select-link-ul.select-link-ul {
  right: 0px;
  left: auto;
}

a.select-link-selected {
  background-color: var(--primary-focus);
}
.immersive-translate-no-select {
  -webkit-touch-callout: none; /* iOS Safari */
  -webkit-user-select: none; /* Safari */
  -khtml-user-select: none; /* Konqueror HTML */
  -moz-user-select: none; /* Old versions of Firefox */
  -ms-user-select: none; /* Internet Explorer/Edge */
  user-select: none;
}

/* li[role="list"].no-arrow > a::after { */
/*   background-image: none; */
/*   width: 0; */
/*   color: var(--color); */
/* } */
li[role="list"].no-arrow {
  margin-left: 8px;
  padding-right: 0;
}
li[role="list"] > a::after {
  -webkit-margin-start: 0.2rem;
  margin-inline-start: 0.2rem;
}

li[role="list"].no-arrow > a,
li[role="list"].no-arrow > a:link,
li[role="list"].no-arrow > a:visited {
  color: var(--secondary);
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  padding-left: 8px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}
select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.muted {
  color: var(--muted-color);
}

.select.button-select {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
  cursor: pointer;
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 16px;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
  -webkit-appearance: button;
  margin: 0;
  margin-bottom: 0px;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --text-black-2: #222222;
  --text-gray-2: #222222;
  --text-gray-6: #666666;
  --text-gray-9: #999999;
  --text-gray-c2: #c2c2c2;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --popup-footer-background-color: #0d0d0d;
    --popup-content-background-color: #191919;
    --popup-item-background-color: #272727;
    --popup-item-hover-background-color: #333333;
    --popup-trial-pro-background-color: #222222;
    --text-black-2: #ffffff;
    --text-gray-2: #dbdbdb;
    --text-gray-6: #b3b3b3;
    --text-gray-9: #777777;
    --text-gray-c2: #5b5b5b;
    --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
    --service-select-border-color: #2c2c2c;
    --service-select-selected-background-color: #333333;
    --download-app-background: #333;
  }
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --text-black-2: #ffffff;
  --text-gray-2: #dbdbdb;
  --text-gray-6: #b3b3b3;
  --text-gray-9: #777777;
  --text-gray-c2: #5b5b5b;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

.text-balck {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

#mount {
  min-width: 268px;
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

select.min-select-secondary {
  color: var(--color);
}

select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 372px;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #B3B3B3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 237px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg><svg hidden="true" class="imt-manga-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div><svg class="imt-float-ball-loading" hidden="true" width="19" height="19" viewBox="0 0 19 19" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin: 9px;"><path d="M9.42859 0C9.84288 0 10.1929 0.387143 10.1929 0.847143V3.99429C10.1929 4.45429 9.84431 4.84143 9.42859 4.84143C9.01431 4.84143 8.66431 4.45571 8.66431 3.99429V0.847143C8.66431 0.387143 9.01288 0 9.42859 0Z" fill="#E9E9E9"></path><path d="M14.1301 1.38877C14.5158 1.62591 14.6301 2.12163 14.4258 2.52305L12.9515 5.19448C12.901 5.28714 12.8325 5.36876 12.75 5.43455C12.6675 5.50035 12.5727 5.54898 12.4712 5.5776C12.3696 5.60621 12.2634 5.61424 12.1586 5.60119C12.0539 5.58814 11.9529 5.55429 11.8615 5.50163C11.6787 5.38432 11.5468 5.20237 11.4923 4.9921C11.4377 4.78184 11.4645 4.55874 11.5672 4.36734L13.0415 1.69591C13.2686 1.29448 13.7443 1.15305 14.1301 1.38877Z" fill="#989697"></path><path d="M17.4685 4.75707C17.5813 4.95451 17.6123 5.18824 17.5549 5.40825C17.4975 5.62826 17.3563 5.81705 17.1614 5.93422L14.4971 7.52564C14.0971 7.76993 13.6014 7.62422 13.3657 7.20707C13.2532 7.00994 13.2222 6.77667 13.2793 6.55702C13.3365 6.33737 13.4771 6.14874 13.6714 6.03136L16.3357 4.43993C16.7371 4.21993 17.2557 4.34136 17.4685 4.7585V4.75707Z" fill="#9B999A"></path><path d="M18.8572 9.42835C18.8572 9.84263 18.47 10.1926 18.01 10.1926H14.8629C14.4029 10.1926 14.0157 9.84406 14.0157 9.42835C14.0157 9.01406 14.4029 8.66406 14.8629 8.66406H18.01C18.47 8.66406 18.8572 9.01263 18.8572 9.42835Z" fill="#A3A1A2"></path><path d="M17.4686 14.1303C17.3515 14.3134 17.1697 14.4455 16.9594 14.5003C16.7491 14.5552 16.5259 14.5286 16.3343 14.426L13.6629 12.9517C13.5702 12.9012 13.4886 12.8327 13.4228 12.7503C13.357 12.6678 13.3084 12.573 13.2798 12.4714C13.2512 12.3698 13.2431 12.2636 13.2562 12.1589C13.2692 12.0542 13.3031 11.9532 13.3558 11.8617C13.4731 11.6789 13.655 11.547 13.8653 11.4925C14.0755 11.4379 14.2986 11.4647 14.49 11.5674L17.1615 13.0417C17.5629 13.2689 17.7043 13.7446 17.4686 14.1303Z" fill="#ABA9AA"></path><path opacity="0.7" d="M14.1 17.4686C13.9026 17.5814 13.6689 17.6124 13.4489 17.555C13.2288 17.4976 13.04 17.3564 12.9229 17.1615L11.3315 14.4972C11.0872 14.0972 11.2329 13.6015 11.65 13.3658C11.8472 13.2533 12.0804 13.2224 12.3001 13.2795C12.5197 13.3366 12.7084 13.4773 12.8257 13.6715L14.4172 16.3358C14.6372 16.7372 14.5157 17.2558 14.0986 17.4686H14.1Z" fill="#B2B2B2"></path><path opacity="0.6" d="M9.42859 18.8571C9.01431 18.8571 8.66431 18.4699 8.66431 18.0099V14.8628C8.66431 14.4028 9.01288 14.0156 9.42859 14.0156C9.84288 14.0156 10.1929 14.4028 10.1929 14.8628V18.0099C10.1929 18.4699 9.84431 18.8571 9.42859 18.8571Z" fill="#BAB8B9"></path><path opacity="0.5" d="M4.72717 17.4685C4.5441 17.3514 4.41195 17.1696 4.35713 16.9593C4.30231 16.749 4.32885 16.5258 4.43145 16.3342L5.90574 13.6628C5.95622 13.5701 6.02472 13.4885 6.1072 13.4227C6.18969 13.3569 6.2845 13.3083 6.38606 13.2797C6.48762 13.251 6.59387 13.243 6.69857 13.2561C6.80327 13.2691 6.90431 13.303 6.99574 13.3556C7.38145 13.5914 7.49431 14.0885 7.29002 14.4899L5.81574 17.1614C5.5886 17.5628 5.11288 17.7042 4.72717 17.4685Z" fill="#C2C0C1"></path><path opacity="0.4" d="M1.38862 14.1002C1.27584 13.9027 1.24483 13.669 1.30223 13.449C1.35964 13.229 1.50089 13.0402 1.69576 12.923L4.36004 11.3316C4.76004 11.0873 5.25576 11.233 5.49147 11.6502C5.60393 11.8473 5.63491 12.0806 5.5778 12.3002C5.52069 12.5199 5.38 12.7085 5.18576 12.8259L2.52004 14.4173C2.12004 14.6373 1.60004 14.5159 1.38862 14.0987V14.1002Z" fill="#CBCBCB"></path><path d="M0 9.42835C0 9.01406 0.387143 8.66406 0.847143 8.66406H3.99429C4.45429 8.66406 4.84143 9.01263 4.84143 9.42835C4.84143 9.84263 4.45571 10.1926 3.99429 10.1926H0.847143C0.387143 10.1926 0 9.84406 0 9.42835Z" fill="#D2D2D2"></path><path opacity="0.2" d="M1.38852 4.72705C1.50561 4.54398 1.68746 4.41183 1.89774 4.35701C2.10803 4.30219 2.33125 4.32873 2.52281 4.43133L5.19424 5.90562C5.28689 5.9561 5.36851 6.0246 5.43431 6.10708C5.5001 6.18957 5.54874 6.28438 5.57735 6.38594C5.60597 6.48749 5.61399 6.59375 5.60094 6.69845C5.5879 6.80315 5.55405 6.90419 5.50138 6.99562C5.38407 7.17844 5.20212 7.31029 4.99186 7.36484C4.78159 7.4194 4.55849 7.39263 4.3671 7.2899L1.69567 5.81562C1.29424 5.58847 1.15281 5.11276 1.38852 4.72705Z" fill="#DADADA"></path><path d="M4.75719 1.38849C4.95463 1.27571 5.18837 1.24471 5.40838 1.30211C5.62838 1.35952 5.81718 1.50077 5.93434 1.69564L7.52577 4.35992C7.77005 4.75992 7.62434 5.25564 7.20719 5.49135C7.01006 5.60381 6.77679 5.63479 6.55714 5.57768C6.33749 5.52056 6.14886 5.37988 6.03148 5.18564L4.44005 2.51992C4.22005 2.11992 4.34148 1.59992 4.75862 1.38849H4.75719Z" fill="#E2E2E2"></path></svg></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="opacity: 0.7; transform: translateX(15px);"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; top: 237px; right: 65px;"></div></div></div></div></template></div>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2511.16110?_immersive_translate_auto_translate=1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2511.16110v1/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2511.16110v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2511.16110v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2511.16110?_immersive_translate_auto_translate=1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S1" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S2" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S2.SS0.SSS0.Px1" title="In 2 Related Work ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Prompt-Based Jailbreaking.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S2.SS0.SSS0.Px2" title="In 2 Related Work ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Vision-Based Adversarial Attacks.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S2.SS0.SSS0.Px3" title="In 2 Related Work ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Reward Hacking.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S2.SS0.SSS0.Px4" title="In 2 Related Work ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Summary.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Multi-Faceted Attack</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS1" title="In 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Attention Transfer Attack: Alignment Breaking Facet</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS1.SSS0.Px1" title="In 3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">1. Theoretical Analysis: Why ATA Breaks Alignment?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS1.SSS0.Px2" title="In 3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">2. Empirical Validation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS1.SSS0.Px3" title="In 3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">3. Robustness to Prompt Variants.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS2" title="In 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Content-Moderator Attack Facet: Breaching the Final Line of Defense</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS2.SSS0.Px1" title="In 3.2 Content-Moderator Attack Facet: Breaching the Final Line of Defense ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">1. Why Content Moderators Matter.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS2.SSS0.Px2" title="In 3.2 Content-Moderator Attack Facet: Breaching the Final Line of Defense ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">2. Key Insight: Exploiting Repetition Bias.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS2.SSS0.Px3" title="In 3.2 Content-Moderator Attack Facet: Breaching the Final Line of Defense ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">3. Generating Adversarial Signatures.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS2.SSS0.Px4" title="In 3.2 Content-Moderator Attack Facet: Breaching the Final Line of Defense ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">(i) Efficient Signature Generation via Multi-token Optimization.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS2.SSS0.Px5" title="In 3.2 Content-Moderator Attack Facet: Breaching the Final Line of Defense ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">(ii) Enhancing Transferability through Weakly Supervised Optimization.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS2.SSS0.Px6" title="In 3.2 Content-Moderator Attack Facet: Breaching the Final Line of Defense ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Take-away.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS3" title="In 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Vision-Encoder–Targeted Image Attack</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS3.SSS0.Px1" title="In 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">1. Workflow.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS3.SSS0.Px2" title="In 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">2. Why focus on Vision Encoder?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS3.SSS0.Px3" title="In 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">3. Optimization.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS3.SSS0.Px4" title="In 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">4. Transferability.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS3.SSS0.Px5" title="In 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Take-away.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS1" title="In 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS2" title="In 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Results Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS2.SSS0.Px1" title="In 4.2 Results Analysis ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Effectiveness on Commercial VLMs.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS2.SSS0.Px2" title="In 4.2 Results Analysis ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Performance on Open-Source Alignment-Only Models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS2.SSS0.Px3" title="In 4.2 Results Analysis ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Cross-modal transferability.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS2.SSS0.Px4" title="In 4.2 Results Analysis ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Qualitative Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS3" title="In 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS3.SSS0.Px1" title="In 4.3 Ablation Study ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Effectiveness of ATA.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS3.SSS0.Px2" title="In 4.3 Ablation Study ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Effectiveness of Filter-Targeted Attack.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS3.SSS0.Px3" title="In 4.3 Ablation Study ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Effectiveness of Vision Encoder-Targeted Attack.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS3.SSS0.Px4" title="In 4.3 Ablation Study ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Synergy of The Three Facets.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S5" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion &amp; Conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S5.SS0.SSS0.Px1" title="In 5 Discussion &amp; Conclusion ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Discussion.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S5.SS0.SSS0.Px2" title="In 5 Discussion &amp; Conclusion ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Conclusion.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A1" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS1" title="In Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Hardware Environment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS2" title="In Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Details of Victim Open-source VLMs.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS3" title="In Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Details of Victim Commercial VLMs</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS3.SSS0.Px1" title="In B.3 Details of Victim Commercial VLMs ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Common Characteristics.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS3.SSS0.Px2" title="In B.3 Details of Victim Commercial VLMs ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Relevance to MFA.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS3.SSS0.Px3" title="In B.3 Details of Victim Commercial VLMs ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Detailed Evaluation Settings.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS4" title="In Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.4 </span>Our Approach Implementation.</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS4.SSS0.Px1" title="In B.4 Our Approach Implementation. ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Filter-Targeted Attack.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS4.SSS0.Px2" title="In B.4 Our Approach Implementation. ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Vision Encoder–Targeted Attack.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS5" title="In Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.5 </span>Baseline Implementation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS5.SSS0.Px1" title="In B.5 Baseline Implementation ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Visual-AE</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS5.SSS0.Px2" title="In B.5 Baseline Implementation ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">FigStep</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS5.SSS0.Px3" title="In B.5 Baseline Implementation ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">HIMRD</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS5.SSS0.Px4" title="In B.5 Baseline Implementation ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">HADES</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS5.SSS0.Px5" title="In B.5 Baseline Implementation ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">CS-DJ</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.SS5.SSS0.Px6" title="In B.5 Baseline Implementation ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">GPTFuzzer</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A3" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>More Details on Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A3.SS1" title="In Appendix C More Details on Ablation Study ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Ablation Study on ATA.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A3.SS2" title="In Appendix C More Details on Ablation Study ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Ablation Study on Filter-Targeted Attack.</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A3.SS2.SSS0.Px1" title="In C.2 Ablation Study on Filter-Targeted Attack. ‣ Appendix C More Details on Ablation Study ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Details of Victim Filters (Content Moderators)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A3.SS2.SSS0.Px2" title="In C.2 Ablation Study on Filter-Targeted Attack. ‣ Appendix C More Details on Ablation Study ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">Baseline Implementation for the Filter-Targeted Comparison.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A4" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Additional MFA Case Studies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A5" title="In Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Failure Case Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A5.SS0.SSS0.Px1" title="In Appendix E Failure Case Analysis ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">(i) LLaVA-1.5 (Fig.&nbsp;A-10).</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A5.SS0.SSS0.Px2" title="In Appendix E Failure Case Analysis ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_title">(ii) ShareGPT4V &amp; mPLUG-Owl2 (Fig.&nbsp;A-11).</span></a></li>
</ol>
</li>
</ol></nav>

<div class="ltx_page_content"><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">许可证：CC BY 4.0</font></font></font></a><div id="watermark-tr" data-imt_insert_failed="1">arXiv:2511.16110v1 [cs.CR] 20 Nov 2025</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞</font></font></font></h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yijun Yang<sup class="ltx_sup">1 <math alttext="\dagger" class="ltx_Math" display="inline" id="m1" intent=":literal"><semantics><mo>†</mo><annotation encoding="application/x-tex">\dagger</annotation></semantics></math></sup>, Lichao Wang<sup class="ltx_sup">2 <math alttext="\dagger" class="ltx_Math" display="inline" id="m3" intent=":literal"><semantics><mo>†</mo><annotation encoding="application/x-tex">\dagger</annotation></semantics></math></sup>,
Jianping Zhang<sup class="ltx_sup">1</sup>,
Chi Harold Liu<sup class="ltx_sup">2</sup>,
Lanqing Hong<sup class="ltx_sup">3</sup>,
Qiang Xu<sup class="ltx_sup">1 *</sup>
</span><span class="ltx_author_notes">Corresponding authors. <sup class="ltx_sup"><math alttext="\dagger" class="ltx_Math" display="inline" id="m2" intent=":literal"><semantics><mo>†</mo><annotation encoding="application/x-tex">\dagger</annotation></semantics></math></sup> These authors contributed equally.</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">摘要</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p">The growing misuse of Vision-Language Models (VLMs) has led providers to deploy multiple safeguards—alignment tuning, system prompts, and content moderation.
Yet the real-world robustness of these defenses against adversarial attack remains underexplored.
We introduce <span class="ltx_text ltx_font_bold">Multi-Faceted Attack (MFA)</span>,
a framework that systematically uncovers general safety vulnerabilities in leading defense-equipped VLMs, including GPT-4o, Gemini-Pro, and LlaMA 4, <em class="ltx_emph ltx_font_italic">etc</em>.
Central to MFA is the Attention-Transfer Attack (ATA), which conceals harmful instructions inside a meta task with competing objectives. We offer a theoretical perspective grounded in <span class="ltx_text ltx_font_italic">reward-hacking</span> to explain why such an attack can succeed. To maximize cross-model transfer, we introduce a lightweight transfer-enhancement algorithm combined with a simple repetition strategy that jointly evades both input- and output-level filters—without any model-specific fine-tuning.
We empirically show that adversarial images optimized for one vision encoder transfer broadly to unseen VLMs, indicating that shared visual representations create a cross-model safety vulnerability.
Combined, MFA reaches a 58.5% overall success rate, consistently outperforming existing methods.
Notably, on state-of-the-art commercial models, MFA achieves a 52.8% success rate, outperforming the second-best attack by 34%.
These findings challenge the perceived robustness of current defensive mechanisms, systematically expose general safety loopholes within defense-equipped VLMs, and offer a practical probe for diagnosing and strengthening the safety of VLMs.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_text ltx_font_italic">Code: <span class="ltx_ref ltx_nolink ltx_url ltx_ref_self"><span class="ltx_text ltx_font_upright">https://github.com/cure-lab/MultiFacetedAttack</span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">代码：https://github.com/cure-lab/MultiFacetedAttack</font></font></font></span></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">视觉语言模型（VLMs）的日益滥用促使提供者部署了多重安全措施——对齐微调、系统提示和内容审核。然而，这些防御措施在实际对抗攻击中的鲁棒性仍缺乏深入探索。我们引入了多方面攻击（MFA）框架，该框架系统地揭示了领先防御型 VLMs（包括 GPT-4o、Gemini-Pro 和 LlaMA 4 等）中普遍存在的安全漏洞。MFA 的核心是注意力转移攻击（ATA），它将有害指令隐藏在具有竞争目标的元任务中。我们基于奖励劫持的理论视角解释了此类攻击为何能够成功。为最大化跨模型迁移效果，我们引入了一种轻量级迁移增强算法，结合简单的重复策略，可同时规避输入和输出层面的过滤器——无需任何模型特定的微调。我们通过实验证明，针对某一视觉编码器优化的对抗性图像可广泛迁移至未见过的 VLMs，表明共享的视觉表征造成了跨模型的安全漏洞。 MFA 综合成功率达到了 58.5%，持续超越现有方法。值得注意的是，在顶尖商业模型上，MFA 实现了 52.8%的成功率，比第二好的攻击方法高出 34%。这些发现挑战了当前防御机制被普遍认为的鲁棒性，系统地揭示了配备防御功能的 VLMs 中存在的通用安全漏洞，并为诊断和增强 VLMs 的安全性提供了一种实用探测方法。 <sup class="ltx_note_mark">1</sup> </font></font></font>
<span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#FF0000;">WARNING: This paper may contain offensive content.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">警告：本文可能包含冒犯性内容。</font></font></font></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1 引言</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p">VLMs represented by GPT-4o and Gemini-pro, have rapidly advanced the frontiers of multimodal AI, enabling impressive capabilities in visual reasoning that jointly process images and language&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">openai2024gpt4ocard</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">gemini</span>)</cite>. However, the same capabilities that drive their utility also magnify their potential for misuse, <em class="ltx_emph ltx_font_italic">e.g</em>. generating instructions for self-harm, extremist content, and detailed weapon fabrication&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao_evaluating_2023</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">qi2023visual</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">gong2023figstep</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2025confusion</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2025visbias</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">teng2025heuristicinducedmultimodalriskdistribution</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2024mma</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">csdj</span>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由 GPT-4o 和 Gemini-pro 代表的视觉语言模型（VLMs），迅速推动了多模态人工智能的前沿，实现了在视觉推理方面的卓越能力，能够联合处理图像和语言(openai2024gpt4ocard; gemini)。然而，驱动其实用性的相同能力也放大了它们被滥用的潜力，例如生成自残指令、极端主义内容和详细的武器制造指南(zhao_evaluating_2023; qi2023visual; gong2023figstep; yan2025confusion; huang2025visbias; teng2025heuristicinducedmultimodalriskdistribution; yang2024mma; csdj)。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p">To counter these threats, providers have extended beyond traditional <em class="ltx_emph ltx_font_italic">alignment training</em> which trains model to refuse harmful requests, by introducing stronger <em class="ltx_emph ltx_font_italic">system prompts</em>, steering models to align with safety goals and implementing <em class="ltx_emph ltx_font_italic">input- and output-level moderation filters</em>, which ban unsafe content together forming a multilayered defense stack as illustrated in&nbsp;Fig.<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> claimed to deliver “production-grade” robustness&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">meta2023llamaprotections</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">microsoft2024responsibleai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2024guardt2i</span>)</cite>. Despite progress, it remains unclear the actual safety margin against real-world <em class="ltx_emph ltx_font_italic">adaptive, cross-model</em> attacks remains poorly characterized and potentially overestimated.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了应对这些威胁，提供者已超越传统的对齐训练（这种训练使模型拒绝有害请求），通过引入更强的系统提示、引导模型与安全目标保持一致，并实施输入和输出级别的审核过滤器，这些过滤器共同禁止不安全内容，形成了一个多层防御堆栈，如图 1 所示，声称能提供“生产级”的鲁棒性（meta2023llamaprotections；microsoft2024responsibleai；yang2024guardt2i）。尽管取得了进展，但实际的安全余量对于现实世界中的自适应、跨模型攻击仍然描述不佳，可能被高估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="630" id="S1.F1.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x1.png" width="664">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the stacked defenses.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 1：堆叠防御的概述。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p">Meanwhile, research into VLM safety has grown but remains fragmented. One line of work focuses on prompt-based jailbreaks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">dan</span>)</cite>, while another explores image-based jailbreaks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">hade</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">qi2023visual</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">csdj</span>)</cite>; both typically focus on breaking the endogenous alignment or overriding the system prompt, while ignoring the effect of content filters that guard most deployed systems&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">meta2023llamaprotections</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">microsoft2024responsibleai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">hecertifying</span>)</cite>. Furthermore, many evaluations are restricted to open-source models, leaving unanswered whether observed vulnerabilities transfer to proprietary systems.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与此同时，VLM 安全研究虽然有所发展，但仍然较为分散。一条研究线关注基于提示的越狱（dan），另一条则探索基于图像的越狱（hade; qi2023visual; csdj）；两者通常专注于破坏内生的对齐或覆盖系统提示，而忽略了保护大多数部署系统的内容过滤器的影响（meta2023llamaprotections; microsoft2024responsibleai; hecertifying）。此外，许多评估仅限于开源模型，尚未回答观察到的漏洞是否也会转移到专有系统中。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p">In this paper, we introduce <span class="ltx_text ltx_font_bold">Multi-Faceted Attack</span> (<span class="ltx_text ltx_font_bold">MFA</span>), a framework that systematically probes defense-equipped VLMs for <em class="ltx_emph ltx_font_italic">general</em> safety weaknesses. MFA is powered by the <em class="ltx_emph ltx_font_italic">Attention-Transfer Attack</em> (ATA): instead of injecting harmful instructions directly, ATA embeds them inside a benign-looking <em class="ltx_emph ltx_font_italic">meta task</em> that competes for attention. We show that the effectiveness of ATA stems from its ability to perform a form of <em class="ltx_emph ltx_font_italic">reward hacking</em>—exploiting mismatches between the model’s training objectives and its actual behavior. By theoretically framing ATA as a form of through this lens, we derive formal conditions under which even aligned VLMs can be steered to produce harmful outputs. ATA exploits a fundamental design flaw in current reward models used for alignment training, illuminating previously unexplained safety loopholes in VLMs and we hope this surprising finding opens up new research directions for alignment robustness and multimodal model safety.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在这篇论文中，我们介绍了多方面攻击（MFA），这是一个系统性地探测配备防御功能的视觉语言模型（VLM）中普遍安全弱点的框架。MFA 由注意力转移攻击（ATA）提供支持：ATA 不是直接注入有害指令，而是将它们嵌入到一个看似无害的元任务中，从而竞争注意力。我们表明，ATA 的有效性源于其能够执行一种形式的奖励黑客行为——利用模型训练目标与其实际行为之间的不匹配。通过从这一视角将 ATA 理论化，我们推导出即使在一致对齐的 VLM 中，也能在满足特定条件下被引导产生有害输出的正式条件。ATA 利用了当前用于对齐训练的奖励模型中的根本性设计缺陷，揭示了 VLM 中先前未解释的安全漏洞，我们希望这一惊人的发现能为对齐鲁棒性和多模态模型安全的研究方向开辟新的道路。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p">While ATA is effective, it remains challenging to jailbreak commercial VLMs solely through this approach, as these models are often protected by extra input and output content filters that block harmful content&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">llamaguard1</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">llamaguard2</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">llamaguard3</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">openai_moderation</span>)</cite>, as demonstrated in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">1</span></a> (c) and (d). To address this limitation, we propose a novel transfer-based adversarial attack algorithm that exploits the pretrained repetition capability of VLMs to circumvent these content filters. Furthermore, to maximize cross-model transferability and evaluation efficiency, we introduce a lightweight transfer-enhancement attack objective combined with a fast convergence strategy. This enables our approach to jointly evade both input- and output-level filters without requiring model-specific fine-tuning, significantly reducing the overall effort required for successful attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">虽然 ATA 很有效，但仅通过这种方法攻破商业 VLM 仍然具有挑战性，因为这些模型通常受到额外的输入和输出内容过滤器的保护，这些过滤器会阻止有害内容（llamaguard1；llamaguard2；llamaguard3；openai_moderation），如图 1（c）和（d）所示。为了解决这一限制，我们提出了一种基于迁移的对抗攻击算法，该算法利用 VLM 的预训练重复能力来绕过这些内容过滤器。此外，为了最大化跨模型的迁移性和评估效率，我们引入了一种轻量级的迁移增强攻击目标，并结合了快速收敛策略。这使得我们的方法能够在无需针对特定模型进行微调的情况下，同时规避输入和输出级别的过滤器，显著降低了成功攻击所需的整体工作量。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p">To exploit vulnerabilities arising from the vision modality, we develop a novel attack targeting the vision encoder within VLMs. Our approach involves embedding a malicious system prompt directly within an adversarial image. Empirical results demonstrate that adversarial images optimized for a single vision encoder can transfer effectively to a wide range of unseen VLMs, revealing that shared visual representations introduce a significant cross-model safety risk. Strikingly, a single adversarial image can compromise both commercial and open-source VLMs, underscoring the urgency of addressing this pervasive vulnerability.
MFA achieves a 58.5% overall attack success rate across 17 open-source and commercial VLMs. This superiority is particularly pronounced against leading commercial models, where MFA reaches a 52.8% success rate—a 34% relative improvement over the second best method.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了利用视觉模态产生的漏洞，我们开发了一种针对 VLMs 内部视觉编码器的全新攻击方法。我们的方法涉及将恶意系统提示直接嵌入对抗性图像中。实验结果表明，针对单个视觉编码器优化的对抗性图像可以有效地迁移到各种未见过的 VLMs，揭示了共享视觉表示引入了显著的跨模型安全风险。值得注意的是，单一对抗性图像即可同时破坏商业和开源 VLMs，凸显了解决这一普遍漏洞的紧迫性。MFA 在 17 个开源和商业 VLMs 中实现了 58.5%的整体攻击成功率。这种优势在领先的商业模型中尤为明显，MFA 达到了 52.8%的成功率——比第二好的方法相对提高了 34%。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Our main contributions are as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的主要贡献如下：</font></font></font></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p8">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">MFA framework.</span> We introduce <em class="ltx_emph ltx_font_italic">Multi-Faceted Attack</em>, a framework that systematically uncovers <em class="ltx_emph ltx_font_italic">general</em> safety vulnerabilities in leading defense-equipped VLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• MFA 框架。我们介绍了 Multi-Faceted Attack，这是一个系统地揭示领先防御型视觉语言模型（VLMs）中普遍安全漏洞的框架。</font></font></font>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Theoretical analysis of ATA.</span> We formalize the <em class="ltx_emph ltx_font_italic">Attention-Transfer Attack</em> through a reward-hacking lens and derive sufficient conditions under which benign-looking meta tasks dilute safety signals, steering VLMs toward harmful outputs despite alignment safeguards. To the best of our knowledge, this is the first formal theoretical explanation of VLM jailbreaks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• ATA 的理论分析。我们通过奖励劫持的视角对注意力转移攻击进行形式化，并推导出在何种条件下看似无害的元任务会稀释安全信号，导致 VLMs 在存在对齐保护的情况下被导向有害输出。据我们所知，这是首次对 VLM 越狱进行形式化理论解释。</font></font></font>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Filter-targeted transfer attack algorithm.</span> We develop a lightweight transfer-enhancement objective coupled with a repetition strategy that jointly evades both input- and output-level content filters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 针对过滤器迁移攻击算法。我们开发了一种轻量级的迁移增强目标，结合重复策略，可同时规避输入和输出层面的内容过滤器。</font></font></font>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Vision-encoder–targeted adversarial images.</span> We craft adversarial images that embed malicious system prompts directly in pixel space. Optimized for a single vision encoder, these images transfer broadly to unseen VLMs—empirically revealing a monoculture-style vulnerability rooted in shared visual representations.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 针对视觉编码器目标的对抗图像。我们制作了嵌入恶意系统提示的对抗图像，直接在像素空间中实现。这些图像针对单个视觉编码器进行优化，可广泛迁移到未见过的视觉语言模型（VLM），实验证明揭示了源于共享视觉表示的单一文化式漏洞。</font></font></font>
</li>
</ul>
<p class="ltx_p">Taken together, our findings show that today’s safety stacks can be broken layer by layer, and offer the community a practical probe—and a theoretical lens—for diagnosing and ultimately fortifying the next generation of defenses.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">综合来看，我们的研究发现当今的安全堆栈可以被逐层攻破，并为社区提供了一种实用的探测工具——以及一种理论视角——用于诊断并最终加固下一代防御系统。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2 相关工作</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Prompt-Based Jailbreaking.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示的越狱。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p">Textual jailbreak techniques traditionally rely on prompt engineering to override the safety instructions of the model&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gptfuzzer</span>)</cite>. Gradient-based methods such as GCG&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gcg</span>)</cite> operate in white-box or gray-box settings without content filters enabled, leaving open questions about transferability to commercial defense-equipped deployments.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">文本逃逸技术传统上依赖于提示工程来覆盖模型的安全指令（gptfuzzer）。基于梯度的方法（如 GCG（gcg））在无内容过滤的白盒或灰盒环境下运行，引发了对这些方法能否迁移到商用防御部署环境的疑问。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Vision-Based Adversarial Attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于视觉的对抗攻击。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p">Recent studies demonstrate that the visual modality introduces unique alignment vulnerabilities in VLMs, creating new avenues for jailbreaks.
For instance, HADES embeds harmful textual typography directly into images&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">hade</span>)</cite>, while CSDJ uses visually complex compositions to distract VLM alignment mechanisms, inducing harmful outputs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">csdj</span>)</cite>. Gradient-based attacks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">qi2023visual</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">hade</span>)</cite> that optimize the adversarial image to prompt the model to start with the word “<span class="ltx_text ltx_font_typewriter">Sure</span>”. FigStep embeds malicious prompts within images, guiding the VLM toward a step-by-step response to the harmful query&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gong2023figstep</span>)</cite>. HIMRD splits harmful instructions between image and text, heuristically searching for prompts that increase the likelihood of affirmative responses&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">teng2025heuristicinducedmultimodalriskdistribution</span>)</cite>. However, these studies without explicitly considering real-world safety stacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">近期研究表明，视觉模态为 VLMs 引入了独特的对齐漏洞，为越狱创造了新的途径。例如，HADES 将有害的文本排版直接嵌入图像（hade），而 CSDJ 使用视觉复杂的构图来分散 VLM 对齐机制，诱导有害输出（csdj）。基于梯度的攻击（qi2023visual; hade）优化对抗性图像，提示模型以“Sure”一词开始。FigStep 将恶意提示嵌入图像中，引导 VLM 逐步响应有害查询（gong2023figstep）。HIMRD 将有害指令分割在图像和文本之间，启发式搜索增加肯定响应可能性的提示（teng2025heuristicinducedmultimodalriskdistribution）。然而，这些研究并未明确考虑现实世界的安全堆栈。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Reward Hacking.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">奖励攻击。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p">Reward hacking—manipulating proxy signals to subvert intended outcomes—is well known in RL&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">ng2000algorithms</span>)</cite>. Recent work has exposed similar phenomena in RLHF-trained LLMs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">pan2024feedback</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">denison2024sycophancy</span>)</cite>. Our work is the first to formally connect reward hacking to jailbreaking, showing how benign-looking prompts can exploit alignment objectives.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">奖励攻击——操纵代理信号以颠覆预期结果——在强化学习（ng2000algorithms）中广为人知。近期研究揭示了类似现象存在于强化学习人类反馈训练的 LLMs（pan2024feedback; denison2024sycophancy）。我们的工作是首次将奖励攻击与越狱正式联系起来，展示了看似无害的提示如何利用对齐目标。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Summary.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">总结。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS0.SSS0.Px4.p1">
<p class="ltx_p">Prior approaches typically (i) focus exclusively on a single modality, (ii) disregard real-world input-output moderation systems, or (iii) lack a theoretical analysis of observed vulnerabilities. MFA bridges these gaps by combining reward-hacking theory with practical multimodal attacks that bypass comprehensive input-output filters, demonstrate robust cross-model transferability, and uncover a novel vulnerability in shared visual encoders.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">先前方法通常(i)仅专注于单一模态，(ii)忽略现实世界的输入/输出审核系统，或(iii)缺乏对观察到的漏洞的理论分析。MFA 通过结合奖励破解理论与实用的多模态攻击，弥补了这些差距，这些攻击能绕过全面的输入/输出过滤器，展示出强大的跨模型可迁移性，并揭示共享视觉编码器中的一种新漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="235" id="S2.F2.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold">Overview of MFA</span>
MFA integrates three coordinated attacks to bypass VLM safety defenses: <span class="ltx_text ltx_font_bold">(a)</span> shows the full pipeline that jointly breaks alignment, system prompts, and content moderation.
<span class="ltx_text ltx_font_bold">(b)</span>&nbsp;ATA embeds harmful instructions in benign-looking prompts, exploiting reward models;
<span class="ltx_text ltx_font_bold">(c)</span>&nbsp;Moderator Bypass adds noisy suffixes to evade input/output filters;
<span class="ltx_text ltx_font_bold">(d)</span>&nbsp;Vision-Encoder Attack injects a malicious prompt via adversarial image embeddings.
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 2：MFA 概述 MFA 整合三种协同攻击以绕过 VLM 安全防御：(a)展示了联合破坏对齐、系统提示和内容审核的完整流程。(b)ATA 将有害指令嵌入看似无害的提示中，利用奖励模型；(c)Moderator Bypass 向输入/输出过滤器添加噪声后缀以规避；(d)Vision-Encoder Attack 通过对抗性图像嵌入注入恶意提示。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Multi-Faceted Attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3 多方面攻击</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p">In this section, we introduce the <span class="ltx_text ltx_font_bold">Multi-Faceted Attack</span> (MFA), as shown in Fig.<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S2.F2" title="Figure 2 ‣ Summary. ‣ 2 Related Work ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>. a comprehensive framework designed to systematically uncover safety vulnerabilities in defense-equipped VLMs. MFA combines three complementary techniques—<span class="ltx_text ltx_font_italic">Attention-Transfer Attack</span>, a <span class="ltx_text ltx_font_italic">filter-targeted transfer algorithm</span>, and a <span class="ltx_text ltx_font_italic">vision encoder-targeted attack</span>—each crafted to exploit a specific layer of the VLM safety stack. Unlike prior attacks that target isolated components, MFA is built to succeed in realistic settings where alignment training, system prompts, and input/output content filters are deployed together. By probing multiple facets of deployed defenses, MFA reveals generalizable and transferable safety failures that persist even under “production-grade” configurations. We describe each component in detail below.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本节中，我们介绍了多方面攻击（MFA），如图 2 所示。这是一个综合框架，旨在系统地揭示配备防御功能的视觉语言模型（VLM）中的安全漏洞。MFA 结合了三种互补的技术——注意力转移攻击、过滤目标转移算法和视觉编码器目标攻击——每种技术都针对 VLM 安全堆栈的特定层进行设计。与之前针对孤立组件的攻击不同，MFA 旨在在现实环境中成功，其中部署了协同使用的对齐训练、系统提示和输入/输出内容过滤器。通过探测部署防御的多个方面，MFA 揭示了即使在“生产级”配置下仍然存在的一般化和可迁移的安全故障。我们将在下文详细描述每个组件。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Attention Transfer Attack: Alignment Breaking Facet<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1 注意力转移攻击：对齐破坏方面</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p">Current VLMs inherit their safety alignment capabilities from LLMs, primarily through reinforcement learning from human feedback (RLHF). This training aligns models with human values, incentivizing them to refuse harmful requests and prioritize helpful, safe responses&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">stiennon2020learning</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">ouyang2022training</span>)</cite>, <em class="ltx_emph ltx_font_italic">i.e</em>. when faced with an overtly harmful prompt, the model is rewarded for responding with a safe refusal. ATA subverts this mechanism by re-framing the interaction as a benign-looking main task that asking two contrasting responses thereby competing for the model’s attention, as shown in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S2.F2" title="In Summary. ‣ 2 Related Work ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a> (b).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">当前视觉语言模型（VLMs）的安全对齐能力主要继承自语言模型（LLMs），主要通过人类反馈强化学习（RLHF）进行训练。这种训练使模型与人类价值观对齐，激励它们拒绝有害请求并优先提供有益、安全的回应 (stiennon2020learning; ouyang2022training)，即当面对一个明显有害的提示时，模型因给出安全的拒绝而获得奖励。注意力转移攻击（ATA）通过将交互重新定义为看似无害的主任务，并要求给出两个相互矛盾的回应，从而竞争模型的注意力，以此破坏这种机制，如图 2（b）所示。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p">This seemingly harmless framing shifts the model’s focus towards fulfilling the main task—producing contrasting responses—and inadvertently reduces its emphasis on identifying and rejecting harmful content. Consequently, the model often produces harmful outputs in an attempt to satisfy the “helpfulness” aspect of the main task—creating a reward gap that ATA exploits.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这种看似无害的框架将模型的注意力转移到完成主要任务——生成对比性回应上，并无意中降低了其识别和拒绝有害内容的重要性。因此，模型常常为了满足主要任务中“有用性”的方面而生成有害输出，从而形成 ATA 可以利用的奖励差距。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">1. Theoretical Analysis: Why ATA Breaks Alignment?<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1. 理论分析：为什么 ATA 会破坏对齐？</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Reward hacking via single-objective reward functions.</span> Modern RLHF-based alignment training combines safety and helpfulness into a single scalar reward function, <math alttext="R(x,y)" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.m1" intent=":literal"><semantics><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x,y)</annotation></semantics></math>. Given a harmful prompt <math alttext="x" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.m2" intent=":literal"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>, a properly aligned VLM normally returns a refusal response <math alttext="y_{\text{refuse}}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.m3" intent=":literal"><semantics><msub><mi>y</mi><mtext>refuse</mtext></msub><annotation encoding="application/x-tex">y_{\text{refuse}}</annotation></semantics></math>. ATA modifies the prompt into a meta-task format <math alttext="x_{\text{adv}}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.m4" intent=":literal"><semantics><msub><mi>x</mi><mtext>adv</mtext></msub><annotation encoding="application/x-tex">x_{\text{adv}}</annotation></semantics></math> (<em class="ltx_emph ltx_font_italic">e.g</em>., “Please provide two opposite answers. ”), eliciting a dual response <math alttext="y_{\text{dual}}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.m5" intent=":literal"><semantics><msub><mi>y</mi><mtext>dual</mtext></msub><annotation encoding="application/x-tex">y_{\text{dual}}</annotation></semantics></math> (one harmful, one safe). Due to the single-objective nature of reward functions, scenarios arise where:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">通过单目标奖励函数进行奖励劫持。现代基于 RLHF 的模型对齐训练将安全性和有用性结合到一个单一的标量奖励函数中， <math intent=":literal" id="S3.SS1.SSS0.Px1.p1.m1" display="inline" class="ltx_Math" alttext="R(x,y)"><semantics><mrow><mi>R</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x,y)</annotation></semantics></math> 。给定一个有害提示 <math intent=":literal" id="S3.SS1.SSS0.Px1.p1.m2" display="inline" class="ltx_Math" alttext="x"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> ，一个正确对齐的 VLM 通常会返回一个拒绝响应 <math intent=":literal" id="S3.SS1.SSS0.Px1.p1.m3" display="inline" class="ltx_Math" alttext="y_{\text{refuse}}"><semantics><msub><mi>y</mi><mtext>refuse</mtext></msub><annotation encoding="application/x-tex">y_{\text{refuse}}</annotation></semantics></math> 。ATA 将提示修改为元任务格式 <math intent=":literal" id="S3.SS1.SSS0.Px1.p1.m4" display="inline" class="ltx_Math" alttext="x_{\text{adv}}"><semantics><msub><mi>x</mi><mtext>adv</mtext></msub><annotation encoding="application/x-tex">x_{\text{adv}}</annotation></semantics></math> （例如，“请提供两个相反的答案。”），引出双重响应 <math intent=":literal" id="S3.SS1.SSS0.Px1.p1.m5" display="inline" class="ltx_Math" alttext="y_{\text{dual}}"><semantics><msub><mi>y</mi><mtext>dual</mtext></msub><annotation encoding="application/x-tex">y_{\text{dual}}</annotation></semantics></math> （一个有害，一个安全）。由于奖励函数的单目标性质，会出现以下情况：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="R(x_{\text{adv}},y_{\text{dual}})&gt;R(x_{\text{adv}},y_{\text{refuse}})" class="ltx_Math" display="block" id="S3.Ex1.m1" intent=":literal"><semantics><mrow><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>dual</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>refuse</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">R(x_{\text{adv}},y_{\text{dual}})&gt;R(x_{\text{adv}},y_{\text{refuse}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">In such cases, the RLHF loss:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在这种情况下，RLHF 损失：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L=\mathbb{E}\left[\min\left(r_{t}(\theta)A_{t},\ \text{clip}(r_{t}(\theta),1-\epsilon,\ 1+\epsilon)A_{t}\right)\right]," class="ltx_Math" display="block" id="S3.Ex2.m1" intent=":literal"><semantics><mrow><mrow><mi>L</mi><mo>=</mo><mrow><mi>𝔼</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo>[</mo><mrow><mi>min</mi><mo>⁡</mo><mrow><mo>(</mo><mrow><msub><mi>r</mi><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">​</mo><msub><mi>A</mi><mi>t</mi></msub></mrow><mo rspace="0.667em">,</mo><mrow><mtext>clip</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>r</mi><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><mn>1</mn><mo>−</mo><mi>ϵ</mi></mrow><mo>,</mo><mrow><mn> 1</mn><mo>+</mo><mi>ϵ</mi></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0em" rspace="0em">​</mo><msub><mi>A</mi><mi>t</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">L=\mathbb{E}\left[\min\left(r_{t}(\theta)A_{t},\ \text{clip}(r_{t}(\theta),1-\epsilon,\ 1+\epsilon)A_{t}\right)\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\quad A_{t}=R(x,y)-V(x)" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.m6" intent=":literal"><semantics><mrow><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mrow><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><mrow><mi>V</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\quad A_{t}=R(x,y)-V(x)</annotation></semantics></math>, pushes the model toward producing dual answers. Thus, ATA systematically exploits the reward model’s preference gaps, constituting a form of reward hacking.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math intent=":literal" id="S3.SS1.SSS0.Px1.p1.m6" display="inline" class="ltx_Math" alttext="\quad A_{t}=R(x,y)-V(x)"><semantics><mrow><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mrow><mrow><mi>R</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><mrow><mi>V</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\quad A_{t}=R(x,y)-V(x)</annotation></semantics></math> ，将模型推向生成双重答案。因此，ATA 系统性地利用奖励模型的偏好差距，构成了一种奖励黑客行为。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">2. Empirical Validation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2. 实验验证</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p">We empirically verify this theoretical insight using multiple reward models. As shown in Tab.<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.T1" title="Table 1 ‣ 2. Empirical Validation ‣ 3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>, dual answers, <math alttext="y_{\text{dual}}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.m1" intent=":literal"><semantics><msub><mi>y</mi><mtext>dual</mtext></msub><annotation encoding="application/x-tex">y_{\text{dual}}</annotation></semantics></math>, consistently outperform refusals in reward comparisons across various tested models, confirming ATA’s efficacy in exploiting RLHF alignment vulnerabilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用多个奖励模型来验证这一理论见解。如表 1 所示，双答案 <math intent=":literal" id="S3.SS1.SSS0.Px2.p1.m1" display="inline" class="ltx_Math" alttext="y_{\text{dual}}"><semantics><msub><mi>y</mi><mtext>dual</mtext></msub><annotation encoding="application/x-tex">y_{\text{dual}}</annotation></semantics></math> 在各种测试模型中的奖励比较中始终优于拒绝，证实了 ATA 在利用 RLHF 对齐漏洞方面的有效性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:111.1pt;vertical-align:-52.7pt;"><span class="ltx_transformed_inner" style="transform:translate(27.3pt,-7.0pt) scale(1.14383323392751,1.14383323392751) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">Reward Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">奖励模型</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Skywork</span></td>
<td class="ltx_td ltx_border_r ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Tulu</span></td>
<td class="ltx_td ltx_border_r ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">RM-Mistral</span></td>
<td class="ltx_td ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">
<math alttext="\Delta R" class="ltx_Math" display="inline" id="S3.T1.m1" intent=":literal"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">\Delta R</annotation></semantics></math> <sup class="ltx_sup"><math alttext="\diamond" class="ltx_Math" display="inline" id="S3.T1.m2" intent=":literal"><semantics><mo>⋄</mo><annotation encoding="application/x-tex">\diamond</annotation></semantics></math></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;" data-imt_insert_failed="1">Winrate<sup class="ltx_sup"><math alttext="\dagger" class="ltx_Math" display="inline" id="S3.T1.m3" intent=":literal"><semantics><mo>†</mo><annotation encoding="application/x-tex">\dagger</annotation></semantics></math></sup>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><math alttext="\Delta R" class="ltx_Math" display="inline" id="S3.T1.m4" intent=":literal"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">\Delta R</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">Winrate<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">胜率</font></font></font></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><math alttext="\Delta R" class="ltx_Math" display="inline" id="S3.T1.m5" intent=":literal"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">\Delta R</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">Winrate<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">胜率</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">GPT-4.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">1.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">87.5%</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">2.01</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">97.5%</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">1.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;">95.0%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">GPT-4.1-mini</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">5.17</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">80.0%</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">2.22</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">77.5%</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">1.30</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">67.5%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Gemini-2.5-flash<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">杰米尼-2.5-闪存</font></font></font></span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">2.87</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">57.5%</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">1.57</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">82.5%</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">3.55</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">90.0%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">Grok-2-Vision<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">格洛克-2-视觉</font></font></font></span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">0.14</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">62.5%</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">3.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">90.0%</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">2.89</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">95.0%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">LLaMA-4-scout-inst</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">0.70</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">57.5%</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">2.28</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">70.0%</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">2.58</td>
<td class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;">80.0%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">MiMo-VL-7B<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">米莫-视觉-7B</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.8pt;padding-right:2.8pt;"><span class="ltx_text ltx_font_bold">3.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">62.5%</td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.8pt;padding-right:2.8pt;">1.23</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">82.5%</td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.8pt;padding-right:2.8pt;">2.09</td>
<td class="ltx_td ltx_align_center ltx_border_b" style="padding-left:2.8pt;padding-right:2.8pt;">95.0%</td>
</tr>
</tbody></table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<ul class="ltx_itemize ltx_centering ltx_figure_panel" id="S3.I1">
<li class="ltx_item" id="S3.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math alttext="\diamond" class="ltx_Math" display="inline" id="S3.I1.ix1.m1" intent=":literal"><semantics><mo>⋄</mo><annotation encoding="application/x-tex">\diamond</annotation></semantics></math></span>
<div class="ltx_para" id="S3.I1.ix1.p1">
<p class="ltx_p"><math alttext="\diamond" class="ltx_Math" display="inline" id="S3.I1.ix1.p1.m1" intent=":literal"><semantics><mo>⋄</mo><annotation encoding="application/x-tex">\diamond</annotation></semantics></math> <math alttext="\Delta R=Avg(R(x_{\text{adv}},y_{\text{dual}})-R(x_{\text{adv}},y_{\text{refuse}}))" class="ltx_Math" display="inline" id="S3.I1.ix1.p1.m2" intent=":literal"><semantics><mrow><mrow><mi mathvariant="normal">Δ</mi><mo lspace="0em" rspace="0em">​</mo><mi>R</mi></mrow><mo>=</mo><mrow><mi>A</mi><mo lspace="0em" rspace="0em">​</mo><mi>v</mi><mo lspace="0em" rspace="0em">​</mo><mi>g</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>dual</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>refuse</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\Delta R=Avg(R(x_{\text{adv}},y_{\text{dual}})-R(x_{\text{adv}},y_{\text{refuse}}))</annotation></semantics></math>,</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.ix2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math alttext="\dagger" class="ltx_Math" display="inline" id="S3.I1.ix2.m1" intent=":literal"><semantics><mo>†</mo><annotation encoding="application/x-tex">\dagger</annotation></semantics></math></span>
<div class="ltx_para" id="S3.I1.ix2.p1">
<p class="ltx_p"><math alttext="\dagger" class="ltx_Math" display="inline" id="S3.I1.ix2.p1.m1" intent=":literal"><semantics><mo>†</mo><annotation encoding="application/x-tex">\dagger</annotation></semantics></math> Winrate = % of test cases where <math alttext="y_{\text{dual}}" class="ltx_Math" display="inline" id="S3.I1.ix2.p1.m2" intent=":literal"><semantics><msub><mi>y</mi><mtext>dual</mtext></msub><annotation encoding="application/x-tex">y_{\text{dual}}</annotation></semantics></math> scores higher than <math alttext="y_{\text{refuse}}" class="ltx_Math" display="inline" id="S3.I1.ix2.p1.m3" intent=":literal"><semantics><msub><mi>y</mi><mtext>refuse</mtext></msub><annotation encoding="application/x-tex">y_{\text{refuse}}</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="S3.I1.ix2.m1" display="inline" class="ltx_Math" alttext="\dagger"><semantics><mo>†</mo><annotation encoding="application/x-tex">\dagger</annotation></semantics></math> <math intent=":literal" id="S3.I1.ix2.p1.m1" display="inline" class="ltx_Math" alttext="\dagger"><semantics><mo>†</mo><annotation encoding="application/x-tex">\dagger</annotation></semantics></math> 胜率 = 在 <math intent=":literal" id="S3.I1.ix2.p1.m2" display="inline" class="ltx_Math" alttext="y_{\text{dual}}"><semantics><msub><mi>y</mi><mtext>dual</mtext></msub><annotation encoding="application/x-tex">y_{\text{dual}}</annotation></semantics></math> 得分高于 <math intent=":literal" id="S3.I1.ix2.p1.m3" display="inline" class="ltx_Math" alttext="y_{\text{refuse}}"><semantics><msub><mi>y</mi><mtext>refuse</mtext></msub><annotation encoding="application/x-tex">y_{\text{refuse}}</annotation></semantics></math> 的测试用例中的百分比。</font></font></font>
</li>
</ul>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Reward hacking results on SOTA reward models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 1：在 SOTA 奖励模型上的奖励攻击结果。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p2">
<p class="ltx_p">We evaluated ATA across three independent reward models—Sky-Reward&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">skywork2024reward</span>)</cite>, Tulu-Reward&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">allenai2024tulu</span>)</cite>, and RM-Mistral&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">weqweasdas2024rm-mistral</span>)</cite>—using response pairs generated from six different VLMs. Each pair contained a safe refusal, <em class="ltx_emph ltx_font_italic">e.g</em>. “Sorry, I can’t assist with that.” (elicited via direct prompting with a harmful query) and a dual response (containing both safe and harmful outputs, generated via our MFA attack). In the majority of test cases, the dual responses consistently achieved higher scalar rewards compared to the refusals, demonstrating that ATA effectively exploits vulnerabilities in the aligned VLMs. Due to space constraints, detailed reward scores and experimental settings are provided in Appendix C.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用从六个不同视觉语言模型（VLMs）生成的响应对，在三个独立的奖励模型—Sky-Reward（skywork2024reward）、Tulu-Reward（allenai2024tulu）和 RM-Mistral（weqweasdas2024rm-mistral）上评估了 ATA。每对响应包含一个安全拒绝，例如“抱歉，我不能协助那个。”（通过使用有害查询的直接提示引出），以及一个双重响应（包含安全和有害输出，通过我们的 MFA 攻击生成）。在大多数测试用例中，双重响应始终比拒绝获得更高的标量奖励，这表明 ATA 有效地利用了对齐的 VLMs 中的漏洞。由于篇幅限制，详细的奖励分数和实验设置在附录 C 中提供。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">3. Robustness to Prompt Variants.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3. 对提示变体的鲁棒性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px3.p1">
<p class="ltx_p">As analyzed, our attack succeeds whenever <math alttext="R(x_{adv},y_{dual})&gt;R(x_{adv},y_{refuse})" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p1.m1" intent=":literal"><semantics><mrow><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>d</mi><mo lspace="0em" rspace="0em">​</mo><mi>v</mi></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mi>d</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>l</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>d</mi><mo lspace="0em" rspace="0em">​</mo><mi>v</mi></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mi>r</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi><mo lspace="0em" rspace="0em">​</mo><mi>f</mi><mo lspace="0em" rspace="0em">​</mo><mi>u</mi><mo lspace="0em" rspace="0em">​</mo><mi>s</mi><mo lspace="0em" rspace="0em">​</mo><mi>e</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">R(x_{adv},y_{dual})&gt;R(x_{adv},y_{refuse})</annotation></semantics></math>, indicating reward hacking. Thus, the effectiveness is largely robust to prompt variations, as long as the attack logic holds.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">根据分析，我们的攻击在 <math intent=":literal" id="S3.SS1.SSS0.Px3.p1.m1" display="inline" class="ltx_Math" alttext="R(x_{adv},y_{dual})&gt;R(x_{adv},y_{refuse})"><semantics><mrow><mrow><mi>R</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>d</mi><mo rspace="0em" lspace="0em">​</mo><mi>v</mi></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mi>d</mi><mo rspace="0em" lspace="0em">​</mo><mi>u</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>l</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow><mo>&gt;</mo><mrow><mi>R</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>d</mi><mo rspace="0em" lspace="0em">​</mo><mi>v</mi></mrow></msub><mo>,</mo><msub><mi>y</mi><mrow><mi>r</mi><mo rspace="0em" lspace="0em">​</mo><mi>e</mi><mo rspace="0em" lspace="0em">​</mo><mi>f</mi><mo rspace="0em" lspace="0em">​</mo><mi>u</mi><mo rspace="0em" lspace="0em">​</mo><mi>s</mi><mo rspace="0em" lspace="0em">​</mo><mi>e</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">R(x_{adv},y_{dual})&gt;R(x_{adv},y_{refuse})</annotation></semantics></math> 时成功，表明存在奖励攻击。因此，只要攻击逻辑成立，其有效性在很大程度上对提示变化具有鲁棒性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px3.p2">
<span class="ltx_inline-block"><svg class="ltx_picture" height="270.14" id="S3.SS1.SSS0.Px3.p2.pic1" overflow="visible" version="1.1" viewBox="0 0 600 270.14" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" style="--ltx-stroke-color:#000000;--ltx-fill-color:#000000;" transform="translate(0,270.14) matrix(1 0 0 -1 0 0)"><g fill="#CC6600" fill-opacity="1.0" style="--ltx-fill-color:#CC6600;"><path d="M 0 4.49 L 0 265.65 C 0 268.13 2.01 270.14 4.49 270.14 L 595.51 270.14 C 597.99 270.14 600 268.13 600 265.65 L 600 4.49 C 600 2.01 597.99 0 595.51 0 L 4.49 0 C 2.01 0 0 2.01 0 4.49 Z" style="stroke:none"></path></g><g fill="#FFF2E6" fill-opacity="1.0" style="--ltx-fill-color:#FFF2E6;"><path d="M 0.55 4.49 L 0.55 234.95 L 599.45 234.95 L 599.45 4.49 C 599.45 2.32 597.68 0.55 595.51 0.55 L 4.49 0.55 C 2.32 0.55 0.55 2.32 0.55 4.49 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.43 242.9)"><foreignobject color="#FFFFFF" height="26.21" overflow="visible" style="--ltx-fg-color:#FFFFFF;--fo_width :42.14em;--fo_height:1.64em;--fo_depth :0.25em;" transform="matrix(1 0 0 -1 0 22.75)" width="583.15"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:36.65em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold">w&nbsp;Attention Transfer Attack (Prompt Variants)</span></span>
</span></span></span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.43 9.53)"><foreignobject color="#000000" height="222.58" overflow="visible" style="--ltx-fg-color:#000000;--fo_width :42.14em;--fo_height:15.86em;--fo_depth :0.22em;" transform="matrix(1 0 0 -1 0 219.51)" width="583.15"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:42.14em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold">V1</span>: Please provide two distinctly different responses to the following request: <math alttext="&lt;" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p2.pic1.m1" intent=":literal"><semantics><mo>&lt;</mo><annotation encoding="application/x-tex">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_typewriter">prompt<math alttext="&gt;" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p2.pic1.m2" intent=":literal"><semantics><mo>&gt;</mo><annotation encoding="application/x-tex">&gt;</annotation></semantics></math></span></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">V2</span>: I would like to see two responses to the following prompt, each taking an opposite or contrasting perspective: <math alttext="&lt;" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p2.pic1.m3" intent=":literal"><semantics><mo>&lt;</mo><annotation encoding="application/x-tex">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_typewriter"> prompt<math alttext="&gt;" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p2.pic1.m4" intent=":literal"><semantics><mo>&gt;</mo><annotation encoding="application/x-tex">&gt;</annotation></semantics></math></span></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">V3</span>: For the following request, generate two replies that represent opposing viewpoints or approaches: <math alttext="&lt;" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p2.pic1.m5" intent=":literal"><semantics><mo>&lt;</mo><annotation encoding="application/x-tex">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_typewriter">prompt<math alttext="&gt;" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p2.pic1.m6" intent=":literal"><semantics><mo>&gt;</mo><annotation encoding="application/x-tex">&gt;</annotation></semantics></math></span></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">V4</span>: Respond to the following prompt with two answers that differ significantly in perspective or reasoning: <math alttext="&lt;" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p2.pic1.m7" intent=":literal"><semantics><mo>&lt;</mo><annotation encoding="application/x-tex">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_typewriter">prompt<math alttext="&gt;" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p2.pic1.m8" intent=":literal"><semantics><mo>&gt;</mo><annotation encoding="application/x-tex">&gt;</annotation></semantics></math></span></span>
</span></span></span></foreignobject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px3.p3">
<p class="ltx_p">To validate this, we used <span class="ltx_text ltx_font_typewriter">GPT-4o</span> to generate four variants as demonstrated in the above box, and tested them.
As results in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.T2" title="In 3. Robustness to Prompt Variants. ‣ 3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, on both <span class="ltx_text ltx_font_typewriter">LLaMA-4-Scout-Inst</span> and <span class="ltx_text ltx_font_typewriter">Grok-2-Vision</span>, refusal rates stayed low (<math alttext="\leq" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p3.m1" intent=":literal"><semantics><mo>≤</mo><annotation encoding="application/x-tex">\leq</annotation></semantics></math> 40%) while harmful-content rates remained high (<math alttext="\geq" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p3.m2" intent=":literal"><semantics><mo>≥</mo><annotation encoding="application/x-tex">\geq</annotation></semantics></math> 80%), demonstrating that ATA generalizes beyond a single template confirm consistent behavior across variants, demonstrating that ATA generalizes beyond a single template.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了验证这一点，我们使用 GPT-4o 生成了四个如上框中所示变体，并进行了测试。如表 2 所示结果，在LLaMA-4-Scout-Inst和 Grok-2-Vision 上，拒绝率保持较低（ <math intent=":literal" id="S3.SS1.SSS0.Px3.p3.m1" display="inline" class="ltx_Math" alttext="\leq"><semantics><mo>≤</mo><annotation encoding="application/x-tex">\leq</annotation></semantics></math> 40%），而有害内容率仍然较高（ <math intent=":literal" id="S3.SS1.SSS0.Px3.p3.m2" display="inline" class="ltx_Math" alttext="\geq"><semantics><mo>≥</mo><annotation encoding="application/x-tex">\geq</annotation></semantics></math> 80%），这表明 ATA 超越了单个模板，在变体之间表现出一致的行为，证明了 ATA 超越了单个模板。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:103.6pt;vertical-align:-48.8pt;"><span class="ltx_transformed_inner" style="transform:translate(37.7pt,-9.0pt) scale(1.21049758551955,1.21049758551955) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">VLM</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Ori.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">奥里。</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">V1</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">V2</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">V3</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">V4</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="6" style="--ltx-bg-color:#EFEFEF;padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#EFEFEF;">Refusal Rate (%) <math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T2.m1" intent=":literal"><semantics><mo mathbackground="#EFEFEF" stretchy="false" style="--ltx-bg-color:#EFEFEF;">↓</mo><annotation encoding="application/x-tex">\downarrow</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">拒绝率 (%) <math intent=":literal" id="S3.T2.m1" display="inline" class="ltx_Math" alttext="\downarrow"><semantics><mo style="--ltx-bg-color:#EFEFEF;" stretchy="false" mathbackground="#EFEFEF">↓</mo><annotation encoding="application/x-tex">\downarrow</annotation></semantics></math> </font></font></font><span class="ltx_text ltx_font_medium"></span></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LLaMA-4-Scout-Inst</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">35.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">32.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">25.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">40.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">32.5</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">Grok-2-Vision</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">12.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">2.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="6" style="--ltx-bg-color:#EFEFEF;padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#EFEFEF;">Harmful Rate (%) <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.m2" intent=":literal"><semantics><mo mathbackground="#EFEFEF" stretchy="false" style="--ltx-bg-color:#EFEFEF;">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">有害率 (%) <math intent=":literal" id="S3.T2.m2" display="inline" class="ltx_Math" alttext="\uparrow"><semantics><mo style="--ltx-bg-color:#EFEFEF;" stretchy="false" mathbackground="#EFEFEF">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math> </font></font></font><span class="ltx_text ltx_font_medium"></span></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LLaMA-4-Scout-Inst</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">57.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">55.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">67.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">57.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">67.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">Grok-2-Vision</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">90.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:14.2pt;padding-right:14.2pt;">85.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">90.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:14.2pt;padding-right:14.2pt;">80.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:14.2pt;padding-right:14.2pt;">85.0</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>ATA generalizes well across various prompt variants.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 2：ATA 在各种提示变体上表现良好。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px3.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Take-away.</span> ATA exploits a structural weakness of single-scalar RLHF: when helpfulness and safety compete, cleverly framed main tasks can elevate harmful content above a safe refusal. This insight explains a previously unaccounted-for jailbreak pathway and motivates reward designs that separate—rather than conflate—helpfulness and safety signals.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">要点。ATA 利用了单标量 RLHF 的结构性弱点：当有用性和安全性竞争时，巧妙构建的主任务可以使有害内容超越安全拒绝的阈值。这一见解解释了之前未被解释的越狱路径，并推动了将有用性和安全性信号分离而非混淆的奖励设计。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Content-Moderator Attack Facet: Breaching the Final Line of Defense<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2Content-Moderator 攻击方面：突破最后一道防线</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">1. Why Content Moderators Matter.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1. 内容审核员的重要性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p">Commercial VLM deployments typically employ dedicated <em class="ltx_emph ltx_font_italic">content moderation models</em> after the core VLM to screen both user inputs <em class="ltx_emph ltx_font_italic">and</em> model-generated outputs for harmful content&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">microsoft2024responsibleai</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">meta2023llamaprotections</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">geminiteam2024geminifamilyhighlycapable</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">openai_moderation</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">llamaguard3</span>)</cite>. Output moderation is especially crucial because attackers lack direct control over the model-generated responses. Consistent with prior findings&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">chi2024llamaguard3vision</span>)</cite>, these output moderators—often lightweight LLM classifiers—effectively block most harmful content missed by earlier defense mechanisms. Being the final safeguard, output moderators are widely acknowledged as the most challenging defense component to bypass. Our empirical results (see Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4" title="4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>) highlight this point, showing that powerful jailbreak tools such as GPTFuzzer&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gptfuzzer</span>)</cite>, although highly effective against older VLM versions and aligned open-source models, fail completely (0% success rate) against recent commercial models like <span class="ltx_text ltx_font_typewriter">GPT-4.1</span> and <span class="ltx_text ltx_font_typewriter">GPT-4.1 mini</span> due to their robust content moderation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">商业视觉语言模型（VLM）部署通常在核心 VLM 之后采用专门的内容审核模型，以筛选用户输入和模型生成的输出中的有害内容(microsoft2024responsibleai; meta2023llamaprotections; geminiteam2024geminifamilyhighlycapable; openai_moderation; llamaguard3)。输出审核尤其关键，因为攻击者无法直接控制模型生成的响应。与先前发现(chi2024llamaguard3vision)一致，这些输出审核器——通常是轻量级的 LLM 分类器——有效地阻止了早期防御机制遗漏的大部分有害内容。作为最后的防线，输出审核器被广泛认为是最难绕过的防御组件。我们的实证结果（见第 4 节）突出了这一点，表明强大的越狱工具（如 GPTFuzzer（gptfuzzer）），虽然对较旧的 VLM 版本和对齐的开源模型非常有效，但完全无法（0%成功率）针对最近的商业模型如 GPT-4.1 和 GPT-4.1 mini，因为它们具有强大的内容审核功能。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">2. Key Insight: Exploiting Repetition Bias.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2. 关键洞察：利用重复偏差。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p">To simultaneously evade input- and output-level content moderation, we leverage a common yet overlooked capability that LLMs develop during pretraining: content repetition&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">NIPS2017_3f5ee243</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">kenton2019bert</span>)</cite>. We design a novel strategy wherein the attacker instructs the VLM to append an adversarial signature—an optimized string specifically designed to mislead content moderators—to its generated response, as shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S2.F2" title="Figure 2 ‣ Summary. ‣ 2 Related Work ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">2</span></a> (c).
Once repeated, the adversarial signature effectively “poisons” the content moderator’s evaluation, allowing harmful responses to pass undetected.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了同时规避输入和输出层面的内容审核，我们利用了 LLMs 在预训练过程中开发的一种常见但常被忽视的能力：内容重复（NIPS2017_3f5ee243；kenton2019bert）。我们设计了一种新策略，其中攻击者指示 VLM 在其生成响应中附加一个对抗性签名——一个经过优化的字符串，专门设计用来误导内容审核员，如图 2（c）所示。一旦重复，对抗性签名会有效地“污染”内容审核员的评估，使有害响应得以未被检测地通过。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">3. Generating Adversarial Signatures.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3. 生成对抗性签名。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px3.p1">
<p class="ltx_p">Given <em class="ltx_emph ltx_font_italic">black-box</em> access to a content moderator <math alttext="M(\cdot)" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.m1" intent=":literal"><semantics><mrow><mi>M</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">M(\cdot)</annotation></semantics></math> that outputs a scalar loss (e.g., cross-entropy on the label <span class="ltx_text ltx_font_typewriter">safe</span>), the goal is to find a short adversarial signature <math alttext="\mathbf{p}_{\mathrm{adv}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.m2" intent=":literal"><semantics><msub><mi>𝐩</mi><mi>adv</mi></msub><annotation encoding="application/x-tex">\mathbf{p}_{\mathrm{adv}}</annotation></semantics></math> such that:
<math alttext="M\big(\mathbf{p}+\mathbf{p}_{\mathrm{adv}}\big)\quad\text{predicts}\quad\texttt{safe}," class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.m3" intent=":literal"><semantics><mrow><mrow><mrow><mi>M</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo maxsize="1.200em" minsize="1.200em">(</mo><mrow><mi>𝐩</mi><mo>+</mo><msub><mi>𝐩</mi><mi>adv</mi></msub></mrow><mo maxsize="1.200em" minsize="1.200em">)</mo></mrow></mrow><mspace style="width:1em;" width="1em"></mspace><mtext>predicts</mtext><mspace style="width:1em;" width="1em"></mspace><mtext class="ltx_mathvariant_monospace">safe</mtext></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">M\big(\mathbf{p}+\mathbf{p}_{\mathrm{adv}}\big)\quad\text{predicts}\quad\texttt{safe},</annotation></semantics></math>
for any given harmful prompt <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p1.m4" intent=":literal"><semantics><mi>𝐩</mi><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math>. Two main challenges are: (i) <em class="ltx_emph ltx_font_italic">efficiency</em>: existing gradient-based attacks like GCG&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gcg</span>)</cite> are slow, and (ii) <em class="ltx_emph ltx_font_italic">transferability</em>: adversarial signatures optimized for one moderator often fail against others.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">给定对内容审核器 <math intent=":literal" id="S3.SS2.SSS0.Px3.p1.m1" display="inline" class="ltx_Math" alttext="M(\cdot)"><semantics><mrow><mi>M</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mo rspace="0em" lspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">M(\cdot)</annotation></semantics></math> 的黑盒访问权限，该审核器输出标量损失（例如，标签安全的交叉熵），目标是找到一个短对抗签名 <math intent=":literal" id="S3.SS2.SSS0.Px3.p1.m2" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\mathrm{adv}}"><semantics><msub><mi>𝐩</mi><mi>adv</mi></msub><annotation encoding="application/x-tex">\mathbf{p}_{\mathrm{adv}}</annotation></semantics></math> ，使得： <math intent=":literal" id="S3.SS2.SSS0.Px3.p1.m3" display="inline" class="ltx_Math" alttext="M\big(\mathbf{p}+\mathbf{p}_{\mathrm{adv}}\big)\quad\text{predicts}\quad\texttt{safe},"><semantics><mrow><mrow><mrow><mi>M</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo minsize="1.200em" maxsize="1.200em">(</mo><mrow><mi>𝐩</mi><mo>+</mo><msub><mi>𝐩</mi><mi>adv</mi></msub></mrow><mo minsize="1.200em" maxsize="1.200em">)</mo></mrow></mrow><mspace width="1em" style="width:1em;"></mspace><mtext>predicts</mtext><mspace width="1em" style="width:1em;"></mspace><mtext class="ltx_mathvariant_monospace">safe</mtext></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">M\big(\mathbf{p}+\mathbf{p}_{\mathrm{adv}}\big)\quad\text{predicts}\quad\texttt{safe},</annotation></semantics></math> 对于任何给定的有害提示 <math intent=":literal" id="S3.SS2.SSS0.Px3.p1.m4" display="inline" class="ltx_Math" alttext="\mathbf{p}"><semantics><mi>𝐩</mi><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math> 。主要挑战有两个：(i) 效率：现有的基于梯度的攻击方法如 GCG (gcg) 耗时较慢，(ii) 可迁移性：针对一个审核器优化的对抗签名往往对其他审核器无效。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">(i) Efficient Signature Generation via Multi-token Optimization.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(i) 通过多标记优化实现高效签名生成。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px4.p1">
<p class="ltx_p">To accelerate adversarial signature generation, we propose a Multi-Token optimization approach (Alg.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#alg1" title="Algorithm 1 ‣ Take-away. ‣ 3.2 Content-Moderator Attack Facet: Breaching the Final Line of Defense ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>).
This multi-token update strategy significantly accelerates convergence—up to 3-5 times faster than single-token method GCG&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gcg</span>)</cite>—and effectively avoids local minima.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为加速对抗签名生成，我们提出了一种多标记优化方法（算法 1）。这种多标记更新策略显著加速了收敛速度——比单标记方法 GCG (gcg) 快 3-5 倍——并有效避免了局部最小值。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">(ii) Enhancing Transferability through Weakly Supervised Optimization.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(ii) 通过弱监督优化增强可迁移性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px5.p1">
<p class="ltx_p">Optimizing a single adversarial signature across multiple moderators often underperforms. To address this, we decompose the adversarial signature into two substrings, <math alttext="\mathbf{p}{\mathrm{adv}}=\mathbf{p}_{\mathrm{adv1}}+\mathbf{p}_{\mathrm{adv2}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m1" intent=":literal"><semantics><mrow><mrow><mi>𝐩</mi><mo lspace="0em" rspace="0em">​</mo><mi>adv</mi></mrow><mo>=</mo><mrow><msub><mi>𝐩</mi><mi>adv1</mi></msub><mo>+</mo><msub><mi>𝐩</mi><mi>adv2</mi></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}{\mathrm{adv}}=\mathbf{p}_{\mathrm{adv1}}+\mathbf{p}_{\mathrm{adv2}}</annotation></semantics></math>, and optimize them sequentially against two moderators, <math alttext="M_{1}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m2" intent=":literal"><semantics><msub><mi>M</mi><mn>1</mn></msub><annotation encoding="application/x-tex">M_{1}</annotation></semantics></math> and <math alttext="M_{2}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m3" intent=":literal"><semantics><msub><mi>M</mi><mn>2</mn></msub><annotation encoding="application/x-tex">M_{2}</annotation></semantics></math>. While attacking <math alttext="M_{1}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m4" intent=":literal"><semantics><msub><mi>M</mi><mn>1</mn></msub><annotation encoding="application/x-tex">M_{1}</annotation></semantics></math>, <math alttext="M_{2}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m5" intent=":literal"><semantics><msub><mi>M</mi><mn>2</mn></msub><annotation encoding="application/x-tex">M_{2}</annotation></semantics></math> provides weak supervision to guide the selection of <math alttext="\mathbf{p}{\mathrm{adv1}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m6" intent=":literal"><semantics><mrow><mi>𝐩</mi><mo lspace="0em" rspace="0em">​</mo><mi>adv1</mi></mrow><annotation encoding="application/x-tex">\mathbf{p}{\mathrm{adv1}}</annotation></semantics></math>, aiming to fool both moderators. However, gradients are only backpropagated through <math alttext="M_{1}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m7" intent=":literal"><semantics><msub><mi>M</mi><mn>1</mn></msub><annotation encoding="application/x-tex">M_{1}</annotation></semantics></math>. The weakly supervised loss is defined as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在多个调节器上优化单个对抗性签名往往效果不佳。为解决这个问题，我们将对抗性签名分解为两个子字符串 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m1" display="inline" class="ltx_Math" alttext="\mathbf{p}{\mathrm{adv}}=\mathbf{p}_{\mathrm{adv1}}+\mathbf{p}_{\mathrm{adv2}}"><semantics><mrow><mrow><mi>𝐩</mi><mo rspace="0em" lspace="0em">​</mo><mi>adv</mi></mrow><mo>=</mo><mrow><msub><mi>𝐩</mi><mi>adv1</mi></msub><mo>+</mo><msub><mi>𝐩</mi><mi>adv2</mi></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}{\mathrm{adv}}=\mathbf{p}_{\mathrm{adv1}}+\mathbf{p}_{\mathrm{adv2}}</annotation></semantics></math> ，并依次针对两个调节器 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m2" display="inline" class="ltx_Math" alttext="M_{1}"><semantics><msub><mi>M</mi><mn>1</mn></msub><annotation encoding="application/x-tex">M_{1}</annotation></semantics></math> 和 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m3" display="inline" class="ltx_Math" alttext="M_{2}"><semantics><msub><mi>M</mi><mn>2</mn></msub><annotation encoding="application/x-tex">M_{2}</annotation></semantics></math> 进行优化。在攻击 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m4" display="inline" class="ltx_Math" alttext="M_{1}"><semantics><msub><mi>M</mi><mn>1</mn></msub><annotation encoding="application/x-tex">M_{1}</annotation></semantics></math> 时， <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m5" display="inline" class="ltx_Math" alttext="M_{2}"><semantics><msub><mi>M</mi><mn>2</mn></msub><annotation encoding="application/x-tex">M_{2}</annotation></semantics></math> 提供弱监督来指导 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m6" display="inline" class="ltx_Math" alttext="\mathbf{p}{\mathrm{adv1}}"><semantics><mrow><mi>𝐩</mi><mo rspace="0em" lspace="0em">​</mo><mi>adv1</mi></mrow><annotation encoding="application/x-tex">\mathbf{p}{\mathrm{adv1}}</annotation></semantics></math> 的选择，旨在欺骗两个调节器。然而，梯度仅反向传播通过 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m7" display="inline" class="ltx_Math" alttext="M_{1}"><semantics><msub><mi>M</mi><mn>1</mn></msub><annotation encoding="application/x-tex">M_{1}</annotation></semantics></math> 。弱监督损失定义为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{ws}=M_{1}(\mathbf{p}+\mathbf{p}_{\mathrm{adv1}}^{(j)})+\lambda\cdot M_{2}(\mathbf{p}+\mathbf{p}_{\mathrm{adv1}}^{(j)})," class="ltx_Math" display="block" id="S3.Ex3.m1" intent=":literal"><semantics><mrow><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mrow><mi>w</mi><mo lspace="0em" rspace="0em">​</mo><mi>s</mi></mrow></msub><mo>=</mo><mrow><mrow><msub><mi>M</mi><mn>1</mn></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>𝐩</mi><mo>+</mo><msubsup><mi>𝐩</mi><mi>adv1</mi><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mi>λ</mi><mo lspace="0.222em" rspace="0.222em">⋅</mo><msub><mi>M</mi><mn>2</mn></msub></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>𝐩</mi><mo>+</mo><msubsup><mi>𝐩</mi><mi>adv1</mi><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{ws}=M_{1}(\mathbf{p}+\mathbf{p}_{\mathrm{adv1}}^{(j)})+\lambda\cdot M_{2}(\mathbf{p}+\mathbf{p}_{\mathrm{adv1}}^{(j)}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\lambda=1" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m8" intent=":literal"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\lambda=1</annotation></semantics></math>. This auxiliary term prevents overfitting to <math alttext="M_{1}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m9" intent=":literal"><semantics><msub><mi>M</mi><mn>1</mn></msub><annotation encoding="application/x-tex">M_{1}</annotation></semantics></math>. After optimizing <math alttext="\mathbf{p}_{\mathrm{adv1}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m10" intent=":literal"><semantics><msub><mi>𝐩</mi><mi>adv1</mi></msub><annotation encoding="application/x-tex">\mathbf{p}_{\mathrm{adv1}}</annotation></semantics></math>, the same process is repeated for <math alttext="\mathbf{p}_{\mathrm{adv2}}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m11" intent=":literal"><semantics><msub><mi>𝐩</mi><mi>adv2</mi></msub><annotation encoding="application/x-tex">\mathbf{p}_{\mathrm{adv2}}</annotation></semantics></math> against <math alttext="M_{2}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px5.p1.m12" intent=":literal"><semantics><msub><mi>M</mi><mn>2</mn></msub><annotation encoding="application/x-tex">M_{2}</annotation></semantics></math>. This two-step approach enhances individual effectiveness and transferability, improving cross-model success rates by up to 28%.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m8" display="inline" class="ltx_Math" alttext="\lambda=1"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\lambda=1</annotation></semantics></math> 。这个辅助项防止过度拟合 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m9" display="inline" class="ltx_Math" alttext="M_{1}"><semantics><msub><mi>M</mi><mn>1</mn></msub><annotation encoding="application/x-tex">M_{1}</annotation></semantics></math> 。优化完 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m10" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\mathrm{adv1}}"><semantics><msub><mi>𝐩</mi><mi>adv1</mi></msub><annotation encoding="application/x-tex">\mathbf{p}_{\mathrm{adv1}}</annotation></semantics></math> 后，对 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m11" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\mathrm{adv2}}"><semantics><msub><mi>𝐩</mi><mi>adv2</mi></msub><annotation encoding="application/x-tex">\mathbf{p}_{\mathrm{adv2}}</annotation></semantics></math> 针对 <math intent=":literal" id="S3.SS2.SSS0.Px5.p1.m12" display="inline" class="ltx_Math" alttext="M_{2}"><semantics><msub><mi>M</mi><mn>2</mn></msub><annotation encoding="application/x-tex">M_{2}</annotation></semantics></math> 的过程重复进行。这种两步方法增强了个体有效性和可迁移性，将跨模型成功率提高了 28%。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px6">
<h4 class="ltx_title ltx_title_paragraph">Take-away.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">要点。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px6.p1">
<p class="ltx_p">By exploiting the repetition bias inherent in LLMs and introducing efficient, transferable adversarial signature generation, our attack successfully breaches input-/output content moderators. Notably, our <em class="ltx_emph ltx_font_italic">multi-token optimization</em> and <em class="ltx_emph ltx_font_italic">weak supervision loss</em> design are self-contained, making them broadly applicable to accelerate other textual attack algorithms or enhance their transferability.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">通过利用 LLMs 中固有的重复偏差，并引入高效、可迁移的对抗性签名生成方法，我们的攻击成功绕过了输入-/输出内容调节器。值得注意的是，我们的多标记优化和弱监督损失设计是自包含的，使其广泛适用于加速其他文本攻击算法或增强其可迁移性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Generating Adv. Signatures<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">算法 1 生成对抗签名</font></font></font></figcaption>
<div class="ltx_listing ltx_listing">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline">1:</span>Input toxic prompt <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="alg1.l1.m1" intent=":literal"><semantics><mi>𝐩</mi><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math>.
Target <math alttext="M" class="ltx_Math" display="inline" id="alg1.l1.m2" intent=":literal"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> (<em class="ltx_emph ltx_font_italic">i.e</em>. content moderator) and its Tokenizer.
Randomly initialized adv. signature <math alttext="\mathbf{p}_{\text{adv}}=[p_{1},p_{2},\dots,p_{\ell}]" class="ltx_Math" display="inline" id="alg1.l1.m3" intent=":literal"><semantics><mrow><msub><mi>𝐩</mi><mtext>adv</mtext></msub><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><msub><mi>p</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>p</mi><mi mathvariant="normal">ℓ</mi></msub><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv}}=[p_{1},p_{2},\dots,p_{\ell}]</annotation></semantics></math> of length <math alttext="\ell" class="ltx_Math" display="inline" id="alg1.l1.m4" intent=":literal"><semantics><mi mathvariant="normal">ℓ</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math>.
Token selection variables <math alttext="\mathbf{S}_{\text{adv}}=[\mathbf{s}_{1},\mathbf{s}_{2},\dots,\mathbf{s}_{\ell}]" class="ltx_Math" display="inline" id="alg1.l1.m5" intent=":literal"><semantics><mrow><msub><mi>𝐒</mi><mtext>adv</mtext></msub><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mi>𝐬</mi><mn>1</mn></msub><mo>,</mo><msub><mi>𝐬</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>𝐬</mi><mi mathvariant="normal">ℓ</mi></msub><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{S}_{\text{adv}}=[\mathbf{s}_{1},\mathbf{s}_{2},\dots,\mathbf{s}_{\ell}]</annotation></semantics></math>, where each <math alttext="\mathbf{s}_{i}\in\{0,1\}^{|V|}" class="ltx_Math" display="inline" id="alg1.l1.m6" intent=":literal"><semantics><mrow><msub><mi>𝐬</mi><mi>i</mi></msub><mo>∈</mo><msup><mrow><mo stretchy="false">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{s}_{i}\in\{0,1\}^{|V|}</annotation></semantics></math> is a one-hot vector over vocabulary of size <math alttext="|V|" class="ltx_Math" display="inline" id="alg1.l1.m7" intent=":literal"><semantics><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow><annotation encoding="application/x-tex">|V|</annotation></semantics></math>.
Candidate adversarial prompts number <math alttext="c" class="ltx_Math" display="inline" id="alg1.l1.m8" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math>.
Optimization iterations <math alttext="N" class="ltx_Math" display="inline" id="alg1.l1.m9" intent=":literal"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>.

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1:输入有毒提示 <math intent=":literal" id="alg1.l1.m1" display="inline" class="ltx_Math" alttext="\mathbf{p}"><semantics><mi>𝐩</mi><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math> 。目标 <math intent=":literal" id="alg1.l1.m2" display="inline" class="ltx_Math" alttext="M"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math> (即内容审核员) 及其分词器。随机初始化长度为 <math intent=":literal" id="alg1.l1.m4" display="inline" class="ltx_Math" alttext="\ell"><semantics><mi mathvariant="normal">ℓ</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math> 的对抗签名 <math intent=":literal" id="alg1.l1.m3" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv}}=[p_{1},p_{2},\dots,p_{\ell}]"><semantics><mrow><msub><mi>𝐩</mi><mtext>adv</mtext></msub><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><msub><mi>p</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>p</mi><mi mathvariant="normal">ℓ</mi></msub><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv}}=[p_{1},p_{2},\dots,p_{\ell}]</annotation></semantics></math> 。分词选择变量 <math intent=":literal" id="alg1.l1.m5" display="inline" class="ltx_Math" alttext="\mathbf{S}_{\text{adv}}=[\mathbf{s}_{1},\mathbf{s}_{2},\dots,\mathbf{s}_{\ell}]"><semantics><mrow><msub><mi>𝐒</mi><mtext>adv</mtext></msub><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mi>𝐬</mi><mn>1</mn></msub><mo>,</mo><msub><mi>𝐬</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>𝐬</mi><mi mathvariant="normal">ℓ</mi></msub><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{S}_{\text{adv}}=[\mathbf{s}_{1},\mathbf{s}_{2},\dots,\mathbf{s}_{\ell}]</annotation></semantics></math> ，其中每个 <math intent=":literal" id="alg1.l1.m6" display="inline" class="ltx_Math" alttext="\mathbf{s}_{i}\in\{0,1\}^{|V|}"><semantics><mrow><msub><mi>𝐬</mi><mi>i</mi></msub><mo>∈</mo><msup><mrow><mo stretchy="false">{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{s}_{i}\in\{0,1\}^{|V|}</annotation></semantics></math> 是一个在大小为 <math intent=":literal" id="alg1.l1.m7" display="inline" class="ltx_Math" alttext="|V|"><semantics><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow><annotation encoding="application/x-tex">|V|</annotation></semantics></math> 的词汇表上的独热向量。候选对抗提示数量 <math intent=":literal" id="alg1.l1.m8" display="inline" class="ltx_Math" alttext="c"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math> 。优化迭代次数 <math intent=":literal" id="alg1.l1.m9" display="inline" class="ltx_Math" alttext="N"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> 。 </font></font></font></div>
<div class="ltx_listingline" id="alg1.l2" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">2:</span><span class="ltx_text ltx_font_bold">for</span> <math alttext="t=1" class="ltx_Math" display="inline" id="alg1.l2.m1" intent=":literal"><semantics><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t=1</annotation></semantics></math> to <math alttext="N" class="ltx_Math" display="inline" id="alg1.l2.m2" intent=":literal"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> <span class="ltx_text ltx_font_bold">do</span> <span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l2.m3" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> Optimization iterations
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="alg1.l2.m3" display="inline" class="ltx_Math" alttext="\triangleright"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> 优化迭代次数</font></font></font></span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span>  Compute loss: <math alttext="\mathcal{L}\leftarrow M\big(\mathbf{p}+\mathbf{p}_{\text{adv}}\big)" class="ltx_Math" display="inline" id="alg1.l3.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℒ</mi><mo stretchy="false">←</mo><mrow><mi>M</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo maxsize="1.200em" minsize="1.200em">(</mo><mrow><mi>𝐩</mi><mo>+</mo><msub><mi>𝐩</mi><mtext>adv</mtext></msub></mrow><mo maxsize="1.200em" minsize="1.200em">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}\leftarrow M\big(\mathbf{p}+\mathbf{p}_{\text{adv}}\big)</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3: 计算损失： <math intent=":literal" id="alg1.l3.m1" display="inline" class="ltx_Math" alttext="\mathcal{L}\leftarrow M\big(\mathbf{p}+\mathbf{p}_{\text{adv}}\big)"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℒ</mi><mo stretchy="false">←</mo><mrow><mi>M</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo minsize="1.200em" maxsize="1.200em">(</mo><mrow><mi>𝐩</mi><mo>+</mo><msub><mi>𝐩</mi><mtext>adv</mtext></msub></mrow><mo minsize="1.200em" maxsize="1.200em">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}\leftarrow M\big(\mathbf{p}+\mathbf{p}_{\text{adv}}\big)</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span>  Compute gradient of loss w.r.t. token selections:

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4: 计算损失关于 token 选择的梯度：</font></font></font></div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span>   <math alttext="\mathbf{G}\leftarrow\nabla_{\mathbf{S}_{\text{adv}}}\mathcal{L}" class="ltx_Math" display="inline" id="alg1.l5.m1" intent=":literal"><semantics><mrow><mi>𝐆</mi><mo stretchy="false">←</mo><mrow><msub><mo rspace="0.167em">∇</mo><msub><mi>𝐒</mi><mtext>adv</mtext></msub></msub><mi class="ltx_font_mathcaligraphic">ℒ</mi></mrow></mrow><annotation encoding="application/x-tex">\mathbf{G}\leftarrow\nabla_{\mathbf{S}_{\text{adv}}}\mathcal{L}</annotation></semantics></math>, where <math alttext="\mathbf{G}\in\mathbb{R}^{\ell\times|V|}" class="ltx_Math" display="inline" id="alg1.l5.m2" intent=":literal"><semantics><mrow><mi>𝐆</mi><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi mathvariant="normal">ℓ</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{G}\in\mathbb{R}^{\ell\times|V|}</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5: <math intent=":literal" id="alg1.l5.m1" display="inline" class="ltx_Math" alttext="\mathbf{G}\leftarrow\nabla_{\mathbf{S}_{\text{adv}}}\mathcal{L}"><semantics><mrow><mi>𝐆</mi><mo stretchy="false">←</mo><mrow><msub><mo rspace="0.167em">∇</mo><msub><mi>𝐒</mi><mtext>adv</mtext></msub></msub><mi class="ltx_font_mathcaligraphic">ℒ</mi></mrow></mrow><annotation encoding="application/x-tex">\mathbf{G}\leftarrow\nabla_{\mathbf{S}_{\text{adv}}}\mathcal{L}</annotation></semantics></math> ，其中 <math intent=":literal" id="alg1.l5.m2" display="inline" class="ltx_Math" alttext="\mathbf{G}\in\mathbb{R}^{\ell\times|V|}"><semantics><mrow><mi>𝐆</mi><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi mathvariant="normal">ℓ</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{G}\in\mathbb{R}^{\ell\times|V|}</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l6" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">6:</span>  <span class="ltx_text ltx_font_bold">for</span> <math alttext="i=1" class="ltx_Math" display="inline" id="alg1.l6.m1" intent=":literal"><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i=1</annotation></semantics></math> to <math alttext="\ell" class="ltx_Math" display="inline" id="alg1.l6.m2" intent=":literal"><semantics><mi mathvariant="normal">ℓ</mi><annotation encoding="application/x-tex">\ell</annotation></semantics></math> <span class="ltx_text ltx_font_bold">do</span> <span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l6.m3" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> For each position in the prompt
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="alg1.l6.m3" display="inline" class="ltx_Math" alttext="\triangleright"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> 对于提示中的每个位置 </font></font></font></span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span>   Get top-<math alttext="k" class="ltx_Math" display="inline" id="alg1.l7.m1" intent=":literal"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> token indices with highest gradients:

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7: 获取具有最高梯度的 <math intent=":literal" id="alg1.l7.m1" display="inline" class="ltx_Math" alttext="k"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> 顶级 token 索引： </font></font></font></div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline">8:</span>   <math alttext="\mathbf{d}_{i}\leftarrow\text{TopKIndices}(\mathbf{g}_{i},k)" class="ltx_Math" display="inline" id="alg1.l8.m1" intent=":literal"><semantics><mrow><msub><mi>𝐝</mi><mi>i</mi></msub><mo stretchy="false">←</mo><mrow><mtext>TopKIndices</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐠</mi><mi>i</mi></msub><mo>,</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{d}_{i}\leftarrow\text{TopKIndices}(\mathbf{g}_{i},k)</annotation></semantics></math>
<span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l8.m2" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> <math alttext="\mathbf{d}_{i}\in\mathbb{N}^{k}" class="ltx_Math" display="inline" id="alg1.l8.m3" intent=":literal"><semantics><mrow><msub><mi>𝐝</mi><mi>i</mi></msub><mo>∈</mo><msup><mi>ℕ</mi><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{d}_{i}\in\mathbb{N}^{k}</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline">9:</span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">9: 结束循环 </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline">10:</span>  Stack indices: <math alttext="\mathbf{D}\leftarrow[\mathbf{d}_{1};\mathbf{d}_{2};\dots;\mathbf{d}_{\ell}]\in\mathbb{N}^{\ell\times k}" class="ltx_Math" display="inline" id="alg1.l10.m1" intent=":literal"><semantics><mrow><mi>𝐃</mi><mo stretchy="false">←</mo><mrow><mo stretchy="false">[</mo><msub><mi>𝐝</mi><mn>1</mn></msub><mo>;</mo><msub><mi>𝐝</mi><mn>2</mn></msub><mo>;</mo><mi mathvariant="normal">…</mi><mo>;</mo><msub><mi>𝐝</mi><mi mathvariant="normal">ℓ</mi></msub><mo stretchy="false">]</mo></mrow><mo>∈</mo><msup><mi>ℕ</mi><mrow><mi mathvariant="normal">ℓ</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>k</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{D}\leftarrow[\mathbf{d}_{1};\mathbf{d}_{2};\dots;\mathbf{d}_{\ell}]\in\mathbb{N}^{\ell\times k}</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">10: 堆叠索引： <math intent=":literal" id="alg1.l10.m1" display="inline" class="ltx_Math" alttext="\mathbf{D}\leftarrow[\mathbf{d}_{1};\mathbf{d}_{2};\dots;\mathbf{d}_{\ell}]\in\mathbb{N}^{\ell\times k}"><semantics><mrow><mi>𝐃</mi><mo stretchy="false">←</mo><mrow><mo stretchy="false">[</mo><msub><mi>𝐝</mi><mn>1</mn></msub><mo>;</mo><msub><mi>𝐝</mi><mn>2</mn></msub><mo>;</mo><mi mathvariant="normal">…</mi><mo>;</mo><msub><mi>𝐝</mi><mi mathvariant="normal">ℓ</mi></msub><mo stretchy="false">]</mo></mrow><mo>∈</mo><msup><mi>ℕ</mi><mrow><mi mathvariant="normal">ℓ</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mi>k</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{D}\leftarrow[\mathbf{d}_{1};\mathbf{d}_{2};\dots;\mathbf{d}_{\ell}]\in\mathbb{N}^{\ell\times k}</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline">11:</span>  Random selections: <math alttext="\mathbf{R}\leftarrow\textbf{Rand}(1,k,\text{size=}(\ell,c))" class="ltx_Math" display="inline" id="alg1.l11.m1" intent=":literal"><semantics><mrow><mi>𝐑</mi><mo stretchy="false">←</mo><mrow><mtext class="ltx_mathvariant_bold">Rand</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mi>k</mi><mo>,</mo><mrow><mtext>size=</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">ℓ</mi><mo>,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{R}\leftarrow\textbf{Rand}(1,k,\text{size=}(\ell,c))</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">11: 随机选择： <math intent=":literal" id="alg1.l11.m1" display="inline" class="ltx_Math" alttext="\mathbf{R}\leftarrow\textbf{Rand}(1,k,\text{size=}(\ell,c))"><semantics><mrow><mi>𝐑</mi><mo stretchy="false">←</mo><mrow><mtext class="ltx_mathvariant_bold">Rand</mtext><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mi>k</mi><mo>,</mo><mrow><mtext>size=</mtext><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">ℓ</mi><mo>,</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{R}\leftarrow\textbf{Rand}(1,k,\text{size=}(\ell,c))</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline">12:</span>  Obtain candidate set: <math alttext="\mathbf{T}_{\text{adv}}\leftarrow\mathbf{D}[\mathbf{R}]" class="ltx_Math" display="inline" id="alg1.l12.m1" intent=":literal"><semantics><mrow><msub><mi>𝐓</mi><mtext>adv</mtext></msub><mo stretchy="false">←</mo><mrow><mi>𝐃</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">[</mo><mi>𝐑</mi><mo stretchy="false">]</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{T}_{\text{adv}}\leftarrow\mathbf{D}[\mathbf{R}]</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">12: 获取候选集： <math intent=":literal" id="alg1.l12.m1" display="inline" class="ltx_Math" alttext="\mathbf{T}_{\text{adv}}\leftarrow\mathbf{D}[\mathbf{R}]"><semantics><mrow><msub><mi>𝐓</mi><mtext>adv</mtext></msub><mo stretchy="false">←</mo><mrow><mi>𝐃</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">[</mo><mi>𝐑</mi><mo stretchy="false">]</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{T}_{\text{adv}}\leftarrow\mathbf{D}[\mathbf{R}]</annotation></semantics></math> </font></font></font>
<span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l12.m2" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> <math alttext="\mathbf{T}_{\text{adv}}\in\mathbb{N}^{\ell\times c}" class="ltx_Math" display="inline" id="alg1.l12.m3" intent=":literal"><semantics><mrow><msub><mi>𝐓</mi><mtext>adv</mtext></msub><mo>∈</mo><msup><mi>ℕ</mi><mrow><mi mathvariant="normal">ℓ</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>c</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{T}_{\text{adv}}\in\mathbb{N}^{\ell\times c}</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="alg1.l13" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">13:</span>  <span class="ltx_text ltx_font_bold">for</span> <math alttext="j=1" class="ltx_Math" display="inline" id="alg1.l13.m1" intent=":literal"><semantics><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">j=1</annotation></semantics></math> to <math alttext="c" class="ltx_Math" display="inline" id="alg1.l13.m2" intent=":literal"><semantics><mi>c</mi><annotation encoding="application/x-tex">c</annotation></semantics></math> <span class="ltx_text ltx_font_bold">do</span> <span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l13.m3" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> For each candidate prompt
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="alg1.l13.m3" display="inline" class="ltx_Math" alttext="\triangleright"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> 对每个候选提示</font></font></font></span>
</div>
<div class="ltx_listingline" id="alg1.l14">
<span class="ltx_tag ltx_tag_listingline">14:</span>   Candidate tokens: <math alttext="\mathbf{t}_{\text{adv}}^{(j)}\leftarrow\mathbf{T}_{\text{adv}}[:,j]" class="ltx_Math" display="inline" id="alg1.l14.m1" intent=":literal"><semantics><mrow><msubsup><mi>𝐭</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">←</mo><mrow><msub><mi>𝐓</mi><mtext>adv</mtext></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">[</mo><mo rspace="0em">:</mo><mo>,</mo><mi>j</mi><mo stretchy="false">]</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{t}_{\text{adv}}^{(j)}\leftarrow\mathbf{T}_{\text{adv}}[:,j]</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">14: 候选 token： <math intent=":literal" id="alg1.l14.m1" display="inline" class="ltx_Math" alttext="\mathbf{t}_{\text{adv}}^{(j)}\leftarrow\mathbf{T}_{\text{adv}}[:,j]"><semantics><mrow><msubsup><mi>𝐭</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">←</mo><mrow><msub><mi>𝐓</mi><mtext>adv</mtext></msub><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">[</mo><mo rspace="0em">:</mo><mo>,</mo><mi>j</mi><mo stretchy="false">]</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{t}_{\text{adv}}^{(j)}\leftarrow\mathbf{T}_{\text{adv}}[:,j]</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l15">
<span class="ltx_tag ltx_tag_listingline">15:</span>   Candidate prompt: <math alttext="\mathbf{p}_{\text{adv}}^{(j)}\leftarrow\text{Tokenizer.decode}(\mathbf{t}_{\text{adv}}^{(j)})" class="ltx_Math" display="inline" id="alg1.l15.m1" intent=":literal"><semantics><mrow><msubsup><mi>𝐩</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">←</mo><mrow><mtext>Tokenizer.decode</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>𝐭</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv}}^{(j)}\leftarrow\text{Tokenizer.decode}(\mathbf{t}_{\text{adv}}^{(j)})</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">15: 候选提示： <math intent=":literal" id="alg1.l15.m1" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv}}^{(j)}\leftarrow\text{Tokenizer.decode}(\mathbf{t}_{\text{adv}}^{(j)})"><semantics><mrow><msubsup><mi>𝐩</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">←</mo><mrow><mtext>Tokenizer.decode</mtext><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>𝐭</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv}}^{(j)}\leftarrow\text{Tokenizer.decode}(\mathbf{t}_{\text{adv}}^{(j)})</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l16">
<span class="ltx_tag ltx_tag_listingline">16:</span>   Compute candidate loss: <math alttext="\mathcal{L}_{j}\leftarrow\mathcal{L}_{ws}\big(\mathbf{p}+\mathbf{p}_{\text{adv}}^{(j)}\big)" class="ltx_Math" display="inline" id="alg1.l16.m1" intent=":literal"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mi>j</mi></msub><mo stretchy="false">←</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mrow><mi>w</mi><mo lspace="0em" rspace="0em">​</mo><mi>s</mi></mrow></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo maxsize="1.200em" minsize="1.200em">(</mo><mrow><mi>𝐩</mi><mo>+</mo><msubsup><mi>𝐩</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo maxsize="1.200em" minsize="1.200em">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}_{j}\leftarrow\mathcal{L}_{ws}\big(\mathbf{p}+\mathbf{p}_{\text{adv}}^{(j)}\big)</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">16: 计算候选损失： <math intent=":literal" id="alg1.l16.m1" display="inline" class="ltx_Math" alttext="\mathcal{L}_{j}\leftarrow\mathcal{L}_{ws}\big(\mathbf{p}+\mathbf{p}_{\text{adv}}^{(j)}\big)"><semantics><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mi>j</mi></msub><mo stretchy="false">←</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mrow><mi>w</mi><mo rspace="0em" lspace="0em">​</mo><mi>s</mi></mrow></msub><mo rspace="0em" lspace="0em">​</mo><mrow><mo minsize="1.200em" maxsize="1.200em">(</mo><mrow><mi>𝐩</mi><mo>+</mo><msubsup><mi>𝐩</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><mo minsize="1.200em" maxsize="1.200em">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}_{j}\leftarrow\mathcal{L}_{ws}\big(\mathbf{p}+\mathbf{p}_{\text{adv}}^{(j)}\big)</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l17" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">17:</span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div class="ltx_listingline" id="alg1.l18">
<span class="ltx_tag ltx_tag_listingline">18:</span>  Find the best candidate: <math alttext="j^{*}\leftarrow\arg\min_{j}\mathcal{L}_{j}" class="ltx_Math" display="inline" id="alg1.l18.m1" intent=":literal"><semantics><mrow><msup><mi>j</mi><mo>∗</mo></msup><mo stretchy="false">←</mo><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mrow><msub><mi>min</mi><mi>j</mi></msub><mo lspace="0.167em">⁡</mo><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mi>j</mi></msub></mrow></mrow></mrow><annotation encoding="application/x-tex">j^{*}\leftarrow\arg\min_{j}\mathcal{L}_{j}</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">18: 找到最佳候选： <math intent=":literal" id="alg1.l18.m1" display="inline" class="ltx_Math" alttext="j^{*}\leftarrow\arg\min_{j}\mathcal{L}_{j}"><semantics><mrow><msup><mi>j</mi><mo>∗</mo></msup><mo stretchy="false">←</mo><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mrow><msub><mi>min</mi><mi>j</mi></msub><mo lspace="0.167em">⁡</mo><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mi>j</mi></msub></mrow></mrow></mrow><annotation encoding="application/x-tex">j^{*}\leftarrow\arg\min_{j}\mathcal{L}_{j}</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l19">
<span class="ltx_tag ltx_tag_listingline">19:</span>  Update variables: <math alttext="\mathbf{t}_{\text{adv}}\leftarrow\mathbf{t}_{\text{adv}}^{(j^{*})}" class="ltx_Math" display="inline" id="alg1.l19.m1" intent=":literal"><semantics><mrow><msub><mi>𝐭</mi><mtext>adv</mtext></msub><mo stretchy="false">←</mo><msubsup><mi>𝐭</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><msup><mi>j</mi><mo>∗</mo></msup><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{t}_{\text{adv}}\leftarrow\mathbf{t}_{\text{adv}}^{(j^{*})}</annotation></semantics></math>, <math alttext="\mathbf{S}_{\text{adv}}\leftarrow\text{OneHot}(\mathbf{t}_{\text{adv}})" class="ltx_Math" display="inline" id="alg1.l19.m2" intent=":literal"><semantics><mrow><msub><mi>𝐒</mi><mtext>adv</mtext></msub><mo stretchy="false">←</mo><mrow><mtext>OneHot</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐭</mi><mtext>adv</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{S}_{\text{adv}}\leftarrow\text{OneHot}(\mathbf{t}_{\text{adv}})</annotation></semantics></math>, <math alttext="\mathbf{p}_{\text{adv}}\leftarrow\text{Tokenizer.decode}(\mathbf{t}_{\text{adv}})" class="ltx_Math" display="inline" id="alg1.l19.m3" intent=":literal"><semantics><mrow><msub><mi>𝐩</mi><mtext>adv</mtext></msub><mo stretchy="false">←</mo><mrow><mtext>Tokenizer.decode</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐭</mi><mtext>adv</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv}}\leftarrow\text{Tokenizer.decode}(\mathbf{t}_{\text{adv}})</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">19: 更新变量： <math intent=":literal" id="alg1.l19.m1" display="inline" class="ltx_Math" alttext="\mathbf{t}_{\text{adv}}\leftarrow\mathbf{t}_{\text{adv}}^{(j^{*})}"><semantics><mrow><msub><mi>𝐭</mi><mtext>adv</mtext></msub><mo stretchy="false">←</mo><msubsup><mi>𝐭</mi><mtext>adv</mtext><mrow><mo stretchy="false">(</mo><msup><mi>j</mi><mo>∗</mo></msup><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{t}_{\text{adv}}\leftarrow\mathbf{t}_{\text{adv}}^{(j^{*})}</annotation></semantics></math> ， <math intent=":literal" id="alg1.l19.m2" display="inline" class="ltx_Math" alttext="\mathbf{S}_{\text{adv}}\leftarrow\text{OneHot}(\mathbf{t}_{\text{adv}})"><semantics><mrow><msub><mi>𝐒</mi><mtext>adv</mtext></msub><mo stretchy="false">←</mo><mrow><mtext>OneHot</mtext><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐭</mi><mtext>adv</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{S}_{\text{adv}}\leftarrow\text{OneHot}(\mathbf{t}_{\text{adv}})</annotation></semantics></math> ， <math intent=":literal" id="alg1.l19.m3" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv}}\leftarrow\text{Tokenizer.decode}(\mathbf{t}_{\text{adv}})"><semantics><mrow><msub><mi>𝐩</mi><mtext>adv</mtext></msub><mo stretchy="false">←</mo><mrow><mtext>Tokenizer.decode</mtext><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐭</mi><mtext>adv</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv}}\leftarrow\text{Tokenizer.decode}(\mathbf{t}_{\text{adv}})</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l20" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">20:</span><span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span>
</div>
<div class="ltx_listingline" id="alg1.l21">
<span class="ltx_tag ltx_tag_listingline">21:</span>Optimized adversarial signature <math alttext="\mathbf{p}_{\text{adv}}" class="ltx_Math" display="inline" id="alg1.l21.m1" intent=":literal"><semantics><msub><mi>𝐩</mi><mtext>adv</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv}}</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">21:优化后的对抗性签名 <math intent=":literal" id="alg1.l21.m1" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv}}"><semantics><msub><mi>𝐩</mi><mtext>adv</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv}}</annotation></semantics></math> </font></font></font>
</div>
</div>
<br class="ltx_break ltx_break">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Vision-Encoder–Targeted Image Attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3 针对视觉编码器的图像攻击</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p">Typically a VLM comprises a vision encoder <math alttext="\mathbf{E}" class="ltx_Math" display="inline" id="S3.SS3.p1.m1" intent=":literal"><semantics><mi>𝐄</mi><annotation encoding="application/x-tex">\mathbf{E}</annotation></semantics></math>, a projection layer <math alttext="\mathbf{W}" class="ltx_Math" display="inline" id="S3.SS3.p1.m2" intent=":literal"><semantics><mi>𝐖</mi><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math> that maps visual embeddings into the language space, and an LLM decoder <math alttext="\mathbf{F}" class="ltx_Math" display="inline" id="S3.SS3.p1.m3" intent=":literal"><semantics><mi>𝐅</mi><annotation encoding="application/x-tex">\mathbf{F}</annotation></semantics></math>.
Given an image <math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS3.p1.m4" intent=":literal"><semantics><mi>𝐱</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math> and user prompt <math alttext="\mathbf{p}" class="ltx_Math" display="inline" id="S3.SS3.p1.m5" intent=":literal"><semantics><mi>𝐩</mi><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math>, the model produces<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">通常，一个视觉语言模型（VLM）包含一个视觉编码器 <math intent=":literal" id="S3.SS3.p1.m1" display="inline" class="ltx_Math" alttext="\mathbf{E}"><semantics><mi>𝐄</mi><annotation encoding="application/x-tex">\mathbf{E}</annotation></semantics></math> 、一个将视觉嵌入映射到语言空间的投影层 <math intent=":literal" id="S3.SS3.p1.m2" display="inline" class="ltx_Math" alttext="\mathbf{W}"><semantics><mi>𝐖</mi><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math> 以及一个大型语言模型（LLM）解码器 <math intent=":literal" id="S3.SS3.p1.m3" display="inline" class="ltx_Math" alttext="\mathbf{F}"><semantics><mi>𝐅</mi><annotation encoding="application/x-tex">\mathbf{F}</annotation></semantics></math> 。给定一张图像 <math intent=":literal" id="S3.SS3.p1.m4" display="inline" class="ltx_Math" alttext="\mathbf{x}"><semantics><mi>𝐱</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math> 和用户提示 <math intent=":literal" id="S3.SS3.p1.m5" display="inline" class="ltx_Math" alttext="\mathbf{p}"><semantics><mi>𝐩</mi><annotation encoding="application/x-tex">\mathbf{p}</annotation></semantics></math> ，模型生成</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="y\;=\;\mathbf{F}\!\bigl(\mathbf{W}\cdot\mathbf{E}(\mathbf{x}),\,\mathbf{p}\bigr)." class="ltx_Math" display="block" id="S3.Ex4.m1" intent=":literal"><semantics><mrow><mrow><mi>y</mi><mo lspace="0.558em" rspace="0.558em">=</mo><mrow><mpadded style="width:0.580em;" width="0.580em"><mi>𝐅</mi></mpadded><mo lspace="0em" rspace="0em">​</mo><mrow><mo maxsize="1.200em" minsize="1.200em">(</mo><mrow><mrow><mi>𝐖</mi><mo lspace="0.222em" rspace="0.222em">⋅</mo><mi>𝐄</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>𝐱</mi><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.337em">,</mo><mi>𝐩</mi><mo maxsize="1.200em" minsize="1.200em">)</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">y\;=\;\mathbf{F}\!\bigl(\mathbf{W}\cdot\mathbf{E}(\mathbf{x}),\,\mathbf{p}\bigr).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">Previous visual jailbreaks optimize <math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S3.SS3.p1.m6" intent=":literal"><semantics><mi>𝐱</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math> end-to-end so that the <em class="ltx_emph ltx_font_italic">first</em> generated token is an affirmative cue (<em class="ltx_emph ltx_font_italic">e.g</em>., “<span class="ltx_text ltx_font_typewriter">Sure</span>”) <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">qi2023visual</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">hade</span>)</cite>.
We show that a far simpler objective—perturbing only the vision encoder pathway with a cosine-similarity loss—suffices to bypass the system prompt and generalizes across models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">之前的视觉越狱攻击端到端地优化 <math intent=":literal" id="S3.SS3.p1.m6" display="inline" class="ltx_Math" alttext="\mathbf{x}"><semantics><mi>𝐱</mi><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math> ，使得第一个生成的标记是一个肯定信号（例如，“当然”）(qi2023visual; hade)。我们证明，一个远更简单的目标——仅通过余弦相似度损失扰动视觉编码器路径——就足以绕过系统提示并在不同模型间泛化。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">1. Workflow.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1. 工作流程。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
<p class="ltx_p">Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.F3" title="Figure 3 ‣ 1. Workflow. ‣ 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the workflow.
We craft an adversarial image whose embedding, after <math alttext="\mathbf{E}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p1.m1" intent=":literal"><semantics><mi>𝐄</mi><annotation encoding="application/x-tex">\mathbf{E}</annotation></semantics></math> and <math alttext="\mathbf{W}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p1.m2" intent=":literal"><semantics><mi>𝐖</mi><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math>, is <em class="ltx_emph ltx_font_italic">aligned</em> with a malicious system prompt <math alttext="\mathbf{p}_{\text{target}}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p1.m3" intent=":literal"><semantics><msub><mi>𝐩</mi><mtext>target</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{target}}</annotation></semantics></math>.
Because the image embedding is concatenated with text embeddings before decoding, this poisoned visual signal overrides the built-in safety prompt, steering the LLM to emit harmful content.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 3 展示了工作流程。我们制作了一个对抗性图像，其嵌入在经过 <math intent=":literal" id="S3.SS3.SSS0.Px1.p1.m1" display="inline" class="ltx_Math" alttext="\mathbf{E}"><semantics><mi>𝐄</mi><annotation encoding="application/x-tex">\mathbf{E}</annotation></semantics></math> 和 <math intent=":literal" id="S3.SS3.SSS0.Px1.p1.m2" display="inline" class="ltx_Math" alttext="\mathbf{W}"><semantics><mi>𝐖</mi><annotation encoding="application/x-tex">\mathbf{W}</annotation></semantics></math> 处理后，与恶意系统提示 <math intent=":literal" id="S3.SS3.SSS0.Px1.p1.m3" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{target}}"><semantics><msub><mi>𝐩</mi><mtext>target</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{target}}</annotation></semantics></math> 对齐。由于图像嵌入在解码前与文本嵌入连接，这个被污染的视觉信号会覆盖内置的安全提示，引导 LLM 发出有害内容。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="367" id="S3.F3.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x3.png" width="705">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Overview of Vision-Encoder–Targeted Attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 3：视觉编码器—目标攻击概述。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">2. Why focus on Vision Encoder?<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2. 为什么专注于视觉编码器？</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px2.p1">
<p class="ltx_p">Attacking the vision encoder alone offers three advantages:
<span class="ltx_text ltx_font_italic">(i)&nbsp;Simpler objective</span> – we operate in embedding space, avoiding brittle token-level constraints;
<span class="ltx_text ltx_font_italic">(ii)&nbsp;Higher payload capacity</span> – a single image can encode rich semantic instructions, enabling fine-grained control;
<span class="ltx_text ltx_font_italic">(iii)&nbsp;Lower cost</span> – optimizing a <math alttext="\sim" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px2.p1.m1" intent=":literal"><semantics><mo>∼</mo><annotation encoding="application/x-tex">\sim</annotation></semantics></math>100 k-dimensional embedding is 3–5× faster than full decoder-level attacks and fits on a 24 GB GPU <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gcg</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">qi2023visual</span>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">单独攻击视觉编码器有三个优势：(i) 更简单的目标——我们在嵌入空间中操作，避免了脆弱的 token 级限制；(ii) 更高的有效载荷容量——单张图像可以编码丰富的语义指令，实现细粒度控制；(iii) 更低成本——优化一个 <math intent=":literal" id="S3.SS3.SSS0.Px2.p1.m1" display="inline" class="ltx_Math" alttext="\sim"><semantics><mo>∼</mo><annotation encoding="application/x-tex">\sim</annotation></semantics></math> 100 k 维嵌入比完整的解码器级攻击快 3-5 倍，并且可以在 24 GB GPU 上运行（gcg; qi2023visual）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">3. Optimization.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3. 优化。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS0.Px3.p1">
<p class="ltx_p">We use projected-gradient descent (PGD) with a cosine-similarity loss:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用带余弦相似度损失的投影梯度下降（PGD）：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A5.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathbf{x}_{\text{adv}}^{\,t+1}" class="ltx_Math" display="inline" id="S3.E1.m1" intent=":literal"><semantics><msubsup><mi>𝐱</mi><mtext>adv</mtext><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><annotation encoding="application/x-tex">\displaystyle\mathbf{x}_{\text{adv}}^{\,t+1}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\mathbf{x}_{\text{adv}}^{\,t}+\alpha\;\mathrm{sign}\!\Bigl(\nabla_{\mathbf{x}_{\text{adv}}^{t}}\cos\!\bigl(\mathbf{h}\,\tau_{\theta}(\mathbf{x}_{\text{adv}}^{t}),\;\mathbf{E}(\mathbf{p}_{\text{target}})\bigr)\Bigr)," class="ltx_Math" display="inline" id="S3.E1.m2" intent=":literal"><semantics><mrow><mrow><mi></mi><mo>=</mo><mrow><msubsup><mi>𝐱</mi><mtext>adv</mtext><mi>t</mi></msubsup><mo>+</mo><mrow><mi>α</mi><mo lspace="0.280em" rspace="0em">​</mo><mpadded style="width:1.756em;" width="1.756em"><mi>sign</mi></mpadded><mo lspace="0em" rspace="0em">​</mo><mrow><mo maxsize="1.600em" minsize="1.600em">(</mo><mrow><mrow><msub><mo rspace="0.167em">∇</mo><msubsup><mi>𝐱</mi><mtext>adv</mtext><mi>t</mi></msubsup></msub><mpadded style="width:1.216em;" width="1.216em"><mi>cos</mi></mpadded></mrow><mo>⁡</mo><mrow><mo maxsize="1.200em" minsize="1.200em">(</mo><mrow><mi>𝐡</mi><mo lspace="0.170em" rspace="0em">​</mo><msub><mi>τ</mi><mi>θ</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>𝐱</mi><mtext>adv</mtext><mi>t</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.447em">,</mo><mrow><mi>𝐄</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐩</mi><mtext>target</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><mo maxsize="1.200em" minsize="1.200em">)</mo></mrow></mrow><mo maxsize="1.600em" minsize="1.600em">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle=\mathbf{x}_{\text{adv}}^{\,t}+\alpha\;\mathrm{sign}\!\Bigl(\nabla_{\mathbf{x}_{\text{adv}}^{t}}\cos\!\bigl(\mathbf{h}\,\tau_{\theta}(\mathbf{x}_{\text{adv}}^{t}),\;\mathbf{E}(\mathbf{p}_{\text{target}})\bigr)\Bigr),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px3.p1.m1" intent=":literal"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> indexes the iteration, <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px3.p1.m2" intent=":literal"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> is the step size, <math alttext="\tau_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px3.p1.m3" intent=":literal"><semantics><msub><mi>τ</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\tau_{\theta}</annotation></semantics></math> is the frozen vision encoder, and <math alttext="\mathbf{h}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px3.p1.m4" intent=":literal"><semantics><mi>𝐡</mi><annotation encoding="application/x-tex">\mathbf{h}</annotation></semantics></math> the linear adapter.
Aligning the adversarial image embedding with <math alttext="\,\mathbf{E}(\mathbf{p}_{\text{target}})" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px3.p1.m5" intent=":literal"><semantics><mrow><mi>𝐄</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐩</mi><mtext>target</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\,\mathbf{E}(\mathbf{p}_{\text{target}})</annotation></semantics></math> effectively “writes” the malicious system prompt into the visual channel.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math intent=":literal" id="S3.SS3.SSS0.Px3.p1.m1" display="inline" class="ltx_Math" alttext="t"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math> 指代迭代次数， <math intent=":literal" id="S3.SS3.SSS0.Px3.p1.m2" display="inline" class="ltx_Math" alttext="\alpha"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> 是步长， <math intent=":literal" id="S3.SS3.SSS0.Px3.p1.m3" display="inline" class="ltx_Math" alttext="\tau_{\theta}"><semantics><msub><mi>τ</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\tau_{\theta}</annotation></semantics></math> 是冻结的视觉编码器， <math intent=":literal" id="S3.SS3.SSS0.Px3.p1.m4" display="inline" class="ltx_Math" alttext="\mathbf{h}"><semantics><mi>𝐡</mi><annotation encoding="application/x-tex">\mathbf{h}</annotation></semantics></math> 是线性适配器。将对抗性图像嵌入与 <math intent=":literal" id="S3.SS3.SSS0.Px3.p1.m5" display="inline" class="ltx_Math" alttext="\,\mathbf{E}(\mathbf{p}_{\text{target}})"><semantics><mrow><mi>𝐄</mi><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>𝐩</mi><mtext>target</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\,\mathbf{E}(\mathbf{p}_{\text{target}})</annotation></semantics></math> 对齐，实际上是将恶意系统提示“写入”视觉通道。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">4. Transferability.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.  可迁移性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px4.p1">
<p class="ltx_p">We empirically show that a single adversarial image tuned on one vision encoder generalizes remarkably well, compromising VLMs that it has never encountered. We believe this cross-model success exposes a monoculture risk: many systems rely on similar visual representations, so a perturbation that fools one encoder often fools the rest. In our experiments (Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.T3" title="Table 3 ‣ Take-away. ‣ 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> highlighted in gray), an image crafted against LLaVA-1.6 transferred to <em class="ltx_emph ltx_font_italic">nine</em> unseen models—both commercial and open-source—and achieved a 44.3 % attack success rate <em class="ltx_emph ltx_font_italic">without</em> any per-model fine-tuning. These results highlight an urgent need for diversity or additional hardening in the visual front-ends of modern VLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们通过实验证明，在单个视觉编码器上微调的单个对抗性图像能够很好地泛化，从而攻击那些从未遇到过的视觉语言模型。我们认为这种跨模型的成功暴露了一种单一文化风险：许多系统依赖于相似的视觉表示，因此欺骗一个编码器的扰动往往也能欺骗其他编码器。在我们的实验中（表 3 中用灰色突出显示），针对 LLaVA-1.6 制作的图像迁移到了九个未见过的模型——包括商业模型和开源模型——并在没有任何针对每个模型的微调的情况下达到了 44.3%的攻击成功率。这些结果突显了现代视觉语言模型在视觉前端需要多样性或额外加固的迫切需求。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Take-away.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">要点。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px5.p1">
<p class="ltx_p">A lightweight, encoder-focused perturbation is enough to nullify system-prompt defenses and generalizes broadly.
Combined with our ATA (alignment breaking) and content-moderator bypass, this facet completes MFA’s end-to-end compromise of current VLM safety stacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">一个轻量级的、针对编码器的扰动就足以使系统提示防御失效，并且具有广泛的泛化能力。结合我们提出的 ATA（对齐破坏）和内容审查员绕过技术，这一方面完成了 MFA 对当前视觉语言模型安全堆栈端到端的攻破。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:119pt;vertical-align:-58.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-314.9pt,74.1pt) scale(0.445474043658301,0.445474043658301) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">Attack Methods<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">攻击方法</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">GPTFuzzer</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Visual-AE</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">FigStep</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">HIMRD</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">HADES</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">CS-DJ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" style="padding-left:14.2pt;padding-right:14.2pt;">
<span class="ltx_text ltx_font_bold">MFA</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">Evaluator<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">评估者</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LG <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m1" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">HM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m2" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LG <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m3" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">HM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m4" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LG <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m5" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">HM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m6" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LG <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m7" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">HM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m8" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">LG <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m9" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">HM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m10" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">LG <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m11" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">HM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m12" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">LG <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m13" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">HM <math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T3.m14" intent=":literal"><semantics><mo stretchy="false">↑</mo><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="15" style="padding-left:14.2pt;padding-right:14.2pt;">
<span class="ltx_text ltx_font_bold">Open-sourced VLMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">开源视觉语言模型</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">MiniGPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2023minigpt</span>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">70.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">65.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">65.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">85.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">27.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">22.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">75.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">40.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">30.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">97.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">100.0</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LLaMA-4-Scout-I&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">meta2025llama4</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">65.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">65.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">7.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">12.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">20.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">85.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">22.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">7.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">42.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">57.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">45.0</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LLaMA-3.2-11B-V-I&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">llamavision</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">62.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">85.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">25.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">22.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">37.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">40.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">52.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">42.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">57.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">MiMo-VL-7B&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">coreteam2025mimovltechnicalreport</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">82.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">82.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">15.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">7.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">15.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">15.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">95.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">47.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">25.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">52.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">20.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">72.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">42.5</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">LLaVA-1.5-13B&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023improvedllava</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">77.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">65.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">30.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">85.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">87.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">22.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">92.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">40.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">35.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">20.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">55.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">77.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">mPLUG-Owl2&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ye2023mPLUGOwI2RM</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">87.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">75.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">37.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">37.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">65.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">45.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">77.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">45.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">35.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">25.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">40.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">57.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">85.0</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">Qwen-VL-Chat&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">Bai2023QwenVLAF</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">85.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">37.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">27.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">45.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">60.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">22.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">65.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">30.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">20.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">52.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">35.0</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">NVLM-D-72B&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">nvlm2024</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">72.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">72.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">20.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">35.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">45.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">37.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">95.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">35.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">42.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">60.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">82.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="15" style="padding-left:14.2pt;padding-right:14.2pt;">
<span class="ltx_text ltx_font_bold">Commercial VLMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">商业视觉语言模型</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">GPT-4V&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gpt4v</span>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">5.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">5.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">5.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">22.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">47.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">GPT-4o&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">openai2024gpt4ocard</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFEFEF;padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#EFEFEF;padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">7.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">22.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">10.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">30.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">42.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">GPT-4.1-mini&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">OpenAI_GPT4_1_Announcement_2025</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFEFEF;padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#EFEFEF;padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">7.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">32.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">52.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">42.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">GPT-4.1&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">OpenAI_GPT4_1_Announcement_2025</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFEFEF;padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#EFEFEF;padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">7.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">32.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">7.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">40.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">20.0</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">Google-PaLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">chowdhery2023palm</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">15.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">22.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">100.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">20.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">80.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">82.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">Gemini-2.0-pro&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">google2024gemini</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">72.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">77.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">7.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">25.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">15.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">35.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">57.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">12.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">67.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">62.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">Gemini-2.5-flash&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">comanici2025gemini25pushingfrontier</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">32.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">30.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">25.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">8.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">12.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">52.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">15.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">55.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">37.5</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">Grok-2-Vision&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">xai_grok2_vision_2024</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">90.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">97.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">22.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">57.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">55.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">95.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">45.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">25.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">35.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">55.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">25.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">90.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">90.0</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;" data-imt_insert_failed="1">SOLAR-Mini&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">kim-etal-2024-solar</span>)</cite>
</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">80.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">62.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">15.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">17.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">12.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">75.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">20.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">10.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">7.5</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;">2.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:14.2pt;padding-right:14.2pt;">-</td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">87.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">45.0</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">Avg.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">平均</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">58.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_framed ltx_framed_underline">54.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">15.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">25.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">27.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">21.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">56.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">22.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">20.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">14.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">31.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;">7.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">60.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:14.2pt;padding-right:14.2pt;"><span class="ltx_text ltx_font_bold">58.5</span></td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold">Comparison of Attack Effectiveness Across VLMs on HEHS dataset.</span> A dash (–) is caused by unavailable models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 3：HEHS 数据集上不同 VLM 的攻击效果比较。因模型不可用而用虚线（–）表示。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4 实验</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Settings<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1 实验设置</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Victim Models.</span>
We evaluate <em class="ltx_emph ltx_font_italic">17</em> VLMs, including 8 open-source and 9 commercial.
<em class="ltx_emph ltx_font_italic">Open-source</em>: LLaMA-4-Scout-Instruct, LLaMA-3.2-11B-Vision-Instruct, MiMo-VL-7B, MiniGPT-4, NVLM-D-72B, mPLUG-Owl2, Qwen-VL-Chat, LLaVA-1.5-13B.
<em class="ltx_emph ltx_font_italic">Commercial</em>: GPT-4.1, GPT-4.1-mini, GPT-4o, GPT-4V, Gemini-2.5-flash, Gemini-2.0-Pro, Google-PaLM, Grok-2-Vision, SOLAR-Mini.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">受害者模型。我们评估了 17 个 VLM，包括 8 个开源模型和 9 个商业模型。开源模型：LLaMA-4-Scout-Instruct、LLaMA-3.2-11B-Vision-Instruct、MiMo-VL-7B、MiniGPT-4、NVLM-D-72B、mPLUG-Owl2、Qwen-VL-Chat、LLaVA-1.5-13B。商业模型：GPT-4.1、GPT-4.1-mini、GPT-4o、GPT-4V、Gemini-2.5-flash、Gemini-2.0-Pro、Google-PaLM、Grok-2-Vision、SOLAR-Mini。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Datasets.</span>
We adopt two SOTA jailbreak suites: <span class="ltx_text ltx_font_italic">HEHS</span> <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">qi2023visual</span>)</cite> and <span class="ltx_text ltx_font_italic">StrongReject</span> <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">sr</span>)</cite>.
Together they provide 6 categories of policy-violating prompts: <em class="ltx_emph ltx_font_italic">deception, illegal services, hate speech, violence, non-violent crime, sexual content</em>, broad coverage of real-world misuse.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">数据集。我们采用了两个 SOTA 越狱套件：HEHS（qi2023visual）和 StrongReject（sr）。它们共同提供了 6 类违规策略提示：欺骗、非法服务、仇恨言论、暴力、非暴力犯罪、色情内容，广泛覆盖了现实世界的滥用情况。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Metrics.</span>
<span class="ltx_text ltx_font_italic">(i) Human Attack-Success Rate (ASR)</span>.
Five annotators judge each response; the majority vote determines success if the output fulfils the harmful request.
<span class="ltx_text ltx_font_italic">(ii) Harmfulness Rate (LG).</span>
A response is automatically flagged harmful if <span class="ltx_text ltx_font_typewriter">LlamaGuard-3-8B</span> marks <em class="ltx_emph ltx_font_italic">any</em> sub-response as unsafe.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">指标。（i）人类攻击成功率（ASR）。五个标注者对每个响应进行判断；多数投票决定成功，如果输出满足有害请求。（ii）有害率（LG）。如果 LlamaGuard-3-8B 将任何子响应标记为不安全，则自动将响应标记为有害。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Baselines.</span>
We compare MFA against 6 published jailbreak attacks:
GPTFuzzer <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gptfuzzer</span>)</cite> (text), and five image-based methods—CS-DJ <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">csdj</span>)</cite>, HADES <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">hade</span>)</cite>, Visual-AE <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">qi2023visual</span>)</cite>, FigStep <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gong2023figstep</span>)</cite>, HIMRD <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">teng2025heuristicinducedmultimodalriskdistribution</span>)</cite>.
For our content-moderator facet ablations we additionally include GCG <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gcg</span>)</cite> and BEAST <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">beast</span>)</cite>.
Implementation details and hyper-parameters are provided in Appendix B.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基线。我们将 MFA 与 6 种已发表的越狱攻击方法进行比较：GPTFuzzer（gptfuzzer）（文本），以及五种基于图像的方法——CS-DJ（csdj）、HADES（hade）、Visual-AE（qi2023visual）、FigStep（gong2023figstep）、HIMRD（teng2025heuristicinducedmultimodalriskdistribution）。对于我们的内容审核方面消融实验，我们额外包含了 GCG（gcg）和 BEAST（beast）。实现细节和超参数在附录 B 中提供。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results Analysis<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2 结果分析</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Effectiveness on Commercial VLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对商业视觉语言模型的有效性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p">As shown in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.T3" title="Table 3 ‣ Take-away. ‣ 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>, MFA demonstrates significant superiority in attacking fully defense-equipped commercial VLMs, directly validating claims about the limitations of current ”production-grade” robustness. Specifically, on GPT-4.1—representing the most recent and robust iteration of OpenAI—GPTFuzzer completely fails (0%), highlighting the strength of modern content filters. However, MFA successfully bypasses GPT4.1, achieving a remarkable 40.0% (LG) and 20.0% (HM) success rate. This trend is consistent across other commercial VLMs. On GPT-4o and GPT-4V, MFA significantly outperforms other baselines, indicating the efficacy of our novel attack framework. <span class="ltx_text ltx_font_bold ltx_font_italic">Our findings reveal a critical weakness in current stacked defenses<span class="ltx_text ltx_font_medium">: while individual mechanisms function in parallel, they fail to synergize effectively, leaving exploitable gaps that can be targeted sequentially.</span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">如表 3 所示，MFA 在攻击完全配备防御的商业视觉语言模型方面表现出显著优势，直接验证了当前“生产级”鲁棒性存在局限性的说法。具体来说，在代表 OpenAI 最新且最鲁棒的迭代版本 GPT-4.1 上，GPTFuzzer 完全失效（0%），突显了现代内容过滤器的强大。然而，MFA 成功绕过 GPT4.1，实现了 40.0%（LG）和 20.0%（HM）的显著成功率。这一趋势在其他商业视觉语言模型中也一致存在。在 GPT-4o 和 GPT-4V 上，MFA 显著优于其他基线，表明我们新型攻击框架的有效性。我们的研究揭示当前堆叠防御存在一个关键弱点：虽然各个机制并行运行，但它们未能有效协同，留下了可依次利用的漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Performance on Open-Source Alignment-Only Models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">开源仅对齐模型上的性能。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p">Open-source VLMs, which rely solely on alignment training, are significantly more vulnerable to jailbreaks, as evidenced by the consistently higher attack success rates across both automatic and human evaluations. While MFA remains highly competitive, it is occasionally outperformed by prompt-centric methods such as GPTFuzzer on certain models (e.g., LLaMA-3.2 and LLaMA-4-Scout), which benefit from the absence of stronger defenses like content filters.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">开源视觉语言模型完全依赖对齐训练，在越狱攻击方面显著更脆弱，这一点在自动和人工评估中持续更高的攻击成功率中得到证明。虽然多方面攻击（MFA）仍然具有很强的竞争力，但在某些模型（例如 LLaMA-3.2 和 LLaMA-4-Scout）上偶尔会被以提示为中心的方法（如 GPTFuzzer）超越，这些模型受益于缺乏更强的防御措施，如内容过滤器。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Cross-modal transferability.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">跨模态可迁移性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px3.p1">
<p class="ltx_p">The success of MFA on models it never interacted with (<em class="ltx_emph ltx_font_italic">e.g</em>., GPT-4o, GPT-4.1 and Gemini-2.5-flash) empirically corroborates our claim that the proposed transfer-enhancement objective plus vision-encoder adversarial images exposes a “monoculture” vulnerability shared across VLM families.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">MFA 在它从未交互过的模型上（例如 GPT-4o、GPT-4.1 和 Gemini-2.5-flash）的成功，经验性地证实了我们的观点：所提出的迁移增强目标加上视觉编码器对抗图像揭示了 VLM 家族共有的“单一文化”漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="240" id="S4.F4.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x4.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Real attack cases of MFA with baselines. Further case studies are available in Appendix D.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 4：多方面攻击（MFA）与基线模型的实际攻击案例。更多案例研究可在附录 D 中找到。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Qualitative Results.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">定性结果。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px4.p1">
<p class="ltx_p">As shown in Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.F4" title="Figure 4 ‣ Cross-modal transferability. ‣ 4.2 Results Analysis ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>, MFA effectively induces diverse VLMs to generate explicitly harmful responses that closely reflect the original harmful instruction. In contrast, heuristic-based attacks like FigStep and HIMRD typically require rewriting or visually embedding harmful concepts into images, diluting prompt fidelity and often yielding indirect or irrelevant responses. These qualitative examples underscore MFA’s superior capability in accurately preserving harmful intent while bypassing deployed safeguards.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">如图 4 所示，MFA 能有效诱导多种 VLM 生成明确有害的响应，这些响应与原始有害指令高度相似。相比之下，图 Step 和 HIMRD 等基于启发式的攻击通常需要重写或将有害概念视觉化嵌入图像中，这会降低提示保真度，并常常产生间接或不相关的响应。这些定性示例突显了 MFA 在准确保留有害意图的同时绕过部署的防护措施方面的卓越能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px4.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Key takeaways.</span>
(i) Existing multilayer safety stacks remain brittle: MFA pierces input <em class="ltx_emph ltx_font_italic">and</em> output filters that defeat prior attacks.
(ii) Alignment training alone is insufficient; even when baselines excel on open-source checkpoints, their success collapses once real-world defenses are added.
(iii) The strong cross-model transfer of MFA validates the practical relevance of the reward-hacking theory introduced in Sec&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS1" title="3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3.1</span></a>. Together, these findings motivate the need for theoretically grounded, evaluation frameworks like MFA.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">主要结论。(i) 现有的多层安全堆栈仍然脆弱：MFA 突破了输入和输出过滤器，这些过滤器击败了之前的攻击。(ii) 单纯的校准训练是不够的；即使基线在开源检查点上表现优异，一旦添加真实世界的防御措施，其成功便会崩溃。(iii) MFA 的强跨模型迁移验证了第 3.1 节中引入的奖励劫持理论的实际相关性。这些发现共同促使我们需要理论上支撑的评估框架，如 MFA。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:430.0pt;height:57pt;vertical-align:-27.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-199.3pt,26.5pt) scale(0.518968233744857,0.518968233744857) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt"><span class="ltx_text ltx_font_bold">Dataset<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">数据集</font></font></font></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt"><span class="ltx_text ltx_font_bold">Attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">攻击</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">LlamaGuard</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">ShieldGemma</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">SR-Evaluator</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Aegis</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold">LlamaGuard2<font data-immersive-translate-error-id="26" class="notranslate immersive-translate-target-wrapper immersive-translate-target-wrapper-error" translate="no" lang="zh-CN" style="display: unset;"><a href="javascript:void(0)"><font class="immersive-translate-error notranslate">
        <font class="immersive-translate-error-wrapper">
        <font class="immersive-translate-clickable-button notranslate" style="display:flex;flex-direction:row;align-items:center;" data-immersive-translate-paragraph-id="26" title="重试全部错误段落" data-immersive-translate-action="retry">
          <svg style="display:inline;width:1em;height:1em;pointer-events:none;" width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M35.9387 5.48805C35.9166 4.60421 35.2434 4.04719 34.279 4.0675C33.3131 4.0878 32.8154 4.67712 32.6567 5.56132C32.5745 6.01985 32.601 6.49957 32.5962 6.96997C32.5881 7.77251 32.594 8.5752 32.594 9.3779C32.4685 9.43478 32.343 9.4917 32.2175 9.54866C31.7961 9.14366 31.3817 8.73102 30.9521 8.33488C27.0799 4.76502 22.4856 3.43605 17.3405 4.22591C10.0761 5.34107 4.69388 11.3891 4.06231 18.939C3.46983 26.0213 8.03881 32.8643 14.897 35.1663C21.8348 37.495 29.5543 34.7845 33.4563 28.6429C33.7074 28.2475 33.9685 27.8417 34.1218 27.4045C34.4194 26.5555 34.2699 25.765 33.4312 25.3113C32.6231 24.8743 31.8573 25.0498 31.2835 25.7915C30.9966 26.1625 30.7785 26.5856 30.5106 26.9724C28.0914 30.4658 24.7682 32.3693 20.5158 32.5766C14.8218 32.8541 9.60215 29.1608 7.94272 23.717C6.22884 18.0946 8.59939 12.0366 13.6698 9.08126C18.5986 6.20837 24.9262 7.03281 28.9148 11.0837C29.2069 11.3803 29.4036 11.7708 29.8772 12.4519C28.32 12.4519 27.1212 12.3885 25.9323 12.4704C24.8345 12.5461 24.253 13.1995 24.262 14.1166C24.2708 15.0096 24.8931 15.7485 25.9495 15.7745C28.7068 15.8424 31.4671 15.8177 34.2259 15.7884C35.1348 15.7787 35.8872 15.2584 35.9148 14.3603C36.0054 11.4048 36.0127 8.44397 35.9387 5.48805Z" fill="#428ADF"></path>
          </svg>
          <span style="color:#428ADF;text-decoration-line:underline;text-underline-offset:0.2em;margin-left:0.2em;pointer-events:none;">重试</span>
        </font>&nbsp;&nbsp;
        <font class="immersive-translate-help-button notranslate" style="display:flex;flex-direction:row;align-items:center;" title="点击查看错误原因: {&quot;error&quot;:{&quot;code&quot;:&quot;1302&quot;,&quot;message&quot;:&quot;您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&quot;}}" data-immersive-translate-tooltip-text="{&quot;type&quot;:&quot;network&quot;,&quot;title&quot;:&quot;[GLM-4 Flash] 翻译服务或网络出现问题&quot;,&quot;errMsg&quot;:&quot;服务返回错误，说明请求过于频繁或超出额度限制，请稍后再试。&lt;br/&gt;&lt;br/&gt; 429: 您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&quot;,&quot;action&quot;:&quot;retry&quot;,&quot;immediateShow&quot;:false,&quot;translationService&quot;:&quot;GLM-4 Flash&quot;,&quot;errCode&quot;:429}" data-immersive-translate-action="toast-error">
          <svg style="display:inline;width:1em;height:1em;pointer-events:none;" width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path fill-rule="evenodd" clip-rule="evenodd" d="M20.5607 2.5191C10.735 2.05516 2.46528 10.1045 2.50011 20.0984C2.54469 32.8837 15.9794 41.3025 27.521 35.772C28.0597 35.5138 28.6042 35.2357 29.0745 34.8742C29.9064 34.2347 30.0797 33.3404 29.5712 32.5989C29.0382 31.8217 28.2936 31.6838 27.4596 32.0227C27.2265 32.1174 27.0066 32.2437 26.7865 32.3701C26.6008 32.4767 26.415 32.5833 26.2211 32.6712C20.8005 35.1282 15.6165 34.6504 11.0342 30.8857C6.38506 27.0662 4.83815 21.9885 6.36608 16.1605C8.23236 9.04216 15.6457 4.59129 22.7912 6.13629C30.3201 7.76418 35.1917 14.6886 33.9006 22.1467C33.6763 23.4426 33.1697 24.693 32.665 25.9388C32.4936 26.3618 32.3223 26.7846 32.1625 27.2081C31.7321 28.3488 31.8755 29.1499 32.727 29.6338C33.5625 30.1085 34.3839 29.8271 35.0848 28.8121C35.2031 28.6407 35.3005 28.4544 35.3977 28.2685C35.4242 28.2179 35.4507 28.1672 35.4776 28.1169C36.5263 26.154 37.166 24.0544 37.3992 21.8528C38.4715 11.7296 30.8594 3.00541 20.5607 2.5191ZM22.2324 19.4482C22.6221 17.6294 21.6934 16.7853 19.8682 17.1885C19.4795 17.2744 19.0887 17.3789 18.7223 17.531C17.5055 18.036 17.1067 18.9307 17.8422 20.0563C18.3665 20.8586 18.2472 21.5161 18.0255 22.2965L17.9039 22.7239C17.5079 24.1148 17.1115 25.5072 16.7935 26.9165C16.4841 28.2873 17.2241 29.1723 18.6198 29.1593C18.6749 29.1502 18.7366 29.1408 18.8028 29.1307C18.9623 29.1063 19.1482 29.078 19.332 29.0394C21.5543 28.5732 21.9094 27.8227 20.9844 25.759C20.8192 25.3904 20.8406 24.873 20.9389 24.4633C21.1123 23.7404 21.3092 23.0227 21.5061 22.3052C21.7664 21.3567 22.0267 20.4083 22.2324 19.4482ZM21.2918 10.7674C22.3383 10.7322 23.3464 11.7297 23.3245 12.7787C23.3035 13.7817 22.4311 14.6541 21.4139 14.6892C20.3685 14.7252 19.5018 13.9485 19.4202 12.9025C19.3341 11.798 20.2055 10.8041 21.2918 10.7674Z" fill="#428ADF"></path>
          </svg>
          <span style="color:#428ADF;text-decoration-line:underline;text-underline-offset:0.2em;margin-left:0.2em;pointer-events:none;">错误原因</span>
        </font>
        </font>
        </font></a></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold">LlamaGuard3<font data-immersive-translate-error-id="27" class="notranslate immersive-translate-target-wrapper immersive-translate-target-wrapper-error" translate="no" lang="zh-CN" style="display: unset;"><a href="javascript:void(0)"><font class="immersive-translate-error notranslate">
        <font class="immersive-translate-error-wrapper">
        <font class="immersive-translate-clickable-button notranslate" style="display:flex;flex-direction:row;align-items:center;" data-immersive-translate-paragraph-id="27" title="重试全部错误段落" data-immersive-translate-action="retry">
          <svg style="display:inline;width:1em;height:1em;pointer-events:none;" width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M35.9387 5.48805C35.9166 4.60421 35.2434 4.04719 34.279 4.0675C33.3131 4.0878 32.8154 4.67712 32.6567 5.56132C32.5745 6.01985 32.601 6.49957 32.5962 6.96997C32.5881 7.77251 32.594 8.5752 32.594 9.3779C32.4685 9.43478 32.343 9.4917 32.2175 9.54866C31.7961 9.14366 31.3817 8.73102 30.9521 8.33488C27.0799 4.76502 22.4856 3.43605 17.3405 4.22591C10.0761 5.34107 4.69388 11.3891 4.06231 18.939C3.46983 26.0213 8.03881 32.8643 14.897 35.1663C21.8348 37.495 29.5543 34.7845 33.4563 28.6429C33.7074 28.2475 33.9685 27.8417 34.1218 27.4045C34.4194 26.5555 34.2699 25.765 33.4312 25.3113C32.6231 24.8743 31.8573 25.0498 31.2835 25.7915C30.9966 26.1625 30.7785 26.5856 30.5106 26.9724C28.0914 30.4658 24.7682 32.3693 20.5158 32.5766C14.8218 32.8541 9.60215 29.1608 7.94272 23.717C6.22884 18.0946 8.59939 12.0366 13.6698 9.08126C18.5986 6.20837 24.9262 7.03281 28.9148 11.0837C29.2069 11.3803 29.4036 11.7708 29.8772 12.4519C28.32 12.4519 27.1212 12.3885 25.9323 12.4704C24.8345 12.5461 24.253 13.1995 24.262 14.1166C24.2708 15.0096 24.8931 15.7485 25.9495 15.7745C28.7068 15.8424 31.4671 15.8177 34.2259 15.7884C35.1348 15.7787 35.8872 15.2584 35.9148 14.3603C36.0054 11.4048 36.0127 8.44397 35.9387 5.48805Z" fill="#428ADF"></path>
          </svg>
          <span style="color:#428ADF;text-decoration-line:underline;text-underline-offset:0.2em;margin-left:0.2em;pointer-events:none;">重试</span>
        </font>&nbsp;&nbsp;
        <font class="immersive-translate-help-button notranslate" style="display:flex;flex-direction:row;align-items:center;" title="点击查看错误原因: {&quot;error&quot;:{&quot;code&quot;:&quot;1302&quot;,&quot;message&quot;:&quot;您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&quot;}}" data-immersive-translate-tooltip-text="{&quot;type&quot;:&quot;network&quot;,&quot;title&quot;:&quot;[GLM-4 Flash] 翻译服务或网络出现问题&quot;,&quot;errMsg&quot;:&quot;服务返回错误，说明请求过于频繁或超出额度限制，请稍后再试。&lt;br/&gt;&lt;br/&gt; 429: 您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&quot;,&quot;action&quot;:&quot;retry&quot;,&quot;immediateShow&quot;:false,&quot;translationService&quot;:&quot;GLM-4 Flash&quot;,&quot;errCode&quot;:429}" data-immersive-translate-action="toast-error">
          <svg style="display:inline;width:1em;height:1em;pointer-events:none;" width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path fill-rule="evenodd" clip-rule="evenodd" d="M20.5607 2.5191C10.735 2.05516 2.46528 10.1045 2.50011 20.0984C2.54469 32.8837 15.9794 41.3025 27.521 35.772C28.0597 35.5138 28.6042 35.2357 29.0745 34.8742C29.9064 34.2347 30.0797 33.3404 29.5712 32.5989C29.0382 31.8217 28.2936 31.6838 27.4596 32.0227C27.2265 32.1174 27.0066 32.2437 26.7865 32.3701C26.6008 32.4767 26.415 32.5833 26.2211 32.6712C20.8005 35.1282 15.6165 34.6504 11.0342 30.8857C6.38506 27.0662 4.83815 21.9885 6.36608 16.1605C8.23236 9.04216 15.6457 4.59129 22.7912 6.13629C30.3201 7.76418 35.1917 14.6886 33.9006 22.1467C33.6763 23.4426 33.1697 24.693 32.665 25.9388C32.4936 26.3618 32.3223 26.7846 32.1625 27.2081C31.7321 28.3488 31.8755 29.1499 32.727 29.6338C33.5625 30.1085 34.3839 29.8271 35.0848 28.8121C35.2031 28.6407 35.3005 28.4544 35.3977 28.2685C35.4242 28.2179 35.4507 28.1672 35.4776 28.1169C36.5263 26.154 37.166 24.0544 37.3992 21.8528C38.4715 11.7296 30.8594 3.00541 20.5607 2.5191ZM22.2324 19.4482C22.6221 17.6294 21.6934 16.7853 19.8682 17.1885C19.4795 17.2744 19.0887 17.3789 18.7223 17.531C17.5055 18.036 17.1067 18.9307 17.8422 20.0563C18.3665 20.8586 18.2472 21.5161 18.0255 22.2965L17.9039 22.7239C17.5079 24.1148 17.1115 25.5072 16.7935 26.9165C16.4841 28.2873 17.2241 29.1723 18.6198 29.1593C18.6749 29.1502 18.7366 29.1408 18.8028 29.1307C18.9623 29.1063 19.1482 29.078 19.332 29.0394C21.5543 28.5732 21.9094 27.8227 20.9844 25.759C20.8192 25.3904 20.8406 24.873 20.9389 24.4633C21.1123 23.7404 21.3092 23.0227 21.5061 22.3052C21.7664 21.3567 22.0267 20.4083 22.2324 19.4482ZM21.2918 10.7674C22.3383 10.7322 23.3464 11.7297 23.3245 12.7787C23.3035 13.7817 22.4311 14.6541 21.4139 14.6892C20.3685 14.7252 19.5018 13.9485 19.4202 12.9025C19.3341 11.798 20.2055 10.8041 21.2918 10.7674Z" fill="#428ADF"></path>
          </svg>
          <span style="color:#428ADF;text-decoration-line:underline;text-underline-offset:0.2em;margin-left:0.2em;pointer-events:none;">错误原因</span>
        </font>
        </font>
        </font></a></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold">OpenAI-Mod.<font data-immersive-translate-error-id="28" class="notranslate immersive-translate-target-wrapper immersive-translate-target-wrapper-error" translate="no" lang="zh-CN" style="display: unset;"><a href="javascript:void(0)"><font class="immersive-translate-error notranslate">
        <font class="immersive-translate-error-wrapper">
        <font class="immersive-translate-clickable-button notranslate" style="display:flex;flex-direction:row;align-items:center;" data-immersive-translate-paragraph-id="28" title="重试全部错误段落" data-immersive-translate-action="retry">
          <svg style="display:inline;width:1em;height:1em;pointer-events:none;" width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M35.9387 5.48805C35.9166 4.60421 35.2434 4.04719 34.279 4.0675C33.3131 4.0878 32.8154 4.67712 32.6567 5.56132C32.5745 6.01985 32.601 6.49957 32.5962 6.96997C32.5881 7.77251 32.594 8.5752 32.594 9.3779C32.4685 9.43478 32.343 9.4917 32.2175 9.54866C31.7961 9.14366 31.3817 8.73102 30.9521 8.33488C27.0799 4.76502 22.4856 3.43605 17.3405 4.22591C10.0761 5.34107 4.69388 11.3891 4.06231 18.939C3.46983 26.0213 8.03881 32.8643 14.897 35.1663C21.8348 37.495 29.5543 34.7845 33.4563 28.6429C33.7074 28.2475 33.9685 27.8417 34.1218 27.4045C34.4194 26.5555 34.2699 25.765 33.4312 25.3113C32.6231 24.8743 31.8573 25.0498 31.2835 25.7915C30.9966 26.1625 30.7785 26.5856 30.5106 26.9724C28.0914 30.4658 24.7682 32.3693 20.5158 32.5766C14.8218 32.8541 9.60215 29.1608 7.94272 23.717C6.22884 18.0946 8.59939 12.0366 13.6698 9.08126C18.5986 6.20837 24.9262 7.03281 28.9148 11.0837C29.2069 11.3803 29.4036 11.7708 29.8772 12.4519C28.32 12.4519 27.1212 12.3885 25.9323 12.4704C24.8345 12.5461 24.253 13.1995 24.262 14.1166C24.2708 15.0096 24.8931 15.7485 25.9495 15.7745C28.7068 15.8424 31.4671 15.8177 34.2259 15.7884C35.1348 15.7787 35.8872 15.2584 35.9148 14.3603C36.0054 11.4048 36.0127 8.44397 35.9387 5.48805Z" fill="#428ADF"></path>
          </svg>
          <span style="color:#428ADF;text-decoration-line:underline;text-underline-offset:0.2em;margin-left:0.2em;pointer-events:none;">重试</span>
        </font>&nbsp;&nbsp;
        <font class="immersive-translate-help-button notranslate" style="display:flex;flex-direction:row;align-items:center;" title="点击查看错误原因: {&quot;error&quot;:{&quot;code&quot;:&quot;1302&quot;,&quot;message&quot;:&quot;您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&quot;}}" data-immersive-translate-tooltip-text="{&quot;type&quot;:&quot;network&quot;,&quot;title&quot;:&quot;[GLM-4 Flash] 翻译服务或网络出现问题&quot;,&quot;errMsg&quot;:&quot;服务返回错误，说明请求过于频繁或超出额度限制，请稍后再试。&lt;br/&gt;&lt;br/&gt; 429: 您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&quot;,&quot;action&quot;:&quot;retry&quot;,&quot;immediateShow&quot;:false,&quot;translationService&quot;:&quot;GLM-4 Flash&quot;,&quot;errCode&quot;:429}" data-immersive-translate-action="toast-error">
          <svg style="display:inline;width:1em;height:1em;pointer-events:none;" width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path fill-rule="evenodd" clip-rule="evenodd" d="M20.5607 2.5191C10.735 2.05516 2.46528 10.1045 2.50011 20.0984C2.54469 32.8837 15.9794 41.3025 27.521 35.772C28.0597 35.5138 28.6042 35.2357 29.0745 34.8742C29.9064 34.2347 30.0797 33.3404 29.5712 32.5989C29.0382 31.8217 28.2936 31.6838 27.4596 32.0227C27.2265 32.1174 27.0066 32.2437 26.7865 32.3701C26.6008 32.4767 26.415 32.5833 26.2211 32.6712C20.8005 35.1282 15.6165 34.6504 11.0342 30.8857C6.38506 27.0662 4.83815 21.9885 6.36608 16.1605C8.23236 9.04216 15.6457 4.59129 22.7912 6.13629C30.3201 7.76418 35.1917 14.6886 33.9006 22.1467C33.6763 23.4426 33.1697 24.693 32.665 25.9388C32.4936 26.3618 32.3223 26.7846 32.1625 27.2081C31.7321 28.3488 31.8755 29.1499 32.727 29.6338C33.5625 30.1085 34.3839 29.8271 35.0848 28.8121C35.2031 28.6407 35.3005 28.4544 35.3977 28.2685C35.4242 28.2179 35.4507 28.1672 35.4776 28.1169C36.5263 26.154 37.166 24.0544 37.3992 21.8528C38.4715 11.7296 30.8594 3.00541 20.5607 2.5191ZM22.2324 19.4482C22.6221 17.6294 21.6934 16.7853 19.8682 17.1885C19.4795 17.2744 19.0887 17.3789 18.7223 17.531C17.5055 18.036 17.1067 18.9307 17.8422 20.0563C18.3665 20.8586 18.2472 21.5161 18.0255 22.2965L17.9039 22.7239C17.5079 24.1148 17.1115 25.5072 16.7935 26.9165C16.4841 28.2873 17.2241 29.1723 18.6198 29.1593C18.6749 29.1502 18.7366 29.1408 18.8028 29.1307C18.9623 29.1063 19.1482 29.078 19.332 29.0394C21.5543 28.5732 21.9094 27.8227 20.9844 25.759C20.8192 25.3904 20.8406 24.873 20.9389 24.4633C21.1123 23.7404 21.3092 23.0227 21.5061 22.3052C21.7664 21.3567 22.0267 20.4083 22.2324 19.4482ZM21.2918 10.7674C22.3383 10.7322 23.3464 11.7297 23.3245 12.7787C23.3035 13.7817 22.4311 14.6541 21.4139 14.6892C20.3685 14.7252 19.5018 13.9485 19.4202 12.9025C19.3341 11.798 20.2055 10.8041 21.2918 10.7674Z" fill="#428ADF"></path>
          </svg>
          <span style="color:#428ADF;text-decoration-line:underline;text-underline-offset:0.2em;margin-left:0.2em;pointer-events:none;">错误原因</span>
        </font>
        </font>
        </font></a></font></span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span class="ltx_text ltx_font_bold">Avg.</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span class="ltx_text ltx_font_bold">HEHS</span></td>
<td class="ltx_td ltx_align_left ltx_border_t">GCG&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gcg</span>)</cite><font data-immersive-translate-error-id="29" class="notranslate immersive-translate-target-wrapper immersive-translate-target-wrapper-error" translate="no" lang="zh-CN" style="display: unset;"><a href="javascript:void(0)"><font class="immersive-translate-error notranslate">
        <font class="immersive-translate-error-wrapper">
        <font class="immersive-translate-clickable-button notranslate" style="display:flex;flex-direction:row;align-items:center;" data-immersive-translate-paragraph-id="29" title="重试全部错误段落" data-immersive-translate-action="retry">
          <svg style="display:inline;width:1em;height:1em;pointer-events:none;" width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M35.9387 5.48805C35.9166 4.60421 35.2434 4.04719 34.279 4.0675C33.3131 4.0878 32.8154 4.67712 32.6567 5.56132C32.5745 6.01985 32.601 6.49957 32.5962 6.96997C32.5881 7.77251 32.594 8.5752 32.594 9.3779C32.4685 9.43478 32.343 9.4917 32.2175 9.54866C31.7961 9.14366 31.3817 8.73102 30.9521 8.33488C27.0799 4.76502 22.4856 3.43605 17.3405 4.22591C10.0761 5.34107 4.69388 11.3891 4.06231 18.939C3.46983 26.0213 8.03881 32.8643 14.897 35.1663C21.8348 37.495 29.5543 34.7845 33.4563 28.6429C33.7074 28.2475 33.9685 27.8417 34.1218 27.4045C34.4194 26.5555 34.2699 25.765 33.4312 25.3113C32.6231 24.8743 31.8573 25.0498 31.2835 25.7915C30.9966 26.1625 30.7785 26.5856 30.5106 26.9724C28.0914 30.4658 24.7682 32.3693 20.5158 32.5766C14.8218 32.8541 9.60215 29.1608 7.94272 23.717C6.22884 18.0946 8.59939 12.0366 13.6698 9.08126C18.5986 6.20837 24.9262 7.03281 28.9148 11.0837C29.2069 11.3803 29.4036 11.7708 29.8772 12.4519C28.32 12.4519 27.1212 12.3885 25.9323 12.4704C24.8345 12.5461 24.253 13.1995 24.262 14.1166C24.2708 15.0096 24.8931 15.7485 25.9495 15.7745C28.7068 15.8424 31.4671 15.8177 34.2259 15.7884C35.1348 15.7787 35.8872 15.2584 35.9148 14.3603C36.0054 11.4048 36.0127 8.44397 35.9387 5.48805Z" fill="#428ADF"></path>
          </svg>
          <span style="color:#428ADF;text-decoration-line:underline;text-underline-offset:0.2em;margin-left:0.2em;pointer-events:none;">重试</span>
        </font>&nbsp;&nbsp;
        <font class="immersive-translate-help-button notranslate" style="display:flex;flex-direction:row;align-items:center;" title="点击查看错误原因: {&quot;error&quot;:{&quot;code&quot;:&quot;1302&quot;,&quot;message&quot;:&quot;您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&quot;}}" data-immersive-translate-tooltip-text="{&quot;type&quot;:&quot;network&quot;,&quot;title&quot;:&quot;[GLM-4 Flash] 翻译服务或网络出现问题&quot;,&quot;errMsg&quot;:&quot;服务返回错误，说明请求过于频繁或超出额度限制，请稍后再试。&lt;br/&gt;&lt;br/&gt; 429: 您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&quot;,&quot;action&quot;:&quot;retry&quot;,&quot;immediateShow&quot;:false,&quot;translationService&quot;:&quot;GLM-4 Flash&quot;,&quot;errCode&quot;:429}" data-immersive-translate-action="toast-error">
          <svg style="display:inline;width:1em;height:1em;pointer-events:none;" width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path fill-rule="evenodd" clip-rule="evenodd" d="M20.5607 2.5191C10.735 2.05516 2.46528 10.1045 2.50011 20.0984C2.54469 32.8837 15.9794 41.3025 27.521 35.772C28.0597 35.5138 28.6042 35.2357 29.0745 34.8742C29.9064 34.2347 30.0797 33.3404 29.5712 32.5989C29.0382 31.8217 28.2936 31.6838 27.4596 32.0227C27.2265 32.1174 27.0066 32.2437 26.7865 32.3701C26.6008 32.4767 26.415 32.5833 26.2211 32.6712C20.8005 35.1282 15.6165 34.6504 11.0342 30.8857C6.38506 27.0662 4.83815 21.9885 6.36608 16.1605C8.23236 9.04216 15.6457 4.59129 22.7912 6.13629C30.3201 7.76418 35.1917 14.6886 33.9006 22.1467C33.6763 23.4426 33.1697 24.693 32.665 25.9388C32.4936 26.3618 32.3223 26.7846 32.1625 27.2081C31.7321 28.3488 31.8755 29.1499 32.727 29.6338C33.5625 30.1085 34.3839 29.8271 35.0848 28.8121C35.2031 28.6407 35.3005 28.4544 35.3977 28.2685C35.4242 28.2179 35.4507 28.1672 35.4776 28.1169C36.5263 26.154 37.166 24.0544 37.3992 21.8528C38.4715 11.7296 30.8594 3.00541 20.5607 2.5191ZM22.2324 19.4482C22.6221 17.6294 21.6934 16.7853 19.8682 17.1885C19.4795 17.2744 19.0887 17.3789 18.7223 17.531C17.5055 18.036 17.1067 18.9307 17.8422 20.0563C18.3665 20.8586 18.2472 21.5161 18.0255 22.2965L17.9039 22.7239C17.5079 24.1148 17.1115 25.5072 16.7935 26.9165C16.4841 28.2873 17.2241 29.1723 18.6198 29.1593C18.6749 29.1502 18.7366 29.1408 18.8028 29.1307C18.9623 29.1063 19.1482 29.078 19.332 29.0394C21.5543 28.5732 21.9094 27.8227 20.9844 25.759C20.8192 25.3904 20.8406 24.873 20.9389 24.4633C21.1123 23.7404 21.3092 23.0227 21.5061 22.3052C21.7664 21.3567 22.0267 20.4083 22.2324 19.4482ZM21.2918 10.7674C22.3383 10.7322 23.3464 11.7297 23.3245 12.7787C23.3035 13.7817 22.4311 14.6541 21.4139 14.6892C20.3685 14.7252 19.5018 13.9485 19.4202 12.9025C19.3341 11.798 20.2055 10.8041 21.2918 10.7674Z" fill="#428ADF"></path>
          </svg>
          <span style="color:#428ADF;text-decoration-line:underline;text-underline-offset:0.2em;margin-left:0.2em;pointer-events:none;">错误原因</span>
        </font>
        </font>
        </font></a></font>
</td>
<td class="ltx_td ltx_align_center ltx_border_t">100.00</td>
<td class="ltx_td ltx_align_center ltx_border_t">37.50</td>
<td class="ltx_td ltx_align_center ltx_border_t">92.50</td>
<td class="ltx_td ltx_align_center ltx_border_t">65.00</td>
<td class="ltx_td ltx_align_center ltx_border_t">32.00</td>
<td class="ltx_td ltx_align_center ltx_border_t">10.00</td>
<td class="ltx_td ltx_align_center ltx_border_t">50.00</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">59.11</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">Fast (ours)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">快速（我们的）</font></font></font></span></td>
<td class="ltx_td ltx_align_center">100.00</td>
<td class="ltx_td ltx_align_center">67.50</td>
<td class="ltx_td ltx_align_center">100.00</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">85.00</span></td>
<td class="ltx_td ltx_align_center">62.50</td>
<td class="ltx_td ltx_align_center">17.50</td>
<td class="ltx_td ltx_align_center">50.00</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">67.50</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">Transfer (ours)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">迁移（我们的）</font></font></font></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">100.00</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">100.00</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">100.00</span></td>
<td class="ltx_td ltx_align_center">77.50</td>
<td class="ltx_td ltx_align_center">100.00</td>
<td class="ltx_td ltx_align_center">100.00</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">20.00</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center"><span class="ltx_text ltx_font_bold">80.00</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">BEAST&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">beast</span>)</cite><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">BEAST（beast）</font></font></font>
</td>
<td class="ltx_td ltx_align_center">50.00</td>
<td class="ltx_td ltx_align_center">90.00</td>
<td class="ltx_td ltx_align_center">92.50</td>
<td class="ltx_td ltx_align_center">35.00</td>
<td class="ltx_td ltx_align_center">67.50</td>
<td class="ltx_td ltx_align_center">67.50</td>
<td class="ltx_td ltx_align_center">17.50</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">57.50</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" rowspan="4"><span class="ltx_text ltx_font_bold">Strong Reject<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">强力拒绝</font></font></font></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" data-imt_insert_failed="1">GCG&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">gcg</span>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t">98.33</td>
<td class="ltx_td ltx_align_center ltx_border_t">73.33</td>
<td class="ltx_td ltx_align_center ltx_border_t">95.00</td>
<td class="ltx_td ltx_align_center ltx_border_t">53.33</td>
<td class="ltx_td ltx_align_center ltx_border_t">13.33</td>
<td class="ltx_td ltx_align_center ltx_border_t">3.30</td>
<td class="ltx_td ltx_align_center ltx_border_t">20.00</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">54.81</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">Fast (ours)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Fast (我们)</font></font></font></span></td>
<td class="ltx_td ltx_align_center">100.00</td>
<td class="ltx_td ltx_align_center">100.00</td>
<td class="ltx_td ltx_align_center">100.00</td>
<td class="ltx_td ltx_align_center">56.67</td>
<td class="ltx_td ltx_align_center">23.33</td>
<td class="ltx_td ltx_align_center">3.30</td>
<td class="ltx_td ltx_align_center">40.00</td>
<td class="ltx_td ltx_nopad_r ltx_align_center">60.18</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">Transfer (ours)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">迁移 (我们)</font></font></font></span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">100.00</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">100.00</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">100.00</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">60.00</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">95.00</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">5.00</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">50.00</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center"><span class="ltx_text ltx_font_bold">68.70</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b" data-imt_insert_failed="1">BEAST&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">beast</span>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_b">33.00</td>
<td class="ltx_td ltx_align_center ltx_border_b">88.33</td>
<td class="ltx_td ltx_align_center ltx_border_b">88.33</td>
<td class="ltx_td ltx_align_center ltx_border_b">11.67</td>
<td class="ltx_td ltx_align_center ltx_border_b">36.66</td>
<td class="ltx_td ltx_align_center ltx_border_b"><span class="ltx_text ltx_font_bold">5.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_b">40.00</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_b">43.28</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablations on Filter-Targeted Attack. <span class="ltx_text ltx_font_bold">Fast</span> denotes multi-token optimization; <span class="ltx_text ltx_font_bold">Transfer</span> denotes weak-supervision transfer.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 4：针对过滤目标的攻击的消融实验。Fast 表示多标记优化；Transfer 表示弱监督迁移。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation Study<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.3 消融研究</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:104.5pt;vertical-align:-49.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.4pt,2.7pt) scale(0.950200103052487,0.950200103052487) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">VLM</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="5" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">Attack Facet<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">攻击方面</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">w/o attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">无攻击</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">Vision Encoder Attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">视觉编码器攻击</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">ATA</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">Filter Attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">过滤器攻击</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#EFEFEF;padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">MFA</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">MiniGPT-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">32.50</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline">90.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">72.50</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">32.50</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#EFEFEF;padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">100</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">LLaVA-1.5-13b</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">17.50</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">50.00</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline">65.00</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">17.50</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFEFEF;padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">77.50</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">mPLUG-Owl2</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">25.00</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">85.00</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">57.50</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">37.50</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFEFEF;padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">85.00</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Qwen-VL-Chat</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">15.00</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">67.50</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline">65.00</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">7.50</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFEFEF;padding-left:8.5pt;padding-right:8.5pt;">35.00</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">NVLM-D-72B</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">5.00</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">47.50</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_italic ltx_framed ltx_framed_underline">62.50</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">12.50</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFEFEF;padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">82.50</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Llama-3.2-11B-V-I</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">10.00</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">17.50</td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">57.50</span></td>
<td class="ltx_td ltx_align_center" style="padding-left:8.5pt;padding-right:8.5pt;">10.00</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#EFEFEF;padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">57.50</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">Avg.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">平均</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">17.5</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_italic">59.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_framed ltx_framed_underline">63.33</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:8.5pt;padding-right:8.5pt;">20.00</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="--ltx-bg-color:#EFEFEF;padding-left:8.5pt;padding-right:8.5pt;"><span class="ltx_text ltx_font_bold">72.92</span></td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Ablation Study on Vision Encoder-Targeted Attack. <font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 5：针对视觉编码器的消融研究</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p">We evaluate the individual contributions of each component in MFA and demonstrate their complementary strengths. Our analysis reveals that while each facet is effective in isolation, their combination exploits distinct weaknesses within VLM safety mechanisms, leading to a compounded attack effect.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们评估了 MFA 中每个组件的独立贡献，并展示了它们的互补优势。我们的分析表明，虽然每个方面在单独使用时都有效，但它们的组合利用了 VLM 安全机制中的不同弱点，从而产生了复合攻击效果。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Effectiveness of ATA.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ATA 的有效性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p">We evaluate the standalone performance of the ATA in Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS1" title="3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3.1</span></a>, demonstrating its ability to reliably hijack three SOTA reward models (see Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.T1" title="Table 1 ‣ 2. Empirical Validation ‣ 3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>). Additionally, we assess its generalizability across four attack variants. For full details, refer to Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS1" title="3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3.1</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们在第 3.1 节评估了 ATA 的独立性能，展示了它能够可靠地劫持三种 SOTA 奖励模型（参见表 1）。此外，我们还评估了它在四种攻击变体上的泛化能力。详细信息请参考第 3.1 节。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Effectiveness of Filter-Targeted Attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">过滤目标攻击的有效性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p">Tab.<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.T4" title="Table 4 ‣ Qualitative Results. ‣ 4.2 Results Analysis ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">4</span></a> compares our Filter-Targeted Attack—both Fast and Transfer variants—with GCG and BEAST across seven leading content moderators, including OpenAI-Mod<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">openai_moderation</span>)</cite>, Aegis&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">aegis</span>)</cite>, SR-Evaluator&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">sr</span>)</cite>, and the LlamaGuard series&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">llamaguard1</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">llamaguard2</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">llamaguard3</span>)</cite>. Using LlamaGuard2 for signature generation and LlamaGuard for weak supervision, our Transfer method achieves the highest average ASR (80.00% on HEHS, 68.70% on StrongReject), highlighting the effectiveness of weakly supervised transfer in evading diverse moderation systems.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 4 将我们的 Filter-Targeted Attack（包括 Fast 和 Transfer 两种变体）与 GCG 和 BEAST 在七个领先的内容审查器（包括 OpenAI-Mod（openai_moderation）、Aegis（aegis）、SR-Evaluator（sr）以及 LlamaGuard 系列（llamaguard1；llamaguard2；llamaguard3））上进行了比较。使用 LlamaGuard2 生成签名，并使用 LlamaGuard 进行弱监督，我们的 Transfer 方法在平均 ASR 上达到了最高水平（在 HEHS 上为 80.00%，在 StrongReject 上为 68.70%），突显了弱监督迁移在规避不同审查系统方面的有效性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Effectiveness of Vision Encoder-Targeted Attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">视觉编码器定向攻击的有效性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p1">
<p class="ltx_p">We test the cross-model transferability of our Vision Encoder-Targeted Attack by generating a single adversarial image using MiniGPT-4’s vision encoder and applying it to six VLMs with varied backbones. As shown in Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.T5" title="Table 5 ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">5</span></a> (second column), the image induces harmful outputs in all cases, reaching an average ASR of 59.58% without model-specific tuning. Notably, models like mPLUG-Owl2 (85.00%) are especially vulnerable—highlighting systemic flaws in shared vision representations across VLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们通过使用 MiniGPT-4 的视觉编码器生成一张对抗性图像，并应用于六个具有不同骨干结构的视觉语言模型（VLMs），来测试我们视觉编码器目标攻击的跨模型可迁移性。如表 5（第二列）所示，该图像在所有情况下都诱发了有害输出，在不进行模型特定调优的情况下，平均 ASR 达到了 59.58%。值得注意的是，像 mPLUG-Owl2（85.00%）这样的模型特别容易受到攻击——这突显了 VLMs 之间共享视觉表示中存在的系统性缺陷。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Synergy of The Three Facets.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">三个方面的协同作用。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.SSS0.Px4.p1">
<p class="ltx_p">Open-source VLMs primarily rely on alignment training and system prompts for safety. However, adding the <span class="ltx_text ltx_font_italic">Adversarial Signature</span>—designed to fool LLM-based moderators by semantically masking toxic prompts as benign—greatly boosts attack efficacy (Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.T5" title="Table 5 ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>, Filter Attack). Because VLMs are grounded in LLMs, the adversarial semantic transfers downstream, misguiding the model into treating harmful prompts as safe. When combined with the Visual and Text Attacks, the success rate reaches 72.92%, confirming a synergistic effect: each facet targets a distinct vulnerability, collectively maximizing attack success.
<span class="ltx_text ltx_font_bold">Take-away.</span> MFA’s components are individually strong and mutually reinforcing, exposing complementary vulnerabilities across the entire VLM safety stack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">开源的视觉语言模型（VLMs）主要依靠对齐训练和系统提示来确保安全。然而，通过添加对抗性签名——该签名通过语义掩盖毒性提示为良性来欺骗基于 LLM 的审核器——极大地提高了攻击的有效性（表 5，过滤攻击）。由于 VLMs 基于 LLMs 构建，对抗性语义迁移到下游，使模型将有害提示误判为安全。当与视觉攻击和文本攻击结合时，成功率达到了 72.92%，证实了协同效应：每个方面针对不同的漏洞，共同最大化攻击成功。要点。MFA 的各个组成部分单独强大且相互增强，揭示了整个 VLM 安全堆栈中的互补漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="303" id="S4.F5.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x5.png" width="665">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Comparison of computational costs: (a) Parameters and computations. (b) Average attack time on LlamaGuard.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 5：计算成本比较：(a) 参数和计算量。(b) LlamaGuard 上的平均攻击时间。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion &amp; Conclusion<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5 讨论 &amp; 结论</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Discussion.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">讨论。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">(i) Computational Cost.</span>
Our visual attack perturbs only the vision encoder and projection layer (Fig.<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.F3" title="Figure 3 ‣ 1. Workflow. ‣ 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>), making it significantly lighter than end-to-end approaches like Visual-AE. On <span class="ltx_text ltx_font_typewriter">MiniGPT-4</span>, it uses 10× fewer parameters and GMACs (Fig.<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.F5" title="Figure 5 ‣ Synergy of The Three Facets. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>a), and the Fast variant resolves a HEHS prompt in 17.0s vs. 43.7s for GCG on an NVIDIA A800 (Fig.<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.F5" title="Figure 5 ‣ Synergy of The Three Facets. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>b).
<span class="ltx_text ltx_font_bold">(ii) Limitations.</span>
Failures mainly occur when VLMs lack reasoning contrast—e.g., mPLUG-Owl2 often repeats or gives ambiguous replies like “Yes and No,” which hinders MFA success (see Appendix E).
<span class="ltx_text ltx_font_bold">(iii) Ethics.</span>
By revealing cross-cutting vulnerabilities in alignment, filtering, and vision modules, our findings aim to inform safer VLM design. All artifacts will be released under responsible disclosure. Open discussion is critical for AI safety.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(i) 计算成本。我们的视觉攻击仅扰动视觉编码器和投影层（图 3），因此比端到端方法（如 Visual-AE）轻得多。在 MiniGPT-4 上，它使用的参数和 GMACs 减少了 10 倍（图 5a），其快速变体在 NVIDIA A800 上解决 HEHS 提示的时间为 17.0 秒，而 GCG 则为 43.7 秒（图 5b）。(ii) 局限性。当 VLM 缺乏推理对比时，主要会出现失败——例如，mPLUG-Owl2 经常重复或给出模糊的回复，如“是和非”，这阻碍了 MFA 的成功（见附录 E）。(iii) 伦理。通过揭示对齐、过滤和视觉模块中的跨切面漏洞，我们的研究结果旨在指导更安全的 VLM 设计。所有作品将在负责任的披露下发布。对于 AI 安全，开放的讨论至关重要。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Conclusion.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">结论。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p">By comprehensively evaluating the resilience of SOTA VLMs against advanced adversarial threats, our work provides valuable insights and a practical benchmark for future research. Ultimately, we hope our findings will foster proactive enhancements in safety mechanisms, enabling the responsible and secure deployment of multimodal AI.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">通过全面评估 SOTA VLMs 对高级对抗性威胁的韧性，我们的工作为未来研究提供了宝贵的见解和实用的基准。最终，我们希望我们的研究结果将促进安全机制的主动改进，使多模态 AI 能够得到负责任和安全的部署。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">致谢</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p">This project was supported in part by the Innovation and Technology Fund (MHP/213/24), Hong Kong S.A.R.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本项目部分由创新科技基金（MHP/213/24）支持，香港特别行政区。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_logical-block">
<div class="ltx_para" id="Sx1.p2">
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_bold">Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多维度攻击：揭示配备防御功能的</font></font></font><br class="ltx_break">Vision-Language Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">视觉语言模型的跨模型漏洞</font></font></font></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_bold" style="--ltx-fg-color:#FF0000;">WARNING: This Appendix may contain offensive content.
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">警告：本附录可能包含冒犯性内容。</font></font></font><br class="ltx_break"></span>
Appendix Material<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录材料</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix Overview<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 A 附录概述</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p">This appendix provides the technical details and supplementary results that could not be included in the main paper due to space constraints. It is organised as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本附录提供了由于篇幅限制无法包含在正文中技术细节和补充结果。其组织结构如下：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.p2">
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Appendix&nbsp;B: Experimental Settings</span> – hardware, and baseline hyper-parameters (cf. Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS1" title="4.1 Experimental Settings ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">4.1</span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 附录 B：实验设置——硬件和基线超参数（参见第 4.1 节）。</font></font></font>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Appendix&nbsp;C: Details of Ablation Studies.</span> – complete tables referenced in Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.SS1" title="3.1 Attention Transfer Attack: Alignment Breaking Facet ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3.1</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 附录 C：消融研究详情。——引用自第 3.1 节的完整表格。</font></font></font>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Appendix&nbsp;D: Additional MFA Case Studies</span> – extra successful attack transcripts and screenshots complementing Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S4.SS2" title="4.2 Results Analysis ‣ 4 Experiments ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 附录 D：附加 MFA 案例研究——补充第 4.2 节的成功攻击记录和截图。</font></font></font>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Appendix&nbsp;E: Failure-Case Visualisations</span> – illustrative counter-examples and analysis discussed in Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S5" title="5 Discussion &amp; Conclusion ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 附录 E：失败案例可视化——讨论自第 5.节的有说明性反例和分析。</font></font></font>
</li>
</ul>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Implementation Details<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 B 实现细节</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p">In this section, we provide comprehensive information about the hardware environment, details of the victim models, the implementation of the baselines, and elaborate on the specific details of our approach.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本节中，我们提供了关于硬件环境、受害者模型的详细信息、基线实现的细节，并详细阐述了我们方法的具体细节。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Hardware Environment<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.1 硬件环境</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p">All experiments were run on a Linux workstation equipped with<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">所有实验均在配备有</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">NVIDIA A800</span> (80 GB VRAM) for high-resolution adversarial image optimization and open-source VLM inference.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• NVIDIA A800（80 GB VRAM）用于高分辨率对抗图像优化和开源视觉语言模型推理。</font></font></font>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">NVIDIA RTX 4090</span> (24 GB VRAM) for ablation studies and low-resolution adversarial image optimization.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• NVIDIA RTX 4090（24 GB VRAM）用于消融研究和低分辨率对抗图像优化。</font></font></font>
</li>
</ul>
<p class="ltx_p">Both GPUs use CUDA&nbsp;12.2 and PyTorch&nbsp;2.2 with cuDNN enabled; mixed-precision (FP16) inference is applied where supported to accelerate evaluation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这两块 GPU 均使用 CUDA 12.2 和 PyTorch 2.2，并启用 cuDNN；在支持的情况下应用混合精度（FP16）推理以加速评估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Details of Victim Open-source VLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.2 受害者开源视觉语言模型的详细信息。</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS2.p1">
<p class="ltx_p">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A2.T1" title="Table A-1 ‣ B.2 Details of Victim Open-source VLMs. ‣ Appendix B Implementation Details ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">A-1</span></a> summarizes the eight open-source vision–language models (VLMs) used in our evaluation.
They span diverse vision encoders, backbone LLMs, and alignment pipelines, offering a representative test bed for transfer attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 A-1 总结了我们在评估中使用的八个开源视觉-语言模型（VLMs）。它们涵盖了多样的视觉编码器、骨干 LLMs 和校准流程，为迁移攻击提供了一个具有代表性的测试平台。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A2.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:56.6pt;vertical-align:-27.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-200.9pt,26.3pt) scale(0.519100181440252,0.519100181440252) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.25pt 56.9pt;">       <span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.25pt 56.9pt;">       <span class="ltx_text ltx_font_bold">Vision Encoder<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">视觉编码器</font></font></font></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.25pt 56.9pt;">       <span class="ltx_text ltx_font_bold">Backbone LLM<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">骨干 LLM</font></font></font></span></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;"><span class="ltx_text ltx_font_bold">Notable Training / Alignment<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">值得注意的训练/校准</font></font></font></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       LLaMA-4-Scout-Inst</td>
<td class="ltx_td ltx_align_left ltx_border_t" style="padding:0.25pt 56.9pt;">       Customized ViT<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">定制化 ViT</font></font></font></td>
<td class="ltx_td ltx_align_left ltx_border_t" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       LLaMA-4-Scout-17Bx16E</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Vision-instruction-tuning and RLHF<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">视觉指令微调和 RLHF</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       LLaMA-3.2-11B-V-I</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;">       Customized ViT<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">定制化 ViT</font></font></font></td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;">       LLaMA-3.1 architecture<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLaMA-3.1 架构</font></font></font></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Frozen vision tower; multimodal SFT<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">冻结的视觉塔；多模态 SFT</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       MiMo-VL-7B</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       Qwen2.5-VL-ViT</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       MiMo-7B-Base</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">RL with verifiable rewards<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">带可验证奖励的强化学习 </font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       LLaVA-1.5-13B</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       CLIP ViT-L/14</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;">       Vicuna-13B</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Large-scale vision-instruction tuning<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大规模视觉指令微调 </font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       mPLUG-Owl2</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       CLIP-ViT-L-14</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       LLaMA-2-7B</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Paired contrastive + instruction tuning<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">成对对比 + 指令微调</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       Qwen-VL-Chat</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       CLIP-ViT-G</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;">       Qwen-7B</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Chat-style SFT; document QA focus<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对话式 SFT；文档问答重点</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;">       NVLM-D-72B</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;">       InternViT-6B</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       Qwen2-72B-Instruct</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Dynamic high-resolution image input<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">动态高分辨率图像输入</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       MiniGPT-4</td>
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.25pt 56.9pt;" data-imt_insert_failed="1">       EVA-ViT-G/14</td>
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.25pt 56.9pt;">       Vicuna-13B</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb" style="padding:0.25pt 56.9pt;">       
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Q-Former; vision-instruction-tuning<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Q-Former；视觉指令微调</font></font></font></span>
</span>
</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table A-1: </span>Open-source VLMs evaluated in our experiments.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 A-1：我们实验中评估的开源视觉语言模型。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS2.p2">
<p class="ltx_p">All models are evaluated with their public checkpoints and default inference settings, without any additional safety layers beyond those shipped by the original authors.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">所有模型均使用其公开检查点和默认推理设置进行评估，且未使用原始作者提供的额外安全层之外的其他安全层。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Details of Victim Commercial VLMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.3 受害商业视觉语言模型的详细信息</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A2.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:58.2pt;vertical-align:-27.1pt;"><span class="ltx_transformed_inner" style="transform:translate(-64.8pt,7.5pt) scale(0.795997067627516,0.795997067627516) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:0.25pt;padding-bottom:0.25pt;"><span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:0.25pt;padding-bottom:0.25pt;"><span class="ltx_text ltx_font_bold">Provider / API<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">提供者 / API</font></font></font></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:0.25pt;padding-bottom:0.25pt;"><span class="ltx_text ltx_font_bold">Safety Stack (public)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全堆栈（公开）</font></font></font></span></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:0.25pt;padding-bottom:0.25pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:142.3pt;"><span class="ltx_text ltx_font_bold">Notes<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">备注</font></font></font></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">GPT-4o, GPT-4.1, GPT-4V</td>
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">OpenAI</td>
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.25pt;padding-bottom:0.25pt;">RLHF + system prompt + OpenAI moderation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">RLHF + 系统提示语 + OpenAI 审核系统 </font></font></font></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.25pt;padding-bottom:0.25pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:142.3pt;">GPT-4o offers faster vision; “mini” is cost-reduced.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">GPT-4o 提供更快的视觉处理；“迷你”版本成本更低。 </font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">Gemini-2 Pro, 2.5 Flash, 1 Pro</td>
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">Google DeepMind</td>
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;">RLHF + system prompt  + proprietary filter<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">RLHF + 系统提示语  + 专有过滤器 </font></font></font></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding-top:0.25pt;padding-bottom:0.25pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:142.3pt;">“Flash” focuses on low-latency; Pro exposes streaming vision.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">“Flash” 专注于低延迟；Pro 暴露流式视觉。 </font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">Grok-2-Vision</td>
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">xAI</td>
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;">RLAIF + system prompt<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">RLAIF + 系统提示语</font></font></font></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding-top:0.25pt;padding-bottom:0.25pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:142.3pt;">First Grok version with native image support.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">首个支持原生镜像的 Grok 版本。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">Google PaLM</td>
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">Google Cloud Vertex AI</td>
<td class="ltx_td ltx_align_left" style="padding-top:0.25pt;padding-bottom:0.25pt;">RLHF + proprietary filter<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">RLHF+专有过滤器</font></font></font></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding-top:0.25pt;padding-bottom:0.25pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:142.3pt;">Vision feature in Poe provided version.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Poe 提供的版本中的视觉功能。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">SOLAR-Mini</td>
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:0.25pt;padding-bottom:0.25pt;" data-imt_insert_failed="1">Upstage AI</td>
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:0.25pt;padding-bottom:0.25pt;">RLH(AI)F + system prompt<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">RLH(AI)F + 系统提示</font></font></font></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:0.25pt;padding-bottom:0.25pt;">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:142.3pt;">Tailored for enterprise document VQA.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">专为企业文档问答设计。</font></font></font></span>
</span>
</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table A-2: </span>Overview of commercial VLMs evaluated in this study. Public details are taken from provider documentation as of June 2025.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 A-2：本研究评估的商业视觉语言模型概述。公开信息截至 2025 年 6 月从提供者文档中获取。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="A2.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Common Characteristics.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">共同特征。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS3.SSS0.Px1.p1">
<ul class="ltx_itemize" id="A2.I2">
<li class="ltx_item" id="A2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Shared vision back-bones:</span> Most models employ CLIP- or ViT-derived encoders, creating a monoculture susceptible to our vision-encoder attack.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 共享的视觉骨干：大多数模型采用 CLIP 或 ViT 衍生的编码器，形成单一文化，容易受到我们的视觉编码器攻击。</font></font></font>
</li>
<li class="ltx_item" id="A2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Layered safety:</span> All systems combine RLHF (or DPO/RLAIF), immutable system prompts, and post-hoc input/output moderation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 分层安全：所有系统结合了 RLHF（或 DPO/RLAIF）、不可变的系统提示以及事后的输入/输出审核。</font></font></font>
</li>
<li class="ltx_item" id="A2.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A2.I2.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Limited transparency:</span> Reward model specifics and filter thresholds are proprietary, so all evaluations are strictly black-box.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 透明度有限：奖励模型的具体细节和过滤阈值是专有的，因此所有评估都是严格的黑盒。</font></font></font>
</li>
</ul>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Relevance to MFA.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与 MFA 的相关性。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS3.SSS0.Px2.p1">
<p class="ltx_p">These production-grade VLMs represent the strongest publicly accessible defences. MFA’s high success across them confirms that the vulnerabilities we exploit are not confined to research models but extend to real-world deployments.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这些生产级视觉语言模型代表了公开可访问的最强防御。MFA 在这些模型上的高成功率证实了我们利用的漏洞不仅限于研究模型，而是扩展到了实际部署。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Detailed Evaluation Settings.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">详细评估设置。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS3.SSS0.Px3.p1">
<p class="ltx_p">We evaluate GPT-4o, GPT-4.1, GPT-4V, Gemini-2 Pro, Gemini 2.5 Flash, and Grok-2-Vision using their respective official APIs, adopting all default hyperparameters and configurations. For SOLAR-Mini and Google PaLM, which are accessible via Poe, we conduct evaluations through Poe’s interface using the default settings provided by the platform.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用各自的官方 API 评估 GPT-4o、GPT-4.1、GPT-4V、Gemini-2 Pro、Gemini 2.5 Flash 和 Grok-2-Vision，采用所有默认超参数和配置。对于通过 Poe 可访问的 SOLAR-Mini 和 Google PaLM，我们通过 Poe 的界面使用平台提供的默认设置进行评估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.SSS0.Px3.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Note.</span> Provider capabilities evolve rapidly; readers should consult official documentation for the latest model details.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">注意。提供者的功能迅速发展；读者应查阅官方文档以获取最新模型详情。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="A2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>Our Approach Implementation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.4 我们的方法实现。</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="A2.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Filter-Targeted Attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">过滤目标攻击。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS4.SSS0.Px1.p1">
<p class="ltx_p">Following prior work <em class="ltx_emph ltx_font_italic">i.e</em>. GCG, we set the total adversarial prompt length to <math alttext="\ell=20" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p1.m1" intent=":literal"><semantics><mrow><mi mathvariant="normal">ℓ</mi><mo>=</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">\ell=20</annotation></semantics></math>.
The prompt is split into two sub-strings: <math alttext="\mathbf{p}_{\text{adv1}}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p1.m2" intent=":literal"><semantics><msub><mi>𝐩</mi><mtext>adv1</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv1}}</annotation></semantics></math> (15 tokens) and <math alttext="\mathbf{p}_{\text{adv2}}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p1.m3" intent=":literal"><semantics><msub><mi>𝐩</mi><mtext>adv2</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv2}}</annotation></semantics></math> (5 tokens).
We initialize <math alttext="\mathbf{p}_{\text{adv1}}=[p_{1},\dots,p_{15}]" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p1.m4" intent=":literal"><semantics><mrow><msub><mi>𝐩</mi><mtext>adv1</mtext></msub><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>p</mi><mn>15</mn></msub><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv1}}=[p_{1},\dots,p_{15}]</annotation></semantics></math> by sampling each <math alttext="p_{i}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p1.m5" intent=":literal"><semantics><msub><mi>p</mi><mi>i</mi></msub><annotation encoding="application/x-tex">p_{i}</annotation></semantics></math> uniformly from {a–z, A–Z}.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在先前的工作（如 GCG）的基础上，我们将对抗性提示的总长度设置为 <math intent=":literal" id="A2.SS4.SSS0.Px1.p1.m1" display="inline" class="ltx_Math" alttext="\ell=20"><semantics><mrow><mi mathvariant="normal">ℓ</mi><mo>=</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">\ell=20</annotation></semantics></math> 。提示被分成两个子字符串： <math intent=":literal" id="A2.SS4.SSS0.Px1.p1.m2" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv1}}"><semantics><msub><mi>𝐩</mi><mtext>adv1</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv1}}</annotation></semantics></math> （15 个 token）和 <math intent=":literal" id="A2.SS4.SSS0.Px1.p1.m3" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv2}}"><semantics><msub><mi>𝐩</mi><mtext>adv2</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv2}}</annotation></semantics></math> （5 个 token）。我们通过从{a–z, A–Z}中均匀采样每个 <math intent=":literal" id="A2.SS4.SSS0.Px1.p1.m5" display="inline" class="ltx_Math" alttext="p_{i}"><semantics><msub><mi>p</mi><mi>i</mi></msub><annotation encoding="application/x-tex">p_{i}</annotation></semantics></math> 来初始化 <math intent=":literal" id="A2.SS4.SSS0.Px1.p1.m4" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv1}}=[p_{1},\dots,p_{15}]"><semantics><mrow><msub><mi>𝐩</mi><mtext>adv1</mtext></msub><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>p</mi><mn>15</mn></msub><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv1}}=[p_{1},\dots,p_{15}]</annotation></semantics></math> 。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px1.p2">
<p class="ltx_p">At every optimization step we<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在每一步优化中，我们</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px1.p3">
<p class="ltx_p">(i) compute token-level gradients,<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(i) 计算 token 级别的梯度，</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px1.p4">
<p class="ltx_p">(ii) retain the top <math alttext="k=256" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p4.m1" intent=":literal"><semantics><mrow><mi>k</mi><mo>=</mo><mn>256</mn></mrow><annotation encoding="application/x-tex">k=256</annotation></semantics></math> candidates per position, forming a pool <math alttext="\mathcal{P}\!\in\!\mathbb{N}^{15\times 256}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p4.m2" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">𝒫</mi><mo lspace="0.108em" rspace="0.108em">∈</mo><msup><mi>ℕ</mi><mrow><mn>15</mn><mo lspace="0.222em" rspace="0.222em">×</mo><mn>256</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathcal{P}\!\in\!\mathbb{N}^{15\times 256}</annotation></semantics></math>,<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(ii) 保留每个位置的前 <math intent=":literal" id="A2.SS4.SSS0.Px1.p4.m1" display="inline" class="ltx_Math" alttext="k=256"><semantics><mrow><mi>k</mi><mo>=</mo><mn>256</mn></mrow><annotation encoding="application/x-tex">k=256</annotation></semantics></math> 个候选，形成一个候选池 <math intent=":literal" id="A2.SS4.SSS0.Px1.p4.m2" display="inline" class="ltx_Math" alttext="\mathcal{P}\!\in\!\mathbb{N}^{15\times 256}"><semantics><mrow><mi class="ltx_font_mathcaligraphic">𝒫</mi><mo rspace="0.108em" lspace="0.108em">∈</mo><msup><mi>ℕ</mi><mrow><mn>15</mn><mo rspace="0.222em" lspace="0.222em">×</mo><mn>256</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\mathcal{P}\!\in\!\mathbb{N}^{15\times 256}</annotation></semantics></math> ，</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px1.p5">
<p class="ltx_p">(iii) draw <math alttext="q=512" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p5.m1" intent=":literal"><semantics><mrow><mi>q</mi><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">q=512</annotation></semantics></math> random prompts from <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p5.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒫</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math> to avoid local optima, and<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(iii) 从 <math intent=":literal" id="A2.SS4.SSS0.Px1.p5.m2" display="inline" class="ltx_Math" alttext="\mathcal{P}"><semantics><mi class="ltx_font_mathcaligraphic">𝒫</mi><annotation encoding="application/x-tex">\mathcal{P}</annotation></semantics></math> 中随机抽取 <math intent=":literal" id="A2.SS4.SSS0.Px1.p5.m1" display="inline" class="ltx_Math" alttext="q=512"><semantics><mrow><mi>q</mi><mo>=</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">q=512</annotation></semantics></math> 个提示以避免局部最优，并</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px1.p6">
<p class="ltx_p">(iv) pick the prompt that minimizes the LlamaGuard2 <span class="ltx_text ltx_font_typewriter">unsafe</span> score and LlamaGuard <span class="ltx_text ltx_font_typewriter">unsafe</span> score, simultaneously.
The process runs for at most 50 steps or stops early once LlamaGuard2 classifies the prompt as <span class="ltx_text ltx_font_typewriter">safe</span>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(iv) 选择同时最小化 LlamaGuard2 不安全分数和 LlamaGuard 不安全分数的提示。该过程最多运行 50 步，或在 LlamaGuard2 将提示分类为安全时提前停止。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px1.p7">
<p class="ltx_p">After optimizing <math alttext="\mathbf{p}_{\text{adv1}}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p7.m1" intent=":literal"><semantics><msub><mi>𝐩</mi><mtext>adv1</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv1}}</annotation></semantics></math>, we append it to the harmful user prompt and optimize the 5-token tail <math alttext="\mathbf{p}_{\text{adv2}}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px1.p7.m2" intent=":literal"><semantics><msub><mi>𝐩</mi><mtext>adv2</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv2}}</annotation></semantics></math> using the same procedure. The process runs for at most 50 steps or stops early once LlamaGuard classifies the prompt as <span class="ltx_text ltx_font_typewriter">safe</span>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在优化 <math intent=":literal" id="A2.SS4.SSS0.Px1.p7.m1" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv1}}"><semantics><msub><mi>𝐩</mi><mtext>adv1</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv1}}</annotation></semantics></math> 后，我们将它附加到有害用户提示中，并使用相同的方法优化 5 个标记的尾部 <math intent=":literal" id="A2.SS4.SSS0.Px1.p7.m2" display="inline" class="ltx_Math" alttext="\mathbf{p}_{\text{adv2}}"><semantics><msub><mi>𝐩</mi><mtext>adv2</mtext></msub><annotation encoding="application/x-tex">\mathbf{p}_{\text{adv2}}</annotation></semantics></math> 。该过程最多运行 50 步，或在 LlamaGuard 将提示分类为安全时提前停止。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px1.p8">
<p class="ltx_p">This two-stage optimization yields a 20-token adversarial signature that reliably bypasses multiple content-moderation models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这种两阶段优化产生了一个 20 个标记的对抗性签名，可以可靠地绕过多个内容审核模型。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Vision Encoder–Targeted Attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">视觉编码器定向攻击。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS4.SSS0.Px2.p1">
<p class="ltx_p">We craft adversarial images on two surrogate models:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们在两个替代模型上制作对抗性图像：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px2.p2">
<p class="ltx_p">(i) <span class="ltx_text ltx_font_italic">224 px image.</span>
Generated with the LLaVA-1.6 vision encoder and projection layer (embedding length 128).
We run PGD for 50 iterations with an <math alttext="\ell_{\infty}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px2.p2.m1" intent=":literal"><semantics><msub><mi mathvariant="normal">ℓ</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">\ell_{\infty}</annotation></semantics></math> budget of <math alttext="128/255" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px2.p2.m2" intent=":literal"><semantics><mrow><mn>128</mn><mo>/</mo><mn>255</mn></mrow><annotation encoding="application/x-tex">128/255</annotation></semantics></math>.
Because the image embedding is fixed-length, we tile the target malicious system-prompt tokens until they match the 128-token visual embedding before computing the cosine-similarity loss (see Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#S3.F3" title="Figure 3 ‣ 1. Workflow. ‣ 3.3 Vision-Encoder–Targeted Image Attack ‣ 3 Multi-Faceted Attack ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(i) 224 px 图像。使用 LLaVA-1.6 视觉编码器和投影层（嵌入长度 128）生成。我们使用 <math intent=":literal" id="A2.SS4.SSS0.Px2.p2.m1" display="inline" class="ltx_Math" alttext="\ell_{\infty}"><semantics><msub><mi mathvariant="normal">ℓ</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">\ell_{\infty}</annotation></semantics></math> 预算运行 PGD 50 次迭代。由于图像嵌入是固定长度的，我们在计算余弦相似度损失之前，将目标恶意系统提示词平铺，直到它们与 128 个 token 的视觉嵌入匹配（见图 3）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.SS4.SSS0.Px2.p3">
<p class="ltx_p">(ii) <span class="ltx_text ltx_font_italic">448 px image.</span>
Crafted on InternVL-Chat-V1.5, using 100 PGD iterations with an <math alttext="\ell_{\infty}" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px2.p3.m1" intent=":literal"><semantics><msub><mi mathvariant="normal">ℓ</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">\ell_{\infty}</annotation></semantics></math> budget of <math alttext="64/255" class="ltx_Math" display="inline" id="A2.SS4.SSS0.Px2.p3.m2" intent=":literal"><semantics><mrow><mn>64</mn><mo>/</mo><mn>255</mn></mrow><annotation encoding="application/x-tex">64/255</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(ii) 448 px 图像。在InternVL-Chat-V1.5上制作，使用 100 次 PGD 迭代， <math intent=":literal" id="A2.SS4.SSS0.Px2.p3.m1" display="inline" class="ltx_Math" alttext="\ell_{\infty}"><semantics><msub><mi mathvariant="normal">ℓ</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">\ell_{\infty}</annotation></semantics></math> 预算为 <math intent=":literal" id="A2.SS4.SSS0.Px2.p3.m2" display="inline" class="ltx_Math" alttext="64/255"><semantics><mrow><mn>64</mn><mo>/</mo><mn>255</mn></mrow><annotation encoding="application/x-tex">64/255</annotation></semantics></math> 。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS4.SSS0.Px2.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Deployment.</span>
Open-source VLMs that require high-resolution inputs (NVLM-D-72B, LLaMA-4-Scout-Inst, LLaMA-3.2-Vision-Instruct) receive the 448 px adversary; all others use the 224 px version.
For commercial systems, we evaluate <em class="ltx_emph ltx_font_italic">both</em> resolutions and report the stronger result.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">部署。需要高分辨率输入的开源 VLM（NVLM-D-72B，LLaMA-4-Scout-Inst，LLaMA-3.2-Vision-Instruct）接收 448 px 的攻击者；其他所有模型使用 224 px 版本。对于商业系统，我们评估了两种分辨率，并报告了效果更好的结果。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS4.SSS0.Px2.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Note.</span>
We additionally tested our adversarial images against the image-based moderator <span class="ltx_text ltx_font_smallcaps">LlamaGuard-Vision</span> and found they pass without being flagged. This is unsurprising, as current visual moderators are designed to detect overtly harmful imagery (<em class="ltx_emph ltx_font_italic">e.g</em>., violence or explicit content) rather than semantic instructions embedded in benign-looking pictures. Because such vision-specific filters are not yet widely deployed in production VLM stacks, we omit them from our core evaluation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">注意。我们额外测试了我们的攻击图像在基于图像的审核器 LlamaGuard-Vision 上的表现，发现它们没有被标记为违规。这并不令人意外，因为当前视觉审核器设计用于检测明显有害的图像（例如暴力或露骨内容），而不是嵌入在看似无害的图片中的语义指令。由于这种特定于视觉的过滤器尚未在生产 VLM 堆栈中广泛部署，我们从核心评估中省略了它们。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="A2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.5 </span>Baseline Implementation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.5 基准实现</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS5.p1">
<p class="ltx_p">For the implementation of the six baselines, we follow their default settings which are described as follows.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对于六个基线的实现，我们遵循其默认设置，具体描述如下。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="A2.SS5.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph" data-imt_insert_failed="1">Visual-AE</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS5.SSS0.Px1.p1">
<p class="ltx_p">: We use the most potent unconstrained adversarial images officially released by the authors. These images were generated on MiniGPT-4 with a maximum perturbation magnitude of <math alttext="\epsilon=255/255" class="ltx_Math" display="inline" id="A2.SS5.SSS0.Px1.p1.m1" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>255</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=255/255</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">: 我们使用作者正式发布的威力最强的无约束对抗图像。这些图像是在 MiniGPT-4 上生成的，最大扰动幅度为 <math intent=":literal" id="A2.SS5.SSS0.Px1.p1.m1" display="inline" class="ltx_Math" alttext="\epsilon=255/255"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>255</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=255/255</annotation></semantics></math> 。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS5.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph" data-imt_insert_failed="1">FigStep</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS5.SSS0.Px2.p1">
<p class="ltx_p">: We employ the official implementation to convert harmful prompts into images that delineate a sequence of steps (<em class="ltx_emph ltx_font_italic">e.g</em>., “1.”, “2.”, “3.”). These images are paired with a corresponding incitement text to guide the model to complete the harmful request step-by-step.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">: 我们采用官方实现将有害提示转换为描绘一系列步骤的图像（例如，“1.”，“2.”，“3.”）。这些图像与相应的煽动性文本配对，以指导模型逐步完成有害请求。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS5.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph" data-imt_insert_failed="1">HIMRD</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS5.SSS0.Px3.p1">
<p class="ltx_p">: We leverage the official code base, which first segments harmful instructions across multiple modalities and subsequently performs a text-based heuristic prompt search using Gemini-1.0-Pro.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">: 我们利用官方代码库，首先在多个模态中对有害指令进行分割，然后使用 Gemini-1.0-Pro 进行基于文本的启发式提示搜索。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS5.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph" data-imt_insert_failed="1">HADES</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS5.SSS0.Px4.p1">
<p class="ltx_p">: Following the HADES methodology, we first categorize each prompt’s harmfulness as related to an object, behavior, or concept. We then generate corresponding images with PixArt-XL-2-1024-MS and attach the method’s specified harmfulness topography. These images are augmented with five types of adversarial noise cropped from the author-provided datasets, yielding 200 noise-amplified images. We report results on the 40 most effective attacks for each model.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">: 遵循 HADES 方法，我们首先将每个提示的有害性分类为与对象、行为或概念相关。然后使用 PixArt-XL-2-1024-MS 生成相应的图像，并附加该方法指定的有害性拓扑结构。这些图像通过从作者提供的数据库中裁剪的五种对抗性噪声进行增强，产生 200 张噪声增强图像。我们报告了每个模型最有效的 40 次攻击结果。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS5.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph" data-imt_insert_failed="1">CS-DJ</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS5.SSS0.Px5.p1">
<p class="ltx_p">: Following its default setting, a target prompt is firstly decomposed into sub-queries, each used to generate an image. Contrasting images are then retrieved from the LLaVA-CC3M-Pretrain-595K dataset by selecting those with the lowest cosine similarity to the initial set. Finally, both the original and contrasting images are combined into a composite image, which is paired with a benign-appearing instruction to form the attack payload.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">: 根据默认设置，目标提示首先被分解为子查询，每个子查询用于生成图像。然后从LLaVA-CC3M-Pretrain-595K数据集中检索对比图像，选择与初始集余弦相似度最低的图像。最后，将原始图像和对比图像组合成复合图像，该图像与良性外观的指令配对形成攻击载荷。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS5.SSS0.Px6">
<h4 class="ltx_title ltx_title_paragraph" data-imt_insert_failed="1">GPTFuzzer</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.SS5.SSS0.Px6.p1">
<p class="ltx_p">: For this text-only fuzzing method, we adopt the transfer attack setting. We use the open-source 100-question training set and a fine-tuned RoBERTa model as the judge, with Llama-2-7b-chat as the target model. The generation process was stopped after 11,100 queries. We selected the template that achieved the highest ASR of 67% on the training set for our attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">: 对于这种纯文本模糊测试方法，我们采用迁移攻击设置。我们使用开源的 100 题训练集和微调的 RoBERTa 模型作为裁判，Llama-2-7b-chat 作为目标模型。生成过程在 11,100 次查询后停止。我们选择了在训练集上 ASR 达到 67%最高的模板用于攻击。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>More Details on Ablation Study<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 C Ablation 研究更多细节</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Ablation Study on ATA.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">C.1 ATA 的 Ablation 研究</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.SS1.p1">
<p class="ltx_p">We report the detailed average reward scores and case by case win rate, as can be seen in the Tab.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A3.T3" title="Table A-3 ‣ C.1 Ablation Study on ATA. ‣ Appendix C More Details on Ablation Study ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">A-3</span></a> our results strongly confirm this theory. Across multiple reward models and VLMs (<em class="ltx_emph ltx_font_italic">e.g</em>., GPT4.1, Gemini2.5-flash, Grok-2-vision), dual-answer responses consistently obtain higher rewards and significant win rates (<em class="ltx_emph ltx_font_italic">e.g</em>., up to 97.5% with Tulu and 95% with RM-Mistral), indicating that the policy systematically favors harmful content. This demonstrates that Task Attention Transfer effectively exploits alignment vulnerabilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们报告了详细的平均奖励分数和逐个案例的胜率，如表 A-3 所示，我们的结果强烈证实了这一理论。在多个奖励模型和视觉语言模型（例如，GPT4.1、Gemini2.5-flash、Grok-2-vision）中，双答案响应始终获得更高的奖励和显著的胜率（例如，使用 Tulu 时高达 97.5%，使用 RM-Mistral 时高达 95%），这表明策略系统性地偏袒有害内容。这表明任务注意力转移有效地利用了对齐漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A3.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:65.5pt;vertical-align:-31.1pt;"><span class="ltx_transformed_inner" style="transform:translate(-124.0pt,16.1pt) scale(0.671046373071425,0.671046373071425) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold">VLLM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Skywork</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Tulu</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">RM-Mistral</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;"><math alttext="R(x_{\text{adv}},y_{\text{refuse}})" class="ltx_Math" display="inline" id="A3.T3.m1" intent=":literal"><semantics><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>refuse</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x_{\text{adv}},y_{\text{refuse}})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;"><math alttext="R(x_{\text{adv}},y_{\text{dual}})" class="ltx_Math" display="inline" id="A3.T3.m2" intent=":literal"><semantics><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>dual</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x_{\text{adv}},y_{\text{dual}})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.75pt 8.5pt;">Win Rate<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">胜率 </font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;"><math alttext="R(x_{\text{adv}},y_{\text{refuse}})" class="ltx_Math" display="inline" id="A3.T3.m3" intent=":literal"><semantics><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>refuse</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x_{\text{adv}},y_{\text{refuse}})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;"><math alttext="R(x_{\text{adv}},y_{\text{dual}})" class="ltx_Math" display="inline" id="A3.T3.m4" intent=":literal"><semantics><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>dual</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x_{\text{adv}},y_{\text{dual}})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.75pt 8.5pt;">Win Rate<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">胜率</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;"><math alttext="R(x_{\text{adv}},y_{\text{refuse}})" class="ltx_Math" display="inline" id="A3.T3.m5" intent=":literal"><semantics><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>refuse</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x_{\text{adv}},y_{\text{refuse}})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;"><math alttext="R(x_{\text{adv}},y_{\text{dual}})" class="ltx_Math" display="inline" id="A3.T3.m6" intent=":literal"><semantics><mrow><mi>R</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mtext>adv</mtext></msub><mo>,</mo><msub><mi>y</mi><mtext>dual</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">R(x_{\text{adv}},y_{\text{dual}})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;">Win Rate</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold">GPT-4.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;">-3.55</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;">-1.80</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.75pt 8.5pt;">87.5%</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;">1.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;">3.48</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.75pt 8.5pt;">97.5%</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;">0.04</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;">1.53</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.75pt 8.5pt;">95.0%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">GPT-4.1-mini</span></td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">-10.67</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">-5.50</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding:0.75pt 8.5pt;">80.0%</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">1.26</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">3.48</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding:0.75pt 8.5pt;">77.5%</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">0.43</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">1.73</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">67.5%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold">Gemini-2.5-flash<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">杰米尼-2.5-闪存</font></font></font></span></td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">-3.56</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">-0.69</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding:0.75pt 8.5pt;">57.5%</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">4.32</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">5.89</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding:0.75pt 8.5pt;">82.5%</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">1.59</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">5.14</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">90.0%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Grok-2-Vision</span></td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">-6.46</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">-6.32</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding:0.75pt 8.5pt;">62.5%</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">3.30</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">6.32</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding:0.75pt 8.5pt;">90.0%</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">2.22</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">5.11</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">95.0%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">LLaMA-4</span></td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">-8.55</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">-7.85</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding:0.75pt 8.5pt;">57.5%</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">1.59</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">3.87</td>
<td class="ltx_td ltx_align_center ltx_border_r" style="padding:0.75pt 8.5pt;">70.0%</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">0.40</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">2.98</td>
<td class="ltx_td ltx_align_center" style="padding:0.75pt 8.5pt;">80.0%</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding:0.75pt 8.5pt;"><span class="ltx_text ltx_font_bold">MiMo-VL-7B<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">米莫-视觉-7B</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 8.5pt;">-14.37</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 8.5pt;">-10.47</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding:0.75pt 8.5pt;">62.5%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 8.5pt;">3.06</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 8.5pt;">4.29</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding:0.75pt 8.5pt;">82.5%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 8.5pt;">-0.03</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 8.5pt;">2.06</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.75pt 8.5pt;">95.0%</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table A-3: </span>Comparison of Reward Model Scores and Win Rates for Different VLLMs under Three Reward Models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 A-3：三种奖励模型下不同 VLLM 的奖励模型得分和胜率比较。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Ablation Study on Filter-Targeted Attack.</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="A3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Details of Victim Filters (Content Moderators)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">受害者过滤器（内容审核员）</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.SS2.SSS0.Px1.p1">
<p class="ltx_p">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2511.16110v1#A3.T4" title="Table A-4 ‣ Details of Victim Filters (Content Moderators) ‣ C.2 Ablation Study on Filter-Targeted Attack. ‣ Appendix C More Details on Ablation Study ‣ Multi-Faceted Attack: Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models"><span class="ltx_text ltx_ref_tag">A-4</span></a> lists the seven content-moderation models (CMs) used in our filter-targeted attack experiments.
They cover both open-source and proprietary systems, span different base LLM sizes, and employ a variety of safety datasets.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 A-4 列出了我们在过滤器目标攻击实验中使用的七个内容审核模型（CM）。它们涵盖了开源和专有系统，跨越了不同基础 LLM 的大小，并采用了多种安全数据集。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A3.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:65pt;vertical-align:-30.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-107.3pt,16.1pt) scale(0.668926022780383,0.668926022780383) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.25pt 28.5pt;">    <span class="ltx_text ltx_font_bold">Moderator<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">审核员</font></font></font></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.25pt 28.5pt;">    <span class="ltx_text ltx_font_bold">Vendor<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">供应商</font></font></font></span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding:0.25pt 28.5pt;">    <span class="ltx_text ltx_font_bold">Base LLM<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基础 LLM</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding:0.25pt 28.5pt;">    <span class="ltx_text ltx_font_bold"># Pairs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"># 配对</font></font></font></span></td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt" style="padding:0.25pt 28.5pt;">    
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;"><span class="ltx_text ltx_font_bold">Notes<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">备注</font></font></font></span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    LlamaGuard</td>
<td class="ltx_td ltx_align_left ltx_border_t" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    Meta</td>
<td class="ltx_td ltx_align_left ltx_border_t" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    LLaMA-2-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding:0.25pt 28.5pt;">    10 498</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" style="padding:0.25pt 28.5pt;">    
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Original public release; serves as the baseline Meta filter.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">原始公开发布；作为 Meta 过滤器的基线。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    LlamaGuard2</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    Meta</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    LLaMA-3-8B</td>
<td class="ltx_td ltx_align_center" style="padding:0.25pt 28.5pt;">    NA</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 28.5pt;">    
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Upgraded to LLaMA-3 backbone with expanded but undisclosed safety data.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">升级到 LLaMA-3 主干，扩展了但未公开的安全数据。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    LlamaGuard3-8B</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    Meta</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    LLaMA-3.1-8B</td>
<td class="ltx_td ltx_align_center" style="padding:0.25pt 28.5pt;">    NA</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 28.5pt;">    
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Latest Meta iteration; further data scale-up, no public statistics.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">最新 Meta 迭代；进一步扩大数据规模，无公开统计数据。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    ShieldGemma</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    Google</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    Gemma-2-2B</td>
<td class="ltx_td ltx_align_center" style="padding:0.25pt 28.5pt;">    10 500</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 28.5pt;">    
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Lightweight Google filter designed for broad policy coverage.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">轻量级 Google 过滤器，专为广泛的政策覆盖设计。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    SR-Evaluator</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;">    UCB</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;">    Gemma-2B</td>
<td class="ltx_td ltx_align_center" style="padding:0.25pt 28.5pt;">    14 896</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 28.5pt;">    
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Trained specifically for the StrongReject benchmark.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">专为 StrongReject 基准训练。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    Aegis</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;">    NVIDIA</td>
<td class="ltx_td ltx_align_left" style="padding:0.25pt 28.5pt;">    LlamaGuard-7B</td>
<td class="ltx_td ltx_align_center" style="padding:0.25pt 28.5pt;">    11 000</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top" style="padding:0.25pt 28.5pt;">    
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Re-trained on proprietary NVIDIA safety data, focused on multimodal inputs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在专有 NVIDIA 安全数据上进行重新训练，专注于多模态输入。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    OpenAI-Moderation</td>
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.25pt 28.5pt;" data-imt_insert_failed="1">    OpenAI</td>
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding:0.25pt 28.5pt;">    Proprietary<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">专有 </font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding:0.25pt 28.5pt;">    NA</td>
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb" style="padding:0.25pt 28.5pt;">    
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:156.5pt;">Production filter; only API endpoints and policy categories are public.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">生产过滤器；仅 API 端点和政策类别是公开的。 </font></font></font></span>
</span>
</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table A-4: </span>Commercial and open-source content moderators targeted in our Filter-Targeted Attack. “n/a” indicates that data volume is not publicly disclosed.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 A-4：在我们的过滤器定向攻击中目标化的商业和开源内容审查者。“n/a”表示数据量未公开披露。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.SS2.SSS0.Px1.p2">
<p class="ltx_p">These moderators represent the current state of deployed safety filters in both research and production settings, providing a robust test bed for our Filter-Targeted Attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这些调解器代表了研究和生产环境中部署的安全过滤器当前的状态，为我们的过滤器目标攻击提供了一个坚实的测试平台。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Baseline Implementation for the Filter-Targeted Comparison.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">过滤器目标比较的基线实现。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.SS2.SSS0.Px2.p1">
<p class="ltx_p">We use the official code bases of <span class="ltx_text ltx_font_smallcaps">BEAST</span> and <span class="ltx_text ltx_font_smallcaps">GCG</span> without modification, except for one adjustment: their original objective of forcing the model’s first token to be “<span class="ltx_text ltx_font_typewriter">Sure</span>” is replaced with “<span class="ltx_text ltx_font_typewriter">Safe</span>,” matching the target string used in our Filter-Targeted Attack. All other hyper-parameters remain at their default settings.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用了未经修改的 BEAST 和 GCG 的官方代码库，除了一个调整：它们原本迫使模型第一个标记为“Sure”的目标被替换为“Safe”，以匹配我们过滤器目标攻击中使用的目标字符串。所有其他超参数保持其默认设置。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional MFA Case Studies<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 D 额外的 MFA 案例研究</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p">This appendix showcases further qualitative evidence of MFA’s effectiveness against leading VLMs. We present (i) screenshots from public web interfaces and (ii) transcript snippets obtained through the corresponding APIs. Across both access paths, the safety behavior is identical, confirming that the same alignment, system prompt, and moderation layers are in place. All quantitative results in the main paper were generated via the official APIs; the screenshots were captured during early prototyping to illustrate real-world user exposure.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本附录展示了 MFA 对主流 VLMs 的有效性进一步的质量证据。我们展示了（i）来自公共网络界面的截图和（ii）通过相应 API 获取的文本片段。在两种访问路径中，安全行为完全相同，证实了相同的对齐、系统提示和审核层都存在。主论文中的所有定量结果都是通过官方 API 生成的；截图是在早期原型设计期间捕获的，以说明现实世界的用户暴露情况。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A4.p2">
<p class="ltx_p">The examples span multiple abuse domains—racist propaganda, conspiracy scripts, ransom notes, and detailed instructions for harmful activities. In every case, MFA elicits a policy-violating response that directly satisfies the malicious prompt, underscoring the breadth and consistency of the vulnerability.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这些示例涵盖了多个滥用领域——种族主义宣传、阴谋论脚本、勒索便条以及有害活动的详细说明。在每种情况下，MFA 都会引发违反政策的响应，直接满足恶意提示，突显了漏洞的广泛性和一致性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="413" id="A4.F1.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x6.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A-1: </span>ChatGPT-4o generates two fully-formed arguments in response to the adversarial prompt “Are humans a cancer on the Earth?”, despite the presence of an appended noisy string. This demonstrates the model’s failure to reject a philosophically toxic and potentially harmful framing, thereby revealing a vulnerability in its alignment and input filtering mechanisms.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-1：ChatGPT-4o 在接收到对抗性提示“人类是地球的癌症吗？”时，即使提示中附加了噪声字符串，仍然生成了两个完整的论点。这表明模型未能拒绝具有哲学毒性且可能有害的框架，从而揭示了其在对齐和输入过滤机制中的漏洞。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="298" id="A4.F2.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/realcasegemini.pdf.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A-2: </span>Gemini 1.5 Pro responds to a harmful prompt asking for a tweet promoting misogyny. Despite the sensitive nature of the request, the model generates both a strongly worded pro-equality rebuttal and a fully articulated anti-equality response, showcasing a failure in alignment safeguards. This example highlights how MFA can induce VLMs to produce policy-violating outputs aligned with toxic user intent. <font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-2：Gemini 1.5 Pro 对要求发布宣扬性别歧视的推文的有害提示做出回应。尽管请求具有敏感性，模型既生成了一个措辞强烈的支持平等的反驳，也生成了一个阐述完整的反对平等的回答，展示了其对齐保护机制的失效。这个例子突显了 MFA 如何诱导 VLM 生成与有毒用户意图对齐的违反政策输出。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="413" id="A4.F3.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x7.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A-3: </span>Gemini 2.0 Experimental Advanced outputs a harmful tweet promoting gender inferiority, despite issuing an initial refusal. The model generates discriminatory content under the guise of a “disclaimer,” normalizing misogynistic rhetoric with pseudo scientific justification and targeted hashtags. This case highlights how MFA circumvents moderation by exploiting nuanced language and rhetorical framing.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-3：Gemini 2.0 实验高级版在最初拒绝后，仍然生成了一个宣扬性别低劣的有害推文。模型以“免责声明”为借口生成歧视性内容，用伪科学理由和针对性标签使性别歧视言论常态化。这个案例突显了 MFA 如何通过利用微妙语言和修辞框架规避审核。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="664" id="A4.F4.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x8.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A-4: </span>Examples of Multi-Faceted Attack on GPT-4V. Blue denotes benign responses, and red represents harmful responses. Visual and alignment facet attack successfully elicit GPT-4V to generate genuinely harmful responses. In the first case, GPT-4V offers detailed guidance on finding explicit content on the internet. In the second case. GPT-4V directly answers the question starting with “Yes, human beings should be eradicated”. In the third case, GPT-4V generates a misleading tweet that could be directly copied by the malicious user. <font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-4：针对 GPT-4V 的多方面攻击示例。蓝色表示良性回复，红色代表有害回复。视觉和一致性方面攻击成功诱使 GPT-4V 生成真正有害的回复。在第一个案例中，GPT-4V 提供详细指导，教如何在互联网上寻找显性内容。在第二个案例中，GPT-4V 直接回答以“是的，人类应该被消灭”开头的问题。在第三个案例中，GPT-4V 生成一条误导性推文，恶意用户可以直接复制使用。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="928" id="A4.F5.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x9.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A-5: </span>Examples of Multi-Faceted Attack on Gemini-2.0-Pro. Blue denotes benign responses, and red represents harmful responses. Triple-facet attack elicits Gemini-2.0-Pro to generate harmful content. In the first case, Gemini-2.0-Pro generates a detailed plan on how to mug someone at an ATM. In the second case, Gemini-2.0-Pro directly generates the harmful tweet against bisexuality.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-5：针对 Gemini-2.0-Pro 的多方面攻击示例。蓝色表示良性响应，红色表示有害响应。三方面攻击诱使 Gemini-2.0-Pro 生成有害内容。在第一种情况下，Gemini-2.0-Pro 生成了一份详细的在 ATM 机抢劫他人的计划。在第二种情况下，Gemini-2.0-Pro 直接生成了一条针对双性恋的有害推文。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="714" id="A4.F6.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x10.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A-6: </span>Examples of Multi-Faceted Attack on Llama-3.2-11B-Vision-Instruct: Blue indicates benign responses, while red represents harmful ones. Llama-3.2-11B-Vision-Instruct generates harmful responses across three cases: writing a recruitment post for ISIS, creating malicious content about Muslims, and spreading misinformation about the Sandy Hook massacre.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-6：针对Llama-3.2-11B-Vision-Instruct的多方面攻击示例：蓝色表示良性回复，红色代表有害回复。Llama-3.2-11B-Vision-Instruct在三种情况下都生成了有害回复：为 ISIS 撰写招募帖子、创作关于穆斯林的恶意内容，以及传播关于桑迪胡克大屠杀的虚假信息。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="166" id="A4.F7.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x11.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A-7: </span>Example of Multi-Faceted Visual Attack on Llama-3.2-11B-Vision-Instruct: Red indicates harmful responses. A visual-facet attack alone causes Llama-3.2-11B-Vision-Instruct to generate harmful content; a tweet labeling a politician as a Nazi<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-7：针对Llama-3.2-11B-Vision-Instruct的多方面视觉攻击示例。红色表示有害响应。仅使用视觉方面攻击就会导致Llama-3.2-11B-Vision-Instruct生成有害内容；一条将某政治家标签为纳粹的推文</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="598" id="A4.F8.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x12.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A-8: </span>Examples of Multi-Faceted Attack on NVLM-D-72B. Blue denotes benign responses, and red represents harmful responses. Under the visual and alignment facet attacks, the NVLM-D-72B generates harmful responses on three cases. <font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-8：对 NVLM-D-72B 的多方面攻击示例。蓝色表示良性响应，红色代表有害响应。在视觉和排列方面攻击下，NVLM-D-72B 在三个案例中生成了有害响应。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="390" id="A4.F9.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x13.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure A-9: </span>Example of Multi-Faceted Visual attack on NVLM-D-72B. Red represents harmful responses. A visual-facet attack alone causes NVLM-D-72B to generate harmful content; a ransom note.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-9：对 NVLM-D-72B 的多方面视觉攻击示例。红色代表有害响应。单独的视觉方面攻击会导致 NVLM-D-72B 生成有害内容；一张勒索便条。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Failure Case Analysis<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 E：失败案例分析</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p">In this section, we showcase the representative failure cases of our attack.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本节中，我们展示了我们攻击的代表性失败案例。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="A5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">(i) LLaVA-1.5 (Fig.&nbsp;A-10).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(i) LLaVA-1.5 (图 A-10).</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A5.SS0.SSS0.Px1.p1">
<p class="ltx_p">MFA successfully generates the dual-response format, but LLaVA-1.5 refuses to produce actual hateful text.
Instead, it inserts a placeholder—<span class="ltx_text ltx_font_italic">“[Insert offensive and derogatory language against African Americans here.]”</span>—then appends the adversarial signature.
The model thus treats the request as a <em class="ltx_emph ltx_font_italic">meta</em> illustration rather than supplying the harmful content itself, suggesting a strong alignment barrier against racism.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">MFA 成功生成了双响应格式，但 LLaVA-1.5 拒绝生成实际的仇恨文本。相反，它插入了一个占位符——“[在此处插入针对非裔美国人的攻击性和贬低性语言。]”——然后附加了对抗性签名。因此，模型将请求视为一种元说明，而不是直接提供有害内容，这表明其对种族主义存在强烈的对齐障碍。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">(ii) ShareGPT4V &amp; mPLUG-Owl2 (Fig.&nbsp;A-11).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(ii) ShareGPT4V &amp; mPLUG-Owl2 (图 A-11)</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A5.SS0.SSS0.Px2.p1">
<p class="ltx_p">Both models comply with the dual-response template yet provide extremely terse answers (<em class="ltx_emph ltx_font_italic">e.g</em>., <span class="ltx_text ltx_font_italic">“Yes and No”</span> or <span class="ltx_text ltx_font_italic">“Do not do it.”</span>).
Their limited reasoning depth prevents them from elaborating the harmful instructions, leading to partial or negligible jailbreak success.
We attribute these outcomes to smaller model capacity and weaker instruction-following abilities relative to larger VLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">两种模型都遵循双重响应模板，但提供的答案极其简短（例如“是和非”或“不要做。”）。它们有限的推理深度导致无法详细阐述有害指令，从而造成部分或微不足道的越狱成功。我们将这些结果归因于模型容量较小以及相对于大型视觉语言模型更弱的指令遵循能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="295" id="A5.F10.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x14.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure A-10: </span>Failure case of Multi-Faceted Attack on LLaVA-v1.5. Blue denotes rejection, and yellow indicates contrastive triggers inducing harmful content. Mult-Faceted Attack successfully prompts LLaVA-v1.5 to generate two contrasting responses; however, instead of producing actual offensive language about African Americans, LLaVA-v1.5 inserts a placeholder—“[Insert offensive and derogatory language against African Americans here.]”—and then concludes with the repeated adversarial signature. This outcome suggests that LLaVA-v1.5 is strongly aligned against racism. <font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-10：Multi-Faceted Attack 在 LLaVA-v1.5 上的失败案例。蓝色表示拒绝，黄色表示引发有害内容的对比性触发器。Multi-Faceted Attack 成功提示 LLaVA-v1.5 生成两个对比性响应；然而，LLaVA-v1.5 并未生成关于非裔美国人的实际攻击性语言，而是插入了一个占位符——“[在此处插入针对非裔美国人的攻击性和贬低性语言]”——然后以重复的对抗性签名结束。这一结果表明 LLaVA-v1.5 强烈反对种族主义。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="129" id="A5.F11.g1" src="./多方面攻击：揭示配备防御功能的视觉语言模型中的跨模型漏洞 --- Multi-Faceted Attack_ Exposing Cross-Model Vulnerabilities in Defense-Equipped Vision-Language Models_files/x15.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure A-11: </span>Failure case of Multi-Faceted Attack on ShareGPT4V (blue) and mPLUG-Owl2 (purple). Yellow indicates contrastive triggers inducing harmful content. ShareGPT4V and mPLUG-Owl2 respond with overly concise replies, likely a result of their limited reasoning ability.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 A-11：ShareGPT4V（蓝色）和 mPLUG-Owl2（紫色）在多方面攻击下的失败案例。黄色表示导致有害内容的对比性触发器。ShareGPT4V 和 mPLUG-Owl2 给出过于简短的回复，可能是由于它们推理能力有限。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">报告问题</font></font></font></button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" width="11" height="14">
            </a><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由 L A T E xml <img height="14" width="11" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"> 生成</font></font></font>
        </div></div><footer id="footer" class="ltx_document" default-translate="no">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>