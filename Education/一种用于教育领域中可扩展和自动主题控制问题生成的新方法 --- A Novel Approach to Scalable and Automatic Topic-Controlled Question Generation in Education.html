<!DOCTYPE html>
<!-- saved from url=(0071)https://arxiv.org/html/2501.05220?_immersive_translate_auto_translate=1 -->
<html lang="en" data-theme="dark" imt-state="dual" imt-trans-position="after"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education</title>
<!--Generated on Thu Jan  9 13:07:42 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/bootstrap.bundle.min.js"></script>
<script src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/html2canvas.min.js"></script>
<script src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/addons_new.js"></script>
<script src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/feedbackOverlay.js"></script>
<meta content="Educational Question Generation,  Formative Assessment,  Summative Assessment,  Personalised Testing,  Natural Language Processing" lang="en" name="keywords">
<!--<base href="/html/2501.05220v1/">--><base href="."><link rel="stylesheet" href="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-modal {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style><style data-id="immersive-translate-default-injected-css">:root {
  --immersive-translate-theme-underline-borderColor: #72ece9;
  --immersive-translate-theme-nativeUnderline-borderColor: #72ece9;
  --immersive-translate-theme-nativeDashed-borderColor: #72ece9;
  --immersive-translate-theme-nativeDotted-borderColor: #72ece9;
  --immersive-translate-theme-highlight-backgroundColor: #ffff00;
  --immersive-translate-theme-dashed-borderColor: #59c1bd;
  --immersive-translate-theme-blockquote-borderColor: #cc3355;
  --immersive-translate-theme-thinDashed-borderColor: #ff374f;
  --immersive-translate-theme-dashedBorder-borderColor: #94a3b8;
  --immersive-translate-theme-dashedBorder-borderRadius: 0;
  --immersive-translate-theme-solidBorder-borderColor: #94a3b8;
  --immersive-translate-theme-solidBorder-borderRadius: 0;
  --immersive-translate-theme-dotted-borderColor: #94a3b8;
  --immersive-translate-theme-wavy-borderColor: #72ece9;
  --immersive-translate-theme-dividingLine-borderColor: #94a3b8;
  --immersive-translate-theme-grey-textColor: #2f4f4f;
  --immersive-translate-theme-marker-backgroundColor: #fbda41;
  --immersive-translate-theme-marker-backgroundColor-rgb: 251, 218, 65;
  --immersive-translate-theme-marker2-backgroundColor: #ffff00;
  --immersive-translate-theme-background-backgroundColor: #dbafaf;
  --immersive-translate-theme-background-backgroundColor-rgb: 219, 175, 175;
  --immersive-translate-theme-background-backgroundOpacity: 12;
  --immersive-translate-theme-opacity-opacity: 10;
}

[imt-state="dual"] .immersive-translate-target-translation-pre-whitespace {
  white-space: pre-wrap !important;
}

[imt-state="dual"] .immersive-translate-pdf-target-container {
  position: absolute;
  background-color: #fff;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica,
    sans-serif;
  top: 0;
  width: 600px;
  height: 100%;
  z-index: 2;
  line-height: 1.3;
  font-size: 16px;
}
[imt-state="dual"] .immersive-translate-target-wrapper[dir="rtl"] {
  text-align: right;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper {
  color: rgb(0, 0, 0);
  white-space: normal;
  position: absolute;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper
  font {
  color: inherit;
  white-space: inherit;
  position: unset;
}

[imt-state="translation"] .immersive-translate-target-wrapper > br {
  display: none;
}

[imt-state="translation"]
  .immersive-translate-target-translation-block-wrapper {
  margin: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-block-wrapper {
  margin: 8px 0 !important;
  display: inline-block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  display: block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  margin-top: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-pdf-block-wrapper {
  margin: 0 !important;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-grey-inner {
  color: var(--immersive-translate-theme-grey-textColor);
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-underline-inner {
  border-bottom: 1px solid
    var(--immersive-translate-theme-underline-borderColor) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeUnderline-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeUnderline-borderColor
  ) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDashed-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDashed-borderColor
  ) !important;
  text-decoration-style: dashed !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-thinDashed-inner {
  border-bottom: 1px dashed
    var(--immersive-translate-theme-thinDashed-borderColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dotted-inner {
  background-image: linear-gradient(
    to right,
    var(--immersive-translate-theme-dotted-borderColor) 30%,
    rgba(255, 255, 255, 0) 0%
  );
  background-position: bottom;
  background-size: 5px 1px;
  background-repeat: repeat-x;
  padding-bottom: 3px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDotted-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDotted-borderColor
  ) !important;
  text-decoration-style: dotted !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-wavy-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-wavy-borderColor
  ) !important;
  text-decoration-style: wavy !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dashed-inner {
  background: linear-gradient(
      to right,
      var(--immersive-translate-theme-dashed-borderColor) 0%,
      var(--immersive-translate-theme-dashed-borderColor) 50%,
      transparent 50%,
      transparent 100%
    )
    repeat-x left bottom;
  background-size: 8px 2px;
  padding-bottom: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {
  content: "";
  display: block;
  max-width: 80px;
  width: 10%;
  border-top: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  padding-top: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dividingLine::before {
  content: "";
  border-left: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  max-height: 16px;
  height: 16px;
  padding-left: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-highlight-inner {
  background: var(--immersive-translate-theme-highlight-backgroundColor);
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-marker {
  line-height: 1.5em;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker2-inner {
  font-weight: bold;
  text-shadow: 10px 0px 3px
      var(--immersive-translate-theme-marker2-backgroundColor),
    16px 3px 9px var(--immersive-translate-theme-marker2-backgroundColor),
    2px 0px 6px var(--immersive-translate-theme-marker2-backgroundColor),
    -12px 0px 12px var(--immersive-translate-theme-marker2-backgroundColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker-inner {
  /* TODO: add more texture */
  background: linear-gradient(
    to right,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.1),
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 3%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 35%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 70%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.8) 95%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.3)
  );
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-weakening {
  opacity: 0.618 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-italic {
  font-style: italic !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-bold {
  font-weight: bold !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-paper {
  margin: 8px 0;
  box-shadow: rgba(0, 0, 0, 0.24) 0px 3px 8px;
  padding: 16px 32px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-blockquote {
  border-left: 4px solid var(--immersive-translate-theme-blockquote-borderColor) !important;
  padding-left: 12px !important;
  margin-top: 4px;
  margin-bottom: 4px;
  padding-top: 4px;
  padding-bottom: 4px;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-mask-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-mask-inner {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

/* opacity theme start */

[imt-state="dual"] .immersive-translate-target-translation-theme-opacity-inner {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-opacity-inner {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner,
[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: none !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-mask-inner:hover {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

/* opacity theme end */

/* background theme start */
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-background {
  margin: 8px 0;
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  border-radius: 4px;
  box-shadow: unset !important;
  padding: 12px;
  display: inline-block;
}
[imt-state="dual"]
  .immersive-translate-target-translation-theme-background-inner {
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  padding-left: 6px;
  padding-right: 6px;
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper
  .immersive-translate-target-translation-theme-background-inner {
  background: unset;
  padding-left: unset;
  padding-right: unset;
}
/* background theme end */

/* vertical css , please remain it in the last one. */
.immersive-translate-target-translation-vertical-block-wrapper {
  margin: 0px 8px !important;
}

.immersive-translate-text {
  font-size: 15px !important;
}

.immersive-translate-error-toast {
  position: fixed;
  top: 5%;
  z-index: 99999999;
  left: 0;
  right: 0;
  margin: auto;
  max-width: 300px;
  padding: 16px;
  border-radius: 12px;
  background-color: rgba(0, 0, 0, 0.8);
  display: flex;
  flex-direction: row;
  justify-content: space-between;
}

@media all and (min-width: 750px) {
  .immersive-translate-error-toast {
    max-width: 400px;
  }
}

.immersive-translate-clickable-button {
  cursor: pointer;
}

.immersive-translate-help-button {
  cursor: pointer;
}

.immersive-translate-loading-text:before {
  content: "...";
}

/* dark mode for loading */

@media only screen and (prefers-color-scheme: dark) {
  .immersive-translate-loading {
    border: 2px rgba(255, 255, 255, 0.25) solid !important;
    border-top: 2px rgba(255, 255, 255, 1) solid !important;
  }
}

.immersive-translate-error-wrapper {
  position: relative;
  display: inline-flex;
  padding: 6px;
  margin: 0 12px;
  white-space: nowrap;
  font-size: 0.9em;
}
[lang="zh-CN"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}
[lang="zh-TW"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}

.immersive-translate-tooltip {
  position: relative;
  display: inline-flex;
  /* little indicater to indicate it's hoverable */
}

.immersive-translate-tooltip-content {
  /* here's the magic */
  position: absolute;
  z-index: 100000000000;

  left: 50%;
  bottom: 0;
  transform: translate(-50%, 110%);
  line-height: 1;
  /* and add a small left margin */

  /* basic styles */
  width: max-content;
  max-width: 250px;
  word-wrap: break-word;
  white-space: pre-line;
  padding: 10px;
  border-radius: 10px;
  background: #000c;
  color: #fff;
  text-align: center;
  font-size: 14px;
  display: none;
  /* hide by default */
}

.immersive-translate-tooltip:hover .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip:hover + .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip-content-table {
  left: unset !important;
  bottom: unset !important;
  transform: translate(-10%, 50%) !important;
}

.immersive-translate-tooltip:hover:before {
  display: inline-block;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5);
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--bg-2, #fff);
  font-size: 14px;
}
</style><style data-id="immersive-translate-user-custom-style">:root {

.immersive-translate-target-inner { font-family: inherit; }


.immersive-translate-target-inner { font-family: inherit; }
}
</style><style data-id="immersive-translate-dynamic-injected-css">.immersive-translate-target-wrapper[dir='rtl'] {text-align: right;display:block!important;}
[dir='rtl'] .immersive-translate-target-wrapper:not([dir]) {text-align:left;direction:ltr;}
.immersive-translate-target-wrapper {word-break:break-word; user-select:text;}
[imt-state=dual] .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {display:block;}
[imt-trans-position=before] .immersive-translate-target-translation-block-wrapper {display:block!important;}
</style></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2501.05220?_immersive_translate_auto_translate=1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2501.05220v1/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2501.05220v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2501.05220v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2501.05220?_immersive_translate_auto_translate=1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S1" title="In A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S2" title="In A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Problem Definition, Background Research, and Research Questions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S2.SS1" title="In 2. Problem Definition, Background Research, and Research Questions ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Problem Definition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S2.SS2" title="In 2. Problem Definition, Background Research, and Research Questions ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S2.SS3" title="In 2. Problem Definition, Background Research, and Research Questions ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Research Questions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3" title="In A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS1" title="In 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Datasets Utilised</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2" title="In 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Creating Novel Datasets for T-CQG</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS1" title="In 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Linking the target topic to data points, SQuAD+ dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS2" title="In 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>MixSQuAD dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS3" title="In 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>MixSQuAD2X dataset</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3" title="In 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Developing T-CQG Models for Education</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3.SSS1" title="In 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Baseline Model to Answer RQ2</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3.SSS2" title="In 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>TopicQG to Answer RQ2</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3.SSS3" title="In 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.3 </span>TopicQGedu to Answer RQ3</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3.SSS4" title="In 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.4 </span>Quantised TopicQG Models to Answer RQ4</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3.SSS5" title="In 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.5 </span>TopicQG2X to Answer RQ5</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3.SSS6" title="In 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.6 </span>Example Questions Generated with Models for the Experiments</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS4" title="In 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Human Annotation-based Evaluation of Semantic Relatedness Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS5" title="In 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Experimental Setup for Automated Performance Evaluations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS6" title="In 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6 </span>Evaluation Metrics</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS6.SSS1" title="In 3.6. Evaluation Metrics ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.1 </span>Evaluating the quality of generations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS6.SSS2" title="In 3.6. Evaluation Metrics ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.2 </span>Semantic relatedness between the questions generated and the topic</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS6.SSS2.Px1" title="In 3.6.2. Semantic relatedness between the questions generated and the topic ‣ 3.6. Evaluation Metrics ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title">BERTScore</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS6.SSS2.Px2" title="In 3.6.2. Semantic relatedness between the questions generated and the topic ‣ 3.6. Evaluation Metrics ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title">WikiSemRel</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4" title="In A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.SS1" title="In 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Most Representative Automated Topic Relevance Metric to Human Evaluations (RQ1)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.SS2" title="In 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Topical Relevance and the Effect of Pre-training on Generated Questions (RQ 2 and RQ 3)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.SS3" title="In 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Impact of Model Quantisation (RQ4) and Data Augmentation (RQ5)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S5" title="In A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S5.SS1" title="In 5. Discussion ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Implications of the Results for Research and Practice</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S6" title="In A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2501.05220?_immersive_translate_auto_translate=1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">许可证：CC BY 4.0</font></font></font></a><div id="watermark-tr" data-imt_insert_failed="1">arXiv:2501.05220v1 [cs.CY] 09 Jan 2025</div></div>
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">一种用于教育领域的可扩展和自动主题控制问题生成的新方法</font></font></font></h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ziqing Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Department of Computer Science, University College London</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">London</span><span class="ltx_text ltx_affiliation_country" id="id3.3.id3">United Kingdom</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:ziqing.li.19@ucl.ac.uk">ziqing.li.19@ucl.ac.uk</a>
</span></span></span>
<span class="ltx_author_before">,&nbsp;</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mutlu Cukurova
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">UCL Knowledge Lab, University College London</span><span class="ltx_text ltx_affiliation_city" id="id5.2.id2">London</span><span class="ltx_text ltx_affiliation_country" id="id6.3.id3">United Kingdom</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:m.cukurova@ucl.ac.uk">m.cukurova@ucl.ac.uk</a>
</span></span></span>
<span class="ltx_author_before">&nbsp;and&nbsp;</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sahan Bulathwela
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">Centre for Artificial Intelligence, University College London</span><span class="ltx_text ltx_affiliation_city" id="id8.2.id2">London</span><span class="ltx_text ltx_affiliation_country" id="id9.3.id3">United Kingdom</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:m.bulathwela@ucl.ac.uk">m.bulathwela@ucl.ac.uk</a>
</span></span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_dates">(2025; Not Available; Not Available; Not Available)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(2025 年；不可用；不可用；不可用)</font></font></font></div>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">摘要。</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id10.id1">The development of Automatic Question Generation (QG) models has the potential to significantly improve educational practices by reducing the teacher workload associated with creating educational content. This paper introduces a novel approach to educational question generation that controls the topical focus of questions. The proposed Topic-Controlled Question Generation (T-CQG) method enhances the relevance and effectiveness of the generated content for educational purposes. Our approach uses fine-tuning on a pre-trained T5-small model, employing specially created datasets tailored to educational needs. The research further explores the impacts of pre-training strategies, quantisation, and data augmentation on the model’s performance. We specifically address the challenge of generating semantically aligned questions with paragraph-level contexts, thereby improving the topic specificity of the generated questions. In addition, we introduce and explore novel evaluation methods to assess the topical relatedness of the generated questions. Our results, validated through rigorous offline and human-backed evaluations, demonstrate that the proposed models effectively generate high-quality, topic-focused questions. These models have the potential to reduce teacher workload and support personalised tutoring systems by serving as bespoke question generators. With its relatively small number of parameters, the proposals not only advance the capabilities of question generation models for handling specific educational topics but also offer a scalable solution that reduces infrastructure costs. This scalability makes them feasible for widespread use in education without reliance on proprietary large language models like ChatGPT.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">自动问题生成（QG）模型的发展有潜力通过减少教师创建教育内容的工作量来显著改善教育实践。本文介绍了一种控制问题主题焦点的教育问题生成新方法。所提出的主题控制问题生成（T-CQG）方法增强了生成内容的教育相关性和有效性。我们的方法基于预训练的 T5-small 模型进行微调，采用专门为教育需求创建的数据集。研究进一步探讨了预训练策略、量化和数据增强对模型性能的影响。我们特别解决了在段落级上下文中生成语义一致的问题的挑战，从而提高了生成问题的主题特异性。此外，我们引入并探索了新的评估方法来评估生成问题的主题相关性。 我们的结果通过严格的离线评估和人工审核验证，证明所提出的模型能够有效生成高质量、主题聚焦的问题。这些模型有潜力减轻教师工作负担，并通过作为定制化问题生成器来支持个性化辅导系统。凭借其相对较少的参数数量，该提案不仅提升了问题生成模型处理特定教育主题的能力，还提供了一种可扩展的解决方案，从而降低了基础设施成本。这种可扩展性使得它们在教育领域广泛使用成为可能，而无需依赖 ChatGPT 等专有大型语言模型。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_keywords">Educational Question Generation, Formative Assessment, Summative Assessment, Personalised Testing, Natural Language Processing
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">教育问题生成、形成性评估、总结性评估、个性化测试、自然语言处理</font></font></font></div>
<span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content" data-imt_insert_failed="1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2025</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content" data-imt_insert_failed="1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>rightsretained</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>LAK25: The 15th International Learning Analytics and Knowledge Conference; March 03–07, 2025; Dublin, Ireland<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">会议：LAK25：第 15 届国际学习分析与知识会议；2025 年 3 月 3 日至 7 日；爱尔兰都柏林</font></font></font></span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_booktitle" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>LAK25: The 15th International Learning Analytics and Knowledge Conference (LAK 2025), March 03–07, 2025, Dublin, Ireland<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">会议名称：LAK25：第 15 届国际学习分析与知识会议（LAK 2025），2025 年 3 月 3 日至 7 日，爱尔兰都柏林</font></font></font></span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3706468.3706487<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">doi：10.1145/3706468.3706487</font></font></font></span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>979-8-4007-0701-8/25/03<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">isbn：979-8-4007-0701-8/25/03</font></font></font></span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id7"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies&nbsp;Natural language generation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ccs：计算方法 自然语言生成</font></font></font></span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id8"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies&nbsp;Information extraction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ccs：计算方法 信息提取</font></font></font></span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id9"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Applied computing&nbsp;Interactive learning environments<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ccs：应用计算 交互式学习环境</font></font></font></span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1. 引言</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">One of the most significant and pertinent challenges facing education systems today is the teachers’ workload. It is argued to be the main reason behind issues associated with teachers’ retention in the profession as well as the lack of interest among graduate students to go into teaching professions. On the other hand, according to the Global Report on Teachers published by the Teacher Task Force and UNESCO, 44 million additional teachers will be needed by 2030 to meet Sustainable Development Goal 4 (SDG4), which aims to achieve universal primary and secondary education for all <cite class="ltx_cite ltx_citemacro_citep">(UNESCO and International Task Force on Teachers for Education
2030, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib53" title="">2024</a>)</cite>, without any improvements to the <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">status quo</span>. Among these concerns, generative AI in education is seen as an opportunity to ’transform a teacher’s day-to-day work’ <cite class="ltx_cite ltx_citemacro_citep">(for Education, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib30" title="">2024</a>)</cite> by reducing their workload and improving educational outcomes through the automation of routine tasks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">当今教育系统面临的最重要和最紧迫的挑战之一是教师的工作量。有人认为这是导致教师职业流失问题以及毕业生对教学职业缺乏兴趣的主要原因。另一方面，根据教师任务小组和联合国教科文组织发布的《教师全球报告》，到 2030 年，为了实现可持续发展目标 4（SDG4），即让所有人人享有全民初级和中等教育（联合国教科文组织和国际教育 2030 教师任务小组，2024 年），在不改变现状的情况下，将需要额外 44 万名教师。在这些担忧中，教育领域的生成式人工智能被视为一个机会，可以通过减少工作量并通过自动化常规任务来提高教育成果，从而“改变教师日常的工作”（教育，2024 年）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Creating lesson materials and generating topic-specific, relevant, and age-appropriate questions for teaching have long been identified as time-intensive tasks for teachers, and an area where increased consistency is also expected to improve educational outcomes for students <cite class="ltx_cite ltx_citemacro_citep">(Giannakos et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib31" title="">2024</a>)</cite>. Although learning analytics and AI in Education researchers have long explored ways to support teachers’ question generation capabilities through data-driven insights and models, attempts on <span class="ltx_text ltx_font_bold" id="S1.p2.1.1">Topic-Controlled Question Generation (T-CQG)</span> have been less successful, primarily due to the lack of quality in the generated content. The use of large language models (LLMs) in teacher-facing interfaces, however, has the potential to address these quality concerns by leveraging recent advancements in NLP for automatic educational question generation (EdQG). EdQG can help teachers reduce the labor-intensive task of generating questions to promote classroom discussions, design formative and summative assessments, create lesson hooks, or address student misconceptions which are all activities that teachers consider among the most time-consuming in their profession <cite class="ltx_cite ltx_citemacro_citep">(for Education, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib30" title="">2024</a>)</cite>. Although most issues related to teachers’ workload are complex, ecosystem-level socio-technical challenges <cite class="ltx_cite ltx_citemacro_citep">(Cukurova et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib16" title="">2023</a>)</cite>, T-CQG can serve as a small yet important practical step towards enhancing teachers’ productivity, aiming to mitigate workload and address issues related to teacher retention and attraction to the profession.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">创建教学材料和生成与主题相关、适合年龄且恰当的问题，长期以来一直被认为是教师耗时的工作，也是期望通过提高一致性来改善学生学习成果的领域（Giannakos 等人，2024）。尽管学习分析和教育人工智能研究人员长期以来通过数据驱动的见解和模型探索支持教师问题生成能力的方法，但主题控制问题生成（T-CQG）方面的尝试不太成功，主要是因为生成内容的质量不高。然而，在面向教师界面的使用大型语言模型（LLMs），可以通过利用自然语言处理（NLP）的最新进展来自动生成教育问题（EdQG），从而解决这些质量方面的担忧。EdQG 可以帮助教师减少生成问题的劳动密集型任务，以促进课堂讨论、设计形成性评估和总结性评估、创建课程钩子或解决学生的误解，这些活动都是教师认为在其职业中最耗时的活动（教育，2024）。 尽管与教师工作负担相关的大多数问题都很复杂，属于生态系统层面的社会技术挑战（Cukurova 等，2023 年），但 T-CQG（主题控制型问题生成）可以作为一个小而重要的实践步骤，朝着提高教师生产力的方向发展，旨在减轻工作负担，并解决与教师留任和吸引人才相关的问题。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In addition to their potential to support teachers, EdQG (and T-CQG) models can be integrated into learning management systems (LMSs) and intelligent tutoring systems (ITSs), to advance the system’s capability to perform precise diagnostics on learner’s knowledge gaps. The responses received from learners can inform the learning analytics pipeline more precisely and frequently to have a refined learner state representation, that can empower the system with targeted interventions. However, such interventions require advancements to generic neural network question generation models that do not have the ability to contextualise generation with constraints.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">除了支持教师外，EdQG（以及 T-CQG）模型可以集成到学习管理系统（LMS）和智能辅导系统（ITS）中，以提升系统对学习者知识差距进行精确诊断的能力。学习者提供的反馈可以更精确、更频繁地输入学习分析流程，从而形成更精细的学习者状态表示，使系统能够实施有针对性的干预。然而，此类干预需要改进通用神经网络问题生成模型，这些模型缺乏在约束条件下进行情境化生成的能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">The novelties that we introduce through this work are three-fold. We 1) propose a novel method to generate a dataset with contrastive examples in order to effectively train a T-CQG model and 2) validate and propose novel ways of evaluating the topical relatedness of the generations to the controlled topic using semantic relatedness metrics while 3) this is the only work that attempts in using a very small language model (sLM) with <math alttext="\approx 60M" class="ltx_Math" display="inline" id="S1.p4.1.m1.1"><semantics id="S1.p4.1.m1.1a"><mrow id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml"><mi id="S1.p4.1.m1.1.1.2" xref="S1.p4.1.m1.1.1.2.cmml"></mi><mo id="S1.p4.1.m1.1.1.1" xref="S1.p4.1.m1.1.1.1.cmml">≈</mo><mrow id="S1.p4.1.m1.1.1.3" xref="S1.p4.1.m1.1.1.3.cmml"><mn id="S1.p4.1.m1.1.1.3.2" xref="S1.p4.1.m1.1.1.3.2.cmml">60</mn><mo id="S1.p4.1.m1.1.1.3.1" xref="S1.p4.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S1.p4.1.m1.1.1.3.3" xref="S1.p4.1.m1.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><apply id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1"><approx id="S1.p4.1.m1.1.1.1.cmml" xref="S1.p4.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S1.p4.1.m1.1.1.2.cmml" xref="S1.p4.1.m1.1.1.2">absent</csymbol><apply id="S1.p4.1.m1.1.1.3.cmml" xref="S1.p4.1.m1.1.1.3"><times id="S1.p4.1.m1.1.1.3.1.cmml" xref="S1.p4.1.m1.1.1.3.1"></times><cn id="S1.p4.1.m1.1.1.3.2.cmml" type="integer" xref="S1.p4.1.m1.1.1.3.2">60</cn><ci id="S1.p4.1.m1.1.1.3.3.cmml" xref="S1.p4.1.m1.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">\approx 60M</annotation><annotation encoding="application/x-llamapun" id="S1.p4.1.m1.1d">≈ 60 italic_M</annotation></semantics></math> parameters, and succeeds in producing a T-CQG neural model.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们通过这项工作引入的新颖之处有三方面。我们 1) 提出了一种生成具有对比示例的数据集的新方法，以有效地训练 T-CQG 模型，2) 验证并提出了使用语义相关性指标评估生成内容与控制主题相关性的新方法，同时 3) 这是唯一尝试使用参数非常小的语言模型（sLM）并成功生成 T-CQG 神经模型的工作。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Problem Definition, Background Research, and Research Questions<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.问题定义、背景研究和研究问题</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we introduce the formal problem definition and prior work, leading to the research questions.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本节中，我们介绍了正式的问题定义和先前的工作，引出研究问题。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Problem Definition<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.1.问题定义</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Although language models have been employed for question generation, their application in educational settings has only recently begun to be systematically explored with a heavy focus on the potential practical applications of proprietary models (e.g. GPT models’ prompt engineering and RAG applications for question generation). While existing research in relevant academic communities with a more technical focus explores generating questions from descriptive texts <cite class="ltx_cite ltx_citemacro_citep">(Du et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib23" title="">2017</a>; Wang et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib56" title="">2018</a>)</cite>, the task remains highly complex and there is less focus on the educational value of the generated questions in evaluations. Context plays a crucial role in the educational value of EdQG, yet much existing work has focused primarily on generating questions from sentences, paragraphs, or structured data in isolation <cite class="ltx_cite ltx_citemacro_citep">(Hu et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib35" title="">2018</a>; Lopez et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib40" title="">2021</a>)</cite>, with limited attention given to topic-controlled question generation in a given context.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管语言模型已被用于生成问题，但它们在教育环境中的应用直到最近才开始系统地探索，重点主要集中在专有模型的潜在实际应用上（例如 GPT 模型的提示工程和用于问题生成的 RAG 应用）。而相关学术领域内更侧重技术的研究则探索从描述性文本中生成问题（Du 等人，2017；Wang 等人，2018），但这项任务仍然非常复杂，且在评估中较少关注生成问题的教育价值。上下文在 EdQG（教育问题生成）的教育价值中起着至关重要的作用，然而大量现有工作主要集中于独立地从句子、段落或结构化数据中生成问题（Hu 等人，2018；Lopez 等人，2021），对在特定上下文中进行主题控制的问题生成关注有限。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Topic-controlled question generation takes a target topic in addition to the descriptive text as context into account while generating the models’ outputs. On the other hand, traditional approaches which take sentences or paragraphs as inputs without contextual topic-control tend to generate questions that arbitrarily combine or select concepts and topics which are likely to be of limited practical value to professionals like teachers. From the learners’ points of view, prior research also suggests a strong correlation between the personalisation of testing and knowledge retention <cite class="ltx_cite ltx_citemacro_citep">(Bahrick et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib4" title="">1993</a>)</cite>, which further supports the importance of topic-controlled question generation. Developing comprehensive, high quality and relevant educational question sets across different topics can significantly enhance teaching practice and support students through intelligent tutoring systems that provide personalised learning to diverse learners.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">主题控制式问题生成在生成模型输出时会考虑目标主题以及描述性文本作为上下文。另一方面，传统方法在不进行主题控制的情况下将句子或段落作为输入，往往生成的问题会任意组合或选择概念和主题，这些内容对教师等专业人士可能缺乏实际价值。从学习者的角度来看，已有研究表明测试的个性化与知识保留之间存在强相关性（Bahrick 等人，1993 年），这进一步支持了主题控制式问题生成的重要性。开发涵盖不同主题的全面、高质量且相关的教育问题集，可以显著提升教学实践，并通过为不同学习者提供个性化学习的智能辅导系统来支持学生。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.14">In the scope of this work, we define topic-controlled question generation (T-CQG) as follows. Let us suppose a learner <math alttext="\ell" class="ltx_Math" display="inline" id="S2.SS1.p3.1.m1.1"><semantics id="S2.SS1.p3.1.m1.1a"><mi id="S2.SS1.p3.1.m1.1.1" mathvariant="normal" xref="S2.SS1.p3.1.m1.1.1.cmml">ℓ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">ℓ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\ell</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.1.m1.1d">roman_ℓ</annotation></semantics></math> has already consumed learning materials that contain the knowledge context <math alttext="c" class="ltx_Math" display="inline" id="S2.SS1.p3.2.m2.1"><semantics id="S2.SS1.p3.2.m2.1a"><mi id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">c</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.2.m2.1d">italic_c</annotation></semantics></math> containing various topics <math alttext="T_{c}" class="ltx_Math" display="inline" id="S2.SS1.p3.3.m3.1"><semantics id="S2.SS1.p3.3.m3.1a"><msub id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml"><mi id="S2.SS1.p3.3.m3.1.1.2" xref="S2.SS1.p3.3.m3.1.1.2.cmml">T</mi><mi id="S2.SS1.p3.3.m3.1.1.3" xref="S2.SS1.p3.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><apply id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.3.m3.1.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p3.3.m3.1.1.2.cmml" xref="S2.SS1.p3.3.m3.1.1.2">𝑇</ci><ci id="S2.SS1.p3.3.m3.1.1.3.cmml" xref="S2.SS1.p3.3.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">T_{c}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.3.m3.1d">italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>. A goal of a teacher or an intelligent system is then to generate a question <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S2.SS1.p3.4.m4.1"><semantics id="S2.SS1.p3.4.m4.1a"><msub id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml"><mover accent="true" id="S2.SS1.p3.4.m4.1.1.2" xref="S2.SS1.p3.4.m4.1.1.2.cmml"><mi id="S2.SS1.p3.4.m4.1.1.2.2" xref="S2.SS1.p3.4.m4.1.1.2.2.cmml">q</mi><mo id="S2.SS1.p3.4.m4.1.1.2.1" xref="S2.SS1.p3.4.m4.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS1.p3.4.m4.1.1.3" xref="S2.SS1.p3.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.1b"><apply id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.4.m4.1.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">subscript</csymbol><apply id="S2.SS1.p3.4.m4.1.1.2.cmml" xref="S2.SS1.p3.4.m4.1.1.2"><ci id="S2.SS1.p3.4.m4.1.1.2.1.cmml" xref="S2.SS1.p3.4.m4.1.1.2.1">^</ci><ci id="S2.SS1.p3.4.m4.1.1.2.2.cmml" xref="S2.SS1.p3.4.m4.1.1.2.2">𝑞</ci></apply><ci id="S2.SS1.p3.4.m4.1.1.3.cmml" xref="S2.SS1.p3.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.4.m4.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S2.SS1.p3.5.m5.1"><semantics id="S2.SS1.p3.5.m5.1a"><msub id="S2.SS1.p3.5.m5.1.1" xref="S2.SS1.p3.5.m5.1.1.cmml"><mover accent="true" id="S2.SS1.p3.5.m5.1.1.2" xref="S2.SS1.p3.5.m5.1.1.2.cmml"><mi id="S2.SS1.p3.5.m5.1.1.2.2" xref="S2.SS1.p3.5.m5.1.1.2.2.cmml">q</mi><mo id="S2.SS1.p3.5.m5.1.1.2.1" xref="S2.SS1.p3.5.m5.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS1.p3.5.m5.1.1.3" xref="S2.SS1.p3.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m5.1b"><apply id="S2.SS1.p3.5.m5.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.5.m5.1.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1">subscript</csymbol><apply id="S2.SS1.p3.5.m5.1.1.2.cmml" xref="S2.SS1.p3.5.m5.1.1.2"><ci id="S2.SS1.p3.5.m5.1.1.2.1.cmml" xref="S2.SS1.p3.5.m5.1.1.2.1">^</ci><ci id="S2.SS1.p3.5.m5.1.1.2.2.cmml" xref="S2.SS1.p3.5.m5.1.1.2.2">𝑞</ci></apply><ci id="S2.SS1.p3.5.m5.1.1.3.cmml" xref="S2.SS1.p3.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m5.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.5.m5.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is an educational question about the target topic <math alttext="t" class="ltx_Math" display="inline" id="S2.SS1.p3.6.m6.1"><semantics id="S2.SS1.p3.6.m6.1a"><mi id="S2.SS1.p3.6.m6.1.1" xref="S2.SS1.p3.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.6.m6.1b"><ci id="S2.SS1.p3.6.m6.1.1.cmml" xref="S2.SS1.p3.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.6.m6.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.6.m6.1d">italic_t</annotation></semantics></math>, where <math alttext="t\in T_{c}" class="ltx_Math" display="inline" id="S2.SS1.p3.7.m7.1"><semantics id="S2.SS1.p3.7.m7.1a"><mrow id="S2.SS1.p3.7.m7.1.1" xref="S2.SS1.p3.7.m7.1.1.cmml"><mi id="S2.SS1.p3.7.m7.1.1.2" xref="S2.SS1.p3.7.m7.1.1.2.cmml">t</mi><mo id="S2.SS1.p3.7.m7.1.1.1" xref="S2.SS1.p3.7.m7.1.1.1.cmml">∈</mo><msub id="S2.SS1.p3.7.m7.1.1.3" xref="S2.SS1.p3.7.m7.1.1.3.cmml"><mi id="S2.SS1.p3.7.m7.1.1.3.2" xref="S2.SS1.p3.7.m7.1.1.3.2.cmml">T</mi><mi id="S2.SS1.p3.7.m7.1.1.3.3" xref="S2.SS1.p3.7.m7.1.1.3.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.7.m7.1b"><apply id="S2.SS1.p3.7.m7.1.1.cmml" xref="S2.SS1.p3.7.m7.1.1"><in id="S2.SS1.p3.7.m7.1.1.1.cmml" xref="S2.SS1.p3.7.m7.1.1.1"></in><ci id="S2.SS1.p3.7.m7.1.1.2.cmml" xref="S2.SS1.p3.7.m7.1.1.2">𝑡</ci><apply id="S2.SS1.p3.7.m7.1.1.3.cmml" xref="S2.SS1.p3.7.m7.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p3.7.m7.1.1.3.1.cmml" xref="S2.SS1.p3.7.m7.1.1.3">subscript</csymbol><ci id="S2.SS1.p3.7.m7.1.1.3.2.cmml" xref="S2.SS1.p3.7.m7.1.1.3.2">𝑇</ci><ci id="S2.SS1.p3.7.m7.1.1.3.3.cmml" xref="S2.SS1.p3.7.m7.1.1.3.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.7.m7.1c">t\in T_{c}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.7.m7.1d">italic_t ∈ italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S2.SS1.p3.8.m8.1"><semantics id="S2.SS1.p3.8.m8.1a"><msub id="S2.SS1.p3.8.m8.1.1" xref="S2.SS1.p3.8.m8.1.1.cmml"><mover accent="true" id="S2.SS1.p3.8.m8.1.1.2" xref="S2.SS1.p3.8.m8.1.1.2.cmml"><mi id="S2.SS1.p3.8.m8.1.1.2.2" xref="S2.SS1.p3.8.m8.1.1.2.2.cmml">q</mi><mo id="S2.SS1.p3.8.m8.1.1.2.1" xref="S2.SS1.p3.8.m8.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS1.p3.8.m8.1.1.3" xref="S2.SS1.p3.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.8.m8.1b"><apply id="S2.SS1.p3.8.m8.1.1.cmml" xref="S2.SS1.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.8.m8.1.1.1.cmml" xref="S2.SS1.p3.8.m8.1.1">subscript</csymbol><apply id="S2.SS1.p3.8.m8.1.1.2.cmml" xref="S2.SS1.p3.8.m8.1.1.2"><ci id="S2.SS1.p3.8.m8.1.1.2.1.cmml" xref="S2.SS1.p3.8.m8.1.1.2.1">^</ci><ci id="S2.SS1.p3.8.m8.1.1.2.2.cmml" xref="S2.SS1.p3.8.m8.1.1.2.2">𝑞</ci></apply><ci id="S2.SS1.p3.8.m8.1.1.3.cmml" xref="S2.SS1.p3.8.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.8.m8.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.8.m8.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> consists of a sequence of tokens <math alttext="q_{t}\in\{w_{1},\dots,w_{|q_{t}|}\}" class="ltx_Math" display="inline" id="S2.SS1.p3.9.m9.4"><semantics id="S2.SS1.p3.9.m9.4a"><mrow id="S2.SS1.p3.9.m9.4.4" xref="S2.SS1.p3.9.m9.4.4.cmml"><msub id="S2.SS1.p3.9.m9.4.4.4" xref="S2.SS1.p3.9.m9.4.4.4.cmml"><mi id="S2.SS1.p3.9.m9.4.4.4.2" xref="S2.SS1.p3.9.m9.4.4.4.2.cmml">q</mi><mi id="S2.SS1.p3.9.m9.4.4.4.3" xref="S2.SS1.p3.9.m9.4.4.4.3.cmml">t</mi></msub><mo id="S2.SS1.p3.9.m9.4.4.3" xref="S2.SS1.p3.9.m9.4.4.3.cmml">∈</mo><mrow id="S2.SS1.p3.9.m9.4.4.2.2" xref="S2.SS1.p3.9.m9.4.4.2.3.cmml"><mo id="S2.SS1.p3.9.m9.4.4.2.2.3" stretchy="false" xref="S2.SS1.p3.9.m9.4.4.2.3.cmml">{</mo><msub id="S2.SS1.p3.9.m9.3.3.1.1.1" xref="S2.SS1.p3.9.m9.3.3.1.1.1.cmml"><mi id="S2.SS1.p3.9.m9.3.3.1.1.1.2" xref="S2.SS1.p3.9.m9.3.3.1.1.1.2.cmml">w</mi><mn id="S2.SS1.p3.9.m9.3.3.1.1.1.3" xref="S2.SS1.p3.9.m9.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p3.9.m9.4.4.2.2.4" xref="S2.SS1.p3.9.m9.4.4.2.3.cmml">,</mo><mi id="S2.SS1.p3.9.m9.2.2" mathvariant="normal" xref="S2.SS1.p3.9.m9.2.2.cmml">…</mi><mo id="S2.SS1.p3.9.m9.4.4.2.2.5" xref="S2.SS1.p3.9.m9.4.4.2.3.cmml">,</mo><msub id="S2.SS1.p3.9.m9.4.4.2.2.2" xref="S2.SS1.p3.9.m9.4.4.2.2.2.cmml"><mi id="S2.SS1.p3.9.m9.4.4.2.2.2.2" xref="S2.SS1.p3.9.m9.4.4.2.2.2.2.cmml">w</mi><mrow id="S2.SS1.p3.9.m9.1.1.1.1" xref="S2.SS1.p3.9.m9.1.1.1.2.cmml"><mo id="S2.SS1.p3.9.m9.1.1.1.1.2" stretchy="false" xref="S2.SS1.p3.9.m9.1.1.1.2.1.cmml">|</mo><msub id="S2.SS1.p3.9.m9.1.1.1.1.1" xref="S2.SS1.p3.9.m9.1.1.1.1.1.cmml"><mi id="S2.SS1.p3.9.m9.1.1.1.1.1.2" xref="S2.SS1.p3.9.m9.1.1.1.1.1.2.cmml">q</mi><mi id="S2.SS1.p3.9.m9.1.1.1.1.1.3" xref="S2.SS1.p3.9.m9.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS1.p3.9.m9.1.1.1.1.3" stretchy="false" xref="S2.SS1.p3.9.m9.1.1.1.2.1.cmml">|</mo></mrow></msub><mo id="S2.SS1.p3.9.m9.4.4.2.2.6" stretchy="false" xref="S2.SS1.p3.9.m9.4.4.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.9.m9.4b"><apply id="S2.SS1.p3.9.m9.4.4.cmml" xref="S2.SS1.p3.9.m9.4.4"><in id="S2.SS1.p3.9.m9.4.4.3.cmml" xref="S2.SS1.p3.9.m9.4.4.3"></in><apply id="S2.SS1.p3.9.m9.4.4.4.cmml" xref="S2.SS1.p3.9.m9.4.4.4"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m9.4.4.4.1.cmml" xref="S2.SS1.p3.9.m9.4.4.4">subscript</csymbol><ci id="S2.SS1.p3.9.m9.4.4.4.2.cmml" xref="S2.SS1.p3.9.m9.4.4.4.2">𝑞</ci><ci id="S2.SS1.p3.9.m9.4.4.4.3.cmml" xref="S2.SS1.p3.9.m9.4.4.4.3">𝑡</ci></apply><set id="S2.SS1.p3.9.m9.4.4.2.3.cmml" xref="S2.SS1.p3.9.m9.4.4.2.2"><apply id="S2.SS1.p3.9.m9.3.3.1.1.1.cmml" xref="S2.SS1.p3.9.m9.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m9.3.3.1.1.1.1.cmml" xref="S2.SS1.p3.9.m9.3.3.1.1.1">subscript</csymbol><ci id="S2.SS1.p3.9.m9.3.3.1.1.1.2.cmml" xref="S2.SS1.p3.9.m9.3.3.1.1.1.2">𝑤</ci><cn id="S2.SS1.p3.9.m9.3.3.1.1.1.3.cmml" type="integer" xref="S2.SS1.p3.9.m9.3.3.1.1.1.3">1</cn></apply><ci id="S2.SS1.p3.9.m9.2.2.cmml" xref="S2.SS1.p3.9.m9.2.2">…</ci><apply id="S2.SS1.p3.9.m9.4.4.2.2.2.cmml" xref="S2.SS1.p3.9.m9.4.4.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m9.4.4.2.2.2.1.cmml" xref="S2.SS1.p3.9.m9.4.4.2.2.2">subscript</csymbol><ci id="S2.SS1.p3.9.m9.4.4.2.2.2.2.cmml" xref="S2.SS1.p3.9.m9.4.4.2.2.2.2">𝑤</ci><apply id="S2.SS1.p3.9.m9.1.1.1.2.cmml" xref="S2.SS1.p3.9.m9.1.1.1.1"><abs id="S2.SS1.p3.9.m9.1.1.1.2.1.cmml" xref="S2.SS1.p3.9.m9.1.1.1.1.2"></abs><apply id="S2.SS1.p3.9.m9.1.1.1.1.1.cmml" xref="S2.SS1.p3.9.m9.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.9.m9.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.9.m9.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p3.9.m9.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.9.m9.1.1.1.1.1.2">𝑞</ci><ci id="S2.SS1.p3.9.m9.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.9.m9.1.1.1.1.1.3">𝑡</ci></apply></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.9.m9.4c">q_{t}\in\{w_{1},\dots,w_{|q_{t}|}\}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.9.m9.4d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ { italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_w start_POSTSUBSCRIPT | italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | end_POSTSUBSCRIPT }</annotation></semantics></math> of arbitrary length <math alttext="|q_{t}|" class="ltx_Math" display="inline" id="S2.SS1.p3.10.m10.1"><semantics id="S2.SS1.p3.10.m10.1a"><mrow id="S2.SS1.p3.10.m10.1.1.1" xref="S2.SS1.p3.10.m10.1.1.2.cmml"><mo id="S2.SS1.p3.10.m10.1.1.1.2" stretchy="false" xref="S2.SS1.p3.10.m10.1.1.2.1.cmml">|</mo><msub id="S2.SS1.p3.10.m10.1.1.1.1" xref="S2.SS1.p3.10.m10.1.1.1.1.cmml"><mi id="S2.SS1.p3.10.m10.1.1.1.1.2" xref="S2.SS1.p3.10.m10.1.1.1.1.2.cmml">q</mi><mi id="S2.SS1.p3.10.m10.1.1.1.1.3" xref="S2.SS1.p3.10.m10.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS1.p3.10.m10.1.1.1.3" stretchy="false" xref="S2.SS1.p3.10.m10.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.10.m10.1b"><apply id="S2.SS1.p3.10.m10.1.1.2.cmml" xref="S2.SS1.p3.10.m10.1.1.1"><abs id="S2.SS1.p3.10.m10.1.1.2.1.cmml" xref="S2.SS1.p3.10.m10.1.1.1.2"></abs><apply id="S2.SS1.p3.10.m10.1.1.1.1.cmml" xref="S2.SS1.p3.10.m10.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.10.m10.1.1.1.1.1.cmml" xref="S2.SS1.p3.10.m10.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p3.10.m10.1.1.1.1.2.cmml" xref="S2.SS1.p3.10.m10.1.1.1.1.2">𝑞</ci><ci id="S2.SS1.p3.10.m10.1.1.1.1.3.cmml" xref="S2.SS1.p3.10.m10.1.1.1.1.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.10.m10.1c">|q_{t}|</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.10.m10.1d">| italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT |</annotation></semantics></math>. This task requires that the question is not only contextually relevant to the paragraph context <math alttext="{c}" class="ltx_Math" display="inline" id="S2.SS1.p3.11.m11.1"><semantics id="S2.SS1.p3.11.m11.1a"><mi id="S2.SS1.p3.11.m11.1.1" xref="S2.SS1.p3.11.m11.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.11.m11.1b"><ci id="S2.SS1.p3.11.m11.1.1.cmml" xref="S2.SS1.p3.11.m11.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.11.m11.1c">{c}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.11.m11.1d">italic_c</annotation></semantics></math>, but also closely aligned with the thematic focus defined by topic <math alttext="t" class="ltx_Math" display="inline" id="S2.SS1.p3.12.m12.1"><semantics id="S2.SS1.p3.12.m12.1a"><mi id="S2.SS1.p3.12.m12.1.1" xref="S2.SS1.p3.12.m12.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.12.m12.1b"><ci id="S2.SS1.p3.12.m12.1.1.cmml" xref="S2.SS1.p3.12.m12.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.12.m12.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.12.m12.1d">italic_t</annotation></semantics></math>. The probability <math alttext="p(q_{t}|c,t)" class="ltx_Math" display="inline" id="S2.SS1.p3.13.m13.3"><semantics id="S2.SS1.p3.13.m13.3a"><mrow id="S2.SS1.p3.13.m13.3.3" xref="S2.SS1.p3.13.m13.3.3.cmml"><mi id="S2.SS1.p3.13.m13.3.3.3" xref="S2.SS1.p3.13.m13.3.3.3.cmml">p</mi><mo id="S2.SS1.p3.13.m13.3.3.2" xref="S2.SS1.p3.13.m13.3.3.2.cmml">⁢</mo><mrow id="S2.SS1.p3.13.m13.3.3.1.1" xref="S2.SS1.p3.13.m13.3.3.1.1.1.cmml"><mo id="S2.SS1.p3.13.m13.3.3.1.1.2" stretchy="false" xref="S2.SS1.p3.13.m13.3.3.1.1.1.cmml">(</mo><mrow id="S2.SS1.p3.13.m13.3.3.1.1.1" xref="S2.SS1.p3.13.m13.3.3.1.1.1.cmml"><msub id="S2.SS1.p3.13.m13.3.3.1.1.1.2" xref="S2.SS1.p3.13.m13.3.3.1.1.1.2.cmml"><mi id="S2.SS1.p3.13.m13.3.3.1.1.1.2.2" xref="S2.SS1.p3.13.m13.3.3.1.1.1.2.2.cmml">q</mi><mi id="S2.SS1.p3.13.m13.3.3.1.1.1.2.3" xref="S2.SS1.p3.13.m13.3.3.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.SS1.p3.13.m13.3.3.1.1.1.1" xref="S2.SS1.p3.13.m13.3.3.1.1.1.1.cmml">|</mo><mrow id="S2.SS1.p3.13.m13.3.3.1.1.1.3.2" xref="S2.SS1.p3.13.m13.3.3.1.1.1.3.1.cmml"><mi id="S2.SS1.p3.13.m13.1.1" xref="S2.SS1.p3.13.m13.1.1.cmml">c</mi><mo id="S2.SS1.p3.13.m13.3.3.1.1.1.3.2.1" xref="S2.SS1.p3.13.m13.3.3.1.1.1.3.1.cmml">,</mo><mi id="S2.SS1.p3.13.m13.2.2" xref="S2.SS1.p3.13.m13.2.2.cmml">t</mi></mrow></mrow><mo id="S2.SS1.p3.13.m13.3.3.1.1.3" stretchy="false" xref="S2.SS1.p3.13.m13.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.13.m13.3b"><apply id="S2.SS1.p3.13.m13.3.3.cmml" xref="S2.SS1.p3.13.m13.3.3"><times id="S2.SS1.p3.13.m13.3.3.2.cmml" xref="S2.SS1.p3.13.m13.3.3.2"></times><ci id="S2.SS1.p3.13.m13.3.3.3.cmml" xref="S2.SS1.p3.13.m13.3.3.3">𝑝</ci><apply id="S2.SS1.p3.13.m13.3.3.1.1.1.cmml" xref="S2.SS1.p3.13.m13.3.3.1.1"><csymbol cd="latexml" id="S2.SS1.p3.13.m13.3.3.1.1.1.1.cmml" xref="S2.SS1.p3.13.m13.3.3.1.1.1.1">conditional</csymbol><apply id="S2.SS1.p3.13.m13.3.3.1.1.1.2.cmml" xref="S2.SS1.p3.13.m13.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.13.m13.3.3.1.1.1.2.1.cmml" xref="S2.SS1.p3.13.m13.3.3.1.1.1.2">subscript</csymbol><ci id="S2.SS1.p3.13.m13.3.3.1.1.1.2.2.cmml" xref="S2.SS1.p3.13.m13.3.3.1.1.1.2.2">𝑞</ci><ci id="S2.SS1.p3.13.m13.3.3.1.1.1.2.3.cmml" xref="S2.SS1.p3.13.m13.3.3.1.1.1.2.3">𝑡</ci></apply><list id="S2.SS1.p3.13.m13.3.3.1.1.1.3.1.cmml" xref="S2.SS1.p3.13.m13.3.3.1.1.1.3.2"><ci id="S2.SS1.p3.13.m13.1.1.cmml" xref="S2.SS1.p3.13.m13.1.1">𝑐</ci><ci id="S2.SS1.p3.13.m13.2.2.cmml" xref="S2.SS1.p3.13.m13.2.2">𝑡</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.13.m13.3c">p(q_{t}|c,t)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.13.m13.3d">italic_p ( italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c , italic_t )</annotation></semantics></math> incorporates the coherence and relevance of each token in the sequence, rendering the generation process highly sensitive to both the context and the topic. This task can be mathematically defined to identify the optimal question <math alttext="\hat{q_{t}}" class="ltx_Math" display="inline" id="S2.SS1.p3.14.m14.1"><semantics id="S2.SS1.p3.14.m14.1a"><mover accent="true" id="S2.SS1.p3.14.m14.1.1" xref="S2.SS1.p3.14.m14.1.1.cmml"><msub id="S2.SS1.p3.14.m14.1.1.2" xref="S2.SS1.p3.14.m14.1.1.2.cmml"><mi id="S2.SS1.p3.14.m14.1.1.2.2" xref="S2.SS1.p3.14.m14.1.1.2.2.cmml">q</mi><mi id="S2.SS1.p3.14.m14.1.1.2.3" xref="S2.SS1.p3.14.m14.1.1.2.3.cmml">t</mi></msub><mo id="S2.SS1.p3.14.m14.1.1.1" xref="S2.SS1.p3.14.m14.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.14.m14.1b"><apply id="S2.SS1.p3.14.m14.1.1.cmml" xref="S2.SS1.p3.14.m14.1.1"><ci id="S2.SS1.p3.14.m14.1.1.1.cmml" xref="S2.SS1.p3.14.m14.1.1.1">^</ci><apply id="S2.SS1.p3.14.m14.1.1.2.cmml" xref="S2.SS1.p3.14.m14.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p3.14.m14.1.1.2.1.cmml" xref="S2.SS1.p3.14.m14.1.1.2">subscript</csymbol><ci id="S2.SS1.p3.14.m14.1.1.2.2.cmml" xref="S2.SS1.p3.14.m14.1.1.2.2">𝑞</ci><ci id="S2.SS1.p3.14.m14.1.1.2.3.cmml" xref="S2.SS1.p3.14.m14.1.1.2.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.14.m14.1c">\hat{q_{t}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.14.m14.1d">over^ start_ARG italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> that maximises the conditional probability as per equation <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S2.E1" title="In 2.1. Problem Definition ‣ 2. Problem Definition, Background Research, and Research Questions ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">1</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本工作的范围内，我们将主题控制问题生成（T-CQG）定义如下。假设学习者 <math id="S2.SS1.p3.1.m1.1" display="inline" class="ltx_Math" alttext="\ell"><semantics id="S2.SS1.p3.1.m1.1a"><mi mathvariant="normal" id="S2.SS1.p3.1.m1.1.1">ℓ</mi><annotation-xml id="S2.SS1.p3.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS1.p3.1.m1.1c" encoding="application/x-tex">\ell</annotation><annotation id="S2.SS1.p3.1.m1.1d" encoding="application/x-llamapun">roman_ℓ</annotation></semantics></math> 已经消费了包含知识背景 <math id="S2.SS1.p3.2.m2.1" display="inline" class="ltx_Math" alttext="c"><semantics id="S2.SS1.p3.2.m2.1a"><mi id="S2.SS1.p3.2.m2.1.1">c</mi><annotation-xml id="S2.SS1.p3.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS1.p3.2.m2.1c" encoding="application/x-tex">c</annotation><annotation id="S2.SS1.p3.2.m2.1d" encoding="application/x-llamapun">italic_c</annotation></semantics></math> 的学习材料，其中包含各种主题 <math id="S2.SS1.p3.3.m3.1" display="inline" class="ltx_Math" alttext="T_{c}"><semantics id="S2.SS1.p3.3.m3.1a"><msub id="S2.SS1.p3.3.m3.1.1"><mi id="S2.SS1.p3.3.m3.1.1.2">T</mi><mi id="S2.SS1.p3.3.m3.1.1.3">c</mi></msub><annotation-xml id="S2.SS1.p3.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS1.p3.3.m3.1c" encoding="application/x-tex">T_{c}</annotation><annotation id="S2.SS1.p3.3.m3.1d" encoding="application/x-llamapun">italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> 。教师或智能系统的目标则是生成一个问题 <math id="S2.SS1.p3.4.m4.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S2.SS1.p3.4.m4.1a"><msub id="S2.SS1.p3.4.m4.1.1"><mover id="S2.SS1.p3.4.m4.1.1.2" accent="true"><mi id="S2.SS1.p3.4.m4.1.1.2.2">q</mi><mo id="S2.SS1.p3.4.m4.1.1.2.1">^</mo></mover><mi id="S2.SS1.p3.4.m4.1.1.3">t</mi></msub><annotation-xml id="S2.SS1.p3.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS1.p3.4.m4.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S2.SS1.p3.4.m4.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> ，其中 <math id="S2.SS1.p3.5.m5.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S2.SS1.p3.5.m5.1a"><msub id="S2.SS1.p3.5.m5.1.1"><mover id="S2.SS1.p3.5.m5.1.1.2" accent="true"><mi id="S2.SS1.p3.5.m5.1.1.2.2">q</mi><mo id="S2.SS1.p3.5.m5.1.1.2.1">^</mo></mover><mi id="S2.SS1.p3.5.m5.1.1.3">t</mi></msub><annotation-xml id="S2.SS1.p3.5.m5.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS1.p3.5.m5.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S2.SS1.p3.5.m5.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 是一个关于目标主题 <math id="S2.SS1.p3.6.m6.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S2.SS1.p3.6.m6.1a"><mi id="S2.SS1.p3.6.m6.1.1">t</mi><annotation-xml id="S2.SS1.p3.6.m6.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS1.p3.6.m6.1c" encoding="application/x-tex">t</annotation><annotation id="S2.SS1.p3.6.m6.1d" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 的教育问题， <math id="S2.SS1.p3.7.m7.1" display="inline" class="ltx_Math" alttext="t\in T_{c}"><semantics id="S2.SS1.p3.7.m7.1a"><mrow id="S2.SS1.p3.7.m7.1.1"><mi id="S2.SS1.p3.7.m7.1.1.2">t</mi><mo id="S2.SS1.p3.7.m7.1.1.1">∈</mo><msub id="S2.SS1.p3.7.m7.1.1.3"><mi id="S2.SS1.p3.7.m7.1.1.3.2">T</mi><mi id="S2.SS1.p3.7.m7.1.1.3.3">c</mi></msub></mrow><annotation-xml id="S2.SS1.p3.7.m7.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS1.p3.7.m7.1c" encoding="application/x-tex">t\in T_{c}</annotation><annotation id="S2.SS1.p3.7.m7.1d" encoding="application/x-llamapun">italic_t ∈ italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> ，而 <math id="S2.SS1.p3.8.m8.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S2.SS1.p3.8.m8.1a"><msub id="S2.SS1.p3.8.m8.1.1"><mover id="S2.SS1.p3.8.m8.1.1.2" accent="true"><mi id="S2.SS1.p3.8.m8.1.1.2.2">q</mi><mo id="S2.SS1.p3.8.m8.1.1.2.1">^</mo></mover><mi id="S2.SS1.p3.8.m8.1.1.3">t</mi></msub><annotation-xml id="S2.SS1.p3.8.m8.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS1.p3.8.m8.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S2.SS1.p3.8.m8.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 由任意长度的标记序列 <math id="S2.SS1.p3.9.m9.4" display="inline" class="ltx_Math" alttext="q_{t}\in\{w_{1},\dots,w_{|q_{t}|}\}"><semantics id="S2.SS1.p3.9.m9.4a"><mrow id="S2.SS1.p3.9.m9.4.4"><msub id="S2.SS1.p3.9.m9.4.4.4"><mi id="S2.SS1.p3.9.m9.4.4.4.2">q</mi><mi id="S2.SS1.p3.9.m9.4.4.4.3">t</mi></msub><mo id="S2.SS1.p3.9.m9.4.4.3">∈</mo><mrow id="S2.SS1.p3.9.m9.4.4.2.2"><mo stretchy="false" id="S2.SS1.p3.9.m9.4.4.2.2.3">{</mo><msub id="S2.SS1.p3.9.m9.3.3.1.1.1"><mi id="S2.SS1.p3.9.m9.3.3.1.1.1.2">w</mi><mn id="S2.SS1.p3.9.m9.3.3.1.1.1.3">1</mn></msub><mo id="S2.SS1.p3.9.m9.4.4.2.2.4">,</mo><mi mathvariant="normal" id="S2.SS1.p3.9.m9.2.2">…</mi><mo id="S2.SS1.p3.9.m9.4.4.2.2.5">,</mo><msub id="S2.SS1.p3.9.m9.4.4.2.2.2"><mi id="S2.SS1.p3.9.m9.4.4.2.2.2.2">w</mi><mrow id="S2.SS1.p3.9.m9.1.1.1.1"><mo stretchy="false" id="S2.SS1.p3.9.m9.1.1.1.1.2">|</mo><msub id="S2.SS1.p3.9.m9.1.1.1.1.1"><mi id="S2.SS1.p3.9.m9.1.1.1.1.1.2">q</mi><mi id="S2.SS1.p3.9.m9.1.1.1.1.1.3">t</mi></msub><mo stretchy="false" id="S2.SS1.p3.9.m9.1.1.1.1.3">|</mo></mrow></msub><mo stretchy="false" id="S2.SS1.p3.9.m9.4.4.2.2.6">}</mo></mrow></mrow><annotation-xml id="S2.SS1.p3.9.m9.4b" encoding="MathML-Content">subscriptsubscript1subscriptsubscript</annotation-xml><annotation id="S2.SS1.p3.9.m9.4c" encoding="application/x-tex">q_{t}\in\{w_{1},\dots,w_{|q_{t}|}\}</annotation><annotation id="S2.SS1.p3.9.m9.4d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∈ { italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_w start_POSTSUBSCRIPT | italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | end_POSTSUBSCRIPT }</annotation></semantics></math> 组成 <math id="S2.SS1.p3.10.m10.1" display="inline" class="ltx_Math" alttext="|q_{t}|"><semantics id="S2.SS1.p3.10.m10.1a"><mrow id="S2.SS1.p3.10.m10.1.1.1"><mo stretchy="false" id="S2.SS1.p3.10.m10.1.1.1.2">|</mo><msub id="S2.SS1.p3.10.m10.1.1.1.1"><mi id="S2.SS1.p3.10.m10.1.1.1.1.2">q</mi><mi id="S2.SS1.p3.10.m10.1.1.1.1.3">t</mi></msub><mo stretchy="false" id="S2.SS1.p3.10.m10.1.1.1.3">|</mo></mrow><annotation-xml id="S2.SS1.p3.10.m10.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS1.p3.10.m10.1c" encoding="application/x-tex">|q_{t}|</annotation><annotation id="S2.SS1.p3.10.m10.1d" encoding="application/x-llamapun">| italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT |</annotation></semantics></math> 。这项任务要求问题不仅与段落背景 <math id="S2.SS1.p3.11.m11.1" display="inline" class="ltx_Math" alttext="{c}"><semantics id="S2.SS1.p3.11.m11.1a"><mi id="S2.SS1.p3.11.m11.1.1">c</mi><annotation-xml id="S2.SS1.p3.11.m11.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS1.p3.11.m11.1c" encoding="application/x-tex">{c}</annotation><annotation id="S2.SS1.p3.11.m11.1d" encoding="application/x-llamapun">italic_c</annotation></semantics></math> 在语境上相关，而且与主题 <math id="S2.SS1.p3.12.m12.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S2.SS1.p3.12.m12.1a"><mi id="S2.SS1.p3.12.m12.1.1">t</mi><annotation-xml id="S2.SS1.p3.12.m12.1b" encoding="MathML-Content"></annotation-xml><annotation id="S2.SS1.p3.12.m12.1c" encoding="application/x-tex">t</annotation><annotation id="S2.SS1.p3.12.m12.1d" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 定义的主题焦点紧密一致。概率 <math id="S2.SS1.p3.13.m13.3" display="inline" class="ltx_Math" alttext="p(q_{t}|c,t)"><semantics id="S2.SS1.p3.13.m13.3a"><mrow id="S2.SS1.p3.13.m13.3.3"><mi id="S2.SS1.p3.13.m13.3.3.3">p</mi><mo id="S2.SS1.p3.13.m13.3.3.2">⁢</mo><mrow id="S2.SS1.p3.13.m13.3.3.1.1"><mo stretchy="false" id="S2.SS1.p3.13.m13.3.3.1.1.2">(</mo><mrow id="S2.SS1.p3.13.m13.3.3.1.1.1"><msub id="S2.SS1.p3.13.m13.3.3.1.1.1.2"><mi id="S2.SS1.p3.13.m13.3.3.1.1.1.2.2">q</mi><mi id="S2.SS1.p3.13.m13.3.3.1.1.1.2.3">t</mi></msub><mo id="S2.SS1.p3.13.m13.3.3.1.1.1.1" fence="false">|</mo><mrow id="S2.SS1.p3.13.m13.3.3.1.1.1.3.2"><mi id="S2.SS1.p3.13.m13.1.1">c</mi><mo id="S2.SS1.p3.13.m13.3.3.1.1.1.3.2.1">,</mo><mi id="S2.SS1.p3.13.m13.2.2">t</mi></mrow></mrow><mo stretchy="false" id="S2.SS1.p3.13.m13.3.3.1.1.3">)</mo></mrow></mrow><annotation-xml id="S2.SS1.p3.13.m13.3b" encoding="MathML-Content">conditionalsubscript</annotation-xml><annotation id="S2.SS1.p3.13.m13.3c" encoding="application/x-tex">p(q_{t}|c,t)</annotation><annotation id="S2.SS1.p3.13.m13.3d" encoding="application/x-llamapun">italic_p ( italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c , italic_t )</annotation></semantics></math> 包含了序列中每个标记的连贯性和相关性，使得生成过程对语境和主题都非常敏感。这项任务可以通过数学定义来识别能够最大化条件概率的最优问题 <math id="S2.SS1.p3.14.m14.1" display="inline" class="ltx_Math" alttext="\hat{q_{t}}"><semantics id="S2.SS1.p3.14.m14.1a"><mover id="S2.SS1.p3.14.m14.1.1" accent="true"><msub id="S2.SS1.p3.14.m14.1.1.2"><mi id="S2.SS1.p3.14.m14.1.1.2.2">q</mi><mi id="S2.SS1.p3.14.m14.1.1.2.3">t</mi></msub><mo id="S2.SS1.p3.14.m14.1.1.1">^</mo></mover><annotation-xml id="S2.SS1.p3.14.m14.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS1.p3.14.m14.1c" encoding="application/x-tex">\hat{q_{t}}</annotation><annotation id="S2.SS1.p3.14.m14.1d" encoding="application/x-llamapun">over^ start_ARG italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> ，如方程 1 所示。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{q_{t}}=\arg\max_{q_{t}}p({q_{t}}|{c},{t})=\arg\max_{q_{t}}\sum_{i=1}^{|{q%
_{t}}|}\log p(w_{i}|{c},{t},w_{1}\dots w_{i-1})" class="ltx_Math" display="block" id="S2.E1.m1.7"><semantics id="S2.E1.m1.7a"><mrow id="S2.E1.m1.7.7" xref="S2.E1.m1.7.7.cmml"><mover accent="true" id="S2.E1.m1.7.7.4" xref="S2.E1.m1.7.7.4.cmml"><msub id="S2.E1.m1.7.7.4.2" xref="S2.E1.m1.7.7.4.2.cmml"><mi id="S2.E1.m1.7.7.4.2.2" xref="S2.E1.m1.7.7.4.2.2.cmml">q</mi><mi id="S2.E1.m1.7.7.4.2.3" xref="S2.E1.m1.7.7.4.2.3.cmml">t</mi></msub><mo id="S2.E1.m1.7.7.4.1" xref="S2.E1.m1.7.7.4.1.cmml">^</mo></mover><mo id="S2.E1.m1.7.7.5" xref="S2.E1.m1.7.7.5.cmml">=</mo><mrow id="S2.E1.m1.6.6.1" xref="S2.E1.m1.6.6.1.cmml"><mrow id="S2.E1.m1.6.6.1.3" xref="S2.E1.m1.6.6.1.3.cmml"><mi id="S2.E1.m1.6.6.1.3.1" xref="S2.E1.m1.6.6.1.3.1.cmml">arg</mi><mo id="S2.E1.m1.6.6.1.3a" lspace="0.167em" xref="S2.E1.m1.6.6.1.3.cmml">⁡</mo><mrow id="S2.E1.m1.6.6.1.3.2" xref="S2.E1.m1.6.6.1.3.2.cmml"><munder id="S2.E1.m1.6.6.1.3.2.1" xref="S2.E1.m1.6.6.1.3.2.1.cmml"><mi id="S2.E1.m1.6.6.1.3.2.1.2" xref="S2.E1.m1.6.6.1.3.2.1.2.cmml">max</mi><msub id="S2.E1.m1.6.6.1.3.2.1.3" xref="S2.E1.m1.6.6.1.3.2.1.3.cmml"><mi id="S2.E1.m1.6.6.1.3.2.1.3.2" xref="S2.E1.m1.6.6.1.3.2.1.3.2.cmml">q</mi><mi id="S2.E1.m1.6.6.1.3.2.1.3.3" xref="S2.E1.m1.6.6.1.3.2.1.3.3.cmml">t</mi></msub></munder><mo id="S2.E1.m1.6.6.1.3.2a" lspace="0.167em" xref="S2.E1.m1.6.6.1.3.2.cmml">⁡</mo><mi id="S2.E1.m1.6.6.1.3.2.2" xref="S2.E1.m1.6.6.1.3.2.2.cmml">p</mi></mrow></mrow><mo id="S2.E1.m1.6.6.1.2" xref="S2.E1.m1.6.6.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.6.6.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.cmml"><mo id="S2.E1.m1.6.6.1.1.1.2" stretchy="false" xref="S2.E1.m1.6.6.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.6.6.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.cmml"><msub id="S2.E1.m1.6.6.1.1.1.1.2" xref="S2.E1.m1.6.6.1.1.1.1.2.cmml"><mi id="S2.E1.m1.6.6.1.1.1.1.2.2" xref="S2.E1.m1.6.6.1.1.1.1.2.2.cmml">q</mi><mi id="S2.E1.m1.6.6.1.1.1.1.2.3" xref="S2.E1.m1.6.6.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.E1.m1.6.6.1.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.1.cmml">|</mo><mrow id="S2.E1.m1.6.6.1.1.1.1.3.2" xref="S2.E1.m1.6.6.1.1.1.1.3.1.cmml"><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">c</mi><mo id="S2.E1.m1.6.6.1.1.1.1.3.2.1" xref="S2.E1.m1.6.6.1.1.1.1.3.1.cmml">,</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">t</mi></mrow></mrow><mo id="S2.E1.m1.6.6.1.1.1.3" stretchy="false" xref="S2.E1.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.7.7.6" xref="S2.E1.m1.7.7.6.cmml">=</mo><mrow id="S2.E1.m1.7.7.2" xref="S2.E1.m1.7.7.2.cmml"><mrow id="S2.E1.m1.7.7.2.3" xref="S2.E1.m1.7.7.2.3.cmml"><mi id="S2.E1.m1.7.7.2.3.1" xref="S2.E1.m1.7.7.2.3.1.cmml">arg</mi><mo id="S2.E1.m1.7.7.2.3a" lspace="0.167em" xref="S2.E1.m1.7.7.2.3.cmml">⁡</mo><munder id="S2.E1.m1.7.7.2.3.2" xref="S2.E1.m1.7.7.2.3.2.cmml"><mi id="S2.E1.m1.7.7.2.3.2.2" xref="S2.E1.m1.7.7.2.3.2.2.cmml">max</mi><msub id="S2.E1.m1.7.7.2.3.2.3" xref="S2.E1.m1.7.7.2.3.2.3.cmml"><mi id="S2.E1.m1.7.7.2.3.2.3.2" xref="S2.E1.m1.7.7.2.3.2.3.2.cmml">q</mi><mi id="S2.E1.m1.7.7.2.3.2.3.3" xref="S2.E1.m1.7.7.2.3.2.3.3.cmml">t</mi></msub></munder></mrow><mo id="S2.E1.m1.7.7.2.2" xref="S2.E1.m1.7.7.2.2.cmml">⁢</mo><mrow id="S2.E1.m1.7.7.2.1" xref="S2.E1.m1.7.7.2.1.cmml"><munderover id="S2.E1.m1.7.7.2.1.2" xref="S2.E1.m1.7.7.2.1.2.cmml"><mo id="S2.E1.m1.7.7.2.1.2.2.2" movablelimits="false" xref="S2.E1.m1.7.7.2.1.2.2.2.cmml">∑</mo><mrow id="S2.E1.m1.7.7.2.1.2.2.3" xref="S2.E1.m1.7.7.2.1.2.2.3.cmml"><mi id="S2.E1.m1.7.7.2.1.2.2.3.2" xref="S2.E1.m1.7.7.2.1.2.2.3.2.cmml">i</mi><mo id="S2.E1.m1.7.7.2.1.2.2.3.1" xref="S2.E1.m1.7.7.2.1.2.2.3.1.cmml">=</mo><mn id="S2.E1.m1.7.7.2.1.2.2.3.3" xref="S2.E1.m1.7.7.2.1.2.2.3.3.cmml">1</mn></mrow><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.2.1.cmml">|</mo><msub id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.2.cmml">q</mi><mi id="S2.E1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E1.m1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.2.1.cmml">|</mo></mrow></munderover><mrow id="S2.E1.m1.7.7.2.1.1" xref="S2.E1.m1.7.7.2.1.1.cmml"><mrow id="S2.E1.m1.7.7.2.1.1.3" xref="S2.E1.m1.7.7.2.1.1.3.cmml"><mi id="S2.E1.m1.7.7.2.1.1.3.1" xref="S2.E1.m1.7.7.2.1.1.3.1.cmml">log</mi><mo id="S2.E1.m1.7.7.2.1.1.3a" lspace="0.167em" xref="S2.E1.m1.7.7.2.1.1.3.cmml">⁡</mo><mi id="S2.E1.m1.7.7.2.1.1.3.2" xref="S2.E1.m1.7.7.2.1.1.3.2.cmml">p</mi></mrow><mo id="S2.E1.m1.7.7.2.1.1.2" xref="S2.E1.m1.7.7.2.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.7.7.2.1.1.1.1" xref="S2.E1.m1.7.7.2.1.1.1.1.1.cmml"><mo id="S2.E1.m1.7.7.2.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.7.7.2.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.7.7.2.1.1.1.1.1" xref="S2.E1.m1.7.7.2.1.1.1.1.1.cmml"><msub id="S2.E1.m1.7.7.2.1.1.1.1.1.3" xref="S2.E1.m1.7.7.2.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.7.7.2.1.1.1.1.1.3.2" xref="S2.E1.m1.7.7.2.1.1.1.1.1.3.2.cmml">w</mi><mi id="S2.E1.m1.7.7.2.1.1.1.1.1.3.3" xref="S2.E1.m1.7.7.2.1.1.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" id="S2.E1.m1.7.7.2.1.1.1.1.1.2" xref="S2.E1.m1.7.7.2.1.1.1.1.1.2.cmml">|</mo><mrow id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">c</mi><mo id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.2" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5.cmml">t</mi><mo id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.3" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.2.cmml">,</mo><mrow id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.2.cmml">w</mi><mn id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.3.cmml">1</mn></msub><mo id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mi id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.3" mathvariant="normal" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.3.cmml">…</mi><mo id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.1a" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><msub id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.cmml"><mi id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.2" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.2.cmml">w</mi><mrow id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.cmml"><mi id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.2" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.2.cmml">i</mi><mo id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.1" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.1.cmml">−</mo><mn id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.3" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.3.cmml">1</mn></mrow></msub></mrow></mrow></mrow><mo id="S2.E1.m1.7.7.2.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.7.7.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.7b"><apply id="S2.E1.m1.7.7.cmml" xref="S2.E1.m1.7.7"><and id="S2.E1.m1.7.7a.cmml" xref="S2.E1.m1.7.7"></and><apply id="S2.E1.m1.7.7b.cmml" xref="S2.E1.m1.7.7"><eq id="S2.E1.m1.7.7.5.cmml" xref="S2.E1.m1.7.7.5"></eq><apply id="S2.E1.m1.7.7.4.cmml" xref="S2.E1.m1.7.7.4"><ci id="S2.E1.m1.7.7.4.1.cmml" xref="S2.E1.m1.7.7.4.1">^</ci><apply id="S2.E1.m1.7.7.4.2.cmml" xref="S2.E1.m1.7.7.4.2"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.4.2.1.cmml" xref="S2.E1.m1.7.7.4.2">subscript</csymbol><ci id="S2.E1.m1.7.7.4.2.2.cmml" xref="S2.E1.m1.7.7.4.2.2">𝑞</ci><ci id="S2.E1.m1.7.7.4.2.3.cmml" xref="S2.E1.m1.7.7.4.2.3">𝑡</ci></apply></apply><apply id="S2.E1.m1.6.6.1.cmml" xref="S2.E1.m1.6.6.1"><times id="S2.E1.m1.6.6.1.2.cmml" xref="S2.E1.m1.6.6.1.2"></times><apply id="S2.E1.m1.6.6.1.3.cmml" xref="S2.E1.m1.6.6.1.3"><arg id="S2.E1.m1.6.6.1.3.1.cmml" xref="S2.E1.m1.6.6.1.3.1"></arg><apply id="S2.E1.m1.6.6.1.3.2.cmml" xref="S2.E1.m1.6.6.1.3.2"><apply id="S2.E1.m1.6.6.1.3.2.1.cmml" xref="S2.E1.m1.6.6.1.3.2.1"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.3.2.1.1.cmml" xref="S2.E1.m1.6.6.1.3.2.1">subscript</csymbol><max id="S2.E1.m1.6.6.1.3.2.1.2.cmml" xref="S2.E1.m1.6.6.1.3.2.1.2"></max><apply id="S2.E1.m1.6.6.1.3.2.1.3.cmml" xref="S2.E1.m1.6.6.1.3.2.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.3.2.1.3.1.cmml" xref="S2.E1.m1.6.6.1.3.2.1.3">subscript</csymbol><ci id="S2.E1.m1.6.6.1.3.2.1.3.2.cmml" xref="S2.E1.m1.6.6.1.3.2.1.3.2">𝑞</ci><ci id="S2.E1.m1.6.6.1.3.2.1.3.3.cmml" xref="S2.E1.m1.6.6.1.3.2.1.3.3">𝑡</ci></apply></apply><ci id="S2.E1.m1.6.6.1.3.2.2.cmml" xref="S2.E1.m1.6.6.1.3.2.2">𝑝</ci></apply></apply><apply id="S2.E1.m1.6.6.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.6.6.1.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1">conditional</csymbol><apply id="S2.E1.m1.6.6.1.1.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.1.1.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.2.2">𝑞</ci><ci id="S2.E1.m1.6.6.1.1.1.1.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.2.3">𝑡</ci></apply><list id="S2.E1.m1.6.6.1.1.1.1.3.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.3.2"><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝑐</ci><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">𝑡</ci></list></apply></apply></apply><apply id="S2.E1.m1.7.7c.cmml" xref="S2.E1.m1.7.7"><eq id="S2.E1.m1.7.7.6.cmml" xref="S2.E1.m1.7.7.6"></eq><share href="https://arxiv.org/html/2501.05220v1#S2.E1.m1.6.6.1.cmml" id="S2.E1.m1.7.7d.cmml" xref="S2.E1.m1.7.7"></share><apply id="S2.E1.m1.7.7.2.cmml" xref="S2.E1.m1.7.7.2"><times id="S2.E1.m1.7.7.2.2.cmml" xref="S2.E1.m1.7.7.2.2"></times><apply id="S2.E1.m1.7.7.2.3.cmml" xref="S2.E1.m1.7.7.2.3"><arg id="S2.E1.m1.7.7.2.3.1.cmml" xref="S2.E1.m1.7.7.2.3.1"></arg><apply id="S2.E1.m1.7.7.2.3.2.cmml" xref="S2.E1.m1.7.7.2.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.3.2.1.cmml" xref="S2.E1.m1.7.7.2.3.2">subscript</csymbol><max id="S2.E1.m1.7.7.2.3.2.2.cmml" xref="S2.E1.m1.7.7.2.3.2.2"></max><apply id="S2.E1.m1.7.7.2.3.2.3.cmml" xref="S2.E1.m1.7.7.2.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.3.2.3.1.cmml" xref="S2.E1.m1.7.7.2.3.2.3">subscript</csymbol><ci id="S2.E1.m1.7.7.2.3.2.3.2.cmml" xref="S2.E1.m1.7.7.2.3.2.3.2">𝑞</ci><ci id="S2.E1.m1.7.7.2.3.2.3.3.cmml" xref="S2.E1.m1.7.7.2.3.2.3.3">𝑡</ci></apply></apply></apply><apply id="S2.E1.m1.7.7.2.1.cmml" xref="S2.E1.m1.7.7.2.1"><apply id="S2.E1.m1.7.7.2.1.2.cmml" xref="S2.E1.m1.7.7.2.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.1.2.1.cmml" xref="S2.E1.m1.7.7.2.1.2">superscript</csymbol><apply id="S2.E1.m1.7.7.2.1.2.2.cmml" xref="S2.E1.m1.7.7.2.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.1.2.2.1.cmml" xref="S2.E1.m1.7.7.2.1.2">subscript</csymbol><sum id="S2.E1.m1.7.7.2.1.2.2.2.cmml" xref="S2.E1.m1.7.7.2.1.2.2.2"></sum><apply id="S2.E1.m1.7.7.2.1.2.2.3.cmml" xref="S2.E1.m1.7.7.2.1.2.2.3"><eq id="S2.E1.m1.7.7.2.1.2.2.3.1.cmml" xref="S2.E1.m1.7.7.2.1.2.2.3.1"></eq><ci id="S2.E1.m1.7.7.2.1.2.2.3.2.cmml" xref="S2.E1.m1.7.7.2.1.2.2.3.2">𝑖</ci><cn id="S2.E1.m1.7.7.2.1.2.2.3.3.cmml" type="integer" xref="S2.E1.m1.7.7.2.1.2.2.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1"><abs id="S2.E1.m1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2"></abs><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2">𝑞</ci><ci id="S2.E1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3">𝑡</ci></apply></apply></apply><apply id="S2.E1.m1.7.7.2.1.1.cmml" xref="S2.E1.m1.7.7.2.1.1"><times id="S2.E1.m1.7.7.2.1.1.2.cmml" xref="S2.E1.m1.7.7.2.1.1.2"></times><apply id="S2.E1.m1.7.7.2.1.1.3.cmml" xref="S2.E1.m1.7.7.2.1.1.3"><log id="S2.E1.m1.7.7.2.1.1.3.1.cmml" xref="S2.E1.m1.7.7.2.1.1.3.1"></log><ci id="S2.E1.m1.7.7.2.1.1.3.2.cmml" xref="S2.E1.m1.7.7.2.1.1.3.2">𝑝</ci></apply><apply id="S2.E1.m1.7.7.2.1.1.1.1.1.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.7.7.2.1.1.1.1.1.2.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.2">conditional</csymbol><apply id="S2.E1.m1.7.7.2.1.1.1.1.1.3.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.7.7.2.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.3.2">𝑤</ci><ci id="S2.E1.m1.7.7.2.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.3.3">𝑖</ci></apply><list id="S2.E1.m1.7.7.2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1"><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">𝑐</ci><ci id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5">𝑡</ci><apply id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1"><times id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.1"></times><apply id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.2">𝑤</ci><cn id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.3.cmml" type="integer" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.2.3">1</cn></apply><ci id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.3">…</ci><apply id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.1.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.2.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.2">𝑤</ci><apply id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3"><minus id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.1.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.1"></minus><ci id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.2.cmml" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.2">𝑖</ci><cn id="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.3.cmml" type="integer" xref="S2.E1.m1.7.7.2.1.1.1.1.1.1.1.1.4.3.3">1</cn></apply></apply></apply></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.7c">\hat{q_{t}}=\arg\max_{q_{t}}p({q_{t}}|{c},{t})=\arg\max_{q_{t}}\sum_{i=1}^{|{q%
_{t}}|}\log p(w_{i}|{c},{t},w_{1}\dots w_{i-1})</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.7d">over^ start_ARG italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG = roman_arg roman_max start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_p ( italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c , italic_t ) = roman_arg roman_max start_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | end_POSTSUPERSCRIPT roman_log italic_p ( italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_c , italic_t , italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT … italic_w start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.2">where, <math alttext="p({q_{t}}|{c},{t})" class="ltx_Math" display="inline" id="S2.SS1.p5.1.m1.3"><semantics id="S2.SS1.p5.1.m1.3a"><mrow id="S2.SS1.p5.1.m1.3.3" xref="S2.SS1.p5.1.m1.3.3.cmml"><mi id="S2.SS1.p5.1.m1.3.3.3" xref="S2.SS1.p5.1.m1.3.3.3.cmml">p</mi><mo id="S2.SS1.p5.1.m1.3.3.2" xref="S2.SS1.p5.1.m1.3.3.2.cmml">⁢</mo><mrow id="S2.SS1.p5.1.m1.3.3.1.1" xref="S2.SS1.p5.1.m1.3.3.1.1.1.cmml"><mo id="S2.SS1.p5.1.m1.3.3.1.1.2" stretchy="false" xref="S2.SS1.p5.1.m1.3.3.1.1.1.cmml">(</mo><mrow id="S2.SS1.p5.1.m1.3.3.1.1.1" xref="S2.SS1.p5.1.m1.3.3.1.1.1.cmml"><msub id="S2.SS1.p5.1.m1.3.3.1.1.1.2" xref="S2.SS1.p5.1.m1.3.3.1.1.1.2.cmml"><mi id="S2.SS1.p5.1.m1.3.3.1.1.1.2.2" xref="S2.SS1.p5.1.m1.3.3.1.1.1.2.2.cmml">q</mi><mi id="S2.SS1.p5.1.m1.3.3.1.1.1.2.3" xref="S2.SS1.p5.1.m1.3.3.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.SS1.p5.1.m1.3.3.1.1.1.1" xref="S2.SS1.p5.1.m1.3.3.1.1.1.1.cmml">|</mo><mrow id="S2.SS1.p5.1.m1.3.3.1.1.1.3.2" xref="S2.SS1.p5.1.m1.3.3.1.1.1.3.1.cmml"><mi id="S2.SS1.p5.1.m1.1.1" xref="S2.SS1.p5.1.m1.1.1.cmml">c</mi><mo id="S2.SS1.p5.1.m1.3.3.1.1.1.3.2.1" xref="S2.SS1.p5.1.m1.3.3.1.1.1.3.1.cmml">,</mo><mi id="S2.SS1.p5.1.m1.2.2" xref="S2.SS1.p5.1.m1.2.2.cmml">t</mi></mrow></mrow><mo id="S2.SS1.p5.1.m1.3.3.1.1.3" stretchy="false" xref="S2.SS1.p5.1.m1.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.1.m1.3b"><apply id="S2.SS1.p5.1.m1.3.3.cmml" xref="S2.SS1.p5.1.m1.3.3"><times id="S2.SS1.p5.1.m1.3.3.2.cmml" xref="S2.SS1.p5.1.m1.3.3.2"></times><ci id="S2.SS1.p5.1.m1.3.3.3.cmml" xref="S2.SS1.p5.1.m1.3.3.3">𝑝</ci><apply id="S2.SS1.p5.1.m1.3.3.1.1.1.cmml" xref="S2.SS1.p5.1.m1.3.3.1.1"><csymbol cd="latexml" id="S2.SS1.p5.1.m1.3.3.1.1.1.1.cmml" xref="S2.SS1.p5.1.m1.3.3.1.1.1.1">conditional</csymbol><apply id="S2.SS1.p5.1.m1.3.3.1.1.1.2.cmml" xref="S2.SS1.p5.1.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p5.1.m1.3.3.1.1.1.2.1.cmml" xref="S2.SS1.p5.1.m1.3.3.1.1.1.2">subscript</csymbol><ci id="S2.SS1.p5.1.m1.3.3.1.1.1.2.2.cmml" xref="S2.SS1.p5.1.m1.3.3.1.1.1.2.2">𝑞</ci><ci id="S2.SS1.p5.1.m1.3.3.1.1.1.2.3.cmml" xref="S2.SS1.p5.1.m1.3.3.1.1.1.2.3">𝑡</ci></apply><list id="S2.SS1.p5.1.m1.3.3.1.1.1.3.1.cmml" xref="S2.SS1.p5.1.m1.3.3.1.1.1.3.2"><ci id="S2.SS1.p5.1.m1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1">𝑐</ci><ci id="S2.SS1.p5.1.m1.2.2.cmml" xref="S2.SS1.p5.1.m1.2.2">𝑡</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.1.m1.3c">p({q_{t}}|{c},{t})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.1.m1.3d">italic_p ( italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c , italic_t )</annotation></semantics></math> denotes the conditional probability that also depends on the tokens <math alttext="w\in q_{t}" class="ltx_Math" display="inline" id="S2.SS1.p5.2.m2.1"><semantics id="S2.SS1.p5.2.m2.1a"><mrow id="S2.SS1.p5.2.m2.1.1" xref="S2.SS1.p5.2.m2.1.1.cmml"><mi id="S2.SS1.p5.2.m2.1.1.2" xref="S2.SS1.p5.2.m2.1.1.2.cmml">w</mi><mo id="S2.SS1.p5.2.m2.1.1.1" xref="S2.SS1.p5.2.m2.1.1.1.cmml">∈</mo><msub id="S2.SS1.p5.2.m2.1.1.3" xref="S2.SS1.p5.2.m2.1.1.3.cmml"><mi id="S2.SS1.p5.2.m2.1.1.3.2" xref="S2.SS1.p5.2.m2.1.1.3.2.cmml">q</mi><mi id="S2.SS1.p5.2.m2.1.1.3.3" xref="S2.SS1.p5.2.m2.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.2.m2.1b"><apply id="S2.SS1.p5.2.m2.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1"><in id="S2.SS1.p5.2.m2.1.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1.1"></in><ci id="S2.SS1.p5.2.m2.1.1.2.cmml" xref="S2.SS1.p5.2.m2.1.1.2">𝑤</ci><apply id="S2.SS1.p5.2.m2.1.1.3.cmml" xref="S2.SS1.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p5.2.m2.1.1.3.1.cmml" xref="S2.SS1.p5.2.m2.1.1.3">subscript</csymbol><ci id="S2.SS1.p5.2.m2.1.1.3.2.cmml" xref="S2.SS1.p5.2.m2.1.1.3.2">𝑞</ci><ci id="S2.SS1.p5.2.m2.1.1.3.3.cmml" xref="S2.SS1.p5.2.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.2.m2.1c">w\in q_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.2.m2.1d">italic_w ∈ italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中， <math id="S2.SS1.p5.1.m1.3" display="inline" class="ltx_Math" alttext="p({q_{t}}|{c},{t})"><semantics id="S2.SS1.p5.1.m1.3a"><mrow id="S2.SS1.p5.1.m1.3.3"><mi id="S2.SS1.p5.1.m1.3.3.3">p</mi><mo id="S2.SS1.p5.1.m1.3.3.2">⁢</mo><mrow id="S2.SS1.p5.1.m1.3.3.1.1"><mo stretchy="false" id="S2.SS1.p5.1.m1.3.3.1.1.2">(</mo><mrow id="S2.SS1.p5.1.m1.3.3.1.1.1"><msub id="S2.SS1.p5.1.m1.3.3.1.1.1.2"><mi id="S2.SS1.p5.1.m1.3.3.1.1.1.2.2">q</mi><mi id="S2.SS1.p5.1.m1.3.3.1.1.1.2.3">t</mi></msub><mo id="S2.SS1.p5.1.m1.3.3.1.1.1.1" fence="false">|</mo><mrow id="S2.SS1.p5.1.m1.3.3.1.1.1.3.2"><mi id="S2.SS1.p5.1.m1.1.1">c</mi><mo id="S2.SS1.p5.1.m1.3.3.1.1.1.3.2.1">,</mo><mi id="S2.SS1.p5.1.m1.2.2">t</mi></mrow></mrow><mo stretchy="false" id="S2.SS1.p5.1.m1.3.3.1.1.3">)</mo></mrow></mrow><annotation-xml id="S2.SS1.p5.1.m1.3b" encoding="MathML-Content">conditionalsubscript</annotation-xml><annotation id="S2.SS1.p5.1.m1.3c" encoding="application/x-tex">p({q_{t}}|{c},{t})</annotation><annotation id="S2.SS1.p5.1.m1.3d" encoding="application/x-llamapun">italic_p ( italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_c , italic_t )</annotation></semantics></math> 表示的条件概率也取决于 <math id="S2.SS1.p5.2.m2.1" display="inline" class="ltx_Math" alttext="w\in q_{t}"><semantics id="S2.SS1.p5.2.m2.1a"><mrow id="S2.SS1.p5.2.m2.1.1"><mi id="S2.SS1.p5.2.m2.1.1.2">w</mi><mo id="S2.SS1.p5.2.m2.1.1.1">∈</mo><msub id="S2.SS1.p5.2.m2.1.1.3"><mi id="S2.SS1.p5.2.m2.1.1.3.2">q</mi><mi id="S2.SS1.p5.2.m2.1.1.3.3">t</mi></msub></mrow><annotation-xml id="S2.SS1.p5.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S2.SS1.p5.2.m2.1c" encoding="application/x-tex">w\in q_{t}</annotation><annotation id="S2.SS1.p5.2.m2.1d" encoding="application/x-llamapun">italic_w ∈ italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 标记。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Related Work<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.2. 相关工作</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Question Generation (QG) involves automatically generating questions from a specific text passage or a document. The main goal of QG is to produce questions that are not only syntactically and semantically correct but also contextually relevant and meaningful for the intended use. There has been a growing use of computational models to generate contextually relevant and grammatically correct questions <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib55" title="">2024</a>)</cite>. In educational contexts specifically, QG has been implemented in various systems including intelligent tutoring systems <cite class="ltx_cite ltx_citemacro_citep">(Yadav et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib57" title="">2023</a>)</cite>, writing support systems <cite class="ltx_cite ltx_citemacro_citep">(Pinto et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib47" title="">2023</a>)</cite>, and knowledge assessment platforms <cite class="ltx_cite ltx_citemacro_citep">(Kuo et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib37" title="">2023</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">问题生成（QG）涉及从特定文本段落或文档中自动生成问题。QG 的主要目标是产生不仅语法和语义正确，而且对预期用途具有上下文相关性和意义的问题。近年来，计算模型被越来越多地用于生成上下文相关且语法正确的问题（Wang 等人，2024）。在教育领域，QG 已被应用于各种系统，包括智能辅导系统（Yadav 等人，2023）、写作支持系统（Pinto 等人，2023）和知识评估平台（Kuo 等人，2023）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Existing research categorises QG into two types: answer-aware and answer-agnostic <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib60" title="">2021</a>)</cite>. In <em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.1.1">answer-aware</em> QG, the target answer is predetermined, and questions are generated to correspond with this answer within the given text context. On the other hand, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.1.2">answer-agnostic</em> QG does not provide the target answer to the language model, allowing for more open-ended question generation which are considered to be educationally more valuable. However, answer-agnostic QG is a more challenging task for NLP research. Early research in answer-agnostic QG relied heavily on rule-based techniques that required experienced educators to develop rules that could convert declarative sentences into interrogative forms <cite class="ltx_cite ltx_citemacro_citep">(Heilman and Smith, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib34" title="">2010</a>; Adamson et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib2" title="">2013</a>)</cite>. These methods, while effective, are labour-intensive and time-consuming, demanding significant manual effort in creating high-quality, handcrafted rules <cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib12" title="">2021</a>)</cite>, which inherently limits their scalability and diversity in question generation. These limitations led more recent research investigations to focus on data-driven neural network (NN) approaches.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">现有研究将问题生成（QG）分为两种类型：答案感知型与答案非感知型（Zhang 等人，2021）。在答案感知型 QG 中，目标答案预先确定，问题生成是为了在给定文本语境中与该答案相对应。另一方面，答案非感知型 QG 不向语言模型提供目标答案，允许生成更开放的问题，这些问题被认为在教育上更有价值。然而，答案非感知型 QG 对自然语言处理（NLP）研究来说是一项更具挑战性的任务。早期的答案非感知型 QG 研究高度依赖基于规则的技巧，这些技巧需要经验丰富的教育者开发规则，将陈述句转换为疑问句形式（Heilman 和 Smith，2010；Adamson 等人，2013）。虽然这些方法有效，但它们劳动密集且耗时，需要大量人工工作来创建高质量的手工规则（Chen 等人，2021），这本质上限制了它们在问题生成中的可扩展性和多样性。这些局限性促使近期的研究更多地关注数据驱动的神经网络（NN）方法。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Early implementations of QG practices with data-driven approaches predominantly utilized sequence-to-sequence (seq2seq) architectures incorporating Recurrent Neural Networks (RNNs) <cite class="ltx_cite ltx_citemacro_citep">(Du et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib23" title="">2017</a>)</cite>. More recently, the focus shifted towards employing end-to-end techniques facilitated by deep neural networks <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib60" title="">2021</a>)</cite>. For instance, <cite class="ltx_cite ltx_citemacro_citep">(Dathathri et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib17" title="">2020</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Khalifa et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib36" title="">2021</a>)</cite> utilised GPT-2 combined with either an attribute classifier or training another autoregressive language model to guide the generated text towards a topic. However, these approaches typically generated content that is too broadly categorised (such as a category being ’science’), failing to achieve the level of topic specificity required for them to be of real-world value for educational practitioners. On the other hand, a more targeted approach by <cite class="ltx_cite ltx_citemacro_citep">(Hu et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib35" title="">2018</a>)</cite> employing an LSTM model equipped with a pre-decoding mechanism, demonstrated the ability to generate questions on detailed topics. This model, though promising in its specificity, was only applied at the sentence level, limiting its utility for broader educational applications. More contemporary models leverage pre-trained transformers like GPT <cite class="ltx_cite ltx_citemacro_citep">(Blobstein et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib6" title="">2023</a>; Elkins et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib24" title="">2024</a>)</cite> (Decoder Only) and T5 (Text-to-Text Transfer Transformer) <cite class="ltx_cite ltx_citemacro_citep">(Vachev et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib54" title="">2022</a>; Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib8" title="">2023</a>)</cite> (Endoder-Decoder). These advanced NLP approaches like transformer architectures have shown to be effective in generating coherent and relevant questions for specified texts <cite class="ltx_cite ltx_citemacro_citep">(Faraby et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib25" title="">2024</a>)</cite>. However, their use in meaningful and relevant educational question generation needs further explorations and evaluations in educational contexts <cite class="ltx_cite ltx_citemacro_citep">(Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib8" title="">2023</a>; Vachev et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib54" title="">2022</a>)</cite>. In short, the problem of topic-specific question generation as scoped in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S2.SS1" title="2.1. Problem Definition ‣ 2. Problem Definition, Background Research, and Research Questions ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2.1</span></a> has been of interest to multiple researchers in the past, yet it is still an open challenge for the community.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">早期采用数据驱动方法进行 QG 实践主要使用了包含循环神经网络（RNNs）的序列到序列（seq2seq）架构（Du 等人，2017）。最近，研究重点转向采用深度神经网络支持端到端技术（Zhang 等人，2021）。例如，（Dathathri 等人，2020）和（Khalifa 等人，2021）利用 GPT-2 结合属性分类器或训练另一个自回归语言模型来引导生成文本朝向特定主题。然而，这些方法通常生成过于宽泛分类的内容（例如一个类别为“科学”），未能达到所需的主题特异性，因此对于教育实践者而言缺乏实际应用价值。另一方面，（Hu 等人，2018）采用配备预解码机制的 LSTM 模型进行更具针对性的方法，展示了生成详细主题问题的能力。尽管该模型在特异性方面具有前景，但仅应用于句子级别，限制了其在更广泛教育应用中的实用性。 更多现代模型利用预训练的转换器，如 GPT（Blobstein 等人，2023 年；Elkins 等人，2024 年）（仅解码器）和 T5（文本到文本迁移转换器）（Vachev 等人，2022 年；Bulathwela 等人，2023 年）（编码器-解码器）。这些先进的自然语言处理方法，如转换器架构，已被证明在为指定文本生成连贯且相关的问题方面是有效的（Faraby 等人，2024 年）。然而，它们在教育环境中生成有意义且相关的问题方面的应用需要进一步探索和评估（Bulathwela 等人，2023 年；Vachev 等人，2022 年）。简而言之，如第 2.1 节所述的特定主题问题生成问题，过去一直引起多位研究人员的兴趣，但它仍然是一个开放的挑战。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">One of the significant challenges in research utilising pre-trained transformer architectures for the scoped problem is the issue of making generated content more specifically aligned with the particular topics studied and its contextual considerations. Previous literature in AI in Education research proposed multiple approaches when linking knowledge components of topics to generated learning materials such as questions. The most common approach is expert human labelling, but it is challenging to be scaled even though its accuracy is unmatched <cite class="ltx_cite ltx_citemacro_citep">(Yudelson et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib58" title="">2013</a>)</cite> and considered as gold-standard. Due to the scaling challenges of expert human labelling, recent works have also proposed methods such as entity linking <cite class="ltx_cite ltx_citemacro_citep">(Brank et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib7" title="">2017</a>; Ferragina and Scaiella, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib28" title="">2010</a>)</cite> that provide scalability even if it tends to sacrifice some accuracy. Another proposed approach is the so-called ”Wikification” which is the practice of using Wikipedia as a source for semantic annotations <cite class="ltx_cite ltx_citemacro_citep">(Zhang and Rettinger, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib59" title="">2014</a>)</cite>. The approach has demonstrated significant advancements in recent years and offers considerable potential for automatically extracting concepts from Wikipedia entries to generate topic-specific educational materials <cite class="ltx_cite ltx_citemacro_citep">(Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib10" title="">2021</a>)</cite>. Additionally, since there has been extensive research on Wikipedia for its potential for semantic labelling of AI-generated content, its concept relatedness metrics that are based on its link structure, page co-occurrence etc. <cite class="ltx_cite ltx_citemacro_citep">(Ponza et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib48" title="">2020</a>)</cite> are well developed and can represent semantic relatedness between Wikipedia concepts to a high accuracy. However, the use of approaches that allow scalable solutions such as Wikification <cite class="ltx_cite ltx_citemacro_citep">(Brank et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib7" title="">2017</a>)</cite> in educational question generation models is yet to be explored in detail in learning analytics.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在利用预训练的 Transformer 架构进行特定领域问题的研究中，一个重要的挑战是如何使生成内容更精确地与所研究的具体主题相一致，并考虑其上下文因素。AI 教育研究领域的先前文献在将主题的知识组件与生成式学习材料（如问题）联系起来时，提出了多种方法。最常见的方法是专家人工标注，尽管其准确率无与伦比（Yudelson 等，2013 年）并被视为黄金标准，但这种方法难以扩展。由于专家人工标注的扩展挑战，近期的研究也提出了诸如实体链接（Brank 等，2017 年；Ferragina 和 Scaiella，2010 年）等方法，这些方法虽然倾向于牺牲一些准确率，但提供了可扩展性。另一种提出的方法是所谓的“维基化”，即使用维基百科作为语义标注的来源（Zhang 和 Rettinger，2014 年）。 该方法近年来取得了显著进展，并展现出相当大的潜力，能够自动从维基百科条目中提取概念，以生成特定主题的教育材料（Bulathwela 等人，2021）。此外，鉴于维基百科在语义标注人工智能生成内容方面的潜力已得到广泛研究，其基于链接结构、页面共现等概念相关度指标（Ponza 等人，2020）已相当成熟，能够以高精度表示维基百科概念之间的语义相关性。然而，在学习教育分析中，尚未详细探索允许可扩展解决方案（如 Wikification，Brank 等人，2017）在教育问题生成模型中的应用。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Research Questions<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.3 研究问题</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">This paper aims to address these challenges associated with the topic-controlled EdGQ. We conducted supervised fine-tuning on a pre-trained T5-small model (hereafter referred to as the T5 model), an approach that is preferable and safer for educational entities to manage and control the language model (LM) with minimal infrastructure costs. The fine-tuning process utilised the novel MixSQuAD dataset, an enrichment of the SQuAD dataset <cite class="ltx_cite ltx_citemacro_citep">(Rajpurkar et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib51" title="">2016</a>)</cite>, which is a commonly used general question generation dataset characterised by its shallow questions. Additionally, we designed experiments to explore the impacts of pre-training strategies, text data augmentation, and model quantisation on the model’s performance. We evaluated the model on the novel MixKhanQ dataset, derived based on the KhanQ dataset <cite class="ltx_cite ltx_citemacro_citep">(Gong and Pan, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib32" title="">2022</a>)</cite>, which features human-like, in-depth questions sourced from Khan Academy, an online education platform. This is designed to assess the model’s effectiveness on academic materials, and its ability to generate educationally meaningful questions to explore its practical value for teaching and learning contexts. Based on these steps, the paper proposes a novel set of models that can perform high-precision topic-controlled educational question generation (T-CQG). The research questions addressed through this work are as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本文旨在解决与主题控制型教育问题生成（EdGQ）相关挑战。我们对预训练的 T5-small 模型（以下简称 T5 模型）进行了监督微调，这是一种更适合教育机构管理和控制语言模型（LM），且基础设施成本最低的方法。微调过程使用了新型 MixSQuAD 数据集，该数据集是对 SQuAD 数据集（Rajpurkar 等人，2016 年）的扩展，后者是一个常用的通用问题生成数据集，其特点是问题较为浅显。此外，我们设计了实验，探索了预训练策略、文本数据增强和模型量化对模型性能的影响。我们在基于 KhanQ 数据集（Gong 和 Pan，2022 年）衍生的新型 MixKhanQ 数据集上评估了模型，该数据集具有类似人类、深入的问题，来源于在线教育平台可汗学院。这是为了评估模型在学术材料上的有效性，以及其生成教育意义问题的能力，以探索其在教学和学习环境中的实际价值。 基于这些步骤，论文提出了一套新型模型，能够实现高精度的主题控制教育问题生成（T-CQG）。本研究通过这项工作解决的研究问题如下：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">RQ1:</span> What are the most representative metrics for automated measures of generated questions on their topic relevance considering human evaluations as the ground truth?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• RQ1：在将人类评估作为基准的情况下，哪些是最能代表自动生成的主题相关性的问题度量指标？</font></font></font>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">RQ2:</span> Is it feasible to fine-tune a pre-trained language model (PLM) to perform T-CQG?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• RQ2：是否可行通过微调预训练语言模型（PLM）来执行 T-CQG？</font></font></font>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">RQ3:</span> Can further pre-training of the PLM on scientific text improve the quality of T-CQG?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• RQ3: 对 PLM 进行进一步的科学文本预训练能否提高 T-CQG 的质量？</font></font></font>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">RQ4:</span> How does model quantisation affect the performance of the fine-tuned models while improving scalability?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• RQ4: 模型量化如何在提高可扩展性的同时影响微调模型的性能？</font></font></font>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">RQ5:</span> To what extent can data augmentation further improve the quality of T-CQG?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• RQ5: 数据增强能在多大程度上进一步提高 T-CQG 的质量？</font></font></font>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3. 方法论</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Datasets Utilised<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1.使用的数据集</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We used the SQuAD 1.1, the Stanford Question Answering Dataset, comprising over 100,000 questions crafted by crowd workers based on a selection of 536 Wikipedia articles <cite class="ltx_cite ltx_citemacro_citep">(Rajpurkar et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib51" title="">2016</a>)</cite> as the source for creating new datasets (SQuAD+, MixSQuAD and MixSQuAD2X as described in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2" title="3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.2</span></a> below) for finetuning the models. When training the TopicQGedu Model (see section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3.SSS3" title="3.3.3. TopicQGedu to Answer RQ3 ‣ 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.3.3</span></a> below), we used PeS2O dataset <cite class="ltx_cite ltx_citemacro_citep">(Soldaini and Lo, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib52" title="">2023</a>)</cite>, a collection of scientific abstracts, to perform the pre-training as prior work has shown this may increase the model’s performance in educational settings <cite class="ltx_cite ltx_citemacro_citep">(Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib8" title="">2023</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用了斯坦福问答数据集 SQuAD 1.1，该数据集包含超过 10 万个由众包工作者基于 536 篇维基百科文章（Rajpurkar 等人，2016 年）编写的问题，作为创建新数据集（如 3.2 节下所述的 SQuAD+、MixSQuAD 和 MixSQuAD2X）的来源，用于微调模型。在训练主题控制教育问题生成模型（见 3.3.3 节下）时，我们使用了 PeS2O 数据集（Soldaini 和 Lo，2023 年），这是一个科学摘要的集合，用于进行预训练，因为先前研究表明这可能会提高模型在教育环境中的性能（Bulathwela 等人，2023 年）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">For evaluation, we used the KhanQ dataset <cite class="ltx_cite ltx_citemacro_citep">(Gong and Pan, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib32" title="">2022</a>)</cite> as it presents a more relevant challenge for educational question generation. It includes 1,034 high-quality questions in the STEM fields generated by learners, which aim to probe deep understanding of subjects taught in Khan Academy’s online courses <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.khanacademy.org/" title="">https://www.khanacademy.org</a></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为评估，我们使用了 KhanQ 数据集（Gong 和 Pan，2022），因为它为教育问题生成提出了更具相关性的挑战。它包含 1,034 个由学习者生成的 STEM 领域高质量问题，旨在探究 Khan Academy 在线课程中教授内容的深度理解。 <sup class="ltx_note_mark">1</sup> </font></font></font>. Despite its smaller size relative to SQuAD, KhanQ aligns more closely with our objective to generate topic-based and relevant educational questions (as per prior work <cite class="ltx_cite ltx_citemacro_citep">(Fawzi et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib27" title="">2024</a>)</cite>). To adapt the dataset for topic-based evaluation, we use the same approach as MixSQuAD (section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS2" title="3.2.2. MixSQuAD dataset ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>) to create a dataset with contrasting topic-based questions. We refer to the transformed version of the KhanQ dataset as <em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.1.1">MixKhanQ</em> dataset.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管相对于 SQuAD 来说规模较小，但 KhanQ 与我们的目标——生成基于主题的相关教育问题（根据先前工作（Fawzi 等人，2024））——更为一致。为了使数据集适应基于主题的评估，我们采用与 MixSQuAD（第 3.2.2 节）相同的方法来创建一个具有对比性主题问题的数据集。我们将转换后的 KhanQ 数据集版本称为 MixKhanQ 数据集。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Creating Novel Datasets for T-CQG<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.C.创建用于 T-CQG 的新数据集</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">A core contribution of this work is to introduce a novel data enrichment method that leads to the creation of new datasets that are derived from conventional question generation datasets. As described in <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS1" title="3.1. Datasets Utilised ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.1</span></a>, we derive the new datasets from SQuAD and KhanQ. These datasets already contain the context <math alttext="c" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_c</annotation></semantics></math> and the <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.4.1">label</em> question <math alttext="q_{t}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">q</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝑞</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> from a human (contrast to <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msub id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mover accent="true" id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2.2" xref="S3.SS2.p1.3.m3.1.1.2.2.cmml">q</mi><mo id="S3.SS2.p1.3.m3.1.1.2.1" xref="S3.SS2.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">subscript</csymbol><apply id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2"><ci id="S3.SS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.p1.3.m3.1.1.2.1">^</ci><ci id="S3.SS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2.2">𝑞</ci></apply><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> in equation <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S2.E1" title="In 2.1. Problem Definition ‣ 2. Problem Definition, Background Research, and Research Questions ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">1</span></a> which denotes the <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.4.2">generated</em> question). We append an additional field to the dataset, <em class="ltx_emph ltx_font_italic" id="S3.SS2.p1.4.3">Topic</em> <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_t</annotation></semantics></math>, and create three novel datasets, 1) SQuAD+, 2) MixSQuAD, and 3) MixSQuAD2X for the T-CQG task. The process of generating the three datasets is presented in figure <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.F1" title="Figure 1 ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">1</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这项工作的核心贡献是引入了一种新的数据增强方法，该方法能够从传统的问答生成数据集中创建新的数据集。如 3.1 所述，我们从 SQuAD 和 KhanQ 中推导出这些新数据集。这些数据集已经包含了人类提供的上下文 <math id="S3.SS2.p1.1.m1.1" display="inline" class="ltx_Math" alttext="c"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1">c</mi><annotation-xml id="S3.SS2.p1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS2.p1.1.m1.1c" encoding="application/x-tex">c</annotation><annotation id="S3.SS2.p1.1.m1.1d" encoding="application/x-llamapun">italic_c</annotation></semantics></math> 和标签问题 <math id="S3.SS2.p1.2.m2.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1"><mi id="S3.SS2.p1.2.m2.1.1.2">q</mi><mi id="S3.SS2.p1.2.m2.1.1.3">t</mi></msub><annotation-xml id="S3.SS2.p1.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS2.p1.2.m2.1c" encoding="application/x-tex">q_{t}</annotation><annotation id="S3.SS2.p1.2.m2.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> （与方程 1 中的 <math id="S3.SS2.p1.3.m3.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S3.SS2.p1.3.m3.1a"><msub id="S3.SS2.p1.3.m3.1.1"><mover id="S3.SS2.p1.3.m3.1.1.2" accent="true"><mi id="S3.SS2.p1.3.m3.1.1.2.2">q</mi><mo id="S3.SS2.p1.3.m3.1.1.2.1">^</mo></mover><mi id="S3.SS2.p1.3.m3.1.1.3">t</mi></msub><annotation-xml id="S3.SS2.p1.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS2.p1.3.m3.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S3.SS2.p1.3.m3.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 表示生成的问句形成对比）。我们向数据集添加了一个额外的字段——主题 <math id="S3.SS2.p1.4.m4.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1">t</mi><annotation-xml id="S3.SS2.p1.4.m4.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS2.p1.4.m4.1c" encoding="application/x-tex">t</annotation><annotation id="S3.SS2.p1.4.m4.1d" encoding="application/x-llamapun">italic_t</annotation></semantics></math> ，并创建了三个新的数据集，用于 T-CQG 任务：1) SQuAD+，2) MixSQuAD，3) MixSQuAD2X。生成这三个数据集的过程如图 1 所示。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="186" id="S3.F1.1.g1" src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/x1.png" width="523">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Methodology for generating the different training datasets proposed in the model from the contexts <math alttext="c" class="ltx_Math" display="inline" id="S3.F1.9.8.m1.1"><semantics id="S3.F1.9.8.m1.1b"><mi id="S3.F1.9.8.m1.1.1" xref="S3.F1.9.8.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.F1.9.8.m1.1c"><ci id="S3.F1.9.8.m1.1.1.cmml" xref="S3.F1.9.8.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.9.8.m1.1d">c</annotation><annotation encoding="application/x-llamapun" id="S3.F1.9.8.m1.1e">italic_c</annotation></semantics></math>, topics <math alttext="t" class="ltx_Math" display="inline" id="S3.F1.10.9.m2.1"><semantics id="S3.F1.10.9.m2.1b"><mi id="S3.F1.10.9.m2.1.1" xref="S3.F1.10.9.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.F1.10.9.m2.1c"><ci id="S3.F1.10.9.m2.1.1.cmml" xref="S3.F1.10.9.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.10.9.m2.1d">t</annotation><annotation encoding="application/x-llamapun" id="S3.F1.10.9.m2.1e">italic_t</annotation></semantics></math> and target questions <math alttext="q_{t}" class="ltx_Math" display="inline" id="S3.F1.11.10.m3.1"><semantics id="S3.F1.11.10.m3.1b"><msub id="S3.F1.11.10.m3.1.1" xref="S3.F1.11.10.m3.1.1.cmml"><mi id="S3.F1.11.10.m3.1.1.2" xref="S3.F1.11.10.m3.1.1.2.cmml">q</mi><mi id="S3.F1.11.10.m3.1.1.3" xref="S3.F1.11.10.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F1.11.10.m3.1c"><apply id="S3.F1.11.10.m3.1.1.cmml" xref="S3.F1.11.10.m3.1.1"><csymbol cd="ambiguous" id="S3.F1.11.10.m3.1.1.1.cmml" xref="S3.F1.11.10.m3.1.1">subscript</csymbol><ci id="S3.F1.11.10.m3.1.1.2.cmml" xref="S3.F1.11.10.m3.1.1.2">𝑞</ci><ci id="S3.F1.11.10.m3.1.1.3.cmml" xref="S3.F1.11.10.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.11.10.m3.1d">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.F1.11.10.m3.1e">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> (shaded as label) from the SQuAD dataset is illustrated using two random examples from the dataset, example <math alttext="i" class="ltx_Math" display="inline" id="S3.F1.12.11.m4.1"><semantics id="S3.F1.12.11.m4.1b"><mi id="S3.F1.12.11.m4.1.1" xref="S3.F1.12.11.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.F1.12.11.m4.1c"><ci id="S3.F1.12.11.m4.1.1.cmml" xref="S3.F1.12.11.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.12.11.m4.1d">i</annotation><annotation encoding="application/x-llamapun" id="S3.F1.12.11.m4.1e">italic_i</annotation></semantics></math> (green) and example <math alttext="j" class="ltx_Math" display="inline" id="S3.F1.13.12.m5.1"><semantics id="S3.F1.13.12.m5.1b"><mi id="S3.F1.13.12.m5.1.1" xref="S3.F1.13.12.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.F1.13.12.m5.1c"><ci id="S3.F1.13.12.m5.1.1.cmml" xref="S3.F1.13.12.m5.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.13.12.m5.1d">j</annotation><annotation encoding="application/x-llamapun" id="S3.F1.13.12.m5.1e">italic_j</annotation></semantics></math> (pink). The contexts <math alttext="c_{i}" class="ltx_Math" display="inline" id="S3.F1.14.13.m6.1"><semantics id="S3.F1.14.13.m6.1b"><msub id="S3.F1.14.13.m6.1.1" xref="S3.F1.14.13.m6.1.1.cmml"><mi id="S3.F1.14.13.m6.1.1.2" xref="S3.F1.14.13.m6.1.1.2.cmml">c</mi><mi id="S3.F1.14.13.m6.1.1.3" xref="S3.F1.14.13.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F1.14.13.m6.1c"><apply id="S3.F1.14.13.m6.1.1.cmml" xref="S3.F1.14.13.m6.1.1"><csymbol cd="ambiguous" id="S3.F1.14.13.m6.1.1.1.cmml" xref="S3.F1.14.13.m6.1.1">subscript</csymbol><ci id="S3.F1.14.13.m6.1.1.2.cmml" xref="S3.F1.14.13.m6.1.1.2">𝑐</ci><ci id="S3.F1.14.13.m6.1.1.3.cmml" xref="S3.F1.14.13.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.14.13.m6.1d">c_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.F1.14.13.m6.1e">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="c_{j}" class="ltx_Math" display="inline" id="S3.F1.15.14.m7.1"><semantics id="S3.F1.15.14.m7.1b"><msub id="S3.F1.15.14.m7.1.1" xref="S3.F1.15.14.m7.1.1.cmml"><mi id="S3.F1.15.14.m7.1.1.2" xref="S3.F1.15.14.m7.1.1.2.cmml">c</mi><mi id="S3.F1.15.14.m7.1.1.3" xref="S3.F1.15.14.m7.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F1.15.14.m7.1c"><apply id="S3.F1.15.14.m7.1.1.cmml" xref="S3.F1.15.14.m7.1.1"><csymbol cd="ambiguous" id="S3.F1.15.14.m7.1.1.1.cmml" xref="S3.F1.15.14.m7.1.1">subscript</csymbol><ci id="S3.F1.15.14.m7.1.1.2.cmml" xref="S3.F1.15.14.m7.1.1.2">𝑐</ci><ci id="S3.F1.15.14.m7.1.1.3.cmml" xref="S3.F1.15.14.m7.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.15.14.m7.1d">c_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.F1.15.14.m7.1e">italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> glued together are concatenated texts treated as a single field in the dataset. The orange rectangles indicate the scope of the datasets while (*) marks the newly proposed datasets.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 1. 模型中从 SQuAD 数据集的上下文 <math id="S3.F1.9.8.m1.1" display="inline" class="ltx_Math" alttext="c"><semantics id="S3.F1.9.8.m1.1b"><mi id="S3.F1.9.8.m1.1.1">c</mi><annotation-xml id="S3.F1.9.8.m1.1c" encoding="MathML-Content"></annotation-xml><annotation id="S3.F1.9.8.m1.1d" encoding="application/x-tex">c</annotation><annotation id="S3.F1.9.8.m1.1e" encoding="application/x-llamapun">italic_c</annotation></semantics></math> 、主题 <math id="S3.F1.10.9.m2.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S3.F1.10.9.m2.1b"><mi id="S3.F1.10.9.m2.1.1">t</mi><annotation-xml id="S3.F1.10.9.m2.1c" encoding="MathML-Content"></annotation-xml><annotation id="S3.F1.10.9.m2.1d" encoding="application/x-tex">t</annotation><annotation id="S3.F1.10.9.m2.1e" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 和目标问题 <math id="S3.F1.11.10.m3.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S3.F1.11.10.m3.1b"><msub id="S3.F1.11.10.m3.1.1"><mi id="S3.F1.11.10.m3.1.1.2">q</mi><mi id="S3.F1.11.10.m3.1.1.3">t</mi></msub><annotation-xml id="S3.F1.11.10.m3.1c" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.F1.11.10.m3.1d" encoding="application/x-tex">q_{t}</annotation><annotation id="S3.F1.11.10.m3.1e" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> （阴影为标签）生成不同训练数据集的方法，通过数据集中的两个随机示例，示例 <math id="S3.F1.12.11.m4.1" display="inline" class="ltx_Math" alttext="i"><semantics id="S3.F1.12.11.m4.1b"><mi id="S3.F1.12.11.m4.1.1">i</mi><annotation-xml id="S3.F1.12.11.m4.1c" encoding="MathML-Content"></annotation-xml><annotation id="S3.F1.12.11.m4.1d" encoding="application/x-tex">i</annotation><annotation id="S3.F1.12.11.m4.1e" encoding="application/x-llamapun">italic_i</annotation></semantics></math> （绿色）和示例 <math id="S3.F1.13.12.m5.1" display="inline" class="ltx_Math" alttext="j"><semantics id="S3.F1.13.12.m5.1b"><mi id="S3.F1.13.12.m5.1.1">j</mi><annotation-xml id="S3.F1.13.12.m5.1c" encoding="MathML-Content"></annotation-xml><annotation id="S3.F1.13.12.m5.1d" encoding="application/x-tex">j</annotation><annotation id="S3.F1.13.12.m5.1e" encoding="application/x-llamapun">italic_j</annotation></semantics></math> （粉色）进行说明。上下文 <math id="S3.F1.14.13.m6.1" display="inline" class="ltx_Math" alttext="c_{i}"><semantics id="S3.F1.14.13.m6.1b"><msub id="S3.F1.14.13.m6.1.1"><mi id="S3.F1.14.13.m6.1.1.2">c</mi><mi id="S3.F1.14.13.m6.1.1.3">i</mi></msub><annotation-xml id="S3.F1.14.13.m6.1c" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.F1.14.13.m6.1d" encoding="application/x-tex">c_{i}</annotation><annotation id="S3.F1.14.13.m6.1e" encoding="application/x-llamapun">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> 和 <math id="S3.F1.15.14.m7.1" display="inline" class="ltx_Math" alttext="c_{j}"><semantics id="S3.F1.15.14.m7.1b"><msub id="S3.F1.15.14.m7.1.1"><mi id="S3.F1.15.14.m7.1.1.2">c</mi><mi id="S3.F1.15.14.m7.1.1.3">j</mi></msub><annotation-xml id="S3.F1.15.14.m7.1c" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.F1.15.14.m7.1d" encoding="application/x-tex">c_{j}</annotation><annotation id="S3.F1.15.14.m7.1e" encoding="application/x-llamapun">italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> 粘合在一起，是数据集中视为单个字段的连接文本。橙色矩形表示数据集的范围，而(*)标记了新提出的数据集。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Linking the target topic to data points, SQuAD+ dataset<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.1.将目标主题链接到数据点，SQuAD+数据集</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.6">To identify semantic annotations for every context and question, we employ wikification <cite class="ltx_cite ltx_citemacro_citep">(Piccinno and Ferragina, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib46" title="">2014</a>)</cite>, which annotates text inputs with relevant concepts from Wikipedia (<math alttext="T_{c}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.1.m1.1"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><msub id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.1.1.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml">T</mi><mi id="S3.SS2.SSS1.p1.1.m1.1.1.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><apply id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2">𝑇</ci><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">T_{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.1.m1.1d">italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>). We retain the top 5 concepts for each text (context and question) based on their PageRank scores, which reflect the authority of the concept over the annotated text. To make sure that we can link the topical alignment between the question and the context, we only retain examples where at least one common Wikipedia concept is present between the context and the question pair (i.e. —<math alttext="T_{c}\cap T_{q}|\geq 1" class="ltx_math_unparsed" display="inline" id="S3.SS2.SSS1.p1.2.m2.1"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><mrow id="S3.SS2.SSS1.p1.2.m2.1b"><msub id="S3.SS2.SSS1.p1.2.m2.1.1"><mi id="S3.SS2.SSS1.p1.2.m2.1.1.2">T</mi><mi id="S3.SS2.SSS1.p1.2.m2.1.1.3">c</mi></msub><mo id="S3.SS2.SSS1.p1.2.m2.1.2">∩</mo><msub id="S3.SS2.SSS1.p1.2.m2.1.3"><mi id="S3.SS2.SSS1.p1.2.m2.1.3.2">T</mi><mi id="S3.SS2.SSS1.p1.2.m2.1.3.3">q</mi></msub><mo fence="false" id="S3.SS2.SSS1.p1.2.m2.1.4" stretchy="false">|</mo><mo id="S3.SS2.SSS1.p1.2.m2.1.5" lspace="0.167em">≥</mo><mn id="S3.SS2.SSS1.p1.2.m2.1.6">1</mn></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.1c">T_{c}\cap T_{q}|\geq 1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.2.m2.1d">italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ∩ italic_T start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT | ≥ 1</annotation></semantics></math>). We select the concept with the highest PageRank score in the question (most authoritative) as the target topic <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.3.m3.1"><semantics id="S3.SS2.SSS1.p1.3.m3.1a"><mi id="S3.SS2.SSS1.p1.3.m3.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.3.m3.1b"><ci id="S3.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.3.m3.1d">italic_t</annotation></semantics></math>. This method ensures that the most closely related annotation is selected as the topic for each pair, and confirms that the topic is appropriately aligned with both the context and the question, thus avoiding situations where the topic may be relevant to one but not the other. As a result, both datasets have been enhanced to include paragraph-level contexts <math alttext="c" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.4.m4.1"><semantics id="S3.SS2.SSS1.p1.4.m4.1a"><mi id="S3.SS2.SSS1.p1.4.m4.1.1" xref="S3.SS2.SSS1.p1.4.m4.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.4.m4.1b"><ci id="S3.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.4.m4.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.4.m4.1d">italic_c</annotation></semantics></math>, identified topics <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.5.m5.1"><semantics id="S3.SS2.SSS1.p1.5.m5.1a"><mi id="S3.SS2.SSS1.p1.5.m5.1.1" xref="S3.SS2.SSS1.p1.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.5.m5.1b"><ci id="S3.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.5.m5.1d">italic_t</annotation></semantics></math>, and corresponding questions <math alttext="q_{t}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p1.6.m6.1"><semantics id="S3.SS2.SSS1.p1.6.m6.1a"><msub id="S3.SS2.SSS1.p1.6.m6.1.1" xref="S3.SS2.SSS1.p1.6.m6.1.1.cmml"><mi id="S3.SS2.SSS1.p1.6.m6.1.1.2" xref="S3.SS2.SSS1.p1.6.m6.1.1.2.cmml">q</mi><mi id="S3.SS2.SSS1.p1.6.m6.1.1.3" xref="S3.SS2.SSS1.p1.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.6.m6.1b"><apply id="S3.SS2.SSS1.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.6.m6.1.1.1.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.6.m6.1.1.2.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1.2">𝑞</ci><ci id="S3.SS2.SSS1.p1.6.m6.1.1.3.cmml" xref="S3.SS2.SSS1.p1.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.6.m6.1c">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p1.6.m6.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, as shown in figure <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.F1" title="Figure 1 ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">1</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了为每个上下文和问题识别语义标注，我们采用维基化方法（Piccinno 和 Ferragina，2014），该方法使用来自维基百科的相关概念（ <math id="S3.SS2.SSS1.p1.1.m1.1" display="inline" class="ltx_Math" alttext="T_{c}"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><msub id="S3.SS2.SSS1.p1.1.m1.1.1"><mi id="S3.SS2.SSS1.p1.1.m1.1.1.2">T</mi><mi id="S3.SS2.SSS1.p1.1.m1.1.1.3">c</mi></msub><annotation-xml id="S3.SS2.SSS1.p1.1.m1.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS2.SSS1.p1.1.m1.1c" encoding="application/x-tex">T_{c}</annotation><annotation id="S3.SS2.SSS1.p1.1.m1.1d" encoding="application/x-llamapun">italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> ）对文本输入进行标注。我们根据 PageRank 分数保留每个文本（上下文和问题）的前 5 个概念，这些分数反映了概念对标注文本的权威性。为确保我们能够链接问题与上下文之间的主题一致性，我们仅保留上下文和问题对中至少存在一个共同维基百科概念的情况（即— <math id="S3.SS2.SSS1.p1.2.m2.1" display="inline" class="ltx_math_unparsed" alttext="T_{c}\cap T_{q}|\geq 1"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><mrow id="S3.SS2.SSS1.p1.2.m2.1b"><msub id="S3.SS2.SSS1.p1.2.m2.1.1"><mi id="S3.SS2.SSS1.p1.2.m2.1.1.2">T</mi><mi id="S3.SS2.SSS1.p1.2.m2.1.1.3">c</mi></msub><mo id="S3.SS2.SSS1.p1.2.m2.1.2">∩</mo><msub id="S3.SS2.SSS1.p1.2.m2.1.3"><mi id="S3.SS2.SSS1.p1.2.m2.1.3.2">T</mi><mi id="S3.SS2.SSS1.p1.2.m2.1.3.3">q</mi></msub><mo stretchy="false" id="S3.SS2.SSS1.p1.2.m2.1.4" fence="false">|</mo><mo lspace="0.167em" id="S3.SS2.SSS1.p1.2.m2.1.5">≥</mo><mn id="S3.SS2.SSS1.p1.2.m2.1.6">1</mn></mrow><annotation id="S3.SS2.SSS1.p1.2.m2.1c" encoding="application/x-tex">T_{c}\cap T_{q}|\geq 1</annotation><annotation id="S3.SS2.SSS1.p1.2.m2.1d" encoding="application/x-llamapun">italic_T start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ∩ italic_T start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT | ≥ 1</annotation></semantics></math> ）。我们选择问题中 PageRank 分数最高的概念（最具权威性）作为目标主题 <math id="S3.SS2.SSS1.p1.3.m3.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S3.SS2.SSS1.p1.3.m3.1a"><mi id="S3.SS2.SSS1.p1.3.m3.1.1">t</mi><annotation-xml id="S3.SS2.SSS1.p1.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS2.SSS1.p1.3.m3.1c" encoding="application/x-tex">t</annotation><annotation id="S3.SS2.SSS1.p1.3.m3.1d" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 。这种方法确保为每对选择最密切相关的标注作为主题，并确认主题与上下文和问题都适当对齐，从而避免主题可能仅与其中之一相关的情况。因此，两个数据集都已增强，包括段落级别的上下文 <math id="S3.SS2.SSS1.p1.4.m4.1" display="inline" class="ltx_Math" alttext="c"><semantics id="S3.SS2.SSS1.p1.4.m4.1a"><mi id="S3.SS2.SSS1.p1.4.m4.1.1">c</mi><annotation-xml id="S3.SS2.SSS1.p1.4.m4.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS2.SSS1.p1.4.m4.1c" encoding="application/x-tex">c</annotation><annotation id="S3.SS2.SSS1.p1.4.m4.1d" encoding="application/x-llamapun">italic_c</annotation></semantics></math> 、识别的主题 <math id="S3.SS2.SSS1.p1.5.m5.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S3.SS2.SSS1.p1.5.m5.1a"><mi id="S3.SS2.SSS1.p1.5.m5.1.1">t</mi><annotation-xml id="S3.SS2.SSS1.p1.5.m5.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS2.SSS1.p1.5.m5.1c" encoding="application/x-tex">t</annotation><annotation id="S3.SS2.SSS1.p1.5.m5.1d" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 以及相应的问题 <math id="S3.SS2.SSS1.p1.6.m6.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S3.SS2.SSS1.p1.6.m6.1a"><msub id="S3.SS2.SSS1.p1.6.m6.1.1"><mi id="S3.SS2.SSS1.p1.6.m6.1.1.2">q</mi><mi id="S3.SS2.SSS1.p1.6.m6.1.1.3">t</mi></msub><annotation-xml id="S3.SS2.SSS1.p1.6.m6.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS2.SSS1.p1.6.m6.1c" encoding="application/x-tex">q_{t}</annotation><annotation id="S3.SS2.SSS1.p1.6.m6.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> ，如图 1 所示。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>MixSQuAD dataset<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.2.MixSQuAD 数据集</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.5">We also create an enhanced dataset to synthesise a contrastive learning setting while fine-tuning the PLM for T-CQG leading to the <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS2.p1.5.1">MixSQuAD</em> dataset. When creating this dataset, we randomly pick pairs of observations from the SQuAD+ dataset described in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS1" title="3.2.1. Linking the target topic to data points, SQuAD+ dataset ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>. For each pair of examples <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.1.m1.1"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><ci id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.1.m1.1d">italic_i</annotation></semantics></math> and <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.2.m2.1"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mi id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><ci id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.2.m2.1d">italic_j</annotation></semantics></math> containing <math alttext="(c_{i},t_{i},q_{t_{i}})" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.3.m3.3"><semantics id="S3.SS2.SSS2.p1.3.m3.3a"><mrow id="S3.SS2.SSS2.p1.3.m3.3.3.3" xref="S3.SS2.SSS2.p1.3.m3.3.3.4.cmml"><mo id="S3.SS2.SSS2.p1.3.m3.3.3.3.4" stretchy="false" xref="S3.SS2.SSS2.p1.3.m3.3.3.4.cmml">(</mo><msub id="S3.SS2.SSS2.p1.3.m3.1.1.1.1" xref="S3.SS2.SSS2.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p1.3.m3.1.1.1.1.2" xref="S3.SS2.SSS2.p1.3.m3.1.1.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS2.p1.3.m3.1.1.1.1.3" xref="S3.SS2.SSS2.p1.3.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.SSS2.p1.3.m3.3.3.3.5" xref="S3.SS2.SSS2.p1.3.m3.3.3.4.cmml">,</mo><msub id="S3.SS2.SSS2.p1.3.m3.2.2.2.2" xref="S3.SS2.SSS2.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS2.SSS2.p1.3.m3.2.2.2.2.2" xref="S3.SS2.SSS2.p1.3.m3.2.2.2.2.2.cmml">t</mi><mi id="S3.SS2.SSS2.p1.3.m3.2.2.2.2.3" xref="S3.SS2.SSS2.p1.3.m3.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.SSS2.p1.3.m3.3.3.3.6" xref="S3.SS2.SSS2.p1.3.m3.3.3.4.cmml">,</mo><msub id="S3.SS2.SSS2.p1.3.m3.3.3.3.3" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.cmml"><mi id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.2" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.2.cmml">q</mi><msub id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.cmml"><mi id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.2" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.2.cmml">t</mi><mi id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.3" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.3.cmml">i</mi></msub></msub><mo id="S3.SS2.SSS2.p1.3.m3.3.3.3.7" stretchy="false" xref="S3.SS2.SSS2.p1.3.m3.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.3.m3.3b"><vector id="S3.SS2.SSS2.p1.3.m3.3.3.4.cmml" xref="S3.SS2.SSS2.p1.3.m3.3.3.3"><apply id="S3.SS2.SSS2.p1.3.m3.1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1.1.1.2">𝑐</ci><ci id="S3.SS2.SSS2.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.SSS2.p1.3.m3.2.2.2.2.cmml" xref="S3.SS2.SSS2.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS2.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p1.3.m3.2.2.2.2.2">𝑡</ci><ci id="S3.SS2.SSS2.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p1.3.m3.2.2.2.2.3">𝑖</ci></apply><apply id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.cmml" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.2.cmml" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.2">𝑞</ci><apply id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.cmml" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.2.cmml" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.2">𝑡</ci><ci id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.3.cmml" xref="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.3">𝑖</ci></apply></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.3.m3.3c">(c_{i},t_{i},q_{t_{i}})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.3.m3.3d">( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math> and <math alttext="(c_{j},t_{j},q_{t_{j}})" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.4.m4.3"><semantics id="S3.SS2.SSS2.p1.4.m4.3a"><mrow id="S3.SS2.SSS2.p1.4.m4.3.3.3" xref="S3.SS2.SSS2.p1.4.m4.3.3.4.cmml"><mo id="S3.SS2.SSS2.p1.4.m4.3.3.3.4" stretchy="false" xref="S3.SS2.SSS2.p1.4.m4.3.3.4.cmml">(</mo><msub id="S3.SS2.SSS2.p1.4.m4.1.1.1.1" xref="S3.SS2.SSS2.p1.4.m4.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p1.4.m4.1.1.1.1.2" xref="S3.SS2.SSS2.p1.4.m4.1.1.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS2.p1.4.m4.1.1.1.1.3" xref="S3.SS2.SSS2.p1.4.m4.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS2.SSS2.p1.4.m4.3.3.3.5" xref="S3.SS2.SSS2.p1.4.m4.3.3.4.cmml">,</mo><msub id="S3.SS2.SSS2.p1.4.m4.2.2.2.2" xref="S3.SS2.SSS2.p1.4.m4.2.2.2.2.cmml"><mi id="S3.SS2.SSS2.p1.4.m4.2.2.2.2.2" xref="S3.SS2.SSS2.p1.4.m4.2.2.2.2.2.cmml">t</mi><mi id="S3.SS2.SSS2.p1.4.m4.2.2.2.2.3" xref="S3.SS2.SSS2.p1.4.m4.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.SS2.SSS2.p1.4.m4.3.3.3.6" xref="S3.SS2.SSS2.p1.4.m4.3.3.4.cmml">,</mo><msub id="S3.SS2.SSS2.p1.4.m4.3.3.3.3" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.cmml"><mi id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.2" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.2.cmml">q</mi><msub id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.cmml"><mi id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.2" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.2.cmml">t</mi><mi id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.3" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.3.cmml">j</mi></msub></msub><mo id="S3.SS2.SSS2.p1.4.m4.3.3.3.7" stretchy="false" xref="S3.SS2.SSS2.p1.4.m4.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.4.m4.3b"><vector id="S3.SS2.SSS2.p1.4.m4.3.3.4.cmml" xref="S3.SS2.SSS2.p1.4.m4.3.3.3"><apply id="S3.SS2.SSS2.p1.4.m4.1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.1.1.2">𝑐</ci><ci id="S3.SS2.SSS2.p1.4.m4.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.1.1.3">𝑗</ci></apply><apply id="S3.SS2.SSS2.p1.4.m4.2.2.2.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.4.m4.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS2.p1.4.m4.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.2.2.2.2.2">𝑡</ci><ci id="S3.SS2.SSS2.p1.4.m4.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.2.2.2.2.3">𝑗</ci></apply><apply id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.2">𝑞</ci><apply id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.2">𝑡</ci><ci id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.3">𝑗</ci></apply></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.4.m4.3c">(c_{j},t_{j},q_{t_{j}})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.4.m4.3d">( italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math> respectively, we create two new examples where they share a common context <math alttext="c_{i}c_{j}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.5.m5.1"><semantics id="S3.SS2.SSS2.p1.5.m5.1a"><mrow id="S3.SS2.SSS2.p1.5.m5.1.1" xref="S3.SS2.SSS2.p1.5.m5.1.1.cmml"><msub id="S3.SS2.SSS2.p1.5.m5.1.1.2" xref="S3.SS2.SSS2.p1.5.m5.1.1.2.cmml"><mi id="S3.SS2.SSS2.p1.5.m5.1.1.2.2" xref="S3.SS2.SSS2.p1.5.m5.1.1.2.2.cmml">c</mi><mi id="S3.SS2.SSS2.p1.5.m5.1.1.2.3" xref="S3.SS2.SSS2.p1.5.m5.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.SSS2.p1.5.m5.1.1.1" xref="S3.SS2.SSS2.p1.5.m5.1.1.1.cmml">⁢</mo><msub id="S3.SS2.SSS2.p1.5.m5.1.1.3" xref="S3.SS2.SSS2.p1.5.m5.1.1.3.cmml"><mi id="S3.SS2.SSS2.p1.5.m5.1.1.3.2" xref="S3.SS2.SSS2.p1.5.m5.1.1.3.2.cmml">c</mi><mi id="S3.SS2.SSS2.p1.5.m5.1.1.3.3" xref="S3.SS2.SSS2.p1.5.m5.1.1.3.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.5.m5.1b"><apply id="S3.SS2.SSS2.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1"><times id="S3.SS2.SSS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.1"></times><apply id="S3.SS2.SSS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.5.m5.1.1.2.1.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS2.p1.5.m5.1.1.2.2.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.2.2">𝑐</ci><ci id="S3.SS2.SSS2.p1.5.m5.1.1.2.3.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.2.3">𝑖</ci></apply><apply id="S3.SS2.SSS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.5.m5.1.1.3.1.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS2.p1.5.m5.1.1.3.2.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.3.2">𝑐</ci><ci id="S3.SS2.SSS2.p1.5.m5.1.1.3.3.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.5.m5.1c">c_{i}c_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p1.5.m5.1d">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> where the two contexts are concatenated. The data representation of the MixSQuAD dataset is presented in figure <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.F1" title="Figure 1 ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">1</span></a>. This approach aims to enhance the model’s understanding of topics and the relationship between context, topic, and question by serving novel contrastive examples. An added benefit of the novel MixSQuAD dataset is that the context presented to the model during fine-tuning is guaranteed not to be previously encountered in the large corpora used for training foundational models. This method results in a diverse collection of 10,000 mixed data entries in the MixSQuAD dataset, fostering a robust learning environment for the models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们还创建了一个增强数据集，用于在微调 PLM 以进行 T-CQG 时合成对比学习环境，从而形成了 MixSQuAD 数据集。在创建这个数据集时，我们从第 3.2.1 节中描述的 SQuAD+数据集中随机挑选观察值对。对于包含 <math id="S3.SS2.SSS2.p1.3.m3.3" display="inline" class="ltx_Math" alttext="(c_{i},t_{i},q_{t_{i}})"><semantics id="S3.SS2.SSS2.p1.3.m3.3a"><mrow id="S3.SS2.SSS2.p1.3.m3.3.3.3"><mo stretchy="false" id="S3.SS2.SSS2.p1.3.m3.3.3.3.4">(</mo><msub id="S3.SS2.SSS2.p1.3.m3.1.1.1.1"><mi id="S3.SS2.SSS2.p1.3.m3.1.1.1.1.2">c</mi><mi id="S3.SS2.SSS2.p1.3.m3.1.1.1.1.3">i</mi></msub><mo id="S3.SS2.SSS2.p1.3.m3.3.3.3.5">,</mo><msub id="S3.SS2.SSS2.p1.3.m3.2.2.2.2"><mi id="S3.SS2.SSS2.p1.3.m3.2.2.2.2.2">t</mi><mi id="S3.SS2.SSS2.p1.3.m3.2.2.2.2.3">i</mi></msub><mo id="S3.SS2.SSS2.p1.3.m3.3.3.3.6">,</mo><msub id="S3.SS2.SSS2.p1.3.m3.3.3.3.3"><mi id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.2">q</mi><msub id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3"><mi id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.2">t</mi><mi id="S3.SS2.SSS2.p1.3.m3.3.3.3.3.3.3">i</mi></msub></msub><mo stretchy="false" id="S3.SS2.SSS2.p1.3.m3.3.3.3.7">)</mo></mrow><annotation-xml id="S3.SS2.SSS2.p1.3.m3.3b" encoding="MathML-Content">subscriptsubscriptsubscriptsubscript</annotation-xml><annotation id="S3.SS2.SSS2.p1.3.m3.3c" encoding="application/x-tex">(c_{i},t_{i},q_{t_{i}})</annotation><annotation id="S3.SS2.SSS2.p1.3.m3.3d" encoding="application/x-llamapun">( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math> 和 <math id="S3.SS2.SSS2.p1.4.m4.3" display="inline" class="ltx_Math" alttext="(c_{j},t_{j},q_{t_{j}})"><semantics id="S3.SS2.SSS2.p1.4.m4.3a"><mrow id="S3.SS2.SSS2.p1.4.m4.3.3.3"><mo stretchy="false" id="S3.SS2.SSS2.p1.4.m4.3.3.3.4">(</mo><msub id="S3.SS2.SSS2.p1.4.m4.1.1.1.1"><mi id="S3.SS2.SSS2.p1.4.m4.1.1.1.1.2">c</mi><mi id="S3.SS2.SSS2.p1.4.m4.1.1.1.1.3">j</mi></msub><mo id="S3.SS2.SSS2.p1.4.m4.3.3.3.5">,</mo><msub id="S3.SS2.SSS2.p1.4.m4.2.2.2.2"><mi id="S3.SS2.SSS2.p1.4.m4.2.2.2.2.2">t</mi><mi id="S3.SS2.SSS2.p1.4.m4.2.2.2.2.3">j</mi></msub><mo id="S3.SS2.SSS2.p1.4.m4.3.3.3.6">,</mo><msub id="S3.SS2.SSS2.p1.4.m4.3.3.3.3"><mi id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.2">q</mi><msub id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3"><mi id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.2">t</mi><mi id="S3.SS2.SSS2.p1.4.m4.3.3.3.3.3.3">j</mi></msub></msub><mo stretchy="false" id="S3.SS2.SSS2.p1.4.m4.3.3.3.7">)</mo></mrow><annotation-xml id="S3.SS2.SSS2.p1.4.m4.3b" encoding="MathML-Content">subscriptsubscriptsubscriptsubscript</annotation-xml><annotation id="S3.SS2.SSS2.p1.4.m4.3c" encoding="application/x-tex">(c_{j},t_{j},q_{t_{j}})</annotation><annotation id="S3.SS2.SSS2.p1.4.m4.3d" encoding="application/x-llamapun">( italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_q start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math> 的示例对 <math id="S3.SS2.SSS2.p1.1.m1.1" display="inline" class="ltx_Math" alttext="i"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.p1.1.m1.1.1">i</mi><annotation-xml id="S3.SS2.SSS2.p1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS2.SSS2.p1.1.m1.1c" encoding="application/x-tex">i</annotation><annotation id="S3.SS2.SSS2.p1.1.m1.1d" encoding="application/x-llamapun">italic_i</annotation></semantics></math> 和 <math id="S3.SS2.SSS2.p1.2.m2.1" display="inline" class="ltx_Math" alttext="j"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mi id="S3.SS2.SSS2.p1.2.m2.1.1">j</mi><annotation-xml id="S3.SS2.SSS2.p1.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS2.SSS2.p1.2.m2.1c" encoding="application/x-tex">j</annotation><annotation id="S3.SS2.SSS2.p1.2.m2.1d" encoding="application/x-llamapun">italic_j</annotation></semantics></math> ，我们创建两个新示例，它们共享一个公共上下文 <math id="S3.SS2.SSS2.p1.5.m5.1" display="inline" class="ltx_Math" alttext="c_{i}c_{j}"><semantics id="S3.SS2.SSS2.p1.5.m5.1a"><mrow id="S3.SS2.SSS2.p1.5.m5.1.1"><msub id="S3.SS2.SSS2.p1.5.m5.1.1.2"><mi id="S3.SS2.SSS2.p1.5.m5.1.1.2.2">c</mi><mi id="S3.SS2.SSS2.p1.5.m5.1.1.2.3">i</mi></msub><mo id="S3.SS2.SSS2.p1.5.m5.1.1.1">⁢</mo><msub id="S3.SS2.SSS2.p1.5.m5.1.1.3"><mi id="S3.SS2.SSS2.p1.5.m5.1.1.3.2">c</mi><mi id="S3.SS2.SSS2.p1.5.m5.1.1.3.3">j</mi></msub></mrow><annotation-xml id="S3.SS2.SSS2.p1.5.m5.1b" encoding="MathML-Content">subscriptsubscript</annotation-xml><annotation id="S3.SS2.SSS2.p1.5.m5.1c" encoding="application/x-tex">c_{i}c_{j}</annotation><annotation id="S3.SS2.SSS2.p1.5.m5.1d" encoding="application/x-llamapun">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> ，其中两个上下文被连接在一起。MixSQuAD 数据集的数据表示如图 1 所示。这种方法旨在通过提供新颖的对比示例来增强模型对主题的理解以及上下文、主题和问题之间关系的学习。新型 MixSQuAD 数据集的一个额外好处是，在微调过程中向模型呈现的上下文保证在用于训练基础模型的大规模语料库中未曾遇到。这种方法在 MixSQuAD 数据集中产生了多样化的 10,000 条混合数据条目，为模型创造了稳健的学习环境。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>MixSQuAD2X dataset<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.3.MixSQuAD2X 数据集</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">The MixSQuAD2X dataset is very similar to MixSQuAD dataset, but the main difference is the utilisation of data augmentation to expand the dataset. In contrast to MixSQuAD, we introduce two additional examples to the dataset with the context <math alttext="c_{2}c_{1}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p1.1.m1.1"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><mrow id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml"><msub id="S3.SS2.SSS3.p1.1.m1.1.1.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS3.p1.1.m1.1.1.2.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.2.cmml">c</mi><mn id="S3.SS2.SSS3.p1.1.m1.1.1.2.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.3.cmml">2</mn></msub><mo id="S3.SS2.SSS3.p1.1.m1.1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.cmml">⁢</mo><msub id="S3.SS2.SSS3.p1.1.m1.1.1.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS3.p1.1.m1.1.1.3.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.2.cmml">c</mi><mn id="S3.SS2.SSS3.p1.1.m1.1.1.3.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.1b"><apply id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1"><times id="S3.SS2.SSS3.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1"></times><apply id="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.2">𝑐</ci><cn id="S3.SS2.SSS3.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.3">2</cn></apply><apply id="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.2">𝑐</ci><cn id="S3.SS2.SSS3.p1.1.m1.1.1.3.3.cmml" type="integer" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.1c">c_{2}c_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p1.1.m1.1d">italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> by reversing the order when concatenating the two randomly chosen contexts. This leads to a dataset that is twice as big as the MixSQuAD dataset.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">MixSQuAD2X 数据集与 MixSQuAD 数据集非常相似，但主要区别在于利用数据增强来扩展数据集。与 MixSQuAD 相比，我们在数据集中引入了两个额外的示例，通过在连接两个随机选择的上下文时反转顺序，添加了上下文 <math id="S3.SS2.SSS3.p1.1.m1.1" display="inline" class="ltx_Math" alttext="c_{2}c_{1}"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><mrow id="S3.SS2.SSS3.p1.1.m1.1.1"><msub id="S3.SS2.SSS3.p1.1.m1.1.1.2"><mi id="S3.SS2.SSS3.p1.1.m1.1.1.2.2">c</mi><mn id="S3.SS2.SSS3.p1.1.m1.1.1.2.3">2</mn></msub><mo id="S3.SS2.SSS3.p1.1.m1.1.1.1">⁢</mo><msub id="S3.SS2.SSS3.p1.1.m1.1.1.3"><mi id="S3.SS2.SSS3.p1.1.m1.1.1.3.2">c</mi><mn id="S3.SS2.SSS3.p1.1.m1.1.1.3.3">1</mn></msub></mrow><annotation-xml id="S3.SS2.SSS3.p1.1.m1.1b" encoding="MathML-Content">subscript2subscript1</annotation-xml><annotation id="S3.SS2.SSS3.p1.1.m1.1c" encoding="application/x-tex">c_{2}c_{1}</annotation><annotation id="S3.SS2.SSS3.p1.1.m1.1d" encoding="application/x-llamapun">italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> 。这使得数据集的大小是 MixSQuAD 数据集的两倍。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Developing T-CQG Models for Education<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3. 为教育开发 T-CQG 模型</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">With the relevant datasets created, we built multiple models to be evaluated in a series of experiments to answer the research questions outlined in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S2" title="2. Problem Definition, Background Research, and Research Questions ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2</span></a>. All the models used in experiments are created by finetuning the <span class="ltx_text ltx_font_typewriter" id="S3.SS3.p1.2.1">T5-Small</span> <cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib50" title="">2022</a>)</cite> model, a small Language Model (sLM) that has also been used for educational question generation in the past <cite class="ltx_cite ltx_citemacro_citep">(Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib8" title="">2023</a>; Fawzi et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib27" title="">2024</a>)</cite>. We fine-tuned the foundational model (<span class="ltx_text ltx_font_typewriter" id="S3.SS3.p1.2.2">t5-small</span> from HuggingFace library<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/google-t5/t5-small" title="">https://huggingface.co/google-t5/t5-small</a></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在创建了相关数据集后，我们构建了多个模型，用于在一系列实验中评估，以回答第 2 节中提出的研究问题。实验中使用的所有模型都是通过微调 T5-Small（Raffel 等人，2022 年）模型创建的，这是一个小型语言模型（sLM），过去也曾用于教育问题生成（Bulathwela 等人，2023 年；Fawzi 等人，2024 年）。我们对基础模型（来自 HuggingFace 库的 t5-small <sup class="ltx_note_mark">2</sup> ）进行了微调。</font></font></font>) using the Adam optimizer with a batch size of 64, the learning rate of <math alttext="1e-3" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mrow id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml"><mn id="S3.SS3.p1.1.m1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.2.2.cmml">1</mn><mo id="S3.SS3.p1.1.m1.1.1.2.1" xref="S3.SS3.p1.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.2.3.cmml">e</mi></mrow><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">−</mo><mn id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><minus id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></minus><apply id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"><times id="S3.SS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.2.1"></times><cn id="S3.SS3.p1.1.m1.1.1.2.2.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.2.2">1</cn><ci id="S3.SS3.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3">𝑒</ci></apply><cn id="S3.SS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS3.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">1e-3</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">1 italic_e - 3</annotation></semantics></math>, and epsilon of <math alttext="1e-8" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mrow id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml"><mn id="S3.SS3.p1.2.m2.1.1.2.2" xref="S3.SS3.p1.2.m2.1.1.2.2.cmml">1</mn><mo id="S3.SS3.p1.2.m2.1.1.2.1" xref="S3.SS3.p1.2.m2.1.1.2.1.cmml">⁢</mo><mi id="S3.SS3.p1.2.m2.1.1.2.3" xref="S3.SS3.p1.2.m2.1.1.2.3.cmml">e</mi></mrow><mo id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.cmml">−</mo><mn id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><minus id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1"></minus><apply id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2"><times id="S3.SS3.p1.2.m2.1.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.2.1"></times><cn id="S3.SS3.p1.2.m2.1.1.2.2.cmml" type="integer" xref="S3.SS3.p1.2.m2.1.1.2.2">1</cn><ci id="S3.SS3.p1.2.m2.1.1.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.2.3">𝑒</ci></apply><cn id="S3.SS3.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS3.p1.2.m2.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">1e-8</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">1 italic_e - 8</annotation></semantics></math>. We use a maximum sequence length of 512 for the encoder, and 128 for the decoder. We train all models for a maximum of 50 epochs with an early stopping based on the validation loss <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Cathgy/Topic-controllable-Question-Generator.git" title="">https://github.com/Cathgy/Topic-controllable-Question-Generator.git</a></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">使用 Adam 优化器，批处理大小为 64，学习率为 <math id="S3.SS3.p1.1.m1.1" display="inline" class="ltx_Math" alttext="1e-3"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1"><mrow id="S3.SS3.p1.1.m1.1.1.2"><mn id="S3.SS3.p1.1.m1.1.1.2.2">1</mn><mo id="S3.SS3.p1.1.m1.1.1.2.1">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.2.3">e</mi></mrow><mo id="S3.SS3.p1.1.m1.1.1.1">−</mo><mn id="S3.SS3.p1.1.m1.1.1.3">3</mn></mrow><annotation-xml id="S3.SS3.p1.1.m1.1b" encoding="MathML-Content">13</annotation-xml><annotation id="S3.SS3.p1.1.m1.1c" encoding="application/x-tex">1e-3</annotation><annotation id="S3.SS3.p1.1.m1.1d" encoding="application/x-llamapun">1 italic_e - 3</annotation></semantics></math> ，epsilon 为 <math id="S3.SS3.p1.2.m2.1" display="inline" class="ltx_Math" alttext="1e-8"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1"><mrow id="S3.SS3.p1.2.m2.1.1.2"><mn id="S3.SS3.p1.2.m2.1.1.2.2">1</mn><mo id="S3.SS3.p1.2.m2.1.1.2.1">⁢</mo><mi id="S3.SS3.p1.2.m2.1.1.2.3">e</mi></mrow><mo id="S3.SS3.p1.2.m2.1.1.1">−</mo><mn id="S3.SS3.p1.2.m2.1.1.3">8</mn></mrow><annotation-xml id="S3.SS3.p1.2.m2.1b" encoding="MathML-Content">18</annotation-xml><annotation id="S3.SS3.p1.2.m2.1c" encoding="application/x-tex">1e-8</annotation><annotation id="S3.SS3.p1.2.m2.1d" encoding="application/x-llamapun">1 italic_e - 8</annotation></semantics></math> 。我们将编码器的最大序列长度设置为 512，解码器的最大序列长度设置为 128。我们使用基于验证损失 <sup class="ltx_note_mark">3</sup> 的早停机制，对所有模型进行最多 50 个 epoch 的训练。</font></font></font>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1. </span>Baseline Model to Answer RQ2</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">We conducted fine-tuning for T-CQG using the same finetuning approach used by <cite class="ltx_cite ltx_citemacro_citep">(Martin et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib43" title="">2020</a>)</cite> for controlling complexity in simplifying texts. We used the proposed SQuAD+ dataset (described in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS1" title="3.2.1. Linking the target topic to data points, SQuAD+ dataset ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>) to finetune the T5 PLM.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用与 Martin 等人（2020）在简化文本中控制复杂度时采用的相同微调方法，对 T-CQG 进行了微调。我们使用了在第 3.2.1 节中描述的所提出的 SQuAD+数据集来微调 T5 PLM。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2. </span>TopicQG to Answer RQ2<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3.2.TopicQG 回答 RQ2</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.3">The key difference between the baseline model and the proposed TopicQG model lies in the data used for fine-tuning the T5-small model. We introduced the TopicQG model to contrastive examples using the novel dataset created, MixSQuAD (described in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS2" title="3.2.2. MixSQuAD dataset ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>). Such mixed contexts, which may feature sentences with vastly differing concepts, are designed to enhance the T5 model’s understanding of the semantic relationships between context <math alttext="c" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.1.m1.1"><semantics id="S3.SS3.SSS2.p1.1.m1.1a"><mi id="S3.SS3.SSS2.p1.1.m1.1.1" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.1b"><ci id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.1.m1.1d">italic_c</annotation></semantics></math>, topic <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.2.m2.1"><semantics id="S3.SS3.SSS2.p1.2.m2.1a"><mi id="S3.SS3.SSS2.p1.2.m2.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.2.m2.1b"><ci id="S3.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.2.m2.1d">italic_t</annotation></semantics></math>, and question <math alttext="q_{t}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.3.m3.1"><semantics id="S3.SS3.SSS2.p1.3.m3.1a"><msub id="S3.SS3.SSS2.p1.3.m3.1.1" xref="S3.SS3.SSS2.p1.3.m3.1.1.cmml"><mi id="S3.SS3.SSS2.p1.3.m3.1.1.2" xref="S3.SS3.SSS2.p1.3.m3.1.1.2.cmml">q</mi><mi id="S3.SS3.SSS2.p1.3.m3.1.1.3" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.3.m3.1b"><apply id="S3.SS3.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.2">𝑞</ci><ci id="S3.SS3.SSS2.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.3.m3.1c">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.3.m3.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基线模型与所提出的 TopicQG 模型之间的关键区别在于用于微调 T5-small 模型的数据。我们使用创建的新数据集 MixSQuAD（在第 3.2.2 节中描述）向 TopicQG 模型引入对比示例。这些混合上下文可能包含概念差异极大的句子，旨在增强 T5 模型对上下文 <math id="S3.SS3.SSS2.p1.1.m1.1" display="inline" class="ltx_Math" alttext="c"><semantics id="S3.SS3.SSS2.p1.1.m1.1a"><mi id="S3.SS3.SSS2.p1.1.m1.1.1">c</mi><annotation-xml id="S3.SS3.SSS2.p1.1.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS3.SSS2.p1.1.m1.1c" encoding="application/x-tex">c</annotation><annotation id="S3.SS3.SSS2.p1.1.m1.1d" encoding="application/x-llamapun">italic_c</annotation></semantics></math> 、主题 <math id="S3.SS3.SSS2.p1.2.m2.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S3.SS3.SSS2.p1.2.m2.1a"><mi id="S3.SS3.SSS2.p1.2.m2.1.1">t</mi><annotation-xml id="S3.SS3.SSS2.p1.2.m2.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS3.SSS2.p1.2.m2.1c" encoding="application/x-tex">t</annotation><annotation id="S3.SS3.SSS2.p1.2.m2.1d" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 和问题 <math id="S3.SS3.SSS2.p1.3.m3.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S3.SS3.SSS2.p1.3.m3.1a"><msub id="S3.SS3.SSS2.p1.3.m3.1.1"><mi id="S3.SS3.SSS2.p1.3.m3.1.1.2">q</mi><mi id="S3.SS3.SSS2.p1.3.m3.1.1.3">t</mi></msub><annotation-xml id="S3.SS3.SSS2.p1.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS3.SSS2.p1.3.m3.1c" encoding="application/x-tex">q_{t}</annotation><annotation id="S3.SS3.SSS2.p1.3.m3.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 之间语义关系的理解。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3. </span>TopicQGedu to Answer RQ3<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3.3.TopicQGedu 回答 RQ3</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS3.p1">
<p class="ltx_p" id="S3.SS3.SSS3.p1.1">Further refining the approach, we developed TopicQGedu, which incorporates an additional pre-training step. In this approach, the sLM model undergoes further training with scientific text documents before being fine-tuned. This step is intended to imbue the model with scientific terminology and concepts, crucial for crafting high-quality educational questions <cite class="ltx_cite ltx_citemacro_citep">(Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib8" title="">2023</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">进一步优化该方法，我们开发了 TopicQGedu，它包含一个额外的预训练步骤。在该方法中，sLM 模型在微调之前会使用科学文本文档进行进一步训练。这一步骤旨在使模型具备科学术语和概念，这对于制作高质量的教育问题至关重要（Bulathwela 等人，2023）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4. </span>Quantised TopicQG Models to Answer RQ4<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3.4.用于回答 RQ4 的量化 TopicQG 模型</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS4.p1">
<p class="ltx_p" id="S3.SS3.SSS4.p1.1">Quantisation allows reducing the memory footprint of neural models significantly to enhance their scalability. To evaluate the degree of loss due to quantising the trained models, we created the quantised versions of the TopicQG model. We used 8-bit quantisation utilising the <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS4.p1.1.1">LLM.int8</em> algorithm <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib19" title="">2022</a>)</cite> and 4-bit precision employing the <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS4.p1.1.2">QLoRa</em> algorithm <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib20" title="">2023</a>)</cite> to create <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS4.p1.1.3">TopicQG8bit</span> and <span class="ltx_text ltx_font_bold" id="S3.SS3.SSS4.p1.1.4">TopicQG4bit</span> models respectively.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">量化可以显著减少神经模型的内存占用，以增强其可扩展性。为了评估因量化训练模型而造成的损失程度，我们创建了 TopicQG 模型的量化版本。我们使用了 8 位量化，采用 LLM.int8 算法（Dettmers 等人，2022 年），以及 4 位精度，采用 QLoRa 算法（Dettmers 等人，2023 年），分别创建了 TopicQG8bit 和 TopicQG4bit 模型。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.5. </span>TopicQG2X to Answer RQ5<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3.5.用于回答 RQ5 的 TopicQG2X 模型</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS5.p1">
<p class="ltx_p" id="S3.SS3.SSS5.p1.1">This model is trained similarly to the Topic QG model, but it exploits data augmentation by being finetuned on the newly proposed MixSQuAD2X dataset (described in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS3" title="3.2.3. MixSQuAD2X dataset ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.2.3</span></a>). The MixSQuAD2X dataset effectively doubles its size by changing the order of concatenation of contexts, introducing new examples to finetune the model with. This strategy has the potential to enhance the model’s robustness and generalisation abilities, improving the relevance and educational value of the generated questions to the given topics.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">该模型与 Topic QG 模型类似地进行训练，但它通过在新提出的 MixSQuAD2X 数据集（如 3.2.3 节所述）上进行微调来利用数据增强。MixSQuAD2X 数据集通过改变上下文连接的顺序，使其大小翻倍，引入新的示例来微调模型。这种策略有可能增强模型的鲁棒性和泛化能力，提高生成问题与给定主题的相关性和教育价值。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS6">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.6. </span>Example Questions Generated with Models for the Experiments<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3.6. 实验中模型生成的示例问题</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS6.p1">
<p class="ltx_p" id="S3.SS3.SSS6.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.T1" title="Table 1 ‣ 3.3.6. Example Questions Generated with Models for the Experiments ‣ 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">1</span></a> presents a random set of topic-controlled question generations based on the context text provided in five different subject areas (Computing, Economics, Chemistry, Art, and Biology).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 1 展示了基于五种不同学科（计算机科学、经济学、化学、艺术和生物学）提供的上下文文本生成的随机主题控制问题集。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>A Sample of Randomly Selected Generations from the TopicQG Model for Different Subject Domains<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 1. 不同学科领域中 TopicQG 模型的随机生成样本</font></font></font></figcaption>
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.T1.1.1"><span class="ltx_text" id="S3.T1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="553" id="S3.T1.1.1.1.g1" src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/x2.png" width="830"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Human Annotation-based Evaluation of Semantic Relatedness Metrics<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.4. 基于人工标注的语义相关性指标评估</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">To assess how representative BERTScore and WikiSemRel are when measuring topical relatedness (RQ1). We created a small gold-standard dataset via human annotation. The annotators (n = 4) consisted of two female and two male postgraduate students in the 20-30 age bracket from a masters degree programme at a university in the UK.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为评估 BERTScore 和 WikiSemRel 在衡量主题相关性（RQ1）时的代表性，我们通过人工标注创建了一个小型黄金标准数据集。标注者（n = 4）由来自英国某大学硕士课程的 4 名研究生组成，其中两名女性和两名男性，年龄在 20-30 岁之间。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.9">To set up the annotation task, we randomly selected 30 questions from the MixKhanQ dataset (KhanQ dataset transformed using the method described in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS2.SSS2" title="3.2.2. MixSQuAD dataset ‣ 3.2. Creating Novel Datasets for T-CQG ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>). For each sample, we provided the participants with the reference question <math alttext="q_{t}" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><msub id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">q</mi><mi id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">𝑞</ci><ci id="S3.SS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and two corresponding generated questions, 1) the question <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S3.SS4.p2.2.m2.1"><semantics id="S3.SS4.p2.2.m2.1a"><msub id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml"><mover accent="true" id="S3.SS4.p2.2.m2.1.1.2" xref="S3.SS4.p2.2.m2.1.1.2.cmml"><mi id="S3.SS4.p2.2.m2.1.1.2.2" xref="S3.SS4.p2.2.m2.1.1.2.2.cmml">q</mi><mo id="S3.SS4.p2.2.m2.1.1.2.1" xref="S3.SS4.p2.2.m2.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS4.p2.2.m2.1.1.3" xref="S3.SS4.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">subscript</csymbol><apply id="S3.SS4.p2.2.m2.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2"><ci id="S3.SS4.p2.2.m2.1.1.2.1.cmml" xref="S3.SS4.p2.2.m2.1.1.2.1">^</ci><ci id="S3.SS4.p2.2.m2.1.1.2.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2.2">𝑞</ci></apply><ci id="S3.SS4.p2.2.m2.1.1.3.cmml" xref="S3.SS4.p2.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.2.m2.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> generated using the <em class="ltx_emph ltx_font_italic" id="S3.SS4.p2.9.1">relevant/prescribed</em> topic and 2) the question <math alttext="\hat{q}_{t^{\prime}}" class="ltx_Math" display="inline" id="S3.SS4.p2.3.m3.1"><semantics id="S3.SS4.p2.3.m3.1a"><msub id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml"><mover accent="true" id="S3.SS4.p2.3.m3.1.1.2" xref="S3.SS4.p2.3.m3.1.1.2.cmml"><mi id="S3.SS4.p2.3.m3.1.1.2.2" xref="S3.SS4.p2.3.m3.1.1.2.2.cmml">q</mi><mo id="S3.SS4.p2.3.m3.1.1.2.1" xref="S3.SS4.p2.3.m3.1.1.2.1.cmml">^</mo></mover><msup id="S3.SS4.p2.3.m3.1.1.3" xref="S3.SS4.p2.3.m3.1.1.3.cmml"><mi id="S3.SS4.p2.3.m3.1.1.3.2" xref="S3.SS4.p2.3.m3.1.1.3.2.cmml">t</mi><mo id="S3.SS4.p2.3.m3.1.1.3.3" xref="S3.SS4.p2.3.m3.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">subscript</csymbol><apply id="S3.SS4.p2.3.m3.1.1.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2"><ci id="S3.SS4.p2.3.m3.1.1.2.1.cmml" xref="S3.SS4.p2.3.m3.1.1.2.1">^</ci><ci id="S3.SS4.p2.3.m3.1.1.2.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2.2">𝑞</ci></apply><apply id="S3.SS4.p2.3.m3.1.1.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.1.3.1.cmml" xref="S3.SS4.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS4.p2.3.m3.1.1.3.2.cmml" xref="S3.SS4.p2.3.m3.1.1.3.2">𝑡</ci><ci id="S3.SS4.p2.3.m3.1.1.3.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">\hat{q}_{t^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.3.m3.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> generated with an <em class="ltx_emph ltx_font_italic" id="S3.SS4.p2.9.2">alternative</em> topic. Annotators were required to independently determine which of the two generated questions <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S3.SS4.p2.4.m4.1"><semantics id="S3.SS4.p2.4.m4.1a"><msub id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml"><mover accent="true" id="S3.SS4.p2.4.m4.1.1.2" xref="S3.SS4.p2.4.m4.1.1.2.cmml"><mi id="S3.SS4.p2.4.m4.1.1.2.2" xref="S3.SS4.p2.4.m4.1.1.2.2.cmml">q</mi><mo id="S3.SS4.p2.4.m4.1.1.2.1" xref="S3.SS4.p2.4.m4.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS4.p2.4.m4.1.1.3" xref="S3.SS4.p2.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><apply id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1">subscript</csymbol><apply id="S3.SS4.p2.4.m4.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.2"><ci id="S3.SS4.p2.4.m4.1.1.2.1.cmml" xref="S3.SS4.p2.4.m4.1.1.2.1">^</ci><ci id="S3.SS4.p2.4.m4.1.1.2.2.cmml" xref="S3.SS4.p2.4.m4.1.1.2.2">𝑞</ci></apply><ci id="S3.SS4.p2.4.m4.1.1.3.cmml" xref="S3.SS4.p2.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.4.m4.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> or <math alttext="\hat{q}_{t^{\prime}}" class="ltx_Math" display="inline" id="S3.SS4.p2.5.m5.1"><semantics id="S3.SS4.p2.5.m5.1a"><msub id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml"><mover accent="true" id="S3.SS4.p2.5.m5.1.1.2" xref="S3.SS4.p2.5.m5.1.1.2.cmml"><mi id="S3.SS4.p2.5.m5.1.1.2.2" xref="S3.SS4.p2.5.m5.1.1.2.2.cmml">q</mi><mo id="S3.SS4.p2.5.m5.1.1.2.1" xref="S3.SS4.p2.5.m5.1.1.2.1.cmml">^</mo></mover><msup id="S3.SS4.p2.5.m5.1.1.3" xref="S3.SS4.p2.5.m5.1.1.3.cmml"><mi id="S3.SS4.p2.5.m5.1.1.3.2" xref="S3.SS4.p2.5.m5.1.1.3.2.cmml">t</mi><mo id="S3.SS4.p2.5.m5.1.1.3.3" xref="S3.SS4.p2.5.m5.1.1.3.3.cmml">′</mo></msup></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><apply id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.5.m5.1.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1">subscript</csymbol><apply id="S3.SS4.p2.5.m5.1.1.2.cmml" xref="S3.SS4.p2.5.m5.1.1.2"><ci id="S3.SS4.p2.5.m5.1.1.2.1.cmml" xref="S3.SS4.p2.5.m5.1.1.2.1">^</ci><ci id="S3.SS4.p2.5.m5.1.1.2.2.cmml" xref="S3.SS4.p2.5.m5.1.1.2.2">𝑞</ci></apply><apply id="S3.SS4.p2.5.m5.1.1.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p2.5.m5.1.1.3.1.cmml" xref="S3.SS4.p2.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS4.p2.5.m5.1.1.3.2.cmml" xref="S3.SS4.p2.5.m5.1.1.3.2">𝑡</ci><ci id="S3.SS4.p2.5.m5.1.1.3.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m5.1c">\hat{q}_{t^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.5.m5.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> is more closely aligned with the reference question<math alttext="{q}_{t}" class="ltx_Math" display="inline" id="S3.SS4.p2.6.m6.1"><semantics id="S3.SS4.p2.6.m6.1a"><msub id="S3.SS4.p2.6.m6.1.1" xref="S3.SS4.p2.6.m6.1.1.cmml"><mi id="S3.SS4.p2.6.m6.1.1.2" xref="S3.SS4.p2.6.m6.1.1.2.cmml">q</mi><mi id="S3.SS4.p2.6.m6.1.1.3" xref="S3.SS4.p2.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m6.1b"><apply id="S3.SS4.p2.6.m6.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.6.m6.1.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS4.p2.6.m6.1.1.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2">𝑞</ci><ci id="S3.SS4.p2.6.m6.1.1.3.cmml" xref="S3.SS4.p2.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m6.1c">{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.6.m6.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, the same tasks the SemRel metrics are going to do. The generated question <math alttext="\hat{q}_{(\cdot)}" class="ltx_Math" display="inline" id="S3.SS4.p2.7.m7.1"><semantics id="S3.SS4.p2.7.m7.1a"><msub id="S3.SS4.p2.7.m7.1.2" xref="S3.SS4.p2.7.m7.1.2.cmml"><mover accent="true" id="S3.SS4.p2.7.m7.1.2.2" xref="S3.SS4.p2.7.m7.1.2.2.cmml"><mi id="S3.SS4.p2.7.m7.1.2.2.2" xref="S3.SS4.p2.7.m7.1.2.2.2.cmml">q</mi><mo id="S3.SS4.p2.7.m7.1.2.2.1" xref="S3.SS4.p2.7.m7.1.2.2.1.cmml">^</mo></mover><mrow id="S3.SS4.p2.7.m7.1.1.1.3" xref="S3.SS4.p2.7.m7.1.2.cmml"><mo id="S3.SS4.p2.7.m7.1.1.1.3.1" stretchy="false" xref="S3.SS4.p2.7.m7.1.2.cmml">(</mo><mo id="S3.SS4.p2.7.m7.1.1.1.1" lspace="0em" rspace="0em" xref="S3.SS4.p2.7.m7.1.1.1.1.cmml">⋅</mo><mo id="S3.SS4.p2.7.m7.1.1.1.3.2" stretchy="false" xref="S3.SS4.p2.7.m7.1.2.cmml">)</mo></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.7.m7.1b"><apply id="S3.SS4.p2.7.m7.1.2.cmml" xref="S3.SS4.p2.7.m7.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.7.m7.1.2.1.cmml" xref="S3.SS4.p2.7.m7.1.2">subscript</csymbol><apply id="S3.SS4.p2.7.m7.1.2.2.cmml" xref="S3.SS4.p2.7.m7.1.2.2"><ci id="S3.SS4.p2.7.m7.1.2.2.1.cmml" xref="S3.SS4.p2.7.m7.1.2.2.1">^</ci><ci id="S3.SS4.p2.7.m7.1.2.2.2.cmml" xref="S3.SS4.p2.7.m7.1.2.2.2">𝑞</ci></apply><ci id="S3.SS4.p2.7.m7.1.1.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.7.m7.1c">\hat{q}_{(\cdot)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.7.m7.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT ( ⋅ ) end_POSTSUBSCRIPT</annotation></semantics></math> annotators selected as closely relevant to the reference question is given <math alttext="1" class="ltx_Math" display="inline" id="S3.SS4.p2.8.m8.1"><semantics id="S3.SS4.p2.8.m8.1a"><mn id="S3.SS4.p2.8.m8.1.1" xref="S3.SS4.p2.8.m8.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.8.m8.1b"><cn id="S3.SS4.p2.8.m8.1.1.cmml" type="integer" xref="S3.SS4.p2.8.m8.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.8.m8.1c">1</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.8.m8.1d">1</annotation></semantics></math> and the other <math alttext="0" class="ltx_Math" display="inline" id="S3.SS4.p2.9.m9.1"><semantics id="S3.SS4.p2.9.m9.1a"><mn id="S3.SS4.p2.9.m9.1.1" xref="S3.SS4.p2.9.m9.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.9.m9.1b"><cn id="S3.SS4.p2.9.m9.1.1.cmml" type="integer" xref="S3.SS4.p2.9.m9.1.1">0</cn></annotation-xml></semantics></math>. We calculated the Mean Absolute Error (MAE) between the mean score assigned by human annotators and the respective SemRel Score as per equation <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.E2" title="In 3.4. Human Annotation-based Evaluation of Semantic Relatedness Metrics ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了设置标注任务，我们从 MixKhanQ 数据集（使用 3.2.2 节中描述的方法转换的 KhanQ 数据集）中随机选择了 30 个问题。对于每个样本，我们向参与者提供参考问题 <math id="S3.SS4.p2.1.m1.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S3.SS4.p2.1.m1.1a"><msub id="S3.SS4.p2.1.m1.1.1"><mi id="S3.SS4.p2.1.m1.1.1.2">q</mi><mi id="S3.SS4.p2.1.m1.1.1.3">t</mi></msub><annotation-xml id="S3.SS4.p2.1.m1.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS4.p2.1.m1.1c" encoding="application/x-tex">q_{t}</annotation><annotation id="S3.SS4.p2.1.m1.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 以及两个相应的生成问题：1) 使用相关/指定主题生成的 <math id="S3.SS4.p2.2.m2.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S3.SS4.p2.2.m2.1a"><msub id="S3.SS4.p2.2.m2.1.1"><mover id="S3.SS4.p2.2.m2.1.1.2" accent="true"><mi id="S3.SS4.p2.2.m2.1.1.2.2">q</mi><mo id="S3.SS4.p2.2.m2.1.1.2.1">^</mo></mover><mi id="S3.SS4.p2.2.m2.1.1.3">t</mi></msub><annotation-xml id="S3.SS4.p2.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS4.p2.2.m2.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S3.SS4.p2.2.m2.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 问题，2) 使用替代主题生成的 <math id="S3.SS4.p2.3.m3.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t^{\prime}}"><semantics id="S3.SS4.p2.3.m3.1a"><msub id="S3.SS4.p2.3.m3.1.1"><mover id="S3.SS4.p2.3.m3.1.1.2" accent="true"><mi id="S3.SS4.p2.3.m3.1.1.2.2">q</mi><mo id="S3.SS4.p2.3.m3.1.1.2.1">^</mo></mover><msup id="S3.SS4.p2.3.m3.1.1.3"><mi id="S3.SS4.p2.3.m3.1.1.3.2">t</mi><mo id="S3.SS4.p2.3.m3.1.1.3.3">′</mo></msup></msub><annotation-xml id="S3.SS4.p2.3.m3.1b" encoding="MathML-Content">subscriptsuperscript</annotation-xml><annotation id="S3.SS4.p2.3.m3.1c" encoding="application/x-tex">\hat{q}_{t^{\prime}}</annotation><annotation id="S3.SS4.p2.3.m3.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> 问题。标注人员需要独立判断两个生成问题 <math id="S3.SS4.p2.4.m4.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S3.SS4.p2.4.m4.1a"><msub id="S3.SS4.p2.4.m4.1.1"><mover id="S3.SS4.p2.4.m4.1.1.2" accent="true"><mi id="S3.SS4.p2.4.m4.1.1.2.2">q</mi><mo id="S3.SS4.p2.4.m4.1.1.2.1">^</mo></mover><mi id="S3.SS4.p2.4.m4.1.1.3">t</mi></msub><annotation-xml id="S3.SS4.p2.4.m4.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS4.p2.4.m4.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S3.SS4.p2.4.m4.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 或 <math id="S3.SS4.p2.5.m5.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t^{\prime}}"><semantics id="S3.SS4.p2.5.m5.1a"><msub id="S3.SS4.p2.5.m5.1.1"><mover id="S3.SS4.p2.5.m5.1.1.2" accent="true"><mi id="S3.SS4.p2.5.m5.1.1.2.2">q</mi><mo id="S3.SS4.p2.5.m5.1.1.2.1">^</mo></mover><msup id="S3.SS4.p2.5.m5.1.1.3"><mi id="S3.SS4.p2.5.m5.1.1.3.2">t</mi><mo id="S3.SS4.p2.5.m5.1.1.3.3">′</mo></msup></msub><annotation-xml id="S3.SS4.p2.5.m5.1b" encoding="MathML-Content">subscriptsuperscript</annotation-xml><annotation id="S3.SS4.p2.5.m5.1c" encoding="application/x-tex">\hat{q}_{t^{\prime}}</annotation><annotation id="S3.SS4.p2.5.m5.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> 中哪一个与参考问题 <math id="S3.SS4.p2.6.m6.1" display="inline" class="ltx_Math" alttext="{q}_{t}"><semantics id="S3.SS4.p2.6.m6.1a"><msub id="S3.SS4.p2.6.m6.1.1"><mi id="S3.SS4.p2.6.m6.1.1.2">q</mi><mi id="S3.SS4.p2.6.m6.1.1.3">t</mi></msub><annotation-xml id="S3.SS4.p2.6.m6.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS4.p2.6.m6.1c" encoding="application/x-tex">{q}_{t}</annotation><annotation id="S3.SS4.p2.6.m6.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 更一致，这正是 SemRel 指标将要执行的任务。标注人员选出的与参考问题 <math id="S3.SS4.p2.7.m7.1" display="inline" class="ltx_Math" alttext="\hat{q}_{(\cdot)}"><semantics id="S3.SS4.p2.7.m7.1a"><msub id="S3.SS4.p2.7.m7.1.2"><mover id="S3.SS4.p2.7.m7.1.2.2" accent="true"><mi id="S3.SS4.p2.7.m7.1.2.2.2">q</mi><mo id="S3.SS4.p2.7.m7.1.2.2.1">^</mo></mover><mrow id="S3.SS4.p2.7.m7.1.1.1.3"><mo stretchy="false" id="S3.SS4.p2.7.m7.1.1.1.3.1">(</mo><mo rspace="0em" lspace="0em" id="S3.SS4.p2.7.m7.1.1.1.1">⋅</mo><mo stretchy="false" id="S3.SS4.p2.7.m7.1.1.1.3.2">)</mo></mrow></msub><annotation-xml id="S3.SS4.p2.7.m7.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS4.p2.7.m7.1c" encoding="application/x-tex">\hat{q}_{(\cdot)}</annotation><annotation id="S3.SS4.p2.7.m7.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT ( ⋅ ) end_POSTSUBSCRIPT</annotation></semantics></math> 最相关的生成问题 <math id="S3.SS4.p2.8.m8.1" display="inline" class="ltx_Math" alttext="1"><semantics id="S3.SS4.p2.8.m8.1a"><mn id="S3.SS4.p2.8.m8.1.1">1</mn><annotation-xml id="S3.SS4.p2.8.m8.1b" encoding="MathML-Content">1</annotation-xml><annotation id="S3.SS4.p2.8.m8.1c" encoding="application/x-tex">1</annotation><annotation id="S3.SS4.p2.8.m8.1d" encoding="application/x-llamapun">1</annotation></semantics></math> 被赋予，而另一个则被赋予 <math id="S3.SS4.p2.9.m9.1" display="inline" class="ltx_Math" alttext="0"><semantics id="S3.SS4.p2.9.m9.1a"><mn id="S3.SS4.p2.9.m9.1.1">0</mn><annotation-xml id="S3.SS4.p2.9.m9.1b" encoding="MathML-Content">0</annotation-xml></semantics></math> 。我们根据公式 2 计算了人类标注人员分配的平均分数与相应的 SemRel 分数之间的平均绝对误差（MAE）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS4.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{MAE(Human, SimRel)}=\frac{\sum_{\hat{q}\in Q}|\text{ Human}(\hat{q})-%
\text{SemRel}(\hat{q})|}{|Q|}\text{ where }Q\in\{q^{1}_{t},q^{1}_{t^{\prime}},%
q^{2}_{t},q^{2}_{t^{\prime}},\dots,q^{30}_{t},q^{30}_{t^{\prime}}\}" class="ltx_Math" display="block" id="S3.E2.m1.11"><semantics id="S3.E2.m1.11a"><mrow id="S3.E2.m1.11.11" xref="S3.E2.m1.11.11.cmml"><mtext id="S3.E2.m1.11.11.8" xref="S3.E2.m1.11.11.8a.cmml">MAE(Human, SimRel)</mtext><mo id="S3.E2.m1.11.11.9" xref="S3.E2.m1.11.11.9.cmml">=</mo><mrow id="S3.E2.m1.11.11.10" xref="S3.E2.m1.11.11.10.cmml"><mfrac id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><mrow id="S3.E2.m1.3.3.3" xref="S3.E2.m1.3.3.3.cmml"><msub id="S3.E2.m1.3.3.3.4" xref="S3.E2.m1.3.3.3.4.cmml"><mo id="S3.E2.m1.3.3.3.4.2" xref="S3.E2.m1.3.3.3.4.2.cmml">∑</mo><mrow id="S3.E2.m1.3.3.3.4.3" xref="S3.E2.m1.3.3.3.4.3.cmml"><mover accent="true" id="S3.E2.m1.3.3.3.4.3.2" xref="S3.E2.m1.3.3.3.4.3.2.cmml"><mi id="S3.E2.m1.3.3.3.4.3.2.2" xref="S3.E2.m1.3.3.3.4.3.2.2.cmml">q</mi><mo id="S3.E2.m1.3.3.3.4.3.2.1" xref="S3.E2.m1.3.3.3.4.3.2.1.cmml">^</mo></mover><mo id="S3.E2.m1.3.3.3.4.3.1" xref="S3.E2.m1.3.3.3.4.3.1.cmml">∈</mo><mi id="S3.E2.m1.3.3.3.4.3.3" xref="S3.E2.m1.3.3.3.4.3.3.cmml">Q</mi></mrow></msub><mrow id="S3.E2.m1.3.3.3.3.1" xref="S3.E2.m1.3.3.3.3.2.cmml"><mo id="S3.E2.m1.3.3.3.3.1.2" lspace="0em" stretchy="false" xref="S3.E2.m1.3.3.3.3.2.1.cmml">|</mo><mrow id="S3.E2.m1.3.3.3.3.1.1" xref="S3.E2.m1.3.3.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.3.3.1.1.2" xref="S3.E2.m1.3.3.3.3.1.1.2.cmml"><mtext id="S3.E2.m1.3.3.3.3.1.1.2.2" xref="S3.E2.m1.3.3.3.3.1.1.2.2a.cmml">&nbsp;Human</mtext><mo id="S3.E2.m1.3.3.3.3.1.1.2.1" xref="S3.E2.m1.3.3.3.3.1.1.2.1.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.3.3.1.1.2.3.2" xref="S3.E2.m1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.3.3.1.1.2.3.2.1" stretchy="false" xref="S3.E2.m1.1.1.1.1.cmml">(</mo><mover accent="true" id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">q</mi><mo id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml">^</mo></mover><mo id="S3.E2.m1.3.3.3.3.1.1.2.3.2.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.3.3.1.1.1" xref="S3.E2.m1.3.3.3.3.1.1.1.cmml">−</mo><mrow id="S3.E2.m1.3.3.3.3.1.1.3" xref="S3.E2.m1.3.3.3.3.1.1.3.cmml"><mtext id="S3.E2.m1.3.3.3.3.1.1.3.2" xref="S3.E2.m1.3.3.3.3.1.1.3.2a.cmml">SemRel</mtext><mo id="S3.E2.m1.3.3.3.3.1.1.3.1" xref="S3.E2.m1.3.3.3.3.1.1.3.1.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.3.3.1.1.3.3.2" xref="S3.E2.m1.2.2.2.2.cmml"><mo id="S3.E2.m1.3.3.3.3.1.1.3.3.2.1" stretchy="false" xref="S3.E2.m1.2.2.2.2.cmml">(</mo><mover accent="true" id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.cmml">q</mi><mo id="S3.E2.m1.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.1.cmml">^</mo></mover><mo id="S3.E2.m1.3.3.3.3.1.1.3.3.2.2" stretchy="false" xref="S3.E2.m1.2.2.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.3.3.1.3" stretchy="false" xref="S3.E2.m1.3.3.3.3.2.1.cmml">|</mo></mrow></mrow><mrow id="S3.E2.m1.4.4.4.3" xref="S3.E2.m1.4.4.4.2.cmml"><mo id="S3.E2.m1.4.4.4.3.1" stretchy="false" xref="S3.E2.m1.4.4.4.2.1.cmml">|</mo><mi id="S3.E2.m1.4.4.4.1" xref="S3.E2.m1.4.4.4.1.cmml">Q</mi><mo id="S3.E2.m1.4.4.4.3.2" stretchy="false" xref="S3.E2.m1.4.4.4.2.1.cmml">|</mo></mrow></mfrac><mo id="S3.E2.m1.11.11.10.1" xref="S3.E2.m1.11.11.10.1.cmml">⁢</mo><mtext id="S3.E2.m1.11.11.10.2" xref="S3.E2.m1.11.11.10.2a.cmml">&nbsp;where&nbsp;</mtext><mo id="S3.E2.m1.11.11.10.1a" xref="S3.E2.m1.11.11.10.1.cmml">⁢</mo><mi id="S3.E2.m1.11.11.10.3" xref="S3.E2.m1.11.11.10.3.cmml">Q</mi></mrow><mo id="S3.E2.m1.11.11.11" xref="S3.E2.m1.11.11.11.cmml">∈</mo><mrow id="S3.E2.m1.11.11.6.6" xref="S3.E2.m1.11.11.6.7.cmml"><mo id="S3.E2.m1.11.11.6.6.7" stretchy="false" xref="S3.E2.m1.11.11.6.7.cmml">{</mo><msubsup id="S3.E2.m1.6.6.1.1.1" xref="S3.E2.m1.6.6.1.1.1.cmml"><mi id="S3.E2.m1.6.6.1.1.1.2.2" xref="S3.E2.m1.6.6.1.1.1.2.2.cmml">q</mi><mi id="S3.E2.m1.6.6.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.3.cmml">t</mi><mn id="S3.E2.m1.6.6.1.1.1.2.3" xref="S3.E2.m1.6.6.1.1.1.2.3.cmml">1</mn></msubsup><mo id="S3.E2.m1.11.11.6.6.8" xref="S3.E2.m1.11.11.6.7.cmml">,</mo><msubsup id="S3.E2.m1.7.7.2.2.2" xref="S3.E2.m1.7.7.2.2.2.cmml"><mi id="S3.E2.m1.7.7.2.2.2.2.2" xref="S3.E2.m1.7.7.2.2.2.2.2.cmml">q</mi><msup id="S3.E2.m1.7.7.2.2.2.3" xref="S3.E2.m1.7.7.2.2.2.3.cmml"><mi id="S3.E2.m1.7.7.2.2.2.3.2" xref="S3.E2.m1.7.7.2.2.2.3.2.cmml">t</mi><mo id="S3.E2.m1.7.7.2.2.2.3.3" xref="S3.E2.m1.7.7.2.2.2.3.3.cmml">′</mo></msup><mn id="S3.E2.m1.7.7.2.2.2.2.3" xref="S3.E2.m1.7.7.2.2.2.2.3.cmml">1</mn></msubsup><mo id="S3.E2.m1.11.11.6.6.9" xref="S3.E2.m1.11.11.6.7.cmml">,</mo><msubsup id="S3.E2.m1.8.8.3.3.3" xref="S3.E2.m1.8.8.3.3.3.cmml"><mi id="S3.E2.m1.8.8.3.3.3.2.2" xref="S3.E2.m1.8.8.3.3.3.2.2.cmml">q</mi><mi id="S3.E2.m1.8.8.3.3.3.3" xref="S3.E2.m1.8.8.3.3.3.3.cmml">t</mi><mn id="S3.E2.m1.8.8.3.3.3.2.3" xref="S3.E2.m1.8.8.3.3.3.2.3.cmml">2</mn></msubsup><mo id="S3.E2.m1.11.11.6.6.10" xref="S3.E2.m1.11.11.6.7.cmml">,</mo><msubsup id="S3.E2.m1.9.9.4.4.4" xref="S3.E2.m1.9.9.4.4.4.cmml"><mi id="S3.E2.m1.9.9.4.4.4.2.2" xref="S3.E2.m1.9.9.4.4.4.2.2.cmml">q</mi><msup id="S3.E2.m1.9.9.4.4.4.3" xref="S3.E2.m1.9.9.4.4.4.3.cmml"><mi id="S3.E2.m1.9.9.4.4.4.3.2" xref="S3.E2.m1.9.9.4.4.4.3.2.cmml">t</mi><mo id="S3.E2.m1.9.9.4.4.4.3.3" xref="S3.E2.m1.9.9.4.4.4.3.3.cmml">′</mo></msup><mn id="S3.E2.m1.9.9.4.4.4.2.3" xref="S3.E2.m1.9.9.4.4.4.2.3.cmml">2</mn></msubsup><mo id="S3.E2.m1.11.11.6.6.11" xref="S3.E2.m1.11.11.6.7.cmml">,</mo><mi id="S3.E2.m1.5.5" mathvariant="normal" xref="S3.E2.m1.5.5.cmml">…</mi><mo id="S3.E2.m1.11.11.6.6.12" xref="S3.E2.m1.11.11.6.7.cmml">,</mo><msubsup id="S3.E2.m1.10.10.5.5.5" xref="S3.E2.m1.10.10.5.5.5.cmml"><mi id="S3.E2.m1.10.10.5.5.5.2.2" xref="S3.E2.m1.10.10.5.5.5.2.2.cmml">q</mi><mi id="S3.E2.m1.10.10.5.5.5.3" xref="S3.E2.m1.10.10.5.5.5.3.cmml">t</mi><mn id="S3.E2.m1.10.10.5.5.5.2.3" xref="S3.E2.m1.10.10.5.5.5.2.3.cmml">30</mn></msubsup><mo id="S3.E2.m1.11.11.6.6.13" xref="S3.E2.m1.11.11.6.7.cmml">,</mo><msubsup id="S3.E2.m1.11.11.6.6.6" xref="S3.E2.m1.11.11.6.6.6.cmml"><mi id="S3.E2.m1.11.11.6.6.6.2.2" xref="S3.E2.m1.11.11.6.6.6.2.2.cmml">q</mi><msup id="S3.E2.m1.11.11.6.6.6.3" xref="S3.E2.m1.11.11.6.6.6.3.cmml"><mi id="S3.E2.m1.11.11.6.6.6.3.2" xref="S3.E2.m1.11.11.6.6.6.3.2.cmml">t</mi><mo id="S3.E2.m1.11.11.6.6.6.3.3" xref="S3.E2.m1.11.11.6.6.6.3.3.cmml">′</mo></msup><mn id="S3.E2.m1.11.11.6.6.6.2.3" xref="S3.E2.m1.11.11.6.6.6.2.3.cmml">30</mn></msubsup><mo id="S3.E2.m1.11.11.6.6.14" stretchy="false" xref="S3.E2.m1.11.11.6.7.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.11b"><apply id="S3.E2.m1.11.11.cmml" xref="S3.E2.m1.11.11"><and id="S3.E2.m1.11.11a.cmml" xref="S3.E2.m1.11.11"></and><apply id="S3.E2.m1.11.11b.cmml" xref="S3.E2.m1.11.11"><eq id="S3.E2.m1.11.11.9.cmml" xref="S3.E2.m1.11.11.9"></eq><ci id="S3.E2.m1.11.11.8a.cmml" xref="S3.E2.m1.11.11.8"><mtext id="S3.E2.m1.11.11.8.cmml" xref="S3.E2.m1.11.11.8">MAE(Human, SimRel)</mtext></ci><apply id="S3.E2.m1.11.11.10.cmml" xref="S3.E2.m1.11.11.10"><times id="S3.E2.m1.11.11.10.1.cmml" xref="S3.E2.m1.11.11.10.1"></times><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4"><divide id="S3.E2.m1.4.4.5.cmml" xref="S3.E2.m1.4.4"></divide><apply id="S3.E2.m1.3.3.3.cmml" xref="S3.E2.m1.3.3.3"><apply id="S3.E2.m1.3.3.3.4.cmml" xref="S3.E2.m1.3.3.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.4.1.cmml" xref="S3.E2.m1.3.3.3.4">subscript</csymbol><sum id="S3.E2.m1.3.3.3.4.2.cmml" xref="S3.E2.m1.3.3.3.4.2"></sum><apply id="S3.E2.m1.3.3.3.4.3.cmml" xref="S3.E2.m1.3.3.3.4.3"><in id="S3.E2.m1.3.3.3.4.3.1.cmml" xref="S3.E2.m1.3.3.3.4.3.1"></in><apply id="S3.E2.m1.3.3.3.4.3.2.cmml" xref="S3.E2.m1.3.3.3.4.3.2"><ci id="S3.E2.m1.3.3.3.4.3.2.1.cmml" xref="S3.E2.m1.3.3.3.4.3.2.1">^</ci><ci id="S3.E2.m1.3.3.3.4.3.2.2.cmml" xref="S3.E2.m1.3.3.3.4.3.2.2">𝑞</ci></apply><ci id="S3.E2.m1.3.3.3.4.3.3.cmml" xref="S3.E2.m1.3.3.3.4.3.3">𝑄</ci></apply></apply><apply id="S3.E2.m1.3.3.3.3.2.cmml" xref="S3.E2.m1.3.3.3.3.1"><abs id="S3.E2.m1.3.3.3.3.2.1.cmml" xref="S3.E2.m1.3.3.3.3.1.2"></abs><apply id="S3.E2.m1.3.3.3.3.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1"><minus id="S3.E2.m1.3.3.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1"></minus><apply id="S3.E2.m1.3.3.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2"><times id="S3.E2.m1.3.3.3.3.1.1.2.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.1"></times><ci id="S3.E2.m1.3.3.3.3.1.1.2.2a.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2"><mtext id="S3.E2.m1.3.3.3.3.1.1.2.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2">&nbsp;Human</mtext></ci><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.3.2"><ci id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1">^</ci><ci id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2">𝑞</ci></apply></apply><apply id="S3.E2.m1.3.3.3.3.1.1.3.cmml" xref="S3.E2.m1.3.3.3.3.1.1.3"><times id="S3.E2.m1.3.3.3.3.1.1.3.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.3.1"></times><ci id="S3.E2.m1.3.3.3.3.1.1.3.2a.cmml" xref="S3.E2.m1.3.3.3.3.1.1.3.2"><mtext id="S3.E2.m1.3.3.3.3.1.1.3.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.3.2">SemRel</mtext></ci><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.3.3.2"><ci id="S3.E2.m1.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.1">^</ci><ci id="S3.E2.m1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2">𝑞</ci></apply></apply></apply></apply></apply><apply id="S3.E2.m1.4.4.4.2.cmml" xref="S3.E2.m1.4.4.4.3"><abs id="S3.E2.m1.4.4.4.2.1.cmml" xref="S3.E2.m1.4.4.4.3.1"></abs><ci id="S3.E2.m1.4.4.4.1.cmml" xref="S3.E2.m1.4.4.4.1">𝑄</ci></apply></apply><ci id="S3.E2.m1.11.11.10.2a.cmml" xref="S3.E2.m1.11.11.10.2"><mtext id="S3.E2.m1.11.11.10.2.cmml" xref="S3.E2.m1.11.11.10.2">&nbsp;where&nbsp;</mtext></ci><ci id="S3.E2.m1.11.11.10.3.cmml" xref="S3.E2.m1.11.11.10.3">𝑄</ci></apply></apply><apply id="S3.E2.m1.11.11c.cmml" xref="S3.E2.m1.11.11"><in id="S3.E2.m1.11.11.11.cmml" xref="S3.E2.m1.11.11.11"></in><share href="https://arxiv.org/html/2501.05220v1#S3.E2.m1.11.11.10.cmml" id="S3.E2.m1.11.11d.cmml" xref="S3.E2.m1.11.11"></share><set id="S3.E2.m1.11.11.6.7.cmml" xref="S3.E2.m1.11.11.6.6"><apply id="S3.E2.m1.6.6.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.1.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1">subscript</csymbol><apply id="S3.E2.m1.6.6.1.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.1.1.1.2.1.cmml" xref="S3.E2.m1.6.6.1.1.1">superscript</csymbol><ci id="S3.E2.m1.6.6.1.1.1.2.2.cmml" xref="S3.E2.m1.6.6.1.1.1.2.2">𝑞</ci><cn id="S3.E2.m1.6.6.1.1.1.2.3.cmml" type="integer" xref="S3.E2.m1.6.6.1.1.1.2.3">1</cn></apply><ci id="S3.E2.m1.6.6.1.1.1.3.cmml" xref="S3.E2.m1.6.6.1.1.1.3">𝑡</ci></apply><apply id="S3.E2.m1.7.7.2.2.2.cmml" xref="S3.E2.m1.7.7.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.2.2.2.1.cmml" xref="S3.E2.m1.7.7.2.2.2">subscript</csymbol><apply id="S3.E2.m1.7.7.2.2.2.2.cmml" xref="S3.E2.m1.7.7.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.2.2.2.2.1.cmml" xref="S3.E2.m1.7.7.2.2.2">superscript</csymbol><ci id="S3.E2.m1.7.7.2.2.2.2.2.cmml" xref="S3.E2.m1.7.7.2.2.2.2.2">𝑞</ci><cn id="S3.E2.m1.7.7.2.2.2.2.3.cmml" type="integer" xref="S3.E2.m1.7.7.2.2.2.2.3">1</cn></apply><apply id="S3.E2.m1.7.7.2.2.2.3.cmml" xref="S3.E2.m1.7.7.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.2.2.2.3.1.cmml" xref="S3.E2.m1.7.7.2.2.2.3">superscript</csymbol><ci id="S3.E2.m1.7.7.2.2.2.3.2.cmml" xref="S3.E2.m1.7.7.2.2.2.3.2">𝑡</ci><ci id="S3.E2.m1.7.7.2.2.2.3.3.cmml" xref="S3.E2.m1.7.7.2.2.2.3.3">′</ci></apply></apply><apply id="S3.E2.m1.8.8.3.3.3.cmml" xref="S3.E2.m1.8.8.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.3.3.3.1.cmml" xref="S3.E2.m1.8.8.3.3.3">subscript</csymbol><apply id="S3.E2.m1.8.8.3.3.3.2.cmml" xref="S3.E2.m1.8.8.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.3.3.3.2.1.cmml" xref="S3.E2.m1.8.8.3.3.3">superscript</csymbol><ci id="S3.E2.m1.8.8.3.3.3.2.2.cmml" xref="S3.E2.m1.8.8.3.3.3.2.2">𝑞</ci><cn id="S3.E2.m1.8.8.3.3.3.2.3.cmml" type="integer" xref="S3.E2.m1.8.8.3.3.3.2.3">2</cn></apply><ci id="S3.E2.m1.8.8.3.3.3.3.cmml" xref="S3.E2.m1.8.8.3.3.3.3">𝑡</ci></apply><apply id="S3.E2.m1.9.9.4.4.4.cmml" xref="S3.E2.m1.9.9.4.4.4"><csymbol cd="ambiguous" id="S3.E2.m1.9.9.4.4.4.1.cmml" xref="S3.E2.m1.9.9.4.4.4">subscript</csymbol><apply id="S3.E2.m1.9.9.4.4.4.2.cmml" xref="S3.E2.m1.9.9.4.4.4"><csymbol cd="ambiguous" id="S3.E2.m1.9.9.4.4.4.2.1.cmml" xref="S3.E2.m1.9.9.4.4.4">superscript</csymbol><ci id="S3.E2.m1.9.9.4.4.4.2.2.cmml" xref="S3.E2.m1.9.9.4.4.4.2.2">𝑞</ci><cn id="S3.E2.m1.9.9.4.4.4.2.3.cmml" type="integer" xref="S3.E2.m1.9.9.4.4.4.2.3">2</cn></apply><apply id="S3.E2.m1.9.9.4.4.4.3.cmml" xref="S3.E2.m1.9.9.4.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.9.9.4.4.4.3.1.cmml" xref="S3.E2.m1.9.9.4.4.4.3">superscript</csymbol><ci id="S3.E2.m1.9.9.4.4.4.3.2.cmml" xref="S3.E2.m1.9.9.4.4.4.3.2">𝑡</ci><ci id="S3.E2.m1.9.9.4.4.4.3.3.cmml" xref="S3.E2.m1.9.9.4.4.4.3.3">′</ci></apply></apply><ci id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5">…</ci><apply id="S3.E2.m1.10.10.5.5.5.cmml" xref="S3.E2.m1.10.10.5.5.5"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.5.5.5.1.cmml" xref="S3.E2.m1.10.10.5.5.5">subscript</csymbol><apply id="S3.E2.m1.10.10.5.5.5.2.cmml" xref="S3.E2.m1.10.10.5.5.5"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.5.5.5.2.1.cmml" xref="S3.E2.m1.10.10.5.5.5">superscript</csymbol><ci id="S3.E2.m1.10.10.5.5.5.2.2.cmml" xref="S3.E2.m1.10.10.5.5.5.2.2">𝑞</ci><cn id="S3.E2.m1.10.10.5.5.5.2.3.cmml" type="integer" xref="S3.E2.m1.10.10.5.5.5.2.3">30</cn></apply><ci id="S3.E2.m1.10.10.5.5.5.3.cmml" xref="S3.E2.m1.10.10.5.5.5.3">𝑡</ci></apply><apply id="S3.E2.m1.11.11.6.6.6.cmml" xref="S3.E2.m1.11.11.6.6.6"><csymbol cd="ambiguous" id="S3.E2.m1.11.11.6.6.6.1.cmml" xref="S3.E2.m1.11.11.6.6.6">subscript</csymbol><apply id="S3.E2.m1.11.11.6.6.6.2.cmml" xref="S3.E2.m1.11.11.6.6.6"><csymbol cd="ambiguous" id="S3.E2.m1.11.11.6.6.6.2.1.cmml" xref="S3.E2.m1.11.11.6.6.6">superscript</csymbol><ci id="S3.E2.m1.11.11.6.6.6.2.2.cmml" xref="S3.E2.m1.11.11.6.6.6.2.2">𝑞</ci><cn id="S3.E2.m1.11.11.6.6.6.2.3.cmml" type="integer" xref="S3.E2.m1.11.11.6.6.6.2.3">30</cn></apply><apply id="S3.E2.m1.11.11.6.6.6.3.cmml" xref="S3.E2.m1.11.11.6.6.6.3"><csymbol cd="ambiguous" id="S3.E2.m1.11.11.6.6.6.3.1.cmml" xref="S3.E2.m1.11.11.6.6.6.3">superscript</csymbol><ci id="S3.E2.m1.11.11.6.6.6.3.2.cmml" xref="S3.E2.m1.11.11.6.6.6.3.2">𝑡</ci><ci id="S3.E2.m1.11.11.6.6.6.3.3.cmml" xref="S3.E2.m1.11.11.6.6.6.3.3">′</ci></apply></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.11c">\text{MAE(Human, SimRel)}=\frac{\sum_{\hat{q}\in Q}|\text{ Human}(\hat{q})-%
\text{SemRel}(\hat{q})|}{|Q|}\text{ where }Q\in\{q^{1}_{t},q^{1}_{t^{\prime}},%
q^{2}_{t},q^{2}_{t^{\prime}},\dots,q^{30}_{t},q^{30}_{t^{\prime}}\}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.11d">MAE(Human, SimRel) = divide start_ARG ∑ start_POSTSUBSCRIPT over^ start_ARG italic_q end_ARG ∈ italic_Q end_POSTSUBSCRIPT | Human ( over^ start_ARG italic_q end_ARG ) - SemRel ( over^ start_ARG italic_q end_ARG ) | end_ARG start_ARG | italic_Q | end_ARG where italic_Q ∈ { italic_q start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_q start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , … , italic_q start_POSTSUPERSCRIPT 30 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_q start_POSTSUPERSCRIPT 30 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5. </span>Experimental Setup for Automated Performance Evaluations<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.5. 自动化性能评估的实验设置</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.F2" title="Figure 2 ‣ 3.5. Experimental Setup for Automated Performance Evaluations ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the experimental setup designed to address RQs 2-5. A total of six models (including TopicQG’s base, 8bit, and 4bit versions) have been developed as described in detail in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3" title="3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.3</span></a> and represented as coloured boxes in figure <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.F2" title="Figure 2 ‣ 3.5. Experimental Setup for Automated Performance Evaluations ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2</span></a>. Each model is evaluated using the MixKhanQ dataset.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 2 展示了为解决 RQ 2-5 而设计的实验设置。共开发了六个模型（包括 TopicQG 的基础版本、8bit 版本和 4bit 版本），这些模型在 3.3 节中有详细描述，并在图 2 中以彩色方框表示。每个模型都使用 MixKhanQ 数据集进行评估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F2">
<p class="ltx_p ltx_align_center ltx_align_center" id="S3.F2.1.1"><span class="ltx_text" id="S3.F2.1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="298" id="S3.F2.1.1.1.g1" src="./一种用于教育领域中可扩展和自动主题控制问题生成的新方法 --- A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education_files/x3.png" width="581"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Methodology for training and evaluating the Baseline model (black), TopicQGedu model (green, RQ3), TopicQG model (dark red, RQ2), its post-training quantised counterparts, TopicQG8bit model(medium red, RQ4), TopicQG4bit model(light red, RQ4) and TopicQG2X model (blue, RQ5). The numbered circles indicate different experimental pathways that test different research questions. The shaded grey box indicates that the <span class="ltx_text ltx_font_typewriter" id="S3.F2.3.1">T5-Small</span> model was available pre-trained prior to the experiments while the non-shaded models contained parameters trained during the experiments.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 2. 训练和评估基线模型（黑色）、TopicQGedu 模型（绿色，RQ3）、TopicQG 模型（深红色，RQ2）、其训练后的量化版本、TopicQG8bit 模型（中红色，RQ4）、TopicQG4bit 模型（浅红色，RQ4）和 TopicQG2X 模型（蓝色，RQ5）的方法。带编号的圆圈表示不同的实验路径，用于测试不同的研究问题。阴影的灰色框表示 T5-Small 模型在实验前已预训练，而非阴影的模型包含在实验中训练的参数。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S3.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6. </span>Evaluation Metrics<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.6.评估指标</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS6.p1">
<p class="ltx_p" id="S3.SS6.p1.3">When evaluating the final models, we focused on two main aspects. 1) The generated question <math alttext="\hat{q_{t}}" class="ltx_Math" display="inline" id="S3.SS6.p1.1.m1.1"><semantics id="S3.SS6.p1.1.m1.1a"><mover accent="true" id="S3.SS6.p1.1.m1.1.1" xref="S3.SS6.p1.1.m1.1.1.cmml"><msub id="S3.SS6.p1.1.m1.1.1.2" xref="S3.SS6.p1.1.m1.1.1.2.cmml"><mi id="S3.SS6.p1.1.m1.1.1.2.2" xref="S3.SS6.p1.1.m1.1.1.2.2.cmml">q</mi><mi id="S3.SS6.p1.1.m1.1.1.2.3" xref="S3.SS6.p1.1.m1.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS6.p1.1.m1.1.1.1" xref="S3.SS6.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS6.p1.1.m1.1b"><apply id="S3.SS6.p1.1.m1.1.1.cmml" xref="S3.SS6.p1.1.m1.1.1"><ci id="S3.SS6.p1.1.m1.1.1.1.cmml" xref="S3.SS6.p1.1.m1.1.1.1">^</ci><apply id="S3.SS6.p1.1.m1.1.1.2.cmml" xref="S3.SS6.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS6.p1.1.m1.1.1.2.1.cmml" xref="S3.SS6.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS6.p1.1.m1.1.1.2.2.cmml" xref="S3.SS6.p1.1.m1.1.1.2.2">𝑞</ci><ci id="S3.SS6.p1.1.m1.1.1.2.3.cmml" xref="S3.SS6.p1.1.m1.1.1.2.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.p1.1.m1.1c">\hat{q_{t}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.p1.1.m1.1d">over^ start_ARG italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> is of high linguistic quality so it has the potential to be used in educational settings, 2) The generated question <math alttext="\hat{q_{t}}" class="ltx_Math" display="inline" id="S3.SS6.p1.2.m2.1"><semantics id="S3.SS6.p1.2.m2.1a"><mover accent="true" id="S3.SS6.p1.2.m2.1.1" xref="S3.SS6.p1.2.m2.1.1.cmml"><msub id="S3.SS6.p1.2.m2.1.1.2" xref="S3.SS6.p1.2.m2.1.1.2.cmml"><mi id="S3.SS6.p1.2.m2.1.1.2.2" xref="S3.SS6.p1.2.m2.1.1.2.2.cmml">q</mi><mi id="S3.SS6.p1.2.m2.1.1.2.3" xref="S3.SS6.p1.2.m2.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS6.p1.2.m2.1.1.1" xref="S3.SS6.p1.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS6.p1.2.m2.1b"><apply id="S3.SS6.p1.2.m2.1.1.cmml" xref="S3.SS6.p1.2.m2.1.1"><ci id="S3.SS6.p1.2.m2.1.1.1.cmml" xref="S3.SS6.p1.2.m2.1.1.1">^</ci><apply id="S3.SS6.p1.2.m2.1.1.2.cmml" xref="S3.SS6.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS6.p1.2.m2.1.1.2.1.cmml" xref="S3.SS6.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS6.p1.2.m2.1.1.2.2.cmml" xref="S3.SS6.p1.2.m2.1.1.2.2">𝑞</ci><ci id="S3.SS6.p1.2.m2.1.1.2.3.cmml" xref="S3.SS6.p1.2.m2.1.1.2.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.p1.2.m2.1c">\hat{q_{t}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.p1.2.m2.1d">over^ start_ARG italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> is <em class="ltx_emph ltx_font_italic" id="S3.SS6.p1.3.1">semantically related</em> to the prescribed topic <math alttext="t" class="ltx_Math" display="inline" id="S3.SS6.p1.3.m3.1"><semantics id="S3.SS6.p1.3.m3.1a"><mi id="S3.SS6.p1.3.m3.1.1" xref="S3.SS6.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS6.p1.3.m3.1b"><ci id="S3.SS6.p1.3.m3.1.1.cmml" xref="S3.SS6.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.p1.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.p1.3.m3.1d">italic_t</annotation></semantics></math> so that it can address the AI-generated questions’ common problem of being ”too general to be useful in practice” in educational settings.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在评估最终模型时，我们关注了两个主要方面。1) 生成的题目 <math id="S3.SS6.p1.1.m1.1" display="inline" class="ltx_Math" alttext="\hat{q_{t}}"><semantics id="S3.SS6.p1.1.m1.1a"><mover id="S3.SS6.p1.1.m1.1.1" accent="true"><msub id="S3.SS6.p1.1.m1.1.1.2"><mi id="S3.SS6.p1.1.m1.1.1.2.2">q</mi><mi id="S3.SS6.p1.1.m1.1.1.2.3">t</mi></msub><mo id="S3.SS6.p1.1.m1.1.1.1">^</mo></mover><annotation-xml id="S3.SS6.p1.1.m1.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS6.p1.1.m1.1c" encoding="application/x-tex">\hat{q_{t}}</annotation><annotation id="S3.SS6.p1.1.m1.1d" encoding="application/x-llamapun">over^ start_ARG italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> 具有高质量的语法，因此有潜力用于教育环境，2) 生成的题目 <math id="S3.SS6.p1.2.m2.1" display="inline" class="ltx_Math" alttext="\hat{q_{t}}"><semantics id="S3.SS6.p1.2.m2.1a"><mover id="S3.SS6.p1.2.m2.1.1" accent="true"><msub id="S3.SS6.p1.2.m2.1.1.2"><mi id="S3.SS6.p1.2.m2.1.1.2.2">q</mi><mi id="S3.SS6.p1.2.m2.1.1.2.3">t</mi></msub><mo id="S3.SS6.p1.2.m2.1.1.1">^</mo></mover><annotation-xml id="S3.SS6.p1.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS6.p1.2.m2.1c" encoding="application/x-tex">\hat{q_{t}}</annotation><annotation id="S3.SS6.p1.2.m2.1d" encoding="application/x-llamapun">over^ start_ARG italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG</annotation></semantics></math> 与指定主题 <math id="S3.SS6.p1.3.m3.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S3.SS6.p1.3.m3.1a"><mi id="S3.SS6.p1.3.m3.1.1">t</mi><annotation-xml id="S3.SS6.p1.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS6.p1.3.m3.1c" encoding="application/x-tex">t</annotation><annotation id="S3.SS6.p1.3.m3.1d" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 具有语义相关性，以便能够解决 AI 生成的题目在教育环境中常见的“过于笼统而缺乏实用性”的问题。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S3.SS6.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.1. </span>Evaluating the quality of generations<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.6.1.评估生成质量</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS6.SSS1.p1">
<p class="ltx_p" id="S3.SS6.SSS1.p1.1">To assess the quality of the generated questions, the similarity between the reference question and the generated question is measured. We employed a suite of metrics, including BLEU <cite class="ltx_cite ltx_citemacro_citep">(Papineni et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib44" title="">2002</a>)</cite>, METEOR<cite class="ltx_cite ltx_citemacro_citep">(Banerjee and Lavie, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib5" title="">2005</a>)</cite>, ROUGE <cite class="ltx_cite ltx_citemacro_citep">(Lin, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib39" title="">2004</a>)</cite>, F1 score, and Perplexity<cite class="ltx_cite ltx_citemacro_citep">(Hansen et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib33" title="">2023</a>)</cite>, which have been used frequently in previous research <cite class="ltx_cite ltx_citemacro_citep">(Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib8" title="">2023</a>)</cite>. These metrics provide a comprehensive evaluation of the fluency, relevance, and coherence of the generated questions, serving as scalable indicators of the automated evaluation of the generated questions’ quality.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了评估生成题目的质量，测量参考题目与生成题目之间的相似度。我们采用了一系列指标，包括 BLEU（Papineni 等人，2002 年）、METEOR（Banerjee 和 Lavie，2005 年）、ROUGE（Lin，2004 年）、F1 分数和困惑度（Hansen 等人，2023 年），这些指标在以往研究中已被频繁使用（Bulathwela 等人，2023 年）。这些指标全面评估了生成题目的流畅性、相关性和连贯性，作为可扩展的自动化评估生成题目质量的指标。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS6.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.2. </span>Semantic relatedness between the questions generated and the topic<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.6.2.生成的问题与主题之间的语义相关性</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS6.SSS2.p1">
<p class="ltx_p" id="S3.SS6.SSS2.p1.3">For measuring the semantic relatedness, <math alttext="SemRel(q_{t},\hat{q}_{t})" class="ltx_Math" display="inline" id="S3.SS6.SSS2.p1.1.m1.2"><semantics id="S3.SS6.SSS2.p1.1.m1.2a"><mrow id="S3.SS6.SSS2.p1.1.m1.2.2" xref="S3.SS6.SSS2.p1.1.m1.2.2.cmml"><mi id="S3.SS6.SSS2.p1.1.m1.2.2.4" xref="S3.SS6.SSS2.p1.1.m1.2.2.4.cmml">S</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3" xref="S3.SS6.SSS2.p1.1.m1.2.2.3.cmml">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.5" xref="S3.SS6.SSS2.p1.1.m1.2.2.5.cmml">e</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3a" xref="S3.SS6.SSS2.p1.1.m1.2.2.3.cmml">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.6" xref="S3.SS6.SSS2.p1.1.m1.2.2.6.cmml">m</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3b" xref="S3.SS6.SSS2.p1.1.m1.2.2.3.cmml">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.7" xref="S3.SS6.SSS2.p1.1.m1.2.2.7.cmml">R</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3c" xref="S3.SS6.SSS2.p1.1.m1.2.2.3.cmml">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.8" xref="S3.SS6.SSS2.p1.1.m1.2.2.8.cmml">e</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3d" xref="S3.SS6.SSS2.p1.1.m1.2.2.3.cmml">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.9" xref="S3.SS6.SSS2.p1.1.m1.2.2.9.cmml">l</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3e" xref="S3.SS6.SSS2.p1.1.m1.2.2.3.cmml">⁢</mo><mrow id="S3.SS6.SSS2.p1.1.m1.2.2.2.2" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.3.cmml"><mo id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.3" stretchy="false" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.3.cmml">(</mo><msub id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1" xref="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.2" xref="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.2.cmml">q</mi><mi id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.3" xref="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.4" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.cmml"><mover accent="true" id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.cmml"><mi id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.2" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.2.cmml">q</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.1" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.3" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.5" stretchy="false" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS2.p1.1.m1.2b"><apply id="S3.SS6.SSS2.p1.1.m1.2.2.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2"><times id="S3.SS6.SSS2.p1.1.m1.2.2.3.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.3"></times><ci id="S3.SS6.SSS2.p1.1.m1.2.2.4.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.4">𝑆</ci><ci id="S3.SS6.SSS2.p1.1.m1.2.2.5.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.5">𝑒</ci><ci id="S3.SS6.SSS2.p1.1.m1.2.2.6.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.6">𝑚</ci><ci id="S3.SS6.SSS2.p1.1.m1.2.2.7.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.7">𝑅</ci><ci id="S3.SS6.SSS2.p1.1.m1.2.2.8.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.8">𝑒</ci><ci id="S3.SS6.SSS2.p1.1.m1.2.2.9.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.9">𝑙</ci><interval closure="open" id="S3.SS6.SSS2.p1.1.m1.2.2.2.3.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2"><apply id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.2">𝑞</ci><ci id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.3">𝑡</ci></apply><apply id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2">subscript</csymbol><apply id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2"><ci id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.1.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.1">^</ci><ci id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.2.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.2">𝑞</ci></apply><ci id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.3">𝑡</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS2.p1.1.m1.2c">SemRel(q_{t},\hat{q}_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.SSS2.p1.1.m1.2d">italic_S italic_e italic_m italic_R italic_e italic_l ( italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>, we needed metrics that can quantify the relatedness between the reference question <math alttext="q_{t}" class="ltx_Math" display="inline" id="S3.SS6.SSS2.p1.2.m2.1"><semantics id="S3.SS6.SSS2.p1.2.m2.1a"><msub id="S3.SS6.SSS2.p1.2.m2.1.1" xref="S3.SS6.SSS2.p1.2.m2.1.1.cmml"><mi id="S3.SS6.SSS2.p1.2.m2.1.1.2" xref="S3.SS6.SSS2.p1.2.m2.1.1.2.cmml">q</mi><mi id="S3.SS6.SSS2.p1.2.m2.1.1.3" xref="S3.SS6.SSS2.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS2.p1.2.m2.1b"><apply id="S3.SS6.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS6.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS6.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS6.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS6.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS6.SSS2.p1.2.m2.1.1.2">𝑞</ci><ci id="S3.SS6.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS6.SSS2.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS2.p1.2.m2.1c">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.SSS2.p1.2.m2.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and the generated question <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S3.SS6.SSS2.p1.3.m3.1"><semantics id="S3.SS6.SSS2.p1.3.m3.1a"><msub id="S3.SS6.SSS2.p1.3.m3.1.1" xref="S3.SS6.SSS2.p1.3.m3.1.1.cmml"><mover accent="true" id="S3.SS6.SSS2.p1.3.m3.1.1.2" xref="S3.SS6.SSS2.p1.3.m3.1.1.2.cmml"><mi id="S3.SS6.SSS2.p1.3.m3.1.1.2.2" xref="S3.SS6.SSS2.p1.3.m3.1.1.2.2.cmml">q</mi><mo id="S3.SS6.SSS2.p1.3.m3.1.1.2.1" xref="S3.SS6.SSS2.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS6.SSS2.p1.3.m3.1.1.3" xref="S3.SS6.SSS2.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS2.p1.3.m3.1b"><apply id="S3.SS6.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS6.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS6.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS6.SSS2.p1.3.m3.1.1">subscript</csymbol><apply id="S3.SS6.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS6.SSS2.p1.3.m3.1.1.2"><ci id="S3.SS6.SSS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS6.SSS2.p1.3.m3.1.1.2.1">^</ci><ci id="S3.SS6.SSS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS6.SSS2.p1.3.m3.1.1.2.2">𝑞</ci></apply><ci id="S3.SS6.SSS2.p1.3.m3.1.1.3.cmml" xref="S3.SS6.SSS2.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS2.p1.3.m3.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.SSS2.p1.3.m3.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. We used the <span class="ltx_text ltx_font_typewriter" id="S3.SS6.SSS2.p1.3.1">BERTScore</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib61" title="">2020</a>)</cite> and the Wikipedia-based Topic Semantic Relatedness (<span class="ltx_text ltx_font_typewriter" id="S3.SS6.SSS2.p1.3.2">WikiSemRel</span>) <cite class="ltx_cite ltx_citemacro_citep">(Ferragina and Scaiella, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib28" title="">2010</a>)</cite> metrics for these evaluations.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了衡量语义相关性， <math id="S3.SS6.SSS2.p1.1.m1.2" display="inline" class="ltx_Math" alttext="SemRel(q_{t},\hat{q}_{t})"><semantics id="S3.SS6.SSS2.p1.1.m1.2a"><mrow id="S3.SS6.SSS2.p1.1.m1.2.2"><mi id="S3.SS6.SSS2.p1.1.m1.2.2.4">S</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.5">e</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3a">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.6">m</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3b">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.7">R</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3c">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.8">e</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3d">⁢</mo><mi id="S3.SS6.SSS2.p1.1.m1.2.2.9">l</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.3e">⁢</mo><mrow id="S3.SS6.SSS2.p1.1.m1.2.2.2.2"><mo stretchy="false" id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.3">(</mo><msub id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1"><mi id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.2">q</mi><mi id="S3.SS6.SSS2.p1.1.m1.1.1.1.1.1.3">t</mi></msub><mo id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.4">,</mo><msub id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2"><mover id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2" accent="true"><mi id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.2">q</mi><mo id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.2.1">^</mo></mover><mi id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.2.3">t</mi></msub><mo stretchy="false" id="S3.SS6.SSS2.p1.1.m1.2.2.2.2.5">)</mo></mrow></mrow><annotation-xml id="S3.SS6.SSS2.p1.1.m1.2b" encoding="MathML-Content">subscriptsubscript</annotation-xml><annotation id="S3.SS6.SSS2.p1.1.m1.2c" encoding="application/x-tex">SemRel(q_{t},\hat{q}_{t})</annotation><annotation id="S3.SS6.SSS2.p1.1.m1.2d" encoding="application/x-llamapun">italic_S italic_e italic_m italic_R italic_e italic_l ( italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> ，我们需要能够量化参考问题 <math id="S3.SS6.SSS2.p1.2.m2.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S3.SS6.SSS2.p1.2.m2.1a"><msub id="S3.SS6.SSS2.p1.2.m2.1.1"><mi id="S3.SS6.SSS2.p1.2.m2.1.1.2">q</mi><mi id="S3.SS6.SSS2.p1.2.m2.1.1.3">t</mi></msub><annotation-xml id="S3.SS6.SSS2.p1.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS6.SSS2.p1.2.m2.1c" encoding="application/x-tex">q_{t}</annotation><annotation id="S3.SS6.SSS2.p1.2.m2.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 和生成问题 <math id="S3.SS6.SSS2.p1.3.m3.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S3.SS6.SSS2.p1.3.m3.1a"><msub id="S3.SS6.SSS2.p1.3.m3.1.1"><mover id="S3.SS6.SSS2.p1.3.m3.1.1.2" accent="true"><mi id="S3.SS6.SSS2.p1.3.m3.1.1.2.2">q</mi><mo id="S3.SS6.SSS2.p1.3.m3.1.1.2.1">^</mo></mover><mi id="S3.SS6.SSS2.p1.3.m3.1.1.3">t</mi></msub><annotation-xml id="S3.SS6.SSS2.p1.3.m3.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS6.SSS2.p1.3.m3.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S3.SS6.SSS2.p1.3.m3.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 之间相关性的指标。我们使用了 BERTScore（Zhang 等人，2020）和基于维基百科的主题语义相关性（WikiSemRel）（Ferragina 和 Scaiella，2010）指标进行这些评估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S3.SS6.SSS2.Px1">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph" data-imt_insert_failed="1">BERTScore</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS6.SSS2.Px1.p1">
<p class="ltx_p" id="S3.SS6.SSS2.Px1.p1.3">leverages BERT contextual embeddings of tokens to calculate the similarity between two text extracts, improving upon the traditional exact match methods. Our early experiments showed that the BERTSCore tend to inflate the similarity between <math alttext="q_{t}" class="ltx_Math" display="inline" id="S3.SS6.SSS2.Px1.p1.1.m1.1"><semantics id="S3.SS6.SSS2.Px1.p1.1.m1.1a"><msub id="S3.SS6.SSS2.Px1.p1.1.m1.1.1" xref="S3.SS6.SSS2.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS6.SSS2.Px1.p1.1.m1.1.1.2" xref="S3.SS6.SSS2.Px1.p1.1.m1.1.1.2.cmml">q</mi><mi id="S3.SS6.SSS2.Px1.p1.1.m1.1.1.3" xref="S3.SS6.SSS2.Px1.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS2.Px1.p1.1.m1.1b"><apply id="S3.SS6.SSS2.Px1.p1.1.m1.1.1.cmml" xref="S3.SS6.SSS2.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS6.SSS2.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS6.SSS2.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS6.SSS2.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS6.SSS2.Px1.p1.1.m1.1.1.2">𝑞</ci><ci id="S3.SS6.SSS2.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS6.SSS2.Px1.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS2.Px1.p1.1.m1.1c">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.SSS2.Px1.p1.1.m1.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S3.SS6.SSS2.Px1.p1.2.m2.1"><semantics id="S3.SS6.SSS2.Px1.p1.2.m2.1a"><msub id="S3.SS6.SSS2.Px1.p1.2.m2.1.1" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.cmml"><mover accent="true" id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.2" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.2.cmml">q</mi><mo id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.1" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.3" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS2.Px1.p1.2.m2.1b"><apply id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.cmml" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1">subscript</csymbol><apply id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2"><ci id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.1">^</ci><ci id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.2">𝑞</ci></apply><ci id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS6.SSS2.Px1.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS2.Px1.p1.2.m2.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.SSS2.Px1.p1.2.m2.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, as there are words like ”what” and ”why” that overlap even if the generated question is not about the salient topic <math alttext="t" class="ltx_Math" display="inline" id="S3.SS6.SSS2.Px1.p1.3.m3.1"><semantics id="S3.SS6.SSS2.Px1.p1.3.m3.1a"><mi id="S3.SS6.SSS2.Px1.p1.3.m3.1.1" xref="S3.SS6.SSS2.Px1.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS2.Px1.p1.3.m3.1b"><ci id="S3.SS6.SSS2.Px1.p1.3.m3.1.1.cmml" xref="S3.SS6.SSS2.Px1.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS2.Px1.p1.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.SSS2.Px1.p1.3.m3.1d">italic_t</annotation></semantics></math> of the reference question. Therefore, we excluded stopwords in the reference and generated questions prior to calculating the BERTScore. BERTSCore is a score in the range (0,1) where 0 indicates no relatedness.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">利用 BERT 词元上下文嵌入来计算两个文本片段之间的相似度，改进了传统的精确匹配方法。我们的早期实验表明，BERTSCore 往往会夸大 <math id="S3.SS6.SSS2.Px1.p1.1.m1.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S3.SS6.SSS2.Px1.p1.1.m1.1a"><msub id="S3.SS6.SSS2.Px1.p1.1.m1.1.1"><mi id="S3.SS6.SSS2.Px1.p1.1.m1.1.1.2">q</mi><mi id="S3.SS6.SSS2.Px1.p1.1.m1.1.1.3">t</mi></msub><annotation-xml id="S3.SS6.SSS2.Px1.p1.1.m1.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS6.SSS2.Px1.p1.1.m1.1c" encoding="application/x-tex">q_{t}</annotation><annotation id="S3.SS6.SSS2.Px1.p1.1.m1.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 和 <math id="S3.SS6.SSS2.Px1.p1.2.m2.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S3.SS6.SSS2.Px1.p1.2.m2.1a"><msub id="S3.SS6.SSS2.Px1.p1.2.m2.1.1"><mover id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2" accent="true"><mi id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.2">q</mi><mo id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.2.1">^</mo></mover><mi id="S3.SS6.SSS2.Px1.p1.2.m2.1.1.3">t</mi></msub><annotation-xml id="S3.SS6.SSS2.Px1.p1.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS6.SSS2.Px1.p1.2.m2.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S3.SS6.SSS2.Px1.p1.2.m2.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 之间的相似度，即使生成的问句与参考问句的显著主题 <math id="S3.SS6.SSS2.Px1.p1.3.m3.1" display="inline" class="ltx_Math" alttext="t"><semantics id="S3.SS6.SSS2.Px1.p1.3.m3.1a"><mi id="S3.SS6.SSS2.Px1.p1.3.m3.1.1">t</mi><annotation-xml id="S3.SS6.SSS2.Px1.p1.3.m3.1b" encoding="MathML-Content"></annotation-xml><annotation id="S3.SS6.SSS2.Px1.p1.3.m3.1c" encoding="application/x-tex">t</annotation><annotation id="S3.SS6.SSS2.Px1.p1.3.m3.1d" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 无关，也会出现“what”和“why”等词语重叠的情况。因此，我们在计算 BERTScore 之前排除了参考问句和生成问句中的停用词。BERTSCore 是一个介于 0 到 1 之间的分数，其中 0 表示无关联性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS6.SSS2.Px2">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph" data-imt_insert_failed="1">WikiSemRel</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS6.SSS2.Px2.p1">
<p class="ltx_p" id="S3.SS6.SSS2.Px2.p1.2">quantifies the semantic relatedness between the Wikipedia-based concepts extracted from the reference question <math alttext="q_{t}" class="ltx_Math" display="inline" id="S3.SS6.SSS2.Px2.p1.1.m1.1"><semantics id="S3.SS6.SSS2.Px2.p1.1.m1.1a"><msub id="S3.SS6.SSS2.Px2.p1.1.m1.1.1" xref="S3.SS6.SSS2.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS6.SSS2.Px2.p1.1.m1.1.1.2" xref="S3.SS6.SSS2.Px2.p1.1.m1.1.1.2.cmml">q</mi><mi id="S3.SS6.SSS2.Px2.p1.1.m1.1.1.3" xref="S3.SS6.SSS2.Px2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS2.Px2.p1.1.m1.1b"><apply id="S3.SS6.SSS2.Px2.p1.1.m1.1.1.cmml" xref="S3.SS6.SSS2.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS6.SSS2.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS6.SSS2.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS6.SSS2.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS6.SSS2.Px2.p1.1.m1.1.1.2">𝑞</ci><ci id="S3.SS6.SSS2.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS6.SSS2.Px2.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS2.Px2.p1.1.m1.1c">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.SSS2.Px2.p1.1.m1.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and the generated question <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S3.SS6.SSS2.Px2.p1.2.m2.1"><semantics id="S3.SS6.SSS2.Px2.p1.2.m2.1a"><msub id="S3.SS6.SSS2.Px2.p1.2.m2.1.1" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.cmml"><mover accent="true" id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.2" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.2.cmml">q</mi><mo id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.1" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.3" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS6.SSS2.Px2.p1.2.m2.1b"><apply id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.cmml" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1">subscript</csymbol><apply id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2"><ci id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.1">^</ci><ci id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.2">𝑞</ci></apply><ci id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS6.SSS2.Px2.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS6.SSS2.Px2.p1.2.m2.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS6.SSS2.Px2.p1.2.m2.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. We employ the WAT API <cite class="ltx_cite ltx_citemacro_citep">(Piccinno and Ferragina, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib46" title="">2014</a>)</cite> service to calculate semantic relatedness using the 1) w2v-based method, that builds embeddings for Wiki entities based on their co-occurrence in Wikipedia pages and 2) Jaccard-based measure, that uses the outward links to other Wikipedia pages to calculate similarity <cite class="ltx_cite ltx_citemacro_citep">(Ponza et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib48" title="">2020</a>)</cite>. We Wikify the generated question to compute the WikiSemRel score which is within range (0,1) where 0 indicates no relatedness.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">量化了参考问题 <math id="S3.SS6.SSS2.Px2.p1.1.m1.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S3.SS6.SSS2.Px2.p1.1.m1.1a"><msub id="S3.SS6.SSS2.Px2.p1.1.m1.1.1"><mi id="S3.SS6.SSS2.Px2.p1.1.m1.1.1.2">q</mi><mi id="S3.SS6.SSS2.Px2.p1.1.m1.1.1.3">t</mi></msub><annotation-xml id="S3.SS6.SSS2.Px2.p1.1.m1.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS6.SSS2.Px2.p1.1.m1.1c" encoding="application/x-tex">q_{t}</annotation><annotation id="S3.SS6.SSS2.Px2.p1.1.m1.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 中从维基百科提取的概念与生成问题 <math id="S3.SS6.SSS2.Px2.p1.2.m2.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S3.SS6.SSS2.Px2.p1.2.m2.1a"><msub id="S3.SS6.SSS2.Px2.p1.2.m2.1.1"><mover id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2" accent="true"><mi id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.2">q</mi><mo id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.2.1">^</mo></mover><mi id="S3.SS6.SSS2.Px2.p1.2.m2.1.1.3">t</mi></msub><annotation-xml id="S3.SS6.SSS2.Px2.p1.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S3.SS6.SSS2.Px2.p1.2.m2.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S3.SS6.SSS2.Px2.p1.2.m2.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 之间的语义相关性。我们采用 WAT API（Piccinno and Ferragina, 2014）服务来计算语义相关性，使用 1) 基于词嵌入的方法，该方法根据维基百科页面中的共现性为维基百科实体构建嵌入，以及 2) 基于 Jaccard 的方法，该方法使用指向其他维基百科页面的外部链接来计算相似性（Ponza et al, 2020）。我们将生成问题维基化以计算 WikiSemRel 分数，该分数范围在 (0,1) 之间，其中 0 表示无相关性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Results<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4. 结果</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we present the results from the experiments described in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3" title="3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3</span></a>. The results of the human evaluations answering RQ1 is presented in table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T2" title="Table 2 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2</span></a>. The offline evaluations to validate RQ 2-5 following the methodology illustrated in figure <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.F2" title="Figure 2 ‣ 3.5. Experimental Setup for Automated Performance Evaluations ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2</span></a> are summarised in tables <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T3" title="Table 3 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T4" title="Table 4 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">4</span></a>. While table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T3" title="Table 3 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3</span></a> presents metrics relating to the linguistic quality of the generation, Table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T4" title="Table 4 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">4</span></a> presents the semantic closeness between the prescribed topic and the generated questions. The perplexity calculation in table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T3" title="Table 3 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3</span></a> is done using the <span class="ltx_text ltx_font_typewriter" id="S4.p1.1.1">TextDescriptives</span> python library with the <span class="ltx_text ltx_font_typewriter" id="S4.p1.1.2">en_core_web_lg</span> language model as the reference language distribution <cite class="ltx_cite ltx_citemacro_citep">(Hansen et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib33" title="">2023</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本节中，我们介绍了第 3 节所述实验的结果。回答 RQ1 的人工评估结果如表 2 所示。按照图 2 所示的方法论进行的 RQ 2-5 的离线评估结果总结在表 3 和表 4 中。表 3 展示了与生成语言质量相关的指标，而表 4 则展示了规定主题与生成问题之间的语义接近度。表 3 中的困惑度计算使用 TextDescriptives python 库，并以 en_core_web_lg 语言模型作为参考语言分布（Hansen 等人，2023）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Alignment between human annotation and Semantic Relatedness (SemRel) scores. The best performance and the next best for each metric is highlighted in <span class="ltx_text ltx_font_bold" id="S4.T2.4.1">bold</span> and <span class="ltx_text ltx_font_italic" id="S4.T2.5.2">italic</span>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 2.人工标注与语义相关性（SemRel）分数之间的对齐情况。每个指标的最佳性能和次佳性能以粗体和斜体突出显示。</font></font></font></figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T2.1.2.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.2">BERT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.3" data-imt_insert_failed="1">WikiSemRel</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1.4" data-imt_insert_failed="1">WikiSemRel</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T2.1.3.2.1"></th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.2.2">Score<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">评分</font></font></font></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.2.3" data-imt_insert_failed="1">(w2v)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.3.2.4" data-imt_insert_failed="1">(Jaccard)</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_t" id="S4.T2.1.1.1"><math alttext="\text{MAE(Human, SemRel)}\downarrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml"><mtext id="S4.T2.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.m1.1.1.2a.cmml">MAE(Human, SemRel)</mtext><mo id="S4.T2.1.1.1.m1.1.1.1" stretchy="false" xref="S4.T2.1.1.1.m1.1.1.1.cmml">↓</mo><mi id="S4.T2.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1"><ci id="S4.T2.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1.1">↓</ci><ci id="S4.T2.1.1.1.m1.1.1.2a.cmml" xref="S4.T2.1.1.1.m1.1.1.2"><mtext id="S4.T2.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.m1.1.1.2">MAE(Human, SemRel)</mtext></ci><csymbol cd="latexml" id="S4.T2.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\text{MAE(Human, SemRel)}\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.m1.1d">MAE(Human, SemRel) ↓</annotation></semantics></math></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.2">0.48</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.3"><span class="ltx_text ltx_font_italic" id="S4.T2.1.1.3.1">0.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.4.1">0.23</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span>Evaluation metrics relating to the quality of the questions generated by the models proposed in section <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.SS3" title="3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3.3</span></a> based on the MixKhanQ dataset. The best performance and the next best for each metric is highlighted in <span class="ltx_text ltx_font_bold" id="S4.T3.11.1">bold</span> and <span class="ltx_text ltx_font_italic" id="S4.T3.12.2">italic</span>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 3. 基于 MixKhanQ 数据集，第 3.3 节中提出的模型生成问题的质量评估指标。每个指标的最佳性能和次佳性能以粗体和斜体突出显示。</font></font></font></figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S4.T3.8.8.9">Model/Metric<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">模型/指标</font></font></font></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1" data-imt_insert_failed="1">BLEU1<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.2.2.2" data-imt_insert_failed="1">BLEU2<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.2.2.2.m1.1"><semantics id="S4.T3.2.2.2.m1.1a"><mo id="S4.T3.2.2.2.m1.1.1" stretchy="false" xref="S4.T3.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.3.3.3" data-imt_insert_failed="1">BLEU3<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.3.3.3.m1.1"><semantics id="S4.T3.3.3.3.m1.1a"><mo id="S4.T3.3.3.3.m1.1.1" stretchy="false" xref="S4.T3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><ci id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.4.4.4" data-imt_insert_failed="1">BLEU4<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.4.4.4.m1.1"><semantics id="S4.T3.4.4.4.m1.1a"><mo id="S4.T3.4.4.4.m1.1.1" stretchy="false" xref="S4.T3.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><ci id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.5.5.5">F1 Score<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.5.5.5.m1.1"><semantics id="S4.T3.5.5.5.m1.1a"><mo id="S4.T3.5.5.5.m1.1.1" stretchy="false" xref="S4.T3.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><ci id="S4.T3.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.m1.1d">↑</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">F1 得分 <math id="S4.T3.5.5.5.m1.1" display="inline" class="ltx_Math" alttext="\uparrow"><semantics id="S4.T3.5.5.5.m1.1a"><mo stretchy="false" id="S4.T3.5.5.5.m1.1.1">↑</mo><annotation-xml id="S4.T3.5.5.5.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T3.5.5.5.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T3.5.5.5.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math> </font></font></font>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.6.6.6" data-imt_insert_failed="1">METEOR<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.6.6.6.m1.1"><semantics id="S4.T3.6.6.6.m1.1a"><mo id="S4.T3.6.6.6.m1.1.1" stretchy="false" xref="S4.T3.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.m1.1b"><ci id="S4.T3.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.m1.1d">↑</annotation></semantics></math>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.7.7.7">Perplexity<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.7.7.7.m1.1"><semantics id="S4.T3.7.7.7.m1.1a"><mo id="S4.T3.7.7.7.m1.1.1" stretchy="false" xref="S4.T3.7.7.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.m1.1b"><ci id="S4.T3.7.7.7.m1.1.1.cmml" xref="S4.T3.7.7.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.7.7.7.m1.1d">↓</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">困惑度 <math id="S4.T3.7.7.7.m1.1" display="inline" class="ltx_Math" alttext="\downarrow"><semantics id="S4.T3.7.7.7.m1.1a"><mo stretchy="false" id="S4.T3.7.7.7.m1.1.1">↓</mo><annotation-xml id="S4.T3.7.7.7.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T3.7.7.7.m1.1c" encoding="application/x-tex">\downarrow</annotation><annotation id="S4.T3.7.7.7.m1.1d" encoding="application/x-llamapun">↓</annotation></semantics></math> </font></font></font>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.8.8.8" data-imt_insert_failed="1">ROUGE-L<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.8.8.8.m1.1"><semantics id="S4.T3.8.8.8.m1.1a"><mo id="S4.T3.8.8.8.m1.1.1" stretchy="false" xref="S4.T3.8.8.8.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.m1.1b"><ci id="S4.T3.8.8.8.m1.1.1.cmml" xref="S4.T3.8.8.8.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.8.8.8.m1.1d">↑</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.8.9.1.1">Baseline<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基线</font></font></font></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.9.1.2">0.519</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.9.1.3">0.316</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.9.1.4">0.216</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.9.1.5">0.175</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.9.1.6">0.319</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.9.1.7">0.216</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.9.1.8"><span class="ltx_text ltx_font_bold" id="S4.T3.8.9.1.8.1">1.303</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.8.9.1.9">0.207</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.10.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.8.10.2.1" data-imt_insert_failed="1">TopicQGedu</th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.10.2.2"><span class="ltx_text ltx_font_bold" id="S4.T3.8.10.2.2.1">0.551</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.10.2.3">0.335</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.10.2.4">0.221</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.10.2.5">0.177</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.10.2.6">0.302</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.10.2.7">0.216</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.10.2.8">1.360</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.10.2.9">0.204</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.11.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.8.11.3.1" data-imt_insert_failed="1">TopicQG</th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.11.3.2"><span class="ltx_text ltx_font_bold" id="S4.T3.8.11.3.2.1">0.551</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.11.3.3"><span class="ltx_text ltx_font_bold" id="S4.T3.8.11.3.3.1">0.343</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.11.3.4"><span class="ltx_text ltx_font_bold" id="S4.T3.8.11.3.4.1">0.236</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.11.3.5"><span class="ltx_text ltx_font_bold" id="S4.T3.8.11.3.5.1">0.191</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.11.3.6"><span class="ltx_text ltx_font_bold" id="S4.T3.8.11.3.6.1">0.330</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.11.3.7"><span class="ltx_text ltx_font_bold" id="S4.T3.8.11.3.7.1">0.233</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.11.3.8"><span class="ltx_text ltx_font_italic" id="S4.T3.8.11.3.8.1">1.323</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.11.3.9"><span class="ltx_text ltx_font_bold" id="S4.T3.8.11.3.9.1">0.230</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.12.4">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T3.8.12.4.1" data-imt_insert_failed="1">8bit</th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.12.4.2"><span class="ltx_text ltx_font_italic" id="S4.T3.8.12.4.2.1">0.546</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.12.4.3"><span class="ltx_text ltx_font_italic" id="S4.T3.8.12.4.3.1">0.339</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.12.4.4"><span class="ltx_text ltx_font_italic" id="S4.T3.8.12.4.4.1">0.231</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.12.4.5"><span class="ltx_text ltx_font_italic" id="S4.T3.8.12.4.5.1">0.186</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.12.4.6">0.319</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.12.4.7"><span class="ltx_text ltx_font_italic" id="S4.T3.8.12.4.7.1">0.226</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.12.4.8">1.327</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.12.4.9"><span class="ltx_text ltx_font_italic" id="S4.T3.8.12.4.9.1">0.225</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.13.5">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T3.8.13.5.1">4bit<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4 位</font></font></font></th>
<td class="ltx_td ltx_align_center" id="S4.T3.8.13.5.2">0.543</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.13.5.3">0.337</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.13.5.4"><span class="ltx_text ltx_font_italic" id="S4.T3.8.13.5.4.1">0.231</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.13.5.5"><span class="ltx_text ltx_font_italic" id="S4.T3.8.13.5.5.1">0.186</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.13.5.6">0.318</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.13.5.7">0.223</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.13.5.8">1.334</td>
<td class="ltx_td ltx_align_center" id="S4.T3.8.13.5.9">0.223</td>
</tr>
<tr class="ltx_tr" id="S4.T3.8.14.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T3.8.14.6.1" data-imt_insert_failed="1">TopicQG2X</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.8.14.6.2">0.536</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.8.14.6.3">0.328</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.8.14.6.4">0.221</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.8.14.6.5">0.177</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.8.14.6.6"><span class="ltx_text ltx_font_italic" id="S4.T3.8.14.6.6.1">0.321</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.8.14.6.7">0.220</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.8.14.6.8">1.345</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T3.8.14.6.9">0.216</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span>Semantic relatedness between the generated questions <math alttext="\hat{q}" class="ltx_Math" display="inline" id="S4.T4.5.m1.1"><semantics id="S4.T4.5.m1.1b"><mover accent="true" id="S4.T4.5.m1.1.1" xref="S4.T4.5.m1.1.1.cmml"><mi id="S4.T4.5.m1.1.1.2" xref="S4.T4.5.m1.1.1.2.cmml">q</mi><mo id="S4.T4.5.m1.1.1.1" xref="S4.T4.5.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T4.5.m1.1c"><apply id="S4.T4.5.m1.1.1.cmml" xref="S4.T4.5.m1.1.1"><ci id="S4.T4.5.m1.1.1.1.cmml" xref="S4.T4.5.m1.1.1.1">^</ci><ci id="S4.T4.5.m1.1.1.2.cmml" xref="S4.T4.5.m1.1.1.2">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.m1.1d">\hat{q}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.5.m1.1e">over^ start_ARG italic_q end_ARG</annotation></semantics></math> on (i) prescribed topic <math alttext="{t}" class="ltx_Math" display="inline" id="S4.T4.6.m2.1"><semantics id="S4.T4.6.m2.1b"><mi id="S4.T4.6.m2.1.1" xref="S4.T4.6.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.T4.6.m2.1c"><ci id="S4.T4.6.m2.1.1.cmml" xref="S4.T4.6.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.m2.1d">{t}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.6.m2.1e">italic_t</annotation></semantics></math> vs. (i) alternative topic <math alttext="{t^{\prime}}" class="ltx_Math" display="inline" id="S4.T4.7.m3.1"><semantics id="S4.T4.7.m3.1b"><msup id="S4.T4.7.m3.1.1" xref="S4.T4.7.m3.1.1.cmml"><mi id="S4.T4.7.m3.1.1.2" xref="S4.T4.7.m3.1.1.2.cmml">t</mi><mo id="S4.T4.7.m3.1.1.3" xref="S4.T4.7.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T4.7.m3.1c"><apply id="S4.T4.7.m3.1.1.cmml" xref="S4.T4.7.m3.1.1"><csymbol cd="ambiguous" id="S4.T4.7.m3.1.1.1.cmml" xref="S4.T4.7.m3.1.1">superscript</csymbol><ci id="S4.T4.7.m3.1.1.2.cmml" xref="S4.T4.7.m3.1.1.2">𝑡</ci><ci id="S4.T4.7.m3.1.1.3.cmml" xref="S4.T4.7.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.m3.1d">{t^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.7.m3.1e">italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> and the reference question on the prescribed topic <math alttext="{q}_{t}" class="ltx_Math" display="inline" id="S4.T4.8.m4.1"><semantics id="S4.T4.8.m4.1b"><msub id="S4.T4.8.m4.1.1" xref="S4.T4.8.m4.1.1.cmml"><mi id="S4.T4.8.m4.1.1.2" xref="S4.T4.8.m4.1.1.2.cmml">q</mi><mi id="S4.T4.8.m4.1.1.3" xref="S4.T4.8.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T4.8.m4.1c"><apply id="S4.T4.8.m4.1.1.cmml" xref="S4.T4.8.m4.1.1"><csymbol cd="ambiguous" id="S4.T4.8.m4.1.1.1.cmml" xref="S4.T4.8.m4.1.1">subscript</csymbol><ci id="S4.T4.8.m4.1.1.2.cmml" xref="S4.T4.8.m4.1.1.2">𝑞</ci><ci id="S4.T4.8.m4.1.1.3.cmml" xref="S4.T4.8.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.m4.1d">{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.T4.8.m4.1e">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. The best performance and the next best for each metric is highlighted in <span class="ltx_text ltx_font_bold" id="S4.T4.17.1">bold</span> and <span class="ltx_text ltx_font_italic" id="S4.T4.18.2">italic</span>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 4.生成的题目 <math id="S4.T4.5.m1.1" display="inline" class="ltx_Math" alttext="\hat{q}"><semantics id="S4.T4.5.m1.1b"><mover id="S4.T4.5.m1.1.1" accent="true"><mi id="S4.T4.5.m1.1.1.2">q</mi><mo id="S4.T4.5.m1.1.1.1">^</mo></mover><annotation-xml id="S4.T4.5.m1.1c" encoding="MathML-Content"></annotation-xml><annotation id="S4.T4.5.m1.1d" encoding="application/x-tex">\hat{q}</annotation><annotation id="S4.T4.5.m1.1e" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG</annotation></semantics></math> 在(i)指定主题 <math id="S4.T4.6.m2.1" display="inline" class="ltx_Math" alttext="{t}"><semantics id="S4.T4.6.m2.1b"><mi id="S4.T4.6.m2.1.1">t</mi><annotation-xml id="S4.T4.6.m2.1c" encoding="MathML-Content"></annotation-xml><annotation id="S4.T4.6.m2.1d" encoding="application/x-tex">{t}</annotation><annotation id="S4.T4.6.m2.1e" encoding="application/x-llamapun">italic_t</annotation></semantics></math> 与(i)替代主题 <math id="S4.T4.7.m3.1" display="inline" class="ltx_Math" alttext="{t^{\prime}}"><semantics id="S4.T4.7.m3.1b"><msup id="S4.T4.7.m3.1.1"><mi id="S4.T4.7.m3.1.1.2">t</mi><mo id="S4.T4.7.m3.1.1.3">′</mo></msup><annotation-xml id="S4.T4.7.m3.1c" encoding="MathML-Content">superscript</annotation-xml><annotation id="S4.T4.7.m3.1d" encoding="application/x-tex">{t^{\prime}}</annotation><annotation id="S4.T4.7.m3.1e" encoding="application/x-llamapun">italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> 以及指定主题的参考题目 <math id="S4.T4.8.m4.1" display="inline" class="ltx_Math" alttext="{q}_{t}"><semantics id="S4.T4.8.m4.1b"><msub id="S4.T4.8.m4.1.1"><mi id="S4.T4.8.m4.1.1.2">q</mi><mi id="S4.T4.8.m4.1.1.3">t</mi></msub><annotation-xml id="S4.T4.8.m4.1c" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.T4.8.m4.1d" encoding="application/x-tex">{q}_{t}</annotation><annotation id="S4.T4.8.m4.1e" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 之间的语义相关性。每个指标的最佳性能和次佳性能以粗体和斜体突出显示。</font></font></font></figcaption>
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.14">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.14.7.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T4.14.7.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T4.14.7.1.2" data-imt_insert_failed="1">BERTScore</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T4.14.7.1.3" data-imt_insert_failed="1">WikiSimRel (Jaccard)</th>
</tr>
<tr class="ltx_tr" id="S4.T4.14.6">
<th class="ltx_td ltx_th ltx_th_row" id="S4.T4.14.6.7"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.9.1.1"><math alttext="\hat{q}_{t}\uparrow" class="ltx_Math" display="inline" id="S4.T4.9.1.1.m1.1"><semantics id="S4.T4.9.1.1.m1.1a"><mrow id="S4.T4.9.1.1.m1.1.1" xref="S4.T4.9.1.1.m1.1.1.cmml"><msub id="S4.T4.9.1.1.m1.1.1.2" xref="S4.T4.9.1.1.m1.1.1.2.cmml"><mover accent="true" id="S4.T4.9.1.1.m1.1.1.2.2" xref="S4.T4.9.1.1.m1.1.1.2.2.cmml"><mi id="S4.T4.9.1.1.m1.1.1.2.2.2" xref="S4.T4.9.1.1.m1.1.1.2.2.2.cmml">q</mi><mo id="S4.T4.9.1.1.m1.1.1.2.2.1" xref="S4.T4.9.1.1.m1.1.1.2.2.1.cmml">^</mo></mover><mi id="S4.T4.9.1.1.m1.1.1.2.3" xref="S4.T4.9.1.1.m1.1.1.2.3.cmml">t</mi></msub><mo id="S4.T4.9.1.1.m1.1.1.1" stretchy="false" xref="S4.T4.9.1.1.m1.1.1.1.cmml">↑</mo><mi id="S4.T4.9.1.1.m1.1.1.3" xref="S4.T4.9.1.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.9.1.1.m1.1b"><apply id="S4.T4.9.1.1.m1.1.1.cmml" xref="S4.T4.9.1.1.m1.1.1"><ci id="S4.T4.9.1.1.m1.1.1.1.cmml" xref="S4.T4.9.1.1.m1.1.1.1">↑</ci><apply id="S4.T4.9.1.1.m1.1.1.2.cmml" xref="S4.T4.9.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T4.9.1.1.m1.1.1.2.1.cmml" xref="S4.T4.9.1.1.m1.1.1.2">subscript</csymbol><apply id="S4.T4.9.1.1.m1.1.1.2.2.cmml" xref="S4.T4.9.1.1.m1.1.1.2.2"><ci id="S4.T4.9.1.1.m1.1.1.2.2.1.cmml" xref="S4.T4.9.1.1.m1.1.1.2.2.1">^</ci><ci id="S4.T4.9.1.1.m1.1.1.2.2.2.cmml" xref="S4.T4.9.1.1.m1.1.1.2.2.2">𝑞</ci></apply><ci id="S4.T4.9.1.1.m1.1.1.2.3.cmml" xref="S4.T4.9.1.1.m1.1.1.2.3">𝑡</ci></apply><csymbol cd="latexml" id="S4.T4.9.1.1.m1.1.1.3.cmml" xref="S4.T4.9.1.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.1.1.m1.1c">\hat{q}_{t}\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.9.1.1.m1.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ↑</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.10.2.2"><math alttext="\hat{q}_{t^{\prime}}\downarrow" class="ltx_Math" display="inline" id="S4.T4.10.2.2.m1.1"><semantics id="S4.T4.10.2.2.m1.1a"><mrow id="S4.T4.10.2.2.m1.1.1" xref="S4.T4.10.2.2.m1.1.1.cmml"><msub id="S4.T4.10.2.2.m1.1.1.2" xref="S4.T4.10.2.2.m1.1.1.2.cmml"><mover accent="true" id="S4.T4.10.2.2.m1.1.1.2.2" xref="S4.T4.10.2.2.m1.1.1.2.2.cmml"><mi id="S4.T4.10.2.2.m1.1.1.2.2.2" xref="S4.T4.10.2.2.m1.1.1.2.2.2.cmml">q</mi><mo id="S4.T4.10.2.2.m1.1.1.2.2.1" xref="S4.T4.10.2.2.m1.1.1.2.2.1.cmml">^</mo></mover><msup id="S4.T4.10.2.2.m1.1.1.2.3" xref="S4.T4.10.2.2.m1.1.1.2.3.cmml"><mi id="S4.T4.10.2.2.m1.1.1.2.3.2" xref="S4.T4.10.2.2.m1.1.1.2.3.2.cmml">t</mi><mo id="S4.T4.10.2.2.m1.1.1.2.3.3" xref="S4.T4.10.2.2.m1.1.1.2.3.3.cmml">′</mo></msup></msub><mo id="S4.T4.10.2.2.m1.1.1.1" stretchy="false" xref="S4.T4.10.2.2.m1.1.1.1.cmml">↓</mo><mi id="S4.T4.10.2.2.m1.1.1.3" xref="S4.T4.10.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.10.2.2.m1.1b"><apply id="S4.T4.10.2.2.m1.1.1.cmml" xref="S4.T4.10.2.2.m1.1.1"><ci id="S4.T4.10.2.2.m1.1.1.1.cmml" xref="S4.T4.10.2.2.m1.1.1.1">↓</ci><apply id="S4.T4.10.2.2.m1.1.1.2.cmml" xref="S4.T4.10.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T4.10.2.2.m1.1.1.2.1.cmml" xref="S4.T4.10.2.2.m1.1.1.2">subscript</csymbol><apply id="S4.T4.10.2.2.m1.1.1.2.2.cmml" xref="S4.T4.10.2.2.m1.1.1.2.2"><ci id="S4.T4.10.2.2.m1.1.1.2.2.1.cmml" xref="S4.T4.10.2.2.m1.1.1.2.2.1">^</ci><ci id="S4.T4.10.2.2.m1.1.1.2.2.2.cmml" xref="S4.T4.10.2.2.m1.1.1.2.2.2">𝑞</ci></apply><apply id="S4.T4.10.2.2.m1.1.1.2.3.cmml" xref="S4.T4.10.2.2.m1.1.1.2.3"><csymbol cd="ambiguous" id="S4.T4.10.2.2.m1.1.1.2.3.1.cmml" xref="S4.T4.10.2.2.m1.1.1.2.3">superscript</csymbol><ci id="S4.T4.10.2.2.m1.1.1.2.3.2.cmml" xref="S4.T4.10.2.2.m1.1.1.2.3.2">𝑡</ci><ci id="S4.T4.10.2.2.m1.1.1.2.3.3.cmml" xref="S4.T4.10.2.2.m1.1.1.2.3.3">′</ci></apply></apply><csymbol cd="latexml" id="S4.T4.10.2.2.m1.1.1.3.cmml" xref="S4.T4.10.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.2.2.m1.1c">\hat{q}_{t^{\prime}}\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.10.2.2.m1.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ↓</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.11.3.3">Difference <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.11.3.3.m1.1"><semantics id="S4.T4.11.3.3.m1.1a"><mo id="S4.T4.11.3.3.m1.1.1" stretchy="false" xref="S4.T4.11.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.11.3.3.m1.1b"><ci id="S4.T4.11.3.3.m1.1.1.cmml" xref="S4.T4.11.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.11.3.3.m1.1d">↑</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">差异 <math id="S4.T4.11.3.3.m1.1" display="inline" class="ltx_Math" alttext="\uparrow"><semantics id="S4.T4.11.3.3.m1.1a"><mo stretchy="false" id="S4.T4.11.3.3.m1.1.1">↑</mo><annotation-xml id="S4.T4.11.3.3.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T4.11.3.3.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T4.11.3.3.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math> </font></font></font>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.12.4.4"><math alttext="\hat{q}_{t}\uparrow" class="ltx_Math" display="inline" id="S4.T4.12.4.4.m1.1"><semantics id="S4.T4.12.4.4.m1.1a"><mrow id="S4.T4.12.4.4.m1.1.1" xref="S4.T4.12.4.4.m1.1.1.cmml"><msub id="S4.T4.12.4.4.m1.1.1.2" xref="S4.T4.12.4.4.m1.1.1.2.cmml"><mover accent="true" id="S4.T4.12.4.4.m1.1.1.2.2" xref="S4.T4.12.4.4.m1.1.1.2.2.cmml"><mi id="S4.T4.12.4.4.m1.1.1.2.2.2" xref="S4.T4.12.4.4.m1.1.1.2.2.2.cmml">q</mi><mo id="S4.T4.12.4.4.m1.1.1.2.2.1" xref="S4.T4.12.4.4.m1.1.1.2.2.1.cmml">^</mo></mover><mi id="S4.T4.12.4.4.m1.1.1.2.3" xref="S4.T4.12.4.4.m1.1.1.2.3.cmml">t</mi></msub><mo id="S4.T4.12.4.4.m1.1.1.1" stretchy="false" xref="S4.T4.12.4.4.m1.1.1.1.cmml">↑</mo><mi id="S4.T4.12.4.4.m1.1.1.3" xref="S4.T4.12.4.4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.12.4.4.m1.1b"><apply id="S4.T4.12.4.4.m1.1.1.cmml" xref="S4.T4.12.4.4.m1.1.1"><ci id="S4.T4.12.4.4.m1.1.1.1.cmml" xref="S4.T4.12.4.4.m1.1.1.1">↑</ci><apply id="S4.T4.12.4.4.m1.1.1.2.cmml" xref="S4.T4.12.4.4.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T4.12.4.4.m1.1.1.2.1.cmml" xref="S4.T4.12.4.4.m1.1.1.2">subscript</csymbol><apply id="S4.T4.12.4.4.m1.1.1.2.2.cmml" xref="S4.T4.12.4.4.m1.1.1.2.2"><ci id="S4.T4.12.4.4.m1.1.1.2.2.1.cmml" xref="S4.T4.12.4.4.m1.1.1.2.2.1">^</ci><ci id="S4.T4.12.4.4.m1.1.1.2.2.2.cmml" xref="S4.T4.12.4.4.m1.1.1.2.2.2">𝑞</ci></apply><ci id="S4.T4.12.4.4.m1.1.1.2.3.cmml" xref="S4.T4.12.4.4.m1.1.1.2.3">𝑡</ci></apply><csymbol cd="latexml" id="S4.T4.12.4.4.m1.1.1.3.cmml" xref="S4.T4.12.4.4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.4.4.m1.1c">\hat{q}_{t}\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.12.4.4.m1.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ↑</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.13.5.5"><math alttext="\hat{q}_{t^{\prime}}\downarrow" class="ltx_Math" display="inline" id="S4.T4.13.5.5.m1.1"><semantics id="S4.T4.13.5.5.m1.1a"><mrow id="S4.T4.13.5.5.m1.1.1" xref="S4.T4.13.5.5.m1.1.1.cmml"><msub id="S4.T4.13.5.5.m1.1.1.2" xref="S4.T4.13.5.5.m1.1.1.2.cmml"><mover accent="true" id="S4.T4.13.5.5.m1.1.1.2.2" xref="S4.T4.13.5.5.m1.1.1.2.2.cmml"><mi id="S4.T4.13.5.5.m1.1.1.2.2.2" xref="S4.T4.13.5.5.m1.1.1.2.2.2.cmml">q</mi><mo id="S4.T4.13.5.5.m1.1.1.2.2.1" xref="S4.T4.13.5.5.m1.1.1.2.2.1.cmml">^</mo></mover><msup id="S4.T4.13.5.5.m1.1.1.2.3" xref="S4.T4.13.5.5.m1.1.1.2.3.cmml"><mi id="S4.T4.13.5.5.m1.1.1.2.3.2" xref="S4.T4.13.5.5.m1.1.1.2.3.2.cmml">t</mi><mo id="S4.T4.13.5.5.m1.1.1.2.3.3" xref="S4.T4.13.5.5.m1.1.1.2.3.3.cmml">′</mo></msup></msub><mo id="S4.T4.13.5.5.m1.1.1.1" stretchy="false" xref="S4.T4.13.5.5.m1.1.1.1.cmml">↓</mo><mi id="S4.T4.13.5.5.m1.1.1.3" xref="S4.T4.13.5.5.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.13.5.5.m1.1b"><apply id="S4.T4.13.5.5.m1.1.1.cmml" xref="S4.T4.13.5.5.m1.1.1"><ci id="S4.T4.13.5.5.m1.1.1.1.cmml" xref="S4.T4.13.5.5.m1.1.1.1">↓</ci><apply id="S4.T4.13.5.5.m1.1.1.2.cmml" xref="S4.T4.13.5.5.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T4.13.5.5.m1.1.1.2.1.cmml" xref="S4.T4.13.5.5.m1.1.1.2">subscript</csymbol><apply id="S4.T4.13.5.5.m1.1.1.2.2.cmml" xref="S4.T4.13.5.5.m1.1.1.2.2"><ci id="S4.T4.13.5.5.m1.1.1.2.2.1.cmml" xref="S4.T4.13.5.5.m1.1.1.2.2.1">^</ci><ci id="S4.T4.13.5.5.m1.1.1.2.2.2.cmml" xref="S4.T4.13.5.5.m1.1.1.2.2.2">𝑞</ci></apply><apply id="S4.T4.13.5.5.m1.1.1.2.3.cmml" xref="S4.T4.13.5.5.m1.1.1.2.3"><csymbol cd="ambiguous" id="S4.T4.13.5.5.m1.1.1.2.3.1.cmml" xref="S4.T4.13.5.5.m1.1.1.2.3">superscript</csymbol><ci id="S4.T4.13.5.5.m1.1.1.2.3.2.cmml" xref="S4.T4.13.5.5.m1.1.1.2.3.2">𝑡</ci><ci id="S4.T4.13.5.5.m1.1.1.2.3.3.cmml" xref="S4.T4.13.5.5.m1.1.1.2.3.3">′</ci></apply></apply><csymbol cd="latexml" id="S4.T4.13.5.5.m1.1.1.3.cmml" xref="S4.T4.13.5.5.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.13.5.5.m1.1c">\hat{q}_{t^{\prime}}\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.13.5.5.m1.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ↓</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.14.6.6">Difference <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.14.6.6.m1.1"><semantics id="S4.T4.14.6.6.m1.1a"><mo id="S4.T4.14.6.6.m1.1.1" stretchy="false" xref="S4.T4.14.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.14.6.6.m1.1b"><ci id="S4.T4.14.6.6.m1.1.1.cmml" xref="S4.T4.14.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.14.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.14.6.6.m1.1d">↑</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">差异 <math id="S4.T4.14.6.6.m1.1" display="inline" class="ltx_Math" alttext="\uparrow"><semantics id="S4.T4.14.6.6.m1.1a"><mo stretchy="false" id="S4.T4.14.6.6.m1.1.1">↑</mo><annotation-xml id="S4.T4.14.6.6.m1.1b" encoding="MathML-Content"></annotation-xml><annotation id="S4.T4.14.6.6.m1.1c" encoding="application/x-tex">\uparrow</annotation><annotation id="S4.T4.14.6.6.m1.1d" encoding="application/x-llamapun">↑</annotation></semantics></math> </font></font></font>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.14.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T4.14.8.1.1">Baseline<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基线</font></font></font></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.14.8.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.14.8.1.2.1">0.859</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.14.8.1.3">0.859</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.14.8.1.4">0.000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.14.8.1.5">0.615</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.14.8.1.6"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T4.14.8.1.6.1">0.070</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.14.8.1.7">0.545</td>
</tr>
<tr class="ltx_tr" id="S4.T4.14.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.14.9.2.1" data-imt_insert_failed="1">TopicQGedu</th>
<td class="ltx_td ltx_align_center" id="S4.T4.14.9.2.2">0.855</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.9.2.3">0.831</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.9.2.4">0.024</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.9.2.5">0.721</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.9.2.6">0.185</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.9.2.7">0.536</td>
</tr>
<tr class="ltx_tr" id="S4.T4.14.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T4.14.10.3.1" data-imt_insert_failed="1">TopicQG</th>
<td class="ltx_td ltx_align_center" id="S4.T4.14.10.3.2"><span class="ltx_text ltx_font_bold" id="S4.T4.14.10.3.2.1">0.859</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.10.3.3"><span class="ltx_text ltx_font_italic" id="S4.T4.14.10.3.3.1">0.830</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.10.3.4"><span class="ltx_text ltx_font_italic" id="S4.T4.14.10.3.4.1">0.029</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.10.3.5"><span class="ltx_text ltx_font_italic" id="S4.T4.14.10.3.5.1">0.727</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.10.3.6"><span class="ltx_text ltx_font_italic" id="S4.T4.14.10.3.6.1">0.132</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.10.3.7"><span class="ltx_text ltx_font_italic" id="S4.T4.14.10.3.7.1">0.595</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.14.11.4">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T4.14.11.4.1">8bit<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">8 位</font></font></font></th>
<td class="ltx_td ltx_align_center" id="S4.T4.14.11.4.2"><span class="ltx_text ltx_font_italic" id="S4.T4.14.11.4.2.1">0.858</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.11.4.3">0.831</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.11.4.4"><span class="ltx_text ltx_font_italic" id="S4.T4.14.11.4.4.1">0.027</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.11.4.5">0.693</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.11.4.6">0.142</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.11.4.7">0.551</td>
</tr>
<tr class="ltx_tr" id="S4.T4.14.12.5">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="S4.T4.14.12.5.1">4bit<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4 位</font></font></font></th>
<td class="ltx_td ltx_align_center" id="S4.T4.14.12.5.2"><span class="ltx_text ltx_font_italic" id="S4.T4.14.12.5.2.1">0.858</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.12.5.3">0.831</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.12.5.4">0.027</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.12.5.5">0.686</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.12.5.6">0.157</td>
<td class="ltx_td ltx_align_center" id="S4.T4.14.12.5.7">0.529</td>
</tr>
<tr class="ltx_tr" id="S4.T4.14.13.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T4.14.13.6.1" data-imt_insert_failed="1">TopicQG2X</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.14.13.6.2"><span class="ltx_text ltx_font_bold" id="S4.T4.14.13.6.2.1">0.859</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.14.13.6.3"><span class="ltx_text ltx_font_bold" id="S4.T4.14.13.6.3.1">0.823</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.14.13.6.4"><span class="ltx_text ltx_font_bold" id="S4.T4.14.13.6.4.1">0.036</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.14.13.6.5"><span class="ltx_text ltx_font_bold" id="S4.T4.14.13.6.5.1">0.735</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.14.13.6.6"><span class="ltx_text ltx_font_bold" id="S4.T4.14.13.6.6.1">0.055</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.14.13.6.7"><span class="ltx_text ltx_font_bold" id="S4.T4.14.13.6.7.1">0.680</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Most Representative Automated Topic Relevance Metric to Human Evaluations (RQ1)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1. 最具代表性的自动主题相关性指标与人工评估（RQ1）</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">In human evaluations of the 30 randomly selected question pairs for topical alignment, only two pairs did not reach a consensus among the participants with one outlier in each case (with the
Fleiss’ kappa <cite class="ltx_cite ltx_citemacro_citep">(Fleiss, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib29" title="">1971</a>)</cite> measure of inter-rater agreement among multiple raters being 0.933). This indicates strong inter-rater reliability in the gold-standard human evaluator data. As per table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T2" title="Table 2 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2</span></a>, the WikiSimRel metrics are more aligned with the human judgements in comparison to the BERTScore. Among the three candidates, we can observe the embedding based (BERT and w2v) methods showing inferior representativeness. This could be due to the fact that embeddings can represent many different attributes about the entities and tokens they represent (e.g. whether the text is a question or a statement). This hypothesis is further reinforced by previous observations that including stopwords like ”what”, ”why” leads to the inflation of BERTScore. However the Jaccard WikiSimRel score that relies exclusively on outward links from Wikipedia pages tends to capture a better representation of the informational and thematic content leading to better alignment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在针对 30 对随机选择的问题对进行主题一致性评估的人类评价中，只有两对在参与者之间未达成共识，每对均有一个极端值（根据多位评价者之间评分者间一致性系数 Fleiss’ kappa（Fleiss，1971）的测量结果为 0.933）。这表明金标准人类评价数据具有极强的评分者间可靠性。根据表 2，与 BERTScore 相比，WikiSimRel 指标更符合人类判断。在三个候选方案中，我们可以观察到基于嵌入（BERT 和 w2v）的方法表现出较差的代表性。这可能是由于嵌入能够表示它们所代表实体和标记的许多不同属性（例如，文本是问题还是陈述）。这一假设得到了先前观察的进一步证实，即包含像“what”、“why”这样的停用词会导致 BERTScore 的膨胀。然而，完全依赖于维基百科页面外部链接的 Jaccard WikiSimRel 分数倾向于更好地捕捉信息内容和主题内容，从而实现更好的一致性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Topical Relevance and the Effect of Pre-training on Generated Questions (RQ 2 and RQ 3)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2.主题相关性与预训练对生成问题的影响（RQ 2 和 RQ 3）</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">Table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T3" title="Table 3 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3</span></a> provides us an indication of the degree to which the generated question <math alttext="\hat{q}_{t}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><msub id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mover accent="true" id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2.2" xref="S4.SS2.p1.1.m1.1.1.2.2.cmml">q</mi><mo id="S4.SS2.p1.1.m1.1.1.2.1" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">subscript</csymbol><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2"><ci id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.2.1">^</ci><ci id="S4.SS2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2">𝑞</ci></apply><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\hat{q}_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> resembles the reference question <math alttext="q_{t}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><msub id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">q</mi><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">𝑞</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">q_{t}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. This is a proxy for topical relevance as the reference question is implicitly aligned with the controlled topic. The results indicate that the proposed TopicQG model outperforms the baseline model in all but perplexity metric. Outperforming in terms of BLEU scores at multiple levels (BLEU1 through BLEU4), indicates enhanced linguistic precision in question generation. It also achieves higher F1, ROUGE-L, and METEOR scores, reflecting the model’s capability to generate questions that are not only relevant and accurate but also semantically aligned with reference texts. Compared with the baseline, a slight increase in perplexity suggests that the TopicQG model may generate questions that diverge from the reference language, potentially due to its ability to learn more complex educational expressions. The perplexity does not raise significant concerns over the quality of generations as the random examples in table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.T1" title="Table 1 ‣ 3.3.6. Example Questions Generated with Models for the Experiments ‣ 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">1</span></a> doesn’t indicate visible signs of deterioration.
It is noteworthy that the randomly selected examples in table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S3.T1" title="Table 1 ‣ 3.3.6. Example Questions Generated with Models for the Experiments ‣ 3.3. Developing T-CQG Models for Education ‣ 3. Methodology ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">1</span></a> are not as good as typical questions generated using a very large language model such as ChatGPT. We hypothesise the size of our model being a main reason for the relatively low quality of generations. However, our own prior work has also shown that such generations can be improved to humanly acceptable levels by simply post-processing them through a pre-trained grammar correction model <cite class="ltx_cite ltx_citemacro_citep">(Fawzi et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib27" title="">2024</a>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib26" title="">[n. d.]</a>)</cite> retaining the accessibility and sustainability benefits of sLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 3 为我们提供了生成问题 <math id="S4.SS2.p1.1.m1.1" display="inline" class="ltx_Math" alttext="\hat{q}_{t}"><semantics id="S4.SS2.p1.1.m1.1a"><msub id="S4.SS2.p1.1.m1.1.1"><mover id="S4.SS2.p1.1.m1.1.1.2" accent="true"><mi id="S4.SS2.p1.1.m1.1.1.2.2">q</mi><mo id="S4.SS2.p1.1.m1.1.1.2.1">^</mo></mover><mi id="S4.SS2.p1.1.m1.1.1.3">t</mi></msub><annotation-xml id="S4.SS2.p1.1.m1.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.p1.1.m1.1c" encoding="application/x-tex">\hat{q}_{t}</annotation><annotation id="S4.SS2.p1.1.m1.1d" encoding="application/x-llamapun">over^ start_ARG italic_q end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 与参考问题 <math id="S4.SS2.p1.2.m2.1" display="inline" class="ltx_Math" alttext="q_{t}"><semantics id="S4.SS2.p1.2.m2.1a"><msub id="S4.SS2.p1.2.m2.1.1"><mi id="S4.SS2.p1.2.m2.1.1.2">q</mi><mi id="S4.SS2.p1.2.m2.1.1.3">t</mi></msub><annotation-xml id="S4.SS2.p1.2.m2.1b" encoding="MathML-Content">subscript</annotation-xml><annotation id="S4.SS2.p1.2.m2.1c" encoding="application/x-tex">q_{t}</annotation><annotation id="S4.SS2.p1.2.m2.1d" encoding="application/x-llamapun">italic_q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> 相似程度的指示。这可以作为主题相关性的代理指标，因为参考问题与控制主题隐式对齐。结果表明，所提出的 TopicQG 模型在除困惑度指标外所有指标上均优于基线模型。在多个级别的 BLEU 分数（BLEU1 至 BLEU4）上表现更优，表明问题生成中语言精确性得到提升。同时，该模型实现了更高的 F1、ROUGE-L 和 METEOR 分数，反映了其生成的问题不仅相关且准确，而且在语义上与参考文本对齐。与基线模型相比，困惑度略有上升，表明 TopicQG 模型生成的问题可能与参考语言有所偏离，这可能是由于其能够学习更复杂的教肓表达。困惑度的上升并未引起对生成质量显著问题的担忧，因为表 1 中的随机示例并未显示出明显的恶化迹象。 值得注意的是，表 1 中随机选择的示例不如使用 ChatGPT 等大型语言模型生成的典型问题好。我们假设模型的大小是生成质量相对较低的主要原因。然而，我们之前的研究也表明，通过使用预训练的语法纠错模型对生成内容进行后处理，可以将这些生成内容改进到人类可接受的水平（Fawzi 等，2024 年，[n. d.]）]) 保留 sLMs 的可访问性和可持续性优势。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T4" title="Table 4 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">4</span></a>, the stronger indicator of topic alignment gives us evidence that the proposed TopicQG models significantly outperform the baseline. In terms of the semantic difference between the educational questions generated with the controlled topic vs. a different topic (using WikiSimRel (Jaccard), the most representative metric from table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T2" title="Table 2 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">2</span></a>), all newly proposed models except the 4bit quantised TopicQG model outperforms the baseline. This can be expected as extreme quantisation can deteriorate the accuracy of the model.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 4 中，更强的主题一致性指标为我们提供了证据，即所提出的 TopicQG 模型显著优于基线模型。在控制主题与不同主题生成的教育问题之间的语义差异方面（使用 WikiSimRel（Jaccard），表 2 中最具代表性的指标），除 4bit 量化 TopicQG 模型外，所有新提出的模型均优于基线模型。这可以预期，因为极端量化会降低模型的准确性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">In terms of the TopicQGedu model that is pre-trained on scientific text, the results are mixed and more difficult to interpret. While it surpasses the predictive performance on the Baseline in a few metrics, it performs below the TopicQG model across all metrics in table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T3" title="Table 3 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3</span></a>. While pre-training on scientific content is hypothesised to improve the topical relevance of the model, we do not observe improvements in this case. To rigorously assess whether the observed differences in performance metrics are statistically significant, we alsoconducted a paired t-test comparing the performance scores of TopicQGedu and TopicQG across the same set of questions. The results yielded a p-value of 0.083 (¿0.05), suggesting that there is no statistically significant difference that TopicQGedu underperforms compared to TopicQG. Given that the T5 model is primarily trained on web-crawled data and Wikipedia articles <cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib50" title="">2022</a>)</cite>, the absence of scientific texts in the training corpus could potentially weaken the model’s performance in scientific concepts and language. Thus pre-training strategies may need to be further explored, especially in specialized domains where deeper domain knowledge might be crucial, even if immediate improvements in conventional metrics are not evident.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对于在科学文本上预训练的 TopicQGedu 模型，结果较为复杂且更难解释。虽然它在某些指标上超越了基线模型的预测性能，但在表 3 的所有指标中，它的表现均低于 TopicQG 模型。尽管预训练科学内容被认为可以提高模型的主题相关性，但在此情况下我们并未观察到改进。为了严格评估性能指标中观察到的差异是否具有统计学意义，我们还进行了配对 t 检验，比较了 TopicQGedu 和 TopicQG 在相同问题集上的性能得分。结果得到 p 值为 0.083（&lt;0.05），表明 TopicQGedu 与 TopicQG 相比没有表现出统计学上的显著差异。鉴于 T5 模型主要在网页爬取数据和维基百科文章上进行训练（Raffel 等，2022），训练语料库中缺乏科学文本可能会削弱模型在科学概念和语言上的性能。 因此，预训练策略可能需要进一步探索，特别是在那些需要更深层领域知识的专门领域，即使在这些传统指标上没有立即的改进。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Impact of Model Quantisation (RQ4) and Data Augmentation (RQ5)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.3.模型量化影响（RQ4）和数据增强影响（RQ5）</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We investigated the effects of 8-bit and 4-bit quantisation on the TopicQG model (the best-performing model on the MixSQuAD dataset), referred to as TopicQG8bit and TopicQG4bit respectively. In comparison to the TopicQG model, the quantised models retain best performance with respect to metrics such as BLEU, F1-Score, MATEOR and ROUGE-L with very minor decreases (<math alttext="\leq 0.01" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">≤</mo><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><leq id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">absent</csymbol><cn id="S4.SS3.p1.1.m1.1.1.3.cmml" type="float" xref="S4.SS3.p1.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\leq 0.01</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">≤ 0.01</annotation></semantics></math>) according to table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T3" title="Table 3 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3</span></a>. As expected, a drop in performance in comparison to the TopicQG model (with no quantisation) is observed. Similarly in table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T4" title="Table 4 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">4</span></a>), a small drop in metrics is observed although it is not a drastic difference. This can be attributed to the fact that the generations change to a very small degree with quantisation indicated by the small deviations in table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T3" title="Table 3 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">3</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们研究了 8 位和 4 位量化对 TopicQG 模型（在 MixSQuAD 数据集上表现最佳的模型）的影响，分别称为 TopicQG8bit 和 TopicQG4bit。与 TopicQG 模型相比，量化模型在 BLEU、F1-Score、MATEOR 和 ROUGE-L 等指标上保持了最佳性能，根据表 3，这些指标仅略有下降 ( <math id="S4.SS3.p1.1.m1.1" display="inline" class="ltx_Math" alttext="\leq 0.01"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1"><mi id="S4.SS3.p1.1.m1.1.1.2"></mi><mo id="S4.SS3.p1.1.m1.1.1.1">≤</mo><mn id="S4.SS3.p1.1.m1.1.1.3">0.01</mn></mrow><annotation-xml id="S4.SS3.p1.1.m1.1b" encoding="MathML-Content">absent0.01</annotation-xml><annotation id="S4.SS3.p1.1.m1.1c" encoding="application/x-tex">\leq 0.01</annotation><annotation id="S4.SS3.p1.1.m1.1d" encoding="application/x-llamapun">≤ 0.01</annotation></semantics></math> )。正如预期，与未量化的 TopicQG 模型相比，性能有所下降。同样地，如表 4 所示，指标略有下降，尽管差异并不显著。这可以归因于量化导致生成内容的变化非常微小，如表 3 中较小的偏差所示。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.3">Regarding memory usage, the full-precision TopicQG model occupies a memory size of <math alttext="\approx 230" class="ltx_Math" display="inline" id="S4.SS3.p2.1.m1.1"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml"></mi><mo id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.cmml">≈</mo><mn id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">230</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><approx id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">absent</csymbol><cn id="S4.SS3.p2.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.p2.1.m1.1.1.3">230</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\approx 230</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.1.m1.1d">≈ 230</annotation></semantics></math> MB. In contrast, the TopicQG8bit model significantly reduces this footprint to <math alttext="\approx 110" class="ltx_Math" display="inline" id="S4.SS3.p2.2.m2.1"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mi id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml"></mi><mo id="S4.SS3.p2.2.m2.1.1.1" xref="S4.SS3.p2.2.m2.1.1.1.cmml">≈</mo><mn id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">110</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><approx id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1.1"></approx><csymbol cd="latexml" id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">absent</csymbol><cn id="S4.SS3.p2.2.m2.1.1.3.cmml" type="integer" xref="S4.SS3.p2.2.m2.1.1.3">110</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">\approx 110</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.2.m2.1d">≈ 110</annotation></semantics></math> MB (59%), and the TopicQG4bit model further reduces it to <math alttext="\approx 94" class="ltx_Math" display="inline" id="S4.SS3.p2.3.m3.1"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mi id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml"></mi><mo id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">≈</mo><mn id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">94</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><approx id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1"></approx><csymbol cd="latexml" id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">absent</csymbol><cn id="S4.SS3.p2.3.m3.1.1.3.cmml" type="integer" xref="S4.SS3.p2.3.m3.1.1.3">94</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">\approx 94</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p2.3.m3.1d">≈ 94</annotation></semantics></math> MB (53%). The potential of quantisation demonstrated in this study is twofold: 1) it significantly lowers the hardware requirements for running the models, and 2) it maintains a satisfactory level of performance, making it feasible to deploy educational topic-controllable question generation on platforms where computational resources are limited. This accessibility could dramatically widen the applications of such models, making them more ubiquitous in educational and other real-time interactive applications on mobile devices. The reduction in model size not only implies lower memory requirements but also suggests lower power consumption, leading to cheaper infrastructure costs and a lower carbon footprint. Such properties are crucial for deploying these models in educational contexts of resource-constrained environments such as middle and low-income countries, mobile devices and embedded systems.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">关于内存使用情况，全精度的 TopicQG 模型占用内存大小为 <math id="S4.SS3.p2.1.m1.1" display="inline" class="ltx_Math" alttext="\approx 230"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1"><mi id="S4.SS3.p2.1.m1.1.1.2"></mi><mo id="S4.SS3.p2.1.m1.1.1.1">≈</mo><mn id="S4.SS3.p2.1.m1.1.1.3">230</mn></mrow><annotation-xml id="S4.SS3.p2.1.m1.1b" encoding="MathML-Content">absent230</annotation-xml><annotation id="S4.SS3.p2.1.m1.1c" encoding="application/x-tex">\approx 230</annotation><annotation id="S4.SS3.p2.1.m1.1d" encoding="application/x-llamapun">≈ 230</annotation></semantics></math> MB。相比之下，TopicQG8bit 模型显著减小了这一占用，降至 <math id="S4.SS3.p2.2.m2.1" display="inline" class="ltx_Math" alttext="\approx 110"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1"><mi id="S4.SS3.p2.2.m2.1.1.2"></mi><mo id="S4.SS3.p2.2.m2.1.1.1">≈</mo><mn id="S4.SS3.p2.2.m2.1.1.3">110</mn></mrow><annotation-xml id="S4.SS3.p2.2.m2.1b" encoding="MathML-Content">absent110</annotation-xml><annotation id="S4.SS3.p2.2.m2.1c" encoding="application/x-tex">\approx 110</annotation><annotation id="S4.SS3.p2.2.m2.1d" encoding="application/x-llamapun">≈ 110</annotation></semantics></math> MB（减少了 59%），而 TopicQG4bit 模型进一步将其降低至 <math id="S4.SS3.p2.3.m3.1" display="inline" class="ltx_Math" alttext="\approx 94"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1"><mi id="S4.SS3.p2.3.m3.1.1.2"></mi><mo id="S4.SS3.p2.3.m3.1.1.1">≈</mo><mn id="S4.SS3.p2.3.m3.1.1.3">94</mn></mrow><annotation-xml id="S4.SS3.p2.3.m3.1b" encoding="MathML-Content">absent94</annotation-xml><annotation id="S4.SS3.p2.3.m3.1c" encoding="application/x-tex">\approx 94</annotation><annotation id="S4.SS3.p2.3.m3.1d" encoding="application/x-llamapun">≈ 94</annotation></semantics></math> MB（减少了 53%）。本研究中展示的量化潜力体现在两个方面：1）显著降低了运行模型的硬件要求，2）保持了令人满意的工作性能，使得在计算资源有限的平台上部署教育主题可控问题生成成为可能。这种可及性将极大地扩展此类模型的应用范围，使其在教育及其他移动设备实时交互应用中更加普及。模型尺寸的减小不仅意味着更低的内存需求，也暗示了更低的功耗，从而降低基础设施成本和碳足迹。这些特性对于在资源受限的教育环境中部署这些模型至关重要，例如中低收入国家、移动设备和嵌入式系统。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">The comparisons between TopicQG and TopicQG2X models in table <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#S4.T4" title="Table 4 ‣ 4. Results ‣ A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education"><span class="ltx_text ltx_ref_tag">4</span></a> show that the data augmentation has an obvious effect on improving the models performance on topical relevance. The greater diversity of examples where the same example is presented to the model in two different ways helps the model better understand to follow the topical theme prescribed in the instruction with the context. It surpasses all other models, including TopicQG, demonstrating superior alignment of the generated questions with the input context and topic. This highlights the effectiveness of data augmentation in enhancing the model’s capacity to generate questions with topic relevance and better contextual consideration of texts.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 4 中 TopicQG 与 TopicQG2X 模型的对比显示，数据增强对提升模型在主题相关性方面的性能有显著效果。相同示例以两种不同方式呈现的多样性帮助模型更好地理解并遵循指令中规定的主题主题，结合上下文进行理解。它超越了包括 TopicQG 在内的所有其他模型，展示了生成问题与输入上下文和主题的更高一致性。这突显了数据增强在提升模型生成主题相关问题的能力以及更好地考虑文本上下文方面的有效性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Discussion<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5. 讨论</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This paper tackled the challenge of topic-based educational question generation with a high degree of specificity. Due to the novelty of the task itself, we evolved our method over multiple steps to propose a method that can lead to high-quality T-CQG while validating novel approaches to evaluate the topical relevance of such generations. The results show that the novel method proposed and evaluated here is capable of generating topical educational questions while retaining coherent grammatical structure. Further experiments also showed how data augmentation increases the model’s performance in topical relevance leading to improved results. The final experiments exploring quantisation indicate that the model’s memory footprint can be halved with minimal loss of generative performance. Supported by human evaluation, the findings provide solid evidence that the questions generated by the proposed model are of high quality and meaningfully related to the educational content and topics, thereby affirming the effectiveness of our topic-controllable educational question generator.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本文解决了基于主题的教育问题生成的高度具体化挑战。由于任务本身的创新性，我们分多步演化了我们的方法，提出了一个能够生成高质量主题控制问题生成（T-CQG）的方法，同时验证了评估此类生成内容主题相关性的新方法。结果表明，本文提出并评估的新方法能够生成主题相关的教育问题，同时保持连贯的语法结构。进一步的实验还展示了数据增强如何提高模型在主题相关性方面的性能，从而获得更好的结果。最后的实验探索了量化，表明模型的内存占用可以减半，同时生成性能损失最小。在人工评估的支持下，这些发现提供了有力证据，证明所提出模型生成的问题具有高质量，且与教育内容和主题有实质性关联，从而证实了我们主题控制教育问题生成器的有效性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Similar to trends in educational research in general <cite class="ltx_cite ltx_citemacro_citep">(Denny et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib18" title="">2024</a>)</cite>, the interest in the use of Generative Artificial Intelligence (GenAI) in LA research community has significantly increased in recent years. Regarding content generation, LLMs are used in tackling challenges such as grammar/ code correction <cite class="ltx_cite ltx_citemacro_citep">(Cotet et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib14" title="">2020</a>; Do&nbsp;Viet and Markov, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib21" title="">2023</a>)</cite>, question generation <cite class="ltx_cite ltx_citemacro_citep">(Elkins et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib24" title="">2024</a>; Fawzi et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib27" title="">2024</a>)</cite>, explanations and hints provision <cite class="ltx_cite ltx_citemacro_citep">(Pardos and Bhandari, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib45" title="">2023</a>; Li et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib38" title="">2024</a>)</cite>, in STEM subjects such as mathematics <cite class="ltx_cite ltx_citemacro_citep">(Amini et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib3" title="">2019</a>; Cobbe et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib13" title="">2021</a>)</cite> and science <cite class="ltx_cite ltx_citemacro_citep">(Malinka et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib42" title="">2023</a>; Elkins et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib24" title="">2024</a>; Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib8" title="">2023</a>)</cite> to non-STEM domains like law <cite class="ltx_cite ltx_citemacro_citep">(Cui et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib15" title="">2023</a>)</cite> and language learning <cite class="ltx_cite ltx_citemacro_citep">(Caines et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib11" title="">2023</a>)</cite>. Nevertheless, the majority of the community resorts to in-context learning <cite class="ltx_cite ltx_citemacro_citep">(Dong et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib22" title="">2022</a>)</cite> within enormous LLMs such as ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(Denny et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib18" title="">2024</a>)</cite>. For instance, there are increasing numbers of attempts of topic-controlled EdQG relying on Model-as-a-Service (MaaS) products that use externally hosted LLMs like ChatGPT (e.g. <cite class="ltx_cite ltx_citemacro_citep">(Elkins et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib24" title="">2024</a>)</cite>). While practically valuable to varying degrees of success, these approaches introduce significant privacy, ethics, and governance challenges <cite class="ltx_cite ltx_citemacro_citep">(Giannakos et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib31" title="">2024</a>)</cite>. The extensive costs associated with the training and deployment of these models on-premise also make them impractical for educational stakeholders from both operational and financial perspectives <cite class="ltx_cite ltx_citemacro_citep">(Fawzi et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib27" title="">2024</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与教育研究领域的总体趋势相似（Denny 等人，2024），近年来 LA 研究界对生成式人工智能（GenAI）的应用兴趣显著增加。在内容生成方面，LLMs 被用于解决诸如语法/代码纠错（Cotet 等人，2020；Do Viet 和 Markov，2023）、问题生成（Elkins 等人，2024；Fawzi 等人，2024）、提供解释和提示（Pardos 和 Bhandari，2023；Li 等人，2024）等挑战，涉及 STEM 学科（如数学（Amini 等人，2019；Cobbe 等人，2021）和科学（Malinka 等人，2023；Elkins 等人，2024；Bulathwela 等人，2023）等非 STEM 领域（如法律（Cui 等人，2023）和语言学习（Caines 等人，2023））。然而，该领域的大多数人依赖于在大型 LLM（如 ChatGPT（Denny 等人，2024））中的情境学习（Dong 等人，2022）。例如，越来越多地尝试使用基于模型即服务（MaaS）产品进行主题控制的教育问题生成（EdQG），这些产品使用外部托管的 LLM（如 ChatGPT（例如（Elkins 等人，2024））。 虽然这些方法在实用价值上取得不同程度的成功，但它们引入了显著的隐私、伦理和治理挑战（Giannakos 等人，2024）。这些模型在本地训练和部署所涉及的巨大成本，也使得它们对教育相关方从运营和财务角度来看都不切实际（Fawzi 等人，2024）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">We argue that over-reliance on such commercial models in academic research is a threat to academic independence and encourages alternative investigations to address significant challenges of education. The novel approach proposed in this paper provides significant opportunities to enhance the applicability of language models in educational contexts for question generation without the limitations posed by approaches relying on externally hosted LLMs like ChatGPT. The model proposed here has the potential to be scaled at a minimal cost in a safe and ethical manner and can be utilised to generate questions that are closely aligned with the specific content of educational materials. The 4-bit quantisation described reduces the model size to 94.41 MB while preserving essential performance, showcasing its potential for widespread use in resource-limited educational scenarios such as mobile devices and embedded systems. Therefore, the model has the potential for decreasing teachers workload on question generation in diverse contexts as well as being utilised in LMSs and ITSs to facilitate personalised learning experiences, allowing educational questions posed to be customised to meet the unique needs and interests of each learner (such as a learner model <cite class="ltx_cite ltx_citemacro_citep">(Qiu et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib49" title="">2024</a>)</cite>).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们认为，在学术研究中过度依赖此类商业模型是对学术独立性的威胁，并鼓励替代性研究以应对教育中的重大挑战。本文提出的创新方法为在教育环境中增强语言模型在问题生成方面的适用性提供了重要机遇，且不受依赖外部托管 LLM（如 ChatGPT）的方法所带来的限制。本文提出的模型具有以极低成本安全、合乎道德地进行扩展的潜力，并可用于生成与教育材料具体内容紧密相关的问题。所描述的 4 位量化将模型大小减少到 94.41 MB，同时保留了核心性能，展示了其在资源有限的教育场景（如移动设备和嵌入式系统）中广泛应用的潜力。 因此，该模型有潜力减少教师在不同情境下进行问题生成的负担，并且可以应用于学习管理系统（LMS）和智能教学系统（ITS）中，以促进个性化学习体验，使提出的教育问题能够根据每个学习者的独特需求和兴趣进行定制（例如学习者模型（Qiu 等人，2024））。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Implications of the Results for Research and Practice<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.1. 研究与实践的启示</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Regarding educational practice, the proposed topic-controlled question generating model can be useful for different tasks within the education domain. Primarily, we see such a tool as a teacher assistant tool to propose questions to teachers to select from. Such a tool would keep teachers in the loop as final decision makers but help them with tasks such as generating topic-specific, relevant, and age-appropriate questions for teaching. As discussed in the introduction, these tasks have long been identified as time-intensive tasks for teachers <cite class="ltx_cite ltx_citemacro_citep">(Giannakos et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib31" title="">2024</a>)</cite>. We envision tools where a teacher can point the system to a video, a presentation or a collection of learning resources where the system will automatically detect numerous salient topics and present them to the teacher as potential educational questions and the draft of a new quiz can be created in a matter of few clicks. This approach has the potential to change the degree of formative assessment due to decreased workload and can further stimulate well-anticipated innovation in education systems <cite class="ltx_cite ltx_citemacro_citep">(Luckin and Cukurova, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib41" title="">2019</a>)</cite>. We argue that the model proposed and evaluated here has the potential to decrease teachers’ workload on such tasks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在教育实践中，所提出的主题控制问题生成模型可用于教育领域的不同任务。主要而言，我们视此类工具为教师辅助工具，向教师提供可供选择的问题。此类工具将使教师作为最终决策者保持参与，同时帮助教师完成生成与主题相关、适用且符合年龄特点的教学问题的任务。正如引言中所述，这些任务长期以来一直被视为教师耗时的工作（Giannakos 等人，2024）。我们设想教师可以指向系统一个视频、演示文稿或学习资源集合，系统将自动检测多个显著主题，并将其呈现给教师作为潜在的教育问题，新测验的草稿可在几次点击内创建。这种做法由于减轻了工作量，有潜力改变形成性评估的程度，并进一步激发教育体系中期待已久的创新（Luckin 和 Cukurova，2019）。 我们认为，这里提出并评估的模型有潜力减少教师在这些任务上的工作量。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Second, the model can be integrated into multiple roles within the learning analytics infrastructures. The key to a precise learner state representation is having precise tests that can verify skill mastery of individuals at finer grain. The proposed method can lead to tools that can generate high-precision assessments within a personalised learning management system that can feed better data into learning analytics. While investing significant resources to create a relatively high coverage question banks is still feasible for short course and MOOC platforms that focus on narrow scopes of knowledge, as the world is gradually moving towards informal, lifelong learning such an investment would be infeasible. Models such as the one proposed here can play a critical role for continuous topic-specific, high quality and relevant question generation in educational systems.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其次，该模型可以集成到学习分析基础设施的多个角色中。精确的学员状态表示的关键在于拥有能够更精细地验证个人技能掌握程度的精确测试。所提出的方法可以导致在个性化学习管理系统中生成高精度评估的工具，从而为学习分析提供更好的数据。虽然为短期课程和专注于狭窄知识领域的 MOOC 平台投入大量资源创建相对高覆盖率的题库仍然是可行的，但随着世界逐渐向非正式、终身学习转变，这种投入将变得不可行。像这里提出的模型这样的模型，可以在教育系统中发挥关键作用，实现持续的主题特定、高质量且相关的题目生成。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">Third, the model can also bring efficiencies to the implementation of question generation in mobile and resource scarce contexts. As we are dealing with very small models, systems built on these models are scalable with minimal costs and has the potential to run on mobile devices without having to connect to the Internet. These considerations are of utmost importance for more equitable use of AI in Education <cite class="ltx_cite ltx_citemacro_citep">(Bulathwela et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib9" title="">2024</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">第三，该模型也能为移动设备和资源匮乏环境中的问题生成实施带来效率。由于我们处理的是非常小的模型，基于这些模型构建的系统具有可扩展性且成本极低，并且有潜力在不连接互联网的情况下在移动设备上运行。这些考虑对于教育中 AI 的更公平使用至关重要（Bulathwela 等人，2024）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Regarding LA and AI in Education research in general, the methodology proposed in this work can be extended to other forms of generation such as feedback, explanations, and content summaries in education. Also, aspects that that go beyond topical relevance (such as linguistic complexity and cognitive load etc.) can be controlled in future explorations to further advance learning analytics systems paving the way to re-imagining the limits of personalised learning material generation with AI. Furthermore, existing research either ignores the evaluation of whether the generated questions truly respond to the controlled conditions, or relies on extensive manual scoring by humans, which is both time-consuming and labour-intensive <cite class="ltx_cite ltx_citemacro_citep">(Yudelson et&nbsp;al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2501.05220v1#bib.bib58" title="">2013</a>)</cite>. Experimental studies with human participants presented here indicate that the ”relatedness score” has the potential to serve as a robust evaluation metric for assessing the semantic relatedness of generated questions to the input text, particularly in educational question generation tasks. It appears to excel in distinguishing between different concepts within the same academic field, making it particularly relevant for educational question generation tasks. As educational content generation research increases in LA literature, the importance of evaluation metrics of such content becomes even more important and the findings of this paper can help researchers consider appropriate metrics.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">关于教育领域中的学习分析与人工智能研究，本工作中提出的方法可以扩展到其他形式的生成，如反馈、解释和内容摘要。此外，在未来的探索中，可以控制那些超越主题相关性的方面（如语言复杂性和认知负荷等），以进一步推进学习分析系统，为重新构想人工智能在个性化学习材料生成方面的极限铺平道路。此外，现有研究要么忽略了评估生成的题目是否真正符合控制条件，要么依赖于人工进行大量评分，这既耗时又费力（Yudelson 等人，2013）。这里展示的涉及人类参与者的实验研究表明，“相关性分数”有潜力作为评估生成题目与输入文本语义相关性的可靠指标，特别是在教育题目生成任务中。 它似乎在区分同一学术领域内的不同概念方面表现出色，因此特别适用于教育问题生成任务。随着教育内容生成研究在 LA 文献中的增加，此类内容评估指标的重要性也日益凸显，本文的研究结果可以帮助研究人员考虑合适的指标。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6.结论</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper proposes a novel approach to fine-tuning pre-trained sLMs to effectively address the challenge of generating topic-controllable questions based on paragraph-level context within educational settings. In addition, a novel method to synthesise training data for this task is presented with a novel Wikipedia concept-based evaluation method. The results show that the model proposed here has the potential to decrease teacher workload and improve personalised learning platforms also proving the effectiveness of training data. The model can also be scaled financially and operationally at a minimal cost to decrease academic researchers’ over-reliance on commercial LLMs like ChatGPT.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本文提出了一种新颖的方法，用于微调预训练的 sLMs，以有效应对在教育环境中基于段落级上下文生成主题可控问题的挑战。此外，还提出了一种合成此任务训练数据的新方法，并采用了一种基于维基百科概念的新颖评估方法。结果表明，本文提出的模型有潜力减少教师工作量，提升个性化学习平台，同时也证明了训练数据的有效性。该模型还可以在财务和运营上进行扩展，以最低成本减少学术研究人员对 ChatGPT 等商业 LLMs 的过度依赖。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">This study, while advancing topic-controllable question generation in education, acknowledges several limitations. The limited human evaluation sample size hinders the statistical power of our findings about the semantic relatedness metrics although the extremely high inter-annotator agreement improves reliability of the result. More extensive human annotations would strengthen the results further. While we demonstrate the proposed novel method that randomly pairs contexts enabling the model T-CQG performance to improve, different pairing strategies that respect the subject domain, subtopics, difficulty level etc. can also lead to more effective training sets and should be explored in future studies. Finally, while the proposed method can be used to train the pre-trained model to contextualise generations to topical relevance, it focuses on topical relevance only. However, how to incorporate multiple aspects in addition to topical relevance such as linguistic complexity and generation length (e.g. short question) together should be explored in the future.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这项研究在推进教育领域中主题可控问题生成的同时，也承认存在一些局限性。由于人工评估样本量有限，虽然极高的标注者间一致性提高了结果的可靠性，但我们的语义相关性指标研究结果统计效力受到限制。更广泛的人工标注将进一步强化结果。尽管我们展示了所提出的创新方法——通过随机配对上下文使模型 T-CQG 性能得到提升，但尊重学科领域、子主题、难度等级等的不同配对策略也能产生更有效的训练集，这些策略应在未来的研究中进行探索。最后，虽然所提出的方法可用于训练预训练模型以使生成内容与主题相关，但它仅关注主题相关性。然而，如何在主题相关性之外结合其他方面（如语言复杂性和生成长度（例如短问题））进行探索，应在未来研究中加以考虑。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">致谢。</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
This work is funded by the European Commission-funded projects ”Humane AI” (Grant No. 820437) and ”X5GON” (Grant No. 761758). This research is also part of the Teacher-AI Complementarity (TaiCo) project funded by the European Commission’s Horizon Program (Project ID: 101177268).

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这项工作得到了欧洲委员会资助的项目“仁心 AI”（资助编号 820437）和“X5GON”（资助编号 761758）的资助。这项研究也是由欧洲委员会“地平线计划”资助的教师-人工智能互补性（TaiCo）项目（项目编号 101177268）的一部分。</font></font></font></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adamson et&nbsp;al<span class="ltx_text" id="bib.bib2.2.2.1">.</span> (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Derek Adamson, Deepak
Bhartiya, Baljeet Gujral, Ritu Kedia,
Ankit Singh, and Carolyn&nbsp;P. Rose.
2013.

</span>
<span class="ltx_bibblock">Automatically Generating Discussion Questions. In
<em class="ltx_emph ltx_font_italic" id="bib.bib2.3.1">Proceedings of the International Conference on
Artificial Intelligence in Education (AIED)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amini et&nbsp;al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aida Amini, Saadia
Gabriel, Peter Lin, Rik
Koncel-Kedziorski, Yejin Choi, and
Hannaneh Hajishirzi. 2019.

</span>
<span class="ltx_bibblock">Mathqa: Towards interpretable math word problem
solving with operation-based formalisms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">arXiv preprint arXiv:1905.13319</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahrick et&nbsp;al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (1993)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
H.&nbsp;P. Bahrick, L.&nbsp;E.
Bahrick, A.&nbsp;S. Bahrick, and P.&nbsp;E.
Bahrick. 1993.

</span>
<span class="ltx_bibblock">Maintenance of foreign language vocabulary and the
spacing effect.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Psychological Science</em> 4,
5 (1993), 316–321.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Banerjee and Lavie (2005)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
S. Banerjee and A.
Lavie. 2005.

</span>
<span class="ltx_bibblock">METEOR: An automatic metric for MT evaluation with
improved correlation with human judgments. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">ACL
Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine
Translation and/or Summarization</em>. 65–72.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blobstein et&nbsp;al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ariel Blobstein, Daniel
Izmaylov, Tal Yifat, Michal Levy, and
Avi Segal. 2023.

</span>
<span class="ltx_bibblock">Angel: A New Generation Tool for Learning Material
based Questions and Answers. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Proc.&nbsp;of the
NeurIPS Workshop on Generative AI for Education (GAIED)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brank et&nbsp;al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Janez Brank, Gregor
Leban, and Marko Grobelnik.
2017.

</span>
<span class="ltx_bibblock">Annotating Documents with Relevant Wikipedia
Concepts. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">Proc. of Slovenian KDD Conference on
Data Mining and Data Warehouses (SiKDD)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bulathwela et&nbsp;al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sahan Bulathwela, Hamze
Muse, and Emine Yilmaz.
2023.

</span>
<span class="ltx_bibblock">Scalable educational question generation with
pre-trained language models. In <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">International
Conference on Artificial Intelligence in Education</em>. Springer,
327–339.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bulathwela et&nbsp;al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sahan Bulathwela,
María Pérez-Ortiz, Catherine
Holloway, Mutlu Cukurova, and John
Shawe-Taylor. 2024.

</span>
<span class="ltx_bibblock">Artificial intelligence alone will not democratise
education: On educational inequality, techno-solutionism and inclusive
tools.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.3.1">Sustainability</em> 16,
2 (2024), 781.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bulathwela et&nbsp;al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sahan Bulathwela,
María Pérez-Ortiz, Emine Yilmaz,
and John Shawe-Taylor. 2021.

</span>
<span class="ltx_bibblock">Semantic TrueLearn: using semantic knowledge graphs
in recommendation systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">arXiv preprint arXiv:2112.04368</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caines et&nbsp;al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andrew Caines, Luca
Benedetto, Shiva Taslimipoor, Christopher
Davis, et&nbsp;al<span class="ltx_text" id="bib.bib11.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">On the application of large language models for
language teaching and assessment technology.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.4.1">arXiv preprint arXiv:2307.08393</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Feng Chen, Jiayuan Xie,
Yi Cai, Tao Wang, and
Qing Li. 2021.

</span>
<span class="ltx_bibblock">Difficulty-Controllable Visual Question
Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">Proc. Web and Big Data:
International Joint Conference</em>. Springer-Verlag,
332–347.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et&nbsp;al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet
Kosaraju, Mohammad Bavarian, Mark Chen,
Heewoo Jun, Lukasz Kaiser,
Matthias Plappert, Jerry Tworek,
Jacob Hilton, Reiichiro Nakano,
et&nbsp;al<span class="ltx_text" id="bib.bib13.3.1">.</span> 2021.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.4.1">arXiv preprint arXiv:2110.14168</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cotet et&nbsp;al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Teodor-Mihai Cotet, Stefan
Ruseti, and Mihai Dascalu.
2020.

</span>
<span class="ltx_bibblock">Neural grammatical error correction for romanian.
In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">2020 IEEE 32nd International Conference on Tools
with Artificial Intelligence (ICTAI)</em>. IEEE, 625–631.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaxi Cui, Zongjian Li,
Yang Yan, Bohua Chen, and
Li Yuan. 2023.

</span>
<span class="ltx_bibblock">Chatlaw: Open-source legal large language model
with integrated external knowledge bases.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">arXiv preprint arXiv:2306.16092</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cukurova et&nbsp;al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mutlu Cukurova, Xin Miao,
and Richard Brooker. 2023.

</span>
<span class="ltx_bibblock">Adoption of artificial intelligence in schools:
unveiling factors influencing teachers’ engagement. In
<em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">International conference on artificial intelligence
in education</em>. Springer, 151–163.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dathathri et&nbsp;al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sumanth Dathathri, Andrea
Madotto, Janice Lan, Jane Hung,
Eric Frank, Piero Molino,
Jason Yosinski, and Rosanne Liu.
2020.

</span>
<span class="ltx_bibblock">Plug and Play Language Models: A Simple Approach to
Controlled Text Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">International
Conference on Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=H1edEyBKDS" title="">https://openreview.net/forum?id=H1edEyBKDS</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Denny et&nbsp;al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Paul Denny, Sumit
Gulwani, Neil&nbsp;T. Heffernan, Tanja
Käser, Steven Moore, Anna&nbsp;N. Rafferty,
and Adish Singla. 2024.

</span>
<span class="ltx_bibblock">Generative AI for Education (GAIED): Advances,
Opportunities, and Challenges.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2402.01580&nbsp;[cs.CY]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2402.01580" title="">https://arxiv.org/abs/2402.01580</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et&nbsp;al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tim Dettmers, Mike Lewis,
Younes Belkada, and Luke Zettlemoyer.
2022.

</span>
<span class="ltx_bibblock">LLM.int8(): 8-bit Matrix Multiplication for
Transformers at Scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">arXiv preprint arXiv:2208.07339</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et&nbsp;al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro
Pagnoni, Ari Holtzman, and Luke
Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock">QLora: Efficient Fine-Tuning of Quantized LLMs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">arXiv preprint arXiv:2305.14314</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Do&nbsp;Viet and Markov (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tung Do&nbsp;Viet and
Konstantin Markov. 2023.

</span>
<span class="ltx_bibblock">Using Large Language Models for Bug Localization
and Fixing. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">2023 12th International Conference
on Awareness Science and Technology (iCAST)</em>. IEEE,
192–197.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et&nbsp;al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qingxiu Dong, Lei Li,
Damai Dai, Ce Zheng,
Zhiyong Wu, Baobao Chang,
Xu Sun, Jingjing Xu, and
Zhifang Sui. 2022.

</span>
<span class="ltx_bibblock">A survey on in-context learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">arXiv preprint arXiv:2301.00234</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et&nbsp;al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xinya Du, Junru Shao,
and Claire Cardie. 2017.

</span>
<span class="ltx_bibblock">Learning to Ask: Neural Question Generation for
Reading Comprehension. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">Proc. Annual Meeting of
the Association for Computational Linguistics</em>. 1342–1352.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elkins et&nbsp;al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sabina Elkins, Ekaterina
Kochmar, Jackie&nbsp;CK Cheung, and Iulian
Serban. 2024.

</span>
<span class="ltx_bibblock">How Teachers Can Use Large Language Models and
Bloom’s Taxonomy to Create Educational Quizzes. In
<em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, Vol.&nbsp;38. 23084–23091.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faraby et&nbsp;al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Said&nbsp;Al Faraby, Ade
Romadhony, and Adiwijaya.
2024.

</span>
<span class="ltx_bibblock">Analysis of LLMs for educational question
classification and generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">Computers and Education: Artificial
Intelligence</em> 7 (2024),
100298.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1016/j.caeai.2024.100298" title="">https://doi.org/10.1016/j.caeai.2024.100298</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fawzi et&nbsp;al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> ([n. d.])<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fares Fawzi, Sadie Amini,
and Sahan Bulathwela.
[n. d.].

</span>
<span class="ltx_bibblock">Small Generative Language Models for Educational
Question Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">Proc.&nbsp;of the NeurIPS
Workshop on Generative AI for Education (GAIED)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fawzi et&nbsp;al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
F. Fawzi, S. Balan,
M. Cukurova, E. Yilmaz, and
S. Bulathwela. 2024.

</span>
<span class="ltx_bibblock">Towards Human-Like Educational Question Generation
with Small Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">Artificial
Intelligence in Education. Posters and Late Breaking Results, Workshops and
Tutorials, Industry and Innovation Tracks, Practitioners, Doctoral Consortium
and Blue Sky</em>, Vol.&nbsp;2150. Springer,
Cham.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ferragina and Scaiella (2010)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Paolo Ferragina and Ugo
Scaiella. 2010.

</span>
<span class="ltx_bibblock">TAGME: on-the-fly annotation of short text
fragments (by wikipedia entities). In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings
of the 19th ACM International Conference on Information and Knowledge
Management</em> (Toronto, ON, Canada) <em class="ltx_emph ltx_font_italic" id="bib.bib28.2.2">(CIKM ’10)</em>.
Association for Computing Machinery,
New York, NY, USA, 1625–1628.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/1871437.1871689" title="">https://doi.org/10.1145/1871437.1871689</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fleiss (1971)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joseph&nbsp;L. Fleiss.
1971.

</span>
<span class="ltx_bibblock">Measuring nominal scale agreement among many
raters.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Psychological Bulletin</em>
76, 5 (1971),
378–382.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">for Education (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Department for Education.
2024.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Use Cases for Generative AI in Education:
User Research Report</em>.

</span>
<span class="ltx_bibblock">Technical Report.
Department for Education, UK Government.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.gov.uk/government/publications/generative-ai-in-education-user-research-and-technical-report" title="">https://www.gov.uk/government/publications/generative-ai-in-education-user-research-and-technical-report</a>
</span>
<span class="ltx_bibblock">Accessed: 2024-09-21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Giannakos et&nbsp;al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michail Giannakos, Roger
Azevedo, Peter Brusilovsky, Mutlu
Cukurova, Yannis Dimitriadis, Davinia
Hernandez-Leo, Sanna Järvelä,
Manolis Mavrikis, and Bart Rienties.
2024.

</span>
<span class="ltx_bibblock">The promise and challenges of generative AI in
education.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">Behaviour &amp; Information Technology</em>
(2024), 1–27.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong and Pan (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Huanli Gong and
Hengchang Pan, Liangming&nbsp;andHu.
2022.

</span>
<span class="ltx_bibblock">KHANQ: A Dataset for Generating Deep Questions in
Education. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 29th
International Conference on Computational Linguistics</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hansen et&nbsp;al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lasse Hansen, Ludvig&nbsp;Renbo
Olsen, and Kenneth Enevoldsen.
2023.

</span>
<span class="ltx_bibblock">TextDescriptives: A Python package for calculating
a large variety of metrics from text.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">Journal of Open Source Software</em>
8, 84 (April
2023), 5153.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.21105/joss.05153" title="">https://doi.org/10.21105/joss.05153</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heilman and Smith (2010)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michael Heilman and
Noah&nbsp;A. Smith. 2010.

</span>
<span class="ltx_bibblock">Good question! Statistical ranking for question
generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the Human Language
Technology Conference and the North American Chapter of the Association for
Computational Linguistics (HLT-NAACL)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenpeng Hu, Bing Liu,
Rui Yan, Dongyan Zhao, and
Jinwen Ma. 2018.

</span>
<span class="ltx_bibblock">Topic-Based Question Generation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">International Conference on Learning
Representations</em>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">ICLR 2018 Conference Blind Submission. Invite to Workshop Track.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khalifa et&nbsp;al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Muhammad Khalifa, Hady
Elsahar, and Marc Dymetman.
2021.

</span>
<span class="ltx_bibblock">A Distributional Approach to Controlled Text
Generation. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">International Conference on
Learning Representations</em>.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=jWkw45-9AbL" title="">https://openreview.net/forum?id=jWkw45-9AbL</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuo et&nbsp;al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bor-Chen Kuo, Frederic&nbsp;TY
Chang, and Zong-En Bai.
2023.

</span>
<span class="ltx_bibblock">Leveraging LLMs for Adaptive Testing and Learning
in Taiwan Adaptive Learning Platform (TALP).. In
<em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">Workshop on Empowering Education with LLMs at
AIED</em>. 101–110.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hai Li, Chenglu Li,
Wanli Xing, Sami Baral, and
Neil Heffernan. 2024.

</span>
<span class="ltx_bibblock">Automated Feedback for Student Math Responses Based
on Multi-Modality and Fine-Tuning. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Proceedings
of the 14th Learning Analytics and Knowledge Conference</em>.
763–770.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Y. Lin.
2004.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of
summaries. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Workshop on Text Summarization
Branches Out</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lopez et&nbsp;al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
L.&nbsp;E. Lopez, D.&nbsp;K. Cruz,
J.&nbsp;C.&nbsp;B. Cruz, and C. Cheng.
2021.

</span>
<span class="ltx_bibblock">Simplifying Paragraph-level Question Generation via
Transformer Language Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">Proceedings of the
PRICAI 2021: Trends in Artificial Intelligence</em> (8–12 November 2021).
Hanoi, Vietnam.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luckin and Cukurova (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rosemary Luckin and
Mutlu Cukurova. 2019.

</span>
<span class="ltx_bibblock">Designing educational technologies in the age of
AI: A learning sciences-driven approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">British Journal of Educational Technology</em>
50, 6 (2019),
2824–2838.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malinka et&nbsp;al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kamil Malinka, Martin
Peresíni, Anton Firc, Ondrej
Hujnák, and Filip Janus.
2023.

</span>
<span class="ltx_bibblock">On the educational impact of chatgpt: Is artificial
intelligence ready to obtain a university degree?. In
<em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the 2023 Conference on Innovation
and Technology in Computer Science Education</em>, Vol.&nbsp;1.
47–53.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martin et&nbsp;al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Louis Martin, Éric
Villemonte&nbsp;de La&nbsp;Clergerie, Benoît Sagot, and
Antoine Bordes. 2020.

</span>
<span class="ltx_bibblock">Controllable Sentence Simplification. In
<em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">LREC 2020 - 12th Language Resources and Evaluation
Conference</em>. Marseille, France.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://inria.hal.science/hal-02678214" title="">https://inria.hal.science/hal-02678214</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et&nbsp;al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2002)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
K. Papineni, S. Roukos,
T. Ward, and W.J. Zhu.
2002.

</span>
<span class="ltx_bibblock">BLEU: a method for automatic evaluation of machine
translation. In <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">Proceedings of the 40th annual
meeting on association for computational linguistics</em>. Association for
Computational Linguistics, 311–318.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pardos and Bhandari (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zachary&nbsp;A Pardos and
Shreya Bhandari. 2023.

</span>
<span class="ltx_bibblock">Learning gain differences between ChatGPT and human
tutor generated algebra hints.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2302.06871</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Piccinno and Ferragina (2014)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Francesco Piccinno and
Paolo Ferragina. 2014.

</span>
<span class="ltx_bibblock">From TagME to WAT: a new entity annotator. In
<em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Proceedings of the First International Workshop on
Entity Recognition &amp; Disambiguation</em> <em class="ltx_emph ltx_font_italic" id="bib.bib46.2.2">(ERD ’14)</em>.
Association for Computing Machinery,
55–62.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/2633211.2634350" title="">https://doi.org/10.1145/2633211.2634350</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pinto et&nbsp;al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gustavo Pinto, Isadora
Cardoso-Pereira, Danilo Monteiro, Danilo
Lucena, Alberto Souza, and Kiev Gama.
2023.

</span>
<span class="ltx_bibblock">Large language models for education: Grading
open-ended questions using chatgpt. In <em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">Proceedings
of the XXXVII Brazilian Symposium on Software Engineering</em>.
293–302.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ponza et&nbsp;al<span class="ltx_text" id="bib.bib48.2.2.1">.</span> (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Marco Ponza, Paolo
Ferragina, and Soumen Chakrabarti.
2020.

</span>
<span class="ltx_bibblock">On Computing Entity Relatedness in Wikipedia, with
Applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.3.1">Knowledge-Based Systems</em>
188 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et&nbsp;al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuxiang Qiu, Karim
Djemili, Denis Elezi, Aaneel&nbsp;Shalman
Srazali, María Pérez-Ortiz,
Emine Yilmaz, John Shawe-Taylor, and
Sahan Bulathwela. 2024.

</span>
<span class="ltx_bibblock">A Toolbox for Modelling Engagement with Educational
Videos. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">Proceedings of the AAAI Conference on
Artificial Intelligence</em>, Vol.&nbsp;38.
23128–23136.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Colin Raffel, Noam
Shazeer, Adam Roberts, Katherine Lee,
Sharan Narang, Michael Matena,
Yanqi Zhou, Wei Li, and
Peter&nbsp;J. Liu. 2022.

</span>
<span class="ltx_bibblock">Exploring the Limits of Transfer Learning with a
Unified Text-to-Text Transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">The Journal of Machine Learning Research</em>
21, 1 (2022),
5485–5551.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et&nbsp;al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2016)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian
Zhang, Konstantin Lopyrev, and Percy
Liang. 2016.

</span>
<span class="ltx_bibblock">SQuAD: 100,000+ Questions for Machine Comprehension
of Text.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1606.05250&nbsp;[cs.CL]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1606.05250" title="">https://arxiv.org/abs/1606.05250</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soldaini and Lo (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Luca Soldaini and Kyle
Lo. 2023.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">peS2o (Pretraining Efficiently on S2ORC)
Dataset</em>.

</span>
<span class="ltx_bibblock">Technical Report. Allen
Institute for AI.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">ODC-By, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/allenai/pes2o" title="">https://github.com/allenai/pes2o</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">UNESCO and International Task Force on Teachers for Education
2030 (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
UNESCO and
International Task Force on Teachers for Education 2030.
2024.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Global Report on Teachers: Addressing
Teacher Shortages and Transforming the Profession</em>.

</span>
<span class="ltx_bibblock">UNESCO, Paris. 187 pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.54675/FIGU8035" title="">https://doi.org/10.54675/FIGU8035</a>
</span>
<span class="ltx_bibblock">CC BY-SA 3.0 IGO.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vachev et&nbsp;al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kristiyan Vachev, Momchil
Hardalov, Georgi Karadzhov, Georgi
Georgiev, Ivan Koychev, and Preslav
Nakov. 2022.

</span>
<span class="ltx_bibblock">Leaf: Multiple-choice question generation. In
<em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">Proc.&nbsp;of the European Conf. on Information
Retrieval</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shen Wang, Tianlong Xu,
Hang Li, Chaoli Zhang,
Joleen Liang, Jiliang Tang,
Philip&nbsp;S. Yu, and Qingsong Wen.
2024.

</span>
<span class="ltx_bibblock">Large Language Models for Education: A Survey and
Outlook.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2403.18105&nbsp;[cs.CL]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2403.18105" title="">https://arxiv.org/abs/2403.18105</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Z. Wang, A.&nbsp;S. Lan,
W. Nie, A.&nbsp;E. Waters,
P.&nbsp;J. Grimaldi, and R.&nbsp;G. Baraniuk.
2018.

</span>
<span class="ltx_bibblock">QG-Net: A Data-Driven Question Generation Model for
Educational Content. In <em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">Proceedings of the Fifth
Annual ACM Conference on Learning at Scale</em> (26–28 June 2018).
London, UK.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yadav et&nbsp;al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gautam Yadav, Ying-Jui
Tseng, and Xiaolin Ni. 2023.

</span>
<span class="ltx_bibblock">Contextualizing problems to student interests at
scale in intelligent tutoring system using large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">arXiv preprint arXiv:2306.00190</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yudelson et&nbsp;al<span class="ltx_text" id="bib.bib58.2.2.1">.</span> (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michael&nbsp;V. Yudelson,
Kenneth&nbsp;R. Koedinger, and Geoffrey&nbsp;J.
Gordon. 2013.

</span>
<span class="ltx_bibblock">Individualized Bayesian Knowledge Tracing Models.
In <em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">Proc.&nbsp;of Artificial Intelligence in Education</em>,
H.&nbsp;Chad Lane, Kalina
Yacef, Jack Mostow, and Philip Pavlik
(Eds.).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Rettinger (2014)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
L. Zhang and A.
Rettinger. 2014.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Final Ontological Word-Sense Disambiguation
Prototype</em>.

</span>
<span class="ltx_bibblock">Deliverable D3.2.3. xLike
Project.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al<span class="ltx_text" id="bib.bib60.2.2.1">.</span> (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ruqing Zhang, Jiafeng
Guo, Lu Chen, Yixing Fan, and
Xueqi Cheng. 2021.

</span>
<span class="ltx_bibblock">A Review on Question Generation from Natural
Language Text.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.3.1">ACM Trans. Inf. Syst.</em> 40,
1, Article 14 (sep
2021), 43&nbsp;pages.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3468889" title="">https://doi.org/10.1145/3468889</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al<span class="ltx_text" id="bib.bib61.2.2.1">.</span> (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha
Kishore, Felix Wu, Kilian&nbsp;Q. Weinberger,
and Yoav Artzi. 2020.

</span>
<span class="ltx_bibblock">BERTScore: Evaluating Text Generation with BERT.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1904.09675&nbsp;[cs.CL]

<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/1904.09675" title="">https://arxiv.org/abs/1904.09675</a>
</span>
</li>
</ul>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">报告问题</font></font></font></button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none; left: 1008px; top: 313.07px; transform: translate(-50%, -100%);">Report Issue for Selection<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">报告选择问题</font></font></font></button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" width="11" height="14">
            </a><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由 L A T E xml <img height="14" width="11" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"> 生成</font></font></font>
        </div></div><footer id="footer" class="ltx_document" default-translate="no">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>/** 基础色阶定义 **/
:root,
#mount[data-theme="light"],
#mount:not([data-theme="dark"]) {
  /* 中性灰阶（light） */
  --c-00: #000000;
  --c-22: #222222;
  --c-33: #333333;
  --c-66: #666666;
  --c-83: #838383;
  --c-99: #999999;
  --c-c7: #c7c7c7;
  --c-cc: #cccccc;
  --c-e6: #e6e6e6;
  --c-f5: #f5f5f5;
  --c-ff: #ffffff;
  /* 品牌主色阶（light） */
  --p-main: #ea4c89;
  --p-hover: #ec5e95;
  --p-active: #e34a85;
  --p-special: #ee71a2;
  --p-disabled: #f4a5c4;
  --p-text-disabled: #f9c9dc;
  --p-weak: #fdedf3;
  /* Surface 层级（light，TC 填充-1） */
  --s-1: #f3f5f6;
  --s-1-hover: #f6f8f9;
  --s-1-active: #edf1f2;
  --s-1-weak: #fafbfb;
  /* 输入/边框（light，TC 填充-2） */
  --input-bg-base: #fafbfc;
  --input-border: #ecf0f7;
  --input-border-strong: #e0e0e6;
  --input-bg-strong: #fafdff;
}

:root[data-theme="dark"],
[data-theme="dark"] {
  /* 中性灰阶（dark） */
  --c-00: #ffffff;
  --c-22: #dbdbdb;
  --c-33: #dbdbdb;
  --c-66: #b3b3b3;
  --c-83: #838383;
  --c-99: #707070;
  --c-c7: #666666;
  --c-cc: #5c5c5c;
  --c-e6: #3b3b3b;
  --c-f5: #262626;
  --c-ff: #222222;
  /* 品牌主色阶（dark） */
  --p-main: #e23c7c;
  --p-hover: #ea4c89;
  --p-active: #d5467d;
  --p-special: #a93a65;
  --p-disabled: #7e2f4d;
  --p-text-disabled: #522335;
  --p-weak: #26171d;
  /* Surface 层级（dark，TC 填充-1） */
  --s-1: #2d2e2f;
  --s-1-hover: #323434;
  --s-1-active: #202121;
  --s-1-weak: #262627;
  /* 输入/边框（dark，TC 填充-2） */
  --input-bg-base: #2b2d30;
  --input-border: #3e434b;
  --input-border-strong: #43474b;
  --input-bg-strong: #1f2123;
}

:root,
#mount [data-theme] {
  /* 业务/通用变量引用色阶（全局可见，含 Shadow DOM） */
  --primary: var(--p-main);
  --primary-hover: var(--p-hover);
  --primary-inverse: #fff;
  --modal-background: var(--s-1);
  --modal-border: var(--input-border);
  --modal-text: var(--c-22);
  --modal-text-secondary: var(--c-66);
  --modal-error: var(--p-main);
  --modal-required: #f53f3f;
  --modal-success: #68cd52;
  --modal-button-background: var(--p-main);
  --modal-button-text: var(--c-ff);
  --modal-input-background: var(--input-bg-base);
  --modal-check-color: var(--p-main);
  --background-color: var(--c-ff);
  --background-light-green: var(--s-1-weak, #f5f7f9);
  --text-black-2: var(--c-22);
  --text-gray-2: var(--c-22);
  --text-gray-6: var(--c-66);
  --text-gray-9: var(--c-99);
  --text-gray-c2: var(--c-c7);
  --switch-background-color: var(--c-c7, hsl(205deg, 16%, 77%));
  --float-ball-more-button-border-color: var(--c-f5, #f6f6f6);
  --float-ball-more-button-background-color: var(--c-ff);
  --float-ball-more-button-svg-color: #6c6f73;
  --service-bg-hover: var(--s-1-hover, #f7faff);
  --service-bg: var(--s-1-weak, #fafbfb);
}

#mount {
  --font-family: var(
    system-ui,
    -apple-system,
    "Segoe UI",
    "Roboto",
    "Ubuntu",
    "Cantarell",
    "Noto Sans",
    sans-serif,
    "Apple Color Emoji",
    "Segoe UI Emoji",
    "Segoe UI Symbol",
    "Noto Color Emoji"
  );
  /* PC/H5 兼容的字号、间距、圆角、阴影变量 */
  --f-12: 12px;
  --f-14: 14px;
  --f-15: 15px;
  --f-16: 16px;
  --f-18: 18px;
  --f-20: 20px;
  --space-4: 4px;
  --space-6: 6px;
  --space-8: 8px;
  --space-12: 12px;
  --space-16: 16px;
  --space-18: 18px;
  --space-24: 24px;
  --radius-8: 8px;
  --radius-12: 12px;
  --radius-16: 16px;
  --control-height-lg: 44px;
  --width-28: 28px;
  --width-24: 24px;
  --width-20: 20px;
  --width-18: 18px;
  --width-16: 16px;
  --width-label-md: 56px;
  --shadow-lg: 0 18px 48px rgba(0, 0, 0, 0.12);

  /* 常规变量 */
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 2px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  /* 兼容旧变量：主色直接引用品牌主色阶 */
  --primary: var(--p-main);
  --primary-hover: var(--p-hover);
  --primary-inverse: #fff;
  /* Modal 业务变量引用色阶 */
  --modal-background: var(--s-1);
  --modal-border: var(--input-border);
  --modal-text: var(--c-22);
  --modal-text-secondary: var(--c-66);
  --modal-error: var(--p-main);
  --modal-required: #f53f3f;
  --modal-success: #68cd52;
  --modal-button-background: var(--p-main);
  --modal-button-text: var(--c-ff);
  --modal-input-background: var(--input-bg-base);
  --modal-check-color: var(--p-main);
  --background-color: var(--c-ff);
  --background-light-green: var(--s-1-weak, #f5f7f9);
  --text-black-2: var(--c-22);
  --text-gray-2: var(--c-22);
  --text-gray-6: var(--c-66);
  --text-gray-9: var(--c-99);
  --text-gray-c2: var(--c-c7);
  --switch-background-color: var(--c-c7, hsl(205deg, 16%, 77%));
  --float-ball-more-button-border-color: var(--c-f5, #f6f6f6);
  --float-ball-more-button-background-color: var(--c-ff);
  --float-ball-more-button-svg-color: #6c6f73;
  --service-bg-hover: var(--s-1-hover, #f7faff);
  --service-bg: var(--s-1-weak, #fafbfb);
  line-height: var(--line-height);
  font-family: var(--font-family);
  font-size: var(--font-size);
}

@media (max-width: 480px) {
  :root,
  #mount {
    --f-12: 10px;
    --f-14: 12px;
    --f-15: 13px;
    --f-16: 14px;
    --f-18: 16px;
    --f-20: 18px;
    --space-4: 4px;
    --space-6: 4px;
    --space-8: 6px;
    --space-12: 8px;
    --space-16: 12px;
    --space-18: 14px;
    --space-24: 18px;
    --radius-8: 6px;
    --radius-12: 10px;
    --radius-16: 12px;
    --control-height-lg: 38px;
    --shadow-lg: 0 12px 32px rgba(0, 0, 0, 0.1);
    --width-28: 24px;
    --width-24: 20px;
    --width-20: 16px;
    --width-18: 14px;
    --width-16: 12px;
    --width-label-md: 52px;
  }
}

#mount * {
  box-sizing: border-box;
}

[hidden] {
  display: none !important;
}

:where(#mount) a,
:where(#mount) [role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
:where(#mount) a:is([aria-current], :hover, :active, :focus),
:where(#mount) [role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}

:where(#mount) label {
  font-size: 13px;
  line-height: 1.3;
  color: var(--text-gray-2, #222222);
}

:where(#mount) button {
  width: 100%;
  font-family: inherit;
  font-size: 15px;
  line-height: 1.3;
  min-height: 44px;
  border-radius: 12px;
  padding: 0 14px;
  border: none;
  background-color: var(--primary, #ea4c89);
  color: #ffffff;
  cursor: pointer;
  transition: background-color 0.2s ease, box-shadow 0.2s ease, color 0.2s ease;
}

:where(#mount) button:hover {
  background-color: var(--primary-hover, #f082ac);
}

:where(#mount) button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

:where(#mount) select,
:where(#mount) input,
:where(#mount) textarea {
  font-family: inherit;
  color: var(--text-gray-2, #222222);
}

:where(#mount) select {
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  font-family: inherit;
  color: var(--text-gray-2, inherit);
  font-size: 13px;
  line-height: 1.3;
  outline: none;
  padding: 8px 16px;
  border: none;
  border-radius: 12px;
  background-color: var(--popup-item-background-color, transparent);
  background-image: var(--icon-xia, none);
  background-repeat: no-repeat;
  background-position: center right 12px;
  background-size: 16px auto;
  cursor: pointer;
}

:where(#mount) input[type="checkbox"] {
  accent-color: var(--primary, #ea4c89);
}

[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

:where(#mount) [type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
:where(#mount) [type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
:where(#mount) [type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
:where(#mount) [type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
:where(#mount) [type="checkbox"][role="switch"]:checked {
  background-image: none;
}
:where(#mount) [type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

:where(#mount) [type="checkbox"][aria-invalid="false"],
:where(#mount) [type="checkbox"]:checked[aria-invalid="false"],
:where(#mount) [type="radio"][aria-invalid="false"],
:where(#mount) [type="radio"]:checked[aria-invalid="false"],
:where(#mount) [type="checkbox"][role="switch"][aria-invalid="false"],
:where(#mount) [type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(#mount) [type="checkbox"][aria-invalid="true"],
:where(#mount) [type="checkbox"]:checked[aria-invalid="true"],
:where(#mount) [type="radio"][aria-invalid="true"],
:where(#mount) [type="radio"]:checked[aria-invalid="true"],
:where(#mount) [type="checkbox"][role="switch"][aria-invalid="true"],
:where(#mount) [type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

.text-black {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.inline-flex {
  display: inline-flex;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

#mount {
  min-width: 268px;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}



.activity-tips {
  border-radius: 8px;
  padding: 0px 8px;
  min-height: 28px;
  background: linear-gradient(83deg, #FACCDE -0.87%, #FCE7EF 43.13%, #FBD6E4 72.08%, #FFB3D1 96.34%);  gap: 2px;
  color: #333;
  cursor: pointer;
  gap: 4px;
}

.activity-tips-icon {
  width: 18px;
  height: 18px;
  flex-shrink: 0;
}

.countdown-container {
  min-width: 50px;
  text-align: left;
  font-weight: 600;
  font-size: 12px;
  letter-spacing: 0.01em;
}

.activity-tips-text {
  font-weight: 600;
  max-width: 100px;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 100%;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #b3b3b3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 261px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg></div></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; top: 261px; right: 65px;"></div></div></div></div></template></div></html>