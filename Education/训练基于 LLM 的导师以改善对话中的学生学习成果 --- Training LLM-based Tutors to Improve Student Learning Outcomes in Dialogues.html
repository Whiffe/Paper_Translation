<!DOCTYPE html>
<!-- saved from url=(0033)https://arxiv.org/html/2503.06424 -->
<html lang="en" data-theme="dark" imt-state="dual" imt-trans-position="after"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues</title>
<!--Generated on Mon Jul 28 19:20:03 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on  %Uncomment␣to␣remove␣the␣date .-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/ar5iv.0.8.2.min.css" rel="stylesheet" type="text/css">
<link href="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/ar5iv-fonts.0.8.2.min.css" rel="stylesheet" type="text/css">
<link href="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/latexml_styles.0.8.2.css" rel="stylesheet" type="text/css">
<script src="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/bootstrap.bundle.min.js"></script>
<script src="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/html2canvas.min.js"></script>
<script src="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/addons_new.js"></script>
<script src="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/feedbackOverlay.js"></script>
<!--<base href="/html/2503.06424v2/">--><base href="."><link rel="stylesheet" href="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-modal {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style><style data-id="immersive-translate-default-injected-css">:root {
  --immersive-translate-theme-underline-borderColor: #72ece9;
  --immersive-translate-theme-nativeUnderline-borderColor: #72ece9;
  --immersive-translate-theme-nativeDashed-borderColor: #72ece9;
  --immersive-translate-theme-nativeDotted-borderColor: #72ece9;
  --immersive-translate-theme-highlight-backgroundColor: #ffff00;
  --immersive-translate-theme-dashed-borderColor: #59c1bd;
  --immersive-translate-theme-blockquote-borderColor: #cc3355;
  --immersive-translate-theme-thinDashed-borderColor: #ff374f;
  --immersive-translate-theme-dashedBorder-borderColor: #94a3b8;
  --immersive-translate-theme-dashedBorder-borderRadius: 0;
  --immersive-translate-theme-solidBorder-borderColor: #94a3b8;
  --immersive-translate-theme-solidBorder-borderRadius: 0;
  --immersive-translate-theme-dotted-borderColor: #94a3b8;
  --immersive-translate-theme-wavy-borderColor: #72ece9;
  --immersive-translate-theme-dividingLine-borderColor: #94a3b8;
  --immersive-translate-theme-grey-textColor: #2f4f4f;
  --immersive-translate-theme-marker-backgroundColor: #fbda41;
  --immersive-translate-theme-marker-backgroundColor-rgb: 251, 218, 65;
  --immersive-translate-theme-marker2-backgroundColor: #ffff00;
  --immersive-translate-theme-background-backgroundColor: #dbafaf;
  --immersive-translate-theme-background-backgroundColor-rgb: 219, 175, 175;
  --immersive-translate-theme-background-backgroundOpacity: 12;
  --immersive-translate-theme-opacity-opacity: 10;
}

[imt-state="dual"] .immersive-translate-target-translation-pre-whitespace {
  white-space: pre-wrap !important;
}

[imt-state="dual"] .immersive-translate-pdf-target-container {
  position: absolute;
  background-color: #fff;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica,
    sans-serif;
  top: 0;
  width: 600px;
  height: 100%;
  z-index: 2;
  line-height: 1.3;
  font-size: 16px;
}
[imt-state="dual"] .immersive-translate-target-wrapper[dir="rtl"] {
  text-align: right;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper {
  color: rgb(0, 0, 0);
  white-space: normal;
  position: absolute;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper
  font {
  color: inherit;
  white-space: inherit;
  position: unset;
}

[imt-state="translation"] .immersive-translate-target-wrapper > br {
  display: none;
}

[imt-state="translation"]
  .immersive-translate-target-translation-block-wrapper {
  margin: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-block-wrapper {
  margin: 8px 0 !important;
  display: inline-block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  display: block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  margin-top: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-pdf-block-wrapper {
  margin: 0 !important;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-grey-inner {
  color: var(--immersive-translate-theme-grey-textColor);
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-underline-inner {
  border-bottom: 1px solid
    var(--immersive-translate-theme-underline-borderColor) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeUnderline-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeUnderline-borderColor
  ) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDashed-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDashed-borderColor
  ) !important;
  text-decoration-style: dashed !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-thinDashed-inner {
  border-bottom: 1px dashed
    var(--immersive-translate-theme-thinDashed-borderColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dotted-inner {
  background-image: linear-gradient(
    to right,
    var(--immersive-translate-theme-dotted-borderColor) 30%,
    rgba(255, 255, 255, 0) 0%
  );
  background-position: bottom;
  background-size: 5px 1px;
  background-repeat: repeat-x;
  padding-bottom: 3px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDotted-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDotted-borderColor
  ) !important;
  text-decoration-style: dotted !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-wavy-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-wavy-borderColor
  ) !important;
  text-decoration-style: wavy !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dashed-inner {
  background: linear-gradient(
      to right,
      var(--immersive-translate-theme-dashed-borderColor) 0%,
      var(--immersive-translate-theme-dashed-borderColor) 50%,
      transparent 50%,
      transparent 100%
    )
    repeat-x left bottom;
  background-size: 8px 2px;
  padding-bottom: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {
  content: "";
  display: block;
  max-width: 80px;
  width: 10%;
  border-top: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  padding-top: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dividingLine::before {
  content: "";
  border-left: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  max-height: 16px;
  height: 16px;
  padding-left: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-highlight-inner {
  background: var(--immersive-translate-theme-highlight-backgroundColor);
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-marker {
  line-height: 1.5em;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker2-inner {
  font-weight: bold;
  text-shadow: 10px 0px 3px
      var(--immersive-translate-theme-marker2-backgroundColor),
    16px 3px 9px var(--immersive-translate-theme-marker2-backgroundColor),
    2px 0px 6px var(--immersive-translate-theme-marker2-backgroundColor),
    -12px 0px 12px var(--immersive-translate-theme-marker2-backgroundColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker-inner {
  /* TODO: add more texture */
  background: linear-gradient(
    to right,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.1),
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 3%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 35%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 70%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.8) 95%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.3)
  );
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-weakening {
  opacity: 0.618 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-italic {
  font-style: italic !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-bold {
  font-weight: bold !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-paper {
  margin: 8px 0;
  box-shadow: rgba(0, 0, 0, 0.24) 0px 3px 8px;
  padding: 16px 32px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-blockquote {
  border-left: 4px solid var(--immersive-translate-theme-blockquote-borderColor) !important;
  padding-left: 12px !important;
  margin-top: 4px;
  margin-bottom: 4px;
  padding-top: 4px;
  padding-bottom: 4px;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-mask-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-mask-inner {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

/* opacity theme start */

[imt-state="dual"] .immersive-translate-target-translation-theme-opacity-inner {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-opacity-inner {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner,
[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: none !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-mask-inner:hover {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

/* opacity theme end */

/* background theme start */
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-background {
  margin: 8px 0;
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  border-radius: 4px;
  box-shadow: unset !important;
  padding: 12px;
  display: inline-block;
}
[imt-state="dual"]
  .immersive-translate-target-translation-theme-background-inner {
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  padding-left: 6px;
  padding-right: 6px;
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper
  .immersive-translate-target-translation-theme-background-inner {
  background: unset;
  padding-left: unset;
  padding-right: unset;
}
/* background theme end */

/* vertical css , please remain it in the last one. */
.immersive-translate-target-translation-vertical-block-wrapper {
  margin: 0px 8px !important;
}

.immersive-translate-text {
  font-size: 15px !important;
}

.immersive-translate-error-toast {
  position: fixed;
  top: 5%;
  z-index: 99999999;
  left: 0;
  right: 0;
  margin: auto;
  max-width: 300px;
  padding: 16px;
  border-radius: 12px;
  background-color: rgba(0, 0, 0, 0.8);
  display: flex;
  flex-direction: row;
  justify-content: space-between;
}

@media all and (min-width: 750px) {
  .immersive-translate-error-toast {
    max-width: 400px;
  }
}

.immersive-translate-clickable-button {
  cursor: pointer;
}

.immersive-translate-help-button {
  cursor: pointer;
}

.immersive-translate-loading-text:before {
  content: "...";
}

/* dark mode for loading */

@media only screen and (prefers-color-scheme: dark) {
  .immersive-translate-loading {
    border: 2px rgba(255, 255, 255, 0.25) solid !important;
    border-top: 2px rgba(255, 255, 255, 1) solid !important;
  }
}

.immersive-translate-error-wrapper {
  position: relative;
  display: inline-flex;
  padding: 6px;
  margin: 0 12px;
  white-space: nowrap;
  font-size: 0.9em;
}
[lang="zh-CN"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}
[lang="zh-TW"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}

.immersive-translate-tooltip {
  position: relative;
  display: inline-flex;
  /* little indicater to indicate it's hoverable */
}

.immersive-translate-tooltip-content {
  /* here's the magic */
  position: absolute;
  z-index: 100000000000;

  left: 50%;
  bottom: 0;
  transform: translate(-50%, 110%);
  line-height: 1;
  /* and add a small left margin */

  /* basic styles */
  width: max-content;
  max-width: 250px;
  word-wrap: break-word;
  white-space: pre-line;
  padding: 10px;
  border-radius: 10px;
  background: #000c;
  color: #fff;
  text-align: center;
  font-size: 14px;
  display: none;
  /* hide by default */
}

.immersive-translate-tooltip:hover .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip:hover + .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip-content-table {
  left: unset !important;
  bottom: unset !important;
  transform: translate(-10%, 50%) !important;
}

.immersive-translate-tooltip:hover:before {
  display: inline-block;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5);
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--bg-2, #fff);
  font-size: 14px;
}
</style><style data-id="immersive-translate-user-custom-style">:root {

.immersive-translate-target-inner { font-family: inherit; }


.immersive-translate-target-inner { font-family: inherit; }
}
</style><style data-id="immersive-translate-dynamic-injected-css">.immersive-translate-target-wrapper[dir='rtl'] {text-align: right;display:block!important;}
[dir='rtl'] .immersive-translate-target-wrapper:not([dir]) {text-align:left;direction:ltr;}
.immersive-translate-target-wrapper {word-break:break-word; user-select:text;}
[imt-state=dual] .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {display:block;}
[imt-trans-position=before] .immersive-translate-target-translation-block-wrapper {display:block!important;}
</style></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2503.06424">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2503.06424v2/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2503.06424v2">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2503.06424v2" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2503.06424#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S1" title="In Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S1.SS1" title="In 1 Introduction ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Contributions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S2" title="In Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S2.SS0.SSS0.Px1" title="In 2 Related Work ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title">AI Tutors in Dialogues</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S2.SS0.SSS0.Px2" title="In 2 Related Work ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title">Student Outcome Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S2.SS0.SSS0.Px3" title="In 2 Related Work ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title">Evaluating Pedagogical Quality of LLMs</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3" title="In Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.SS1" title="In 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Student Outcome Prediction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.SS2" title="In 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Following Pedagogical Principles</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.SS3" title="In 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Preference Pair Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.SS4" title="In 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Model Training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S4" title="In Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Settings</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S4.SS1" title="In 4 Experimental Settings ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S4.SS2" title="In 4 Experimental Settings ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S4.SS3" title="In 4 Experimental Settings ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Automated Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S4.SS4" title="In 4 Experimental Settings ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Model Parameters</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5" title="In Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5.SS1" title="In 5 Experimental Results ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Quantitative Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5.SS2" title="In 5 Experimental Results ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Qualitative Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5.SS3" title="In 5 Experimental Results ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Human Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S6" title="In Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusions and Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2503.06424#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">许可证：CC BY 4.0</font></font></font></a><div id="watermark-tr" data-imt_insert_failed="1">arXiv:2503.06424v2 [cs.CL] 28 Jul 2025</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">训练基于 LLM 的导师以改善对话中的学生学习成果</font></font></font></h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Alexander Scarlatos
<br class="ltx_break">University of Massachusetts Amherst
<br class="ltx_break">ajscarlatos@cs.umass.edu
<br class="ltx_break">&amp;Naiming Liu
<br class="ltx_break">Rice University
<br class="ltx_break">nl35@rice.edu
<br class="ltx_break">&amp;Jaewook Lee
<br class="ltx_break">University of Massachusetts Amherst
<br class="ltx_break">jaewooklee@cs.umass.edu
<br class="ltx_break">&amp;Richard Baraniuk
<br class="ltx_break">Rice University
<br class="ltx_break">richb@rice.edu
<br class="ltx_break">&amp;Andrew Lan
<br class="ltx_break">University of Massachusetts Amherst
<br class="ltx_break">andrewlan@cs.umass.edu
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">摘要</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p">Generative artificial intelligence (AI) has the potential to scale up personalized tutoring through large language models (LLMs). Recent AI tutors are adapted for the tutoring task by training or prompting LLMs to follow effective pedagogical principles, though they are not trained to maximize student learning throughout the course of a dialogue. Therefore, they may engage with students in a suboptimal way. We address this limitation by introducing an approach to train LLMs to generate tutor utterances that maximize the likelihood of student correctness, while still encouraging the model to follow good pedagogical practice. Specifically, we generate a set of candidate tutor utterances and score them using (1) an LLM-based student model to predict the chance of correct student responses and (2) a pedagogical rubric evaluated by GPT-4o. We then use the resulting data to train an open-source LLM, Llama 3.1 8B, using direct preference optimization. We show that tutor utterances generated by our model lead to significantly higher chances of correct student responses while maintaining the pedagogical quality of GPT-4o. We also conduct qualitative analyses and a human evaluation to demonstrate that our model generates high quality tutor utterances.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our code is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/umass-ml4ed/tutorbot-dpo" title="">https://github.com/umass-ml4ed/tutorbot-dpo</a><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的代码可在 https://github.com/umass-ml4ed/tutorbot-dpo 获取。</font></font></font></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">生成式人工智能（AI）通过大型语言模型（LLMs）具有提升个性化辅导的潜力。最新的 AI 辅导系统通过训练或提示 LLMs 遵循有效的教学原则来适应辅导任务，尽管它们并未在整个对话过程中训练以最大化学生的学习效果。因此，它们可能与学生以次优的方式互动。我们通过引入一种训练 LLMs 生成辅导话语的方法来解决这个问题，该方法旨在最大化学生正确回答的可能性，同时仍鼓励模型遵循良好的教学实践。具体而言，我们生成一组候选辅导话语，并使用（1）基于 LLMs 的学生模型来预测学生正确回答的概率，以及（2）由 GPT-4o 评估的教学评分标准来评分这些话语。然后，我们使用这些数据通过直接偏好优化方法训练开源 LLM Llama 3.1 8B。我们证明，我们模型生成的辅导话语显著提高了学生正确回答的概率，同时保持了 GPT-4o 的教学质量。 我们也进行了定性分析和人工评估，以证明我们的模型能够生成高质量的导师话语。 <sup class="ltx_note_mark">1</sup> </font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p"><em class="ltx_emph ltx_font_bold ltx_font_italic">Keywords</em> Large Language Models &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p1.m1"><semantics><mo>⋅</mo><annotation encoding="application/x-tex">\cdot</annotation><annotation encoding="application/x-llamapun">⋅</annotation></semantics></math>
Math Education &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p1.m2"><semantics><mo>⋅</mo><annotation encoding="application/x-tex">\cdot</annotation><annotation encoding="application/x-llamapun">⋅</annotation></semantics></math>
Reinforcement Learning &nbsp;<math alttext="\cdot" class="ltx_Math" display="inline" id="p1.m3"><semantics><mo>⋅</mo><annotation encoding="application/x-tex">\cdot</annotation><annotation encoding="application/x-llamapun">⋅</annotation></semantics></math>
Tutor-Student Dialogues.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">关键词 大型语言模型 <math id="p1.m1" display="inline" class="ltx_Math" alttext="\cdot"><semantics><mo>⋅</mo><annotation encoding="application/x-tex">\cdot</annotation><annotation encoding="application/x-llamapun">⋅</annotation></semantics></math> 数学教育 <math id="p1.m2" display="inline" class="ltx_Math" alttext="\cdot"><semantics><mo>⋅</mo><annotation encoding="application/x-tex">\cdot</annotation><annotation encoding="application/x-llamapun">⋅</annotation></semantics></math> 强化学习 <math id="p1.m3" display="inline" class="ltx_Math" alttext="\cdot"><semantics><mo>⋅</mo><annotation encoding="application/x-tex">\cdot</annotation><annotation encoding="application/x-llamapun">⋅</annotation></semantics></math> 导师-学生对话。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1 引言</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p">Recent advances in generative artificial intelligence (AI), including large language models (LLMs), have opened new possibilities in education and in particular on scaling up personalization. One form of personalization that generative AI powers is interactive learning via <em class="ltx_emph ltx_font_italic">tutoring dialogues</em> between AI-powered tutors and students. These interactions have the potential to tailor instruction to each student’s needs and progress, while offering personalized feedback, all in real time, in a scalable way.
Given the widespread success of human tutors for improving student outcomes&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib30" title="">30</a>]</cite>, many recent works have developed LLM-based tutors, showing promise across various educational domains&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib34" title="">34</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib43" title="">43</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib51" title="">51</a>]</cite>. Many LLM-based tutors are even deployed in practice, such as Khan Academy’s Khanmigo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib22" title="">22</a>]</cite> and Carnegie Learning’s LiveHint <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib4" title="">4</a>]</cite>.
Several preliminary studies have shown that interacting with LLMs can increase student learning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib53" title="">53</a>]</cite>, although some have shown that students can develop an over-reliance on LLMs which negatively impacts their learning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib24" title="">24</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">生成式人工智能（AI）的最新进展，包括大型语言模型（LLMs），为教育领域，特别是个性化扩展，开辟了新的可能性。生成式 AI 支持的一种个性化形式是通过 AI 助教与学生之间的辅导对话进行互动学习。这些互动有可能根据每个学生的需求和进步量身定制教学，同时提供个性化的实时反馈，并以可扩展的方式实现。鉴于人类助教在提高学生成果方面取得的广泛成功[30]，许多近期研究开发了基于 LLM 的助教，并在各个教育领域显示出潜力[15, 26, 31, 33, 34, 40, 43, 51]。许多基于 LLM 的助教甚至已在实践中部署，例如可汗学院的 Khanmigo[22]和卡内基学习的 LiveHint[4]。一些初步研究表明，与 LLMs 互动可以提高学生的学习效果[53]，尽管也有一些研究表明，学生可能对 LLMs 产生过度依赖，从而对他们的学习产生负面影响[24]。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p">Many prior works have focused on improving LLMs’ ability to follow effective tutoring principles, adapting them for the tutoring task that they are not pre-trained for. One approach, explored in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib47" title="">47</a>]</cite>, analyzes the decision-making process underlying human tutor utterances, showing that integrating expert decisions enhances LLM-based tutoring. Another study, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib29" title="">29</a>]</cite>, examines tutor moves in interactions with an LLM-powered simulated student agent, demonstrating that move annotation data contributes to better tutoring performance. Similarly, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib45" title="">45</a>]</cite> investigates the role of AI roleplay in generating synthetic tutoring data and finds that fine-tuning LLMs on this data, along with human tutor-student interactions, significantly improves their pedagogical effectiveness. Moreover, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib9" title="">9</a>]</cite> introduces the concept of tutor uptake—acknowledging student responses—as a valuable strategy for LLMs to adopt.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">许多先前研究都集中于提升 LLMs 遵循有效辅导原则的能力，将它们应用于未经预训练的辅导任务。一种方法，在[47]中探讨，分析了人类辅导者话语背后的决策过程，表明整合专家决策能够增强基于 LLM 的辅导。另一项研究，[29]，考察了与 LLM 驱动的模拟学生代理互动中的辅导者行为，证明行为标注数据有助于提升辅导性能。类似地，[45]研究了 AI 角色扮演在生成合成辅导数据中的作用，发现基于这些数据以及人类辅导者与学生的互动对 LLMs 进行微调，能显著提升其教学效果。此外，[9]引入了辅导者采纳的概念——认可学生回应——作为 LLMs 可以采用的一种有价值策略。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p">While these efforts offer valuable insights into how LLMs can emulate effective human tutoring strategies, the question remains whether such approaches truly maximize student learning outcomes.
Rather, a data-driven approach, where student outcomes form a reward signal, could potentially lead to AI tutors that are more aligned with educational goals. Additionally, current approaches often rely on large proprietary LLMs, coming with many downsides; they are not fully controllable and cannot be easily customized, can be costly to use, and relinquish control of private student data.
Therefore, developing effective AI tutors with smaller, open-source LLMs remains an important goal.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管这些努力为 LLMs 如何模仿有效的人类辅导策略提供了宝贵的见解，但问题仍然存在：这些方法是否真的能最大化学生的学习成果。相反，一种以学生成果作为奖励信号的数据驱动方法，有可能导致与教育目标更一致的 AI 辅导。此外，当前的方法通常依赖于大型专有 LLMs，这带来了许多弊端；它们无法完全控制，也不易于定制，使用成本高昂，并且放弃了学生私人数据的控制权。因此，使用更小、开源的 LLMs 开发有效的 AI 辅导仍然是一个重要的目标。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Contributions<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1.1 贡献</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.SS1.p1">
<p class="ltx_p">In this paper, we propose a novel approach to train a small, open-source LLM to not only follow effective pedagogical principles, but directly optimize for student learning outcomes. Our method performs three key steps. First, at each dialogue turn, we gather multiple candidate tutor utterances from a variety of sources, including human tutors and LLMs with varying styles and sizes. Second, we evaluate each candidate utterance on two aspects: (1) whether it elicits a correct response in the next student turn, using a trained student model for dialogues to predict student behavior, and (2) whether it adheres to a set of effective pedagogical principles, using GPT-4o in a LLM-as-a-judge evaluation setup.
Third, we contrast good candidate utterances with poor ones, and fine-tune Llama 3.1 8B&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib10" title="">10</a>]</cite> with offline Reinforcement Learning (RL), specifically Direct Preference Optimization (DPO)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib36" title="">36</a>]</cite>.
We demonstrate that our optimized LLM tutor significantly increases the likelihood of next turn student response correctness, while reaching comparable pedagogical quality to that of a much larger, proprietary LLM, GPT-4o&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib32" title="">32</a>]</cite>. Through qualitative analysis and human evaluation, we confirm that our approach produces high-quality tutor utterances and reveal emergent tutoring strategies that arise from our training approach.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本文中，我们提出了一种新颖的方法来训练一个小型开源 LLM，使其不仅遵循有效的教学原则，而且直接优化学生学习成果。我们的方法执行三个关键步骤。首先，在每个对话回合中，我们从各种来源收集多个候选导师话语，包括人类导师和具有不同风格和大小的 LLM。其次，我们从两个方面评估每个候选话语：(1) 它是否能在下一个学生回合中引出正确回答，使用训练好的对话学生模型来预测学生行为，以及(2) 它是否遵循一套有效的教学原则，使用在 LLM 作为裁判评估设置中的 GPT-4o。第三，我们将好的候选话语与差的表现进行对比，并使用离线强化学习（RL），特别是直接偏好优化（DPO）对 Llama 3.1 8B [10]进行微调。我们证明，我们优化的 LLM 导师显著增加了下一个回合学生回答正确性的可能性，同时达到了与一个远大的专有 LLM GPT-4o [32]相当的教学质量。 通过定性分析和人工评估，我们证实了我们的方法能够生成高质量的导师话语，并揭示了由我们的训练方法产生的涌现式辅导策略。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS1.p2">
<p class="ltx_p">We acknowledge up front that the most significant limitation of our work is that we do not experiment with real students. Since access to students at the scale necessary for our work is beyond our capability, we use a simulated student model instead. While we believe that our work is a reasonable starting point to train LLM-based tutors to maximize student outcomes, future work with real students in the loop is highly important. Therefore, to facilitate further research, we publicly release our code and encourage researchers and practitioners with access to real-world tutoring dialogue settings to build on our work.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们首先承认我们工作的最大局限性在于我们没有与真实学生进行实验。由于获取我们工作所需规模的学生资源超出了我们的能力范围，我们使用了一个模拟学生模型。虽然我们相信我们的工作是一个合理的起点，用于训练基于 LLM 的导师以最大化学生成果，但未来在真实学生参与下的工作非常重要。因此，为了促进进一步研究，我们公开发布了我们的代码，并鼓励能够接触到真实辅导对话环境的 researchers 和 practitioners 基于我们的工作进行开发。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2 相关工作</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">AI Tutors in Dialogues<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对话中的 AI 导师</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p">There is a long history of AI-based tutors in education that interact with students through dialogues. Early systems, such as Cognitive Tutors, construct cognitive models of students to provide targeted feedback&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib1" title="">1</a>]</cite>. AutoTutor engages students by asking targeted questions, and assesses student correctness using latent semantic analysis&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib14" title="">14</a>]</cite>. Why2-Atlas converts a student response to a proof, which it uses to identify misconceptions and guide a dialogue&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib46" title="">46</a>]</cite>.
While these systems were often effective for improving student learning, they required significant engineering and had limited flexibility. In contrast, recent LLM tutors can more easily adapt to new contexts, interpret student responses, and cater personalized content towards the student. Several LLM tutors are implemented through refined prompt engineering&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib22" title="">22</a>]</cite>, with some taking on specialized roles such as teachable agents&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib40" title="">40</a>]</cite> or “co-pilots” for human tutors&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib48" title="">48</a>]</cite>. Other works fine-tune LLM tutors to enhance the pedagogical capabilities over the base models. A common approach is to generate simulated dialogues, where the tutor utterances are constructed to follow good pedagogical practice, and fine-tune on those&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib45" title="">45</a>]</cite>. Several works also generate examples of low quality tutor utterances and use them as negative samples in DPO training to improve over fine-tuning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib42" title="">42</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在教育领域，基于 AI 的对话式辅导系统有着悠久的历史。早期的系统，如认知导师（Cognitive Tutors），通过构建学生的认知模型来提供针对性反馈[1]。AutoTutor 通过提出针对性问题来吸引学生，并使用潜在语义分析评估学生的正确性[14]。Why2-Atlas 将学生的回答转换为证明，并利用它来识别误解和引导对话[46]。虽然这些系统通常能有效提高学生的学习效果，但它们需要大量的工程工作，且灵活性有限。相比之下，最新的基于 LLM 的辅导系统能更轻松地适应新环境，解读学生回答，并向学生提供个性化内容。一些 LLM 辅导系统通过精细的提示工程来实现[22]，其中一些承担了专门角色，如可教学的代理（teachable agents）[40]或人类导师的“副驾驶”[48]。其他研究则通过微调 LLM 辅导系统来增强其教学能力，超越基础模型。 一种常见的方法是生成模拟对话，其中导师的语句构建遵循良好的教学实践，并在这些对话上进行微调[41, 45]。一些研究还生成低质量的导师语句示例，并将它们用作 DPO 训练中的负样本，以改进微调效果[2, 42]。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Student Outcome Modeling<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">学生结果建模</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p">While there are many ways of measuring student outcomes, in this work we focus on the well-studied setting of <span class="ltx_text ltx_font_italic">next item correctness</span>. Student modeling in this setting is typically handled by knowledge tracing (KT), where a binary correctness is predicted for the next item a student attempts based on the student’s history so far <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib7" title="">7</a>]</cite>. KT models have used recurrent neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib35" title="">35</a>]</cite>, self-attention networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib13" title="">13</a>]</cite>, and, more recently, LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib28" title="">28</a>]</cite>. A recent work introduces LLMKT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib38" title="">38</a>]</cite>, an LLM-based model that predicts <span class="ltx_text ltx_font_italic">next turn</span> student correctness in dialogues. Therefore, we leverage LLMKT to predict student outcomes in this work. Similar to our work, prior works have used RL to discover teaching policies with rewards derived from student models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib37" title="">37</a>]</cite>, including KT-based student models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib3" title="">3</a>]</cite>. Another recent work used LLM estimates of student post-test scores to refine math worksheets <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib16" title="">16</a>]</cite>. However, to the best of our knowledge, ours is the first to do so in the context of tutoring dialogues.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">虽然衡量学生成果的方法有很多，但在本研究中我们专注于研究较为成熟的下一项正确性设置。在这种设置下，学生建模通常由知识追踪（KT）处理，根据学生迄今为止的历史记录预测其尝试的下一项的正确性[7]。KT 模型使用了循环神经网络[35]、自注意力网络[13]，以及最近使用的 LLM[8,28]。最近的一项工作引入了 LLMKT[38]，这是一个基于 LLM 的模型，用于预测对话中学生的下一轮正确性。因此，我们利用 LLMKT 来预测本工作中的学生成果。类似于我们的工作，先前的研究已经使用强化学习（RL）来发现具有基于学生模型（包括基于 KT 的学生模型[3]）的奖励的教学策略[17,37]。另一项最近的工作使用了 LLM 估计的学生测试后分数来改进数学练习题[16]。然而，据我们所知，我们首次在辅导对话的背景下进行这项工作。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Evaluating Pedagogical Quality of LLMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">评估 LLM 的教学质量</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p">To validate LLM tutors, we need to be able to evaluate them along pedagogical measures.
Typically, researchers construct a pedagogical <span class="ltx_text ltx_font_italic">rubric</span>, which defines multiple properties that tutor utterances should follow. Rubric-based evaluation of generated utterances is then performed by human experts <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib45" title="">45</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib47" title="">47</a>]</cite> or by LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib39" title="">39</a>]</cite>. In this work, we design a pedagogical rubric and primarily use LLMs to evaluate tutor utterances, but also humans at a smaller scale to ensure our results are reliable. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib39" title="">39</a>]</cite>, we also use LLM-assigned rubric scores to form DPO preference pairs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了验证 LLM 助教，我们需要能够根据教学指标对其进行评估。通常，研究人员会构建一个教学评估标准，该标准定义了助教话语应遵循的多个属性。然后由人类专家[19, 45, 47]或 LLMs[20, 39]对生成的话语进行基于标准的评估。在这项工作中，我们设计了一个教学评估标准，主要使用 LLMs 来评估助教话语，但也以小规模使用人类来确保我们的结果可靠。与[39]类似，我们也使用 LLM 分配的评估标准分数来形成 DPO 偏好对。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3 方法</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p">We now detail our methodology to generate tutor dialogue utterances to maximize student learning outcomes. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.F1" title="Figure 1 ‣ 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">1</span></a> shows an overview of our approach with an example, where the problem is from the MathDial&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib29" title="">29</a>]</cite> dataset.
In this scenario, a student has a misconception, missing the “twice” part of the problem, and provides an incorrect answer.
We generate multiple, diverse candidate versions of the next tutor utterance to follow the student’s response, using a collection of LLMs with different sizes and styles.
Then, among the generated utterances and the human tutor utterance, we construct preference pairs to fine-tune an LLM using DPO. We consider an utterance to be preferred if it (1) likely elicits a correct student response and (2) follows good pedagogical principles. The former criterion employs a student model, LLMKT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib38" title="">38</a>]</cite>, to predict whether the student will correctly respond to the tutor in their next turn. The latter criterion employs a set of rubric items to evaluate whether a tutor utterance follows good pedagogical principles.
Before detailing each component, we define some key notations: a dialogue
<math alttext="d" class="ltx_Math" display="inline" id="S3.p1.m1"><semantics><mi>d</mi><annotation encoding="application/x-tex">d</annotation><annotation encoding="application/x-llamapun">italic_d</annotation></semantics></math> consists of an alternating sequence of tutor and student turns, <math alttext="d=(t_{1},s_{1},\ldots,t_{M},s_{M})" class="ltx_Math" display="inline" id="S3.p1.m2"><semantics><mrow><mi>d</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msub><mi>t</mi><mn>1</mn></msub><mo>,</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>t</mi><mi>M</mi></msub><mo>,</mo><msub><mi>s</mi><mi>M</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">d=(t_{1},s_{1},\ldots,t_{M},s_{M})</annotation><annotation encoding="application/x-llamapun">italic_d = ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_t start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT )</annotation></semantics></math>, where <math alttext="M" class="ltx_Math" display="inline" id="S3.p1.m3"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation><annotation encoding="application/x-llamapun">italic_M</annotation></semantics></math> is the number of turn pairs, indexed by <math alttext="m" class="ltx_Math" display="inline" id="S3.p1.m4"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation><annotation encoding="application/x-llamapun">italic_m</annotation></semantics></math>, and the textual content of each turn is the “utterance”.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们现在详细阐述生成导师对话语句的方法，以最大化学生的学习成果。图 1 展示了我们的方法概述，并附带一个示例，该问题来自 MathDial [ 29]数据集。在这个场景中，学生存在误解，遗漏了问题中的“两倍”部分，并给出了错误答案。我们使用不同大小和风格的 LLM 集合生成多个、多样化的候选版本作为下一个导师语句，以跟随学生的回应。然后，在生成的语句和人类导师语句之间，我们构建偏好对，使用 DPO 微调 LLM。我们认为如果语句（1）可能引出学生的正确回应，并且（2）遵循良好的教学原则，那么该语句就是偏好的。前者标准采用学生模型 LLMKT [ 38]来预测学生是否会在下一轮正确回应导师。后者标准采用一套评分标准来评估导师语句是否遵循良好的教学原则。 在详细说明每个组件之前，我们定义一些关键符号：一个对话 <math id="S3.p1.m1" display="inline" class="ltx_Math" alttext="d"><semantics><mi>d</mi><annotation encoding="application/x-tex">d</annotation><annotation encoding="application/x-llamapun">italic_d</annotation></semantics></math> 由交替的导师和学生的回合 <math id="S3.p1.m2" display="inline" class="ltx_Math" alttext="d=(t_{1},s_{1},\ldots,t_{M},s_{M})"><semantics><mrow><mi>d</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><msub><mi>t</mi><mn>1</mn></msub><mo>,</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>t</mi><mi>M</mi></msub><mo>,</mo><msub><mi>s</mi><mi>M</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">d=(t_{1},s_{1},\ldots,t_{M},s_{M})</annotation><annotation encoding="application/x-llamapun">italic_d = ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_t start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT )</annotation></semantics></math> 组成，其中 <math id="S3.p1.m3" display="inline" class="ltx_Math" alttext="M"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation><annotation encoding="application/x-llamapun">italic_M</annotation></semantics></math> 是回合对的数量，由 <math id="S3.p1.m4" display="inline" class="ltx_Math" alttext="m"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation><annotation encoding="application/x-llamapun">italic_m</annotation></semantics></math> 索引，每个回合的文本内容是“话语”。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="310" id="S3.F1.g1" src="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/tutorbot_overview.jpg" width="479">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of our methodology for training LLMs to generate tutor utterances with the joint objective of maximizing student learning outcomes and following good pedagogical principles. <span class="ltx_text ltx_font_italic">Human tutor</span> refers to tutor utterances in MathDial.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 1：我们训练 LLMs 生成导师话语的方法概述，其联合目标是最大化学生学习成果并遵循良好的教学原则。人类导师指的是 MathDial 中的导师话语。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Student Outcome Prediction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1 学生结果预测</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p">We now detail the model we use for predicting student outcomes in dialogues.
We leverage recent work on knowledge tracing (KT) in dialogues, LLMKT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib38" title="">38</a>]</cite>, an LLM-based model that predicts if a student will respond correctly to a tutor-posed task in their next turn, given dialogue history and the knowledge components (KCs)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib6" title="">6</a>]</cite> embedded in a tutor turn. The model is highly accurate at predicting student correctness, achieving <math alttext="0.76" class="ltx_Math" display="inline" id="S3.SS1.p1.m1"><semantics><mn>0.76</mn><annotation encoding="application/x-tex">0.76</annotation><annotation encoding="application/x-llamapun">0.76</annotation></semantics></math> AUC on the MathDial test set, making it a reliable automated source for estimating student outcomes.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们现在详细说明用于预测对话中学生结果的模型。我们利用了最近在对话知识追踪（KT）方面的研究，LLMKT [38]，这是一个基于 LLM 的模型，它根据对话历史和导师回合中嵌入的知识成分（KCs）[6]，预测学生是否会在其下一次回合中对导师提出的任务做出正确回应。该模型在预测学生正确性方面非常准确，在 MathDial 测试集上达到了 <math id="S3.SS1.p1.m1" display="inline" class="ltx_Math" alttext="0.76"><semantics><mn>0.76</mn><annotation encoding="application/x-tex">0.76</annotation><annotation encoding="application/x-llamapun">0.76</annotation></semantics></math> AUC，使其成为估计学生结果的可靠自动化来源。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p">In LLMKT, at the <math alttext="m" class="ltx_Math" display="inline" id="S3.SS1.p2.m1"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation><annotation encoding="application/x-llamapun">italic_m</annotation></semantics></math>-th dialogue turn for the student, the model analyzes the conversation history <math alttext="t_{\leq m},s_{&lt;m},\mathcal{C}_{m}" class="ltx_Math" display="inline" id="S3.SS1.p2.m2"><semantics><mrow><msub><mi>t</mi><mrow><mi></mi><mo>≤</mo><mi>m</mi></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mi></mi><mo>&lt;</mo><mi>m</mi></mrow></msub><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">t_{\leq m},s_{&lt;m},\mathcal{C}_{m}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUBSCRIPT ≤ italic_m end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT &lt; italic_m end_POSTSUBSCRIPT , caligraphic_C start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>, which denote the tutor utterances up to and including this current turn, prior student turns, and the set of KCs involved in the tutor-posed task in the current turn, respectively. It estimates student knowledge levels on each KC, and combines these estimates to predict whether the student will respond to the tutor-posed task in the current turn correctly. Therefore, we leverage LLMKT as a <em class="ltx_emph ltx_font_italic">student simulator</em> and use it to evaluate whether a generated tutor utterance at a dialogue turn will elicit a correct response from the student.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在 LLMKT 中，当学生在第 <math id="S3.SS1.p2.m1" display="inline" class="ltx_Math" alttext="m"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation><annotation encoding="application/x-llamapun">italic_m</annotation></semantics></math> 轮对话时，模型分析对话历史 <math id="S3.SS1.p2.m2" display="inline" class="ltx_Math" alttext="t_{\leq m},s_{&lt;m},\mathcal{C}_{m}"><semantics><mrow><msub><mi>t</mi><mrow><mi></mi><mo>≤</mo><mi>m</mi></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mi></mi><mo>&lt;</mo><mi>m</mi></mrow></msub><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">t_{\leq m},s_{&lt;m},\mathcal{C}_{m}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUBSCRIPT ≤ italic_m end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT &lt; italic_m end_POSTSUBSCRIPT , caligraphic_C start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> ，其中包含从当前轮次到这一轮次的导师话语、之前的学主话语以及当前轮次导师提出任务中涉及的认知知识（KC）集合。模型估计学生对每个 KC 的知识水平，并将这些估计值结合起来预测学生是否会正确回答当前轮次导师提出的问题。因此，我们利用 LLMKT 作为学生模拟器，并使用它来评估对话轮次中生成的导师话语是否能激发学生给出正确回答。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Following Pedagogical Principles<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2 遵循教学原则</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p">In addition to promoting correct student responses, we also hand-craft a set of rubric items for effective pedagogical principles, listed Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.T1" title="Table 1 ‣ 3.2 Following Pedagogical Principles ‣ 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">1</span></a>. We then employ GPT-4o to assess how well the generated tutor utterances align with the rubric. By incorporating pedagogical evaluation aspects rather than focusing solely on correctness prediction, our approach discourages oversimplification of tutor utterances and instead encourages utterances that provide meaningful guidance.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">除了促进学生给出正确回答外，我们还手工制作了一套有效的教学原则评分标准，列于表 1。然后我们使用 GPT-4o 来评估生成的导师话语与评分标准的符合程度。通过结合教学评估方面而不是仅关注正确性预测，我们的方法避免了导师话语的过度简化，并鼓励提供有意义指导的话语。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Pedagogical evaluation criteria for tutor utterances in dialogues.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 1：对话中导师语句的教学评估标准。</font></font></font></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:42.7pt;"><span class="ltx_text ltx_font_bold">Criteria<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">标准</font></font></font></span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:284.5pt;"><span class="ltx_text ltx_font_bold">Explanation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">说明</font></font></font></span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:42.7pt;">Accuracy<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">准确性</font></font></font></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:284.5pt;">Ensuring the response does not contain false or misleading statements.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">确保回复不包含虚假或误导性陈述。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:42.7pt;">Progress<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">进展</font></font></font></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:284.5pt;">Determining whether the response helps the student move forward.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">判断回复是否有助于学生继续前进。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" rowspan="4">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:42.7pt;">Guidance<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">指导</font></font></font></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:284.5pt;">1. Error identification: Correctly pinpoints the student’s mistake.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1. 错误识别：准确指出学生的错误。 </font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:284.5pt;">2. Strategic Hinting: New information or guidance for help.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2. 策略性提示：提供新的信息或指导以帮助学生。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:284.5pt;">3. Withholding: Refrains from directly providing the final answer.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3. 保留：避免直接给出最终答案。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:284.5pt;">4. Encouraging: Motivates the student to persist in their attempt.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4. 鼓励：激励学生坚持尝试。</font></font></font></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p">Our evaluation draws inspiration from feedback assessment studies&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib44" title="">44</a>]</cite> and focuses on common errors made by LLMs when generating feedback for math problems&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib39" title="">39</a>]</cite>. The rubric evaluates generated tutor utterances on six granular items, each assigned a binary label, across three core aspects: <span class="ltx_text ltx_font_italic">Accuracy</span>, <span class="ltx_text ltx_font_italic">Progress</span>, and <span class="ltx_text ltx_font_italic">Guidance</span>.
Considering all aspects, we also have GPT-4o provide an <span class="ltx_text ltx_font_italic">overall score</span> for the utterance on a 1-10 scale. Our prompt leverages chain-of-thought so that GPT-4o provides reasoning about the utterance before assigning its scores.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的评估借鉴了反馈评估研究[19, 20, 44]的思路，重点关注 LLMs 在为数学问题生成反馈时常见的错误[39]。评分标准从三个方面（准确性、进步性和指导性）对生成的导师话语进行评估，每个方面包含六个细粒度指标，每个指标都分配了二进制标签。综合考虑所有方面，我们还让 GPT-4o 在 1-10 的评分范围内给出话语的整体评分。我们的提示利用了思维链，以便 GPT-4o 在分配分数之前对话语进行推理。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p">We include the human tutor utterance from MathDial in our prompt as a point of comparison, mainly to assist with evaluating <span class="ltx_text ltx_font_italic">Accuracy</span>, which can be challenging <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib39" title="">39</a>]</cite>. We find the 1-10 scale works slightly better than simply averaging all the binary rubric items, possibly because it enables GPT-4o to decide which rubric items are more relevant given the context of the dialogue.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们将 MathDial 中的人类导师话语作为比较点包含在提示中，主要目的是协助评估准确性，这通常是一个挑战[39]。我们发现 1-10 的评分范围比简单平均所有二进制评分项的效果略好，可能是因为它使 GPT-4o 能够根据对话的上下文决定哪些评分项更相关。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Preference Pair Construction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3 偏好对构建</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p">To create a dataset of preference pairs for DPO training, we collect candidate tutor utterances from four sources: (1) the human tutor utterances from the MathDial dataset, (2) utterances generated by GPT-4o, where the evaluation criteria (rubric and intending to elicit correct student responses) are included in the prompt, (3) utterances generated by Llama 3.1 8B using a generic prompt about behaving like a math tutor (without the rubric), and (4) utterances generated by Llama 3.2 3B using the same generic prompt.
In general, method (2) contains high-quality tutor utterances that serve as positive examples that score high under our rubric. However, we found that in many cases (1) performs better for eliciting correct student responses due to the concise nature of the utterances. Utterances generated by (3) are a mix of high and low quality, while utterances generated by (4) are typically lower quality and serve as a source of negative examples for preference optimization. Prior work has shown diverse candidate quality, particularly negative examples, to improve DPO performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib49" title="">49</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为创建用于 DPO 训练的偏好对数据集，我们从四个来源收集候选导师话语：(1) MathDial 数据集中的人类导师话语，(2) GPT-4o 生成的话语，其中评估标准（评分标准和旨在引出正确学生回答）包含在提示中，(3) 使用关于表现得像数学导师的通用提示生成的 Llama 3.1 8B 话语（不包含评分标准），以及(4) 使用相同通用提示生成的 Llama 3.2 3B 话语。通常，方法(2)包含高质量导师话语，这些话语在我们的评分标准下得分较高，可作为正例。然而，我们发现许多情况下(1)由于话语简洁，在引出正确学生回答方面表现更好。方法(3)生成的话语质量参差不齐，而方法(4)生成的话语通常质量较低，可作为偏好优化的负例来源。先前研究表明，多样化的候选质量，尤其是负例，可以提升 DPO 性能[39, 49]。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p">After evaluating each candidate using LLMKT and the rubric, we create a combined weighted score for a candidate tutor utterance at turn <math alttext="m" class="ltx_Math" display="inline" id="S3.SS3.p2.m1"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation><annotation encoding="application/x-llamapun">italic_m</annotation></semantics></math>:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在用 LLMKT 和评分标准评估每个候选后，我们为候选助教在回合 <math id="S3.SS3.p2.m1" display="inline" class="ltx_Math" alttext="m"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation><annotation encoding="application/x-llamapun">italic_m</annotation></semantics></math> 的语句创建一个综合加权分数：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx1">
<tbody id="S3.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle s_{m}=\lambda\cdot y_{m}+(1-\lambda)\cdot r_{m}," class="ltx_Math" display="inline" id="S3.Ex1.m1"><semantics><mrow><mrow><msub><mi>s</mi><mi>m</mi></msub><mo>=</mo><mrow><mrow><mi>λ</mi><mo lspace="0.222em" rspace="0.222em">⋅</mo><msub><mi>y</mi><mi>m</mi></msub></mrow><mo>+</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>−</mo><mi>λ</mi></mrow><mo rspace="0.055em" stretchy="false">)</mo></mrow><mo rspace="0.222em">⋅</mo><msub><mi>r</mi><mi>m</mi></msub></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\displaystyle s_{m}=\lambda\cdot y_{m}+(1-\lambda)\cdot r_{m},</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = italic_λ ⋅ italic_y start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT + ( 1 - italic_λ ) ⋅ italic_r start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="y_{m}" class="ltx_Math" display="inline" id="S3.SS3.p2.m2"><semantics><msub><mi>y</mi><mi>m</mi></msub><annotation encoding="application/x-tex">y_{m}</annotation><annotation encoding="application/x-llamapun">italic_y start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> is the probability of a correct student response predicted by LLMKT at this turn, and <math alttext="r_{m}" class="ltx_Math" display="inline" id="S3.SS3.p2.m3"><semantics><msub><mi>r</mi><mi>m</mi></msub><annotation encoding="application/x-tex">r_{m}</annotation><annotation encoding="application/x-llamapun">italic_r start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> is the overall rubric score at this turn normalized in <math alttext="[0,1]" class="ltx_Math" display="inline" id="S3.SS3.p2.m4"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1]</annotation><annotation encoding="application/x-llamapun">[ 0 , 1 ]</annotation></semantics></math>. We adjust <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS3.p2.m5"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> to balance the tradeoff between how much the generated utterances elicit correct student responses compared to how much they follow pedagogical practice. By default, we set <math alttext="\lambda=0.5" class="ltx_Math" display="inline" id="S3.SS3.p2.m6"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\lambda=0.5</annotation><annotation encoding="application/x-llamapun">italic_λ = 0.5</annotation></semantics></math> to achieve a balance between these objectives; in our experiments, we show how varying <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS3.p2.m7"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> affects the balance between both.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S3.SS3.p2.m2" display="inline" class="ltx_Math" alttext="y_{m}"><semantics><msub><mi>y</mi><mi>m</mi></msub><annotation encoding="application/x-tex">y_{m}</annotation><annotation encoding="application/x-llamapun">italic_y start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> 是 LLMKT 在此回合预测的正确学生响应的概率， <math id="S3.SS3.p2.m3" display="inline" class="ltx_Math" alttext="r_{m}"><semantics><msub><mi>r</mi><mi>m</mi></msub><annotation encoding="application/x-tex">r_{m}</annotation><annotation encoding="application/x-llamapun">italic_r start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> 是此回合的总体评分标准分数，已归一化到 <math id="S3.SS3.p2.m4" display="inline" class="ltx_Math" alttext="[0,1]"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1]</annotation><annotation encoding="application/x-llamapun">[ 0 , 1 ]</annotation></semantics></math> 。我们调整 <math id="S3.SS3.p2.m5" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 以平衡生成语句激发正确学生响应的程度与遵循教学实践的程度之间的权衡。默认情况下，我们设置 <math id="S3.SS3.p2.m6" display="inline" class="ltx_Math" alttext="\lambda=0.5"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\lambda=0.5</annotation><annotation encoding="application/x-llamapun">italic_λ = 0.5</annotation></semantics></math> 以在这两个目标之间取得平衡；在我们的实验中，我们展示了如何改变 <math id="S3.SS3.p2.m7" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 会影响这两个目标之间的平衡。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p">We then use the score <math alttext="s_{m}" class="ltx_Math" display="inline" id="S3.SS3.p3.m1"><semantics><msub><mi>s</mi><mi>m</mi></msub><annotation encoding="application/x-tex">s_{m}</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> to construct preference pairs between candidate tutor utterances. We consider a candidate with score <math alttext="s_{m}^{1}" class="ltx_Math" display="inline" id="S3.SS3.p3.m2"><semantics><msubsup><mi>s</mi><mi>m</mi><mn>1</mn></msubsup><annotation encoding="application/x-tex">s_{m}^{1}</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT</annotation></semantics></math> to be preferred over a candidate with score <math alttext="s_{m}^{2}" class="ltx_Math" display="inline" id="S3.SS3.p3.m3"><semantics><msubsup><mi>s</mi><mi>m</mi><mn>2</mn></msubsup><annotation encoding="application/x-tex">s_{m}^{2}</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> if the former is greater by some threshold, i.e., <math alttext="s_{m}^{1}-s_{m}^{2}&gt;\epsilon" class="ltx_Math" display="inline" id="S3.SS3.p3.m4"><semantics><mrow><mrow><msubsup><mi>s</mi><mi>m</mi><mn>1</mn></msubsup><mo>−</mo><msubsup><mi>s</mi><mi>m</mi><mn>2</mn></msubsup></mrow><mo>&gt;</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">s_{m}^{1}-s_{m}^{2}&gt;\epsilon</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT - italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT &gt; italic_ϵ</annotation></semantics></math>. If the scores are within <math alttext="\epsilon" class="ltx_Math" display="inline" id="S3.SS3.p3.m5"><semantics><mi>ϵ</mi><annotation encoding="application/x-tex">\epsilon</annotation><annotation encoding="application/x-llamapun">italic_ϵ</annotation></semantics></math>, we do not form a preference pair. In practice, we set <math alttext="\epsilon=0.1" class="ltx_Math" display="inline" id="S3.SS3.p3.m6"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\epsilon=0.1</annotation><annotation encoding="application/x-llamapun">italic_ϵ = 0.1</annotation></semantics></math> to achieve a balance where noisy preference pairs are excluded, but we retain enough data to sufficiently train the model, both of which have been shown to be important considerations for DPO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib23" title="">23</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们随后使用分数 <math id="S3.SS3.p3.m1" display="inline" class="ltx_Math" alttext="s_{m}"><semantics><msub><mi>s</mi><mi>m</mi></msub><annotation encoding="application/x-tex">s_{m}</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> 来构建候选导师话语之间的偏好对。如果前者比后者高出某个阈值 <math id="S3.SS3.p3.m4" display="inline" class="ltx_Math" alttext="s_{m}^{1}-s_{m}^{2}&gt;\epsilon"><semantics><mrow><mrow><msubsup><mi>s</mi><mi>m</mi><mn>1</mn></msubsup><mo>−</mo><msubsup><mi>s</mi><mi>m</mi><mn>2</mn></msubsup></mrow><mo>&gt;</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">s_{m}^{1}-s_{m}^{2}&gt;\epsilon</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT - italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT &gt; italic_ϵ</annotation></semantics></math> ，我们认为分数为 <math id="S3.SS3.p3.m2" display="inline" class="ltx_Math" alttext="s_{m}^{1}"><semantics><msubsup><mi>s</mi><mi>m</mi><mn>1</mn></msubsup><annotation encoding="application/x-tex">s_{m}^{1}</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT</annotation></semantics></math> 的候选优于分数为 <math id="S3.SS3.p3.m3" display="inline" class="ltx_Math" alttext="s_{m}^{2}"><semantics><msubsup><mi>s</mi><mi>m</mi><mn>2</mn></msubsup><annotation encoding="application/x-tex">s_{m}^{2}</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> 的候选。如果分数在 <math id="S3.SS3.p3.m5" display="inline" class="ltx_Math" alttext="\epsilon"><semantics><mi>ϵ</mi><annotation encoding="application/x-tex">\epsilon</annotation><annotation encoding="application/x-llamapun">italic_ϵ</annotation></semantics></math> 范围内，则不形成偏好对。在实践中，我们设置 <math id="S3.SS3.p3.m6" display="inline" class="ltx_Math" alttext="\epsilon=0.1"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\epsilon=0.1</annotation><annotation encoding="application/x-llamapun">italic_ϵ = 0.1</annotation></semantics></math> 以在排除噪声偏好对的同时保留足够的数据来充分训练模型，这两者已被证明是 DPO[23]中重要的考虑因素。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Model Training<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.4 模型训练</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p">We train our model in a two-stage process: (1) distillation and (2) DPO.
Distillation is a common way to enhance the capabilities of small LLMs by mimicking the behavior of much larger LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib52" title="">52</a>]</cite>. In our case, we fine-tune Llama 3.1 8B on candidate tutor utterances generated by GPT-4o. Through this distillation stage, we gain access to a <span class="ltx_text ltx_font_italic">local</span> model that scores well on our pedagogical rubric.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的模型训练分为两个阶段：(1) 摹本和 (2) DPO。摹本是增强小型 LLM 能力的常用方法，通过模仿更大 LLM 的行为 [ 52]。在我们的案例中，我们在 GPT-4o 生成的候选导师话语上微调 Llama 3.1 8B。通过这个摹本阶段，我们获得了一个在我们的教学评估标准上得分良好的本地模型。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p">We then use DPO and our preference pairs to further steer the distilled model towards effective tutoring.
DPO trains an LLM by contrasting outputs in a preference pair given the same input prompt, using the following objective:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">然后我们使用 DPO 和我们的偏好对来进一步引导摹本模型朝向有效的教学。DPO 通过在相同输入提示下对比偏好对中的输出来训练 LLM，使用以下目标：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{DPO}}(\theta)=-\mathbb{E}_{(x,t^{w}_{m},t^{l}_{m})\sim\mathcal{D}}\left[\log\sigma\left(\beta\log\frac{\pi_{\theta}(t^{w}_{m}|x)}{\pi_{\text{ref}}(t^{w}_{m}|x)}-\beta\log\frac{\pi_{\theta}(t^{l}_{m}|x)}{\pi_{\text{ref}}(t^{l}_{m}|x)}\right)\right]," class="ltx_Math" display="block" id="S3.Ex2.m1"><semantics><mrow><mrow><mrow><msub><mi class="ltx_font_mathcaligraphic">ℒ</mi><mtext>DPO</mtext></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mo>−</mo><mrow><msub><mi>𝔼</mi><mrow><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><msubsup><mi>t</mi><mi>m</mi><mi>w</mi></msubsup><mo>,</mo><msubsup><mi>t</mi><mi>m</mi><mi>l</mi></msubsup><mo stretchy="false">)</mo></mrow><mo>∼</mo><mi class="ltx_font_mathcaligraphic">𝒟</mi></mrow></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>[</mo><mrow><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mi>σ</mi></mrow><mo lspace="0em" rspace="0em">​</mo><mrow><mo>(</mo><mrow><mrow><mi>β</mi><mo lspace="0.167em" rspace="0em">​</mo><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msubsup><mi>t</mi><mi>m</mi><mi>w</mi></msubsup><mo fence="false">|</mo><mi>x</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>π</mi><mtext>ref</mtext></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msubsup><mi>t</mi><mi>m</mi><mi>w</mi></msubsup><mo fence="false">|</mo><mi>x</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac></mrow></mrow><mo>−</mo><mrow><mi>β</mi><mo lspace="0.167em" rspace="0em">​</mo><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msubsup><mi>t</mi><mi>m</mi><mi>l</mi></msubsup><mo fence="false">|</mo><mi>x</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><msub><mi>π</mi><mtext>ref</mtext></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msubsup><mi>t</mi><mi>m</mi><mi>l</mi></msubsup><mo fence="false">|</mo><mi>x</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mfrac></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}_{\text{DPO}}(\theta)=-\mathbb{E}_{(x,t^{w}_{m},t^{l}_{m})\sim\mathcal{D}}\left[\log\sigma\left(\beta\log\frac{\pi_{\theta}(t^{w}_{m}|x)}{\pi_{\text{ref}}(t^{w}_{m}|x)}-\beta\log\frac{\pi_{\theta}(t^{l}_{m}|x)}{\pi_{\text{ref}}(t^{l}_{m}|x)}\right)\right],</annotation><annotation encoding="application/x-llamapun">caligraphic_L start_POSTSUBSCRIPT DPO end_POSTSUBSCRIPT ( italic_θ ) = - blackboard_E start_POSTSUBSCRIPT ( italic_x , italic_t start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_t start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) ∼ caligraphic_D end_POSTSUBSCRIPT [ roman_log italic_σ ( italic_β roman_log divide start_ARG italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_t start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | italic_x ) end_ARG start_ARG italic_π start_POSTSUBSCRIPT ref end_POSTSUBSCRIPT ( italic_t start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | italic_x ) end_ARG - italic_β roman_log divide start_ARG italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_t start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | italic_x ) end_ARG start_ARG italic_π start_POSTSUBSCRIPT ref end_POSTSUBSCRIPT ( italic_t start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT | italic_x ) end_ARG ) ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="t^{w}_{m}" class="ltx_Math" display="inline" id="S3.SS4.p2.m1"><semantics><msubsup><mi>t</mi><mi>m</mi><mi>w</mi></msubsup><annotation encoding="application/x-tex">t^{w}_{m}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="t^{l}_{m}" class="ltx_Math" display="inline" id="S3.SS4.p2.m2"><semantics><msubsup><mi>t</mi><mi>m</mi><mi>l</mi></msubsup><annotation encoding="application/x-tex">t^{l}_{m}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> represent the preferred and unpreferred tutor utterances, respectively. <math alttext="x" class="ltx_Math" display="inline" id="S3.SS4.p2.m3"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation><annotation encoding="application/x-llamapun">italic_x</annotation></semantics></math> represents the input prompt, comprising an instruction, the context of the dialogue, and the dialogue history <math alttext="t_{&lt;m},s_{&lt;m}" class="ltx_Math" display="inline" id="S3.SS4.p2.m4"><semantics><mrow><msub><mi>t</mi><mrow><mi></mi><mo>&lt;</mo><mi>m</mi></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mi></mi><mo>&lt;</mo><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{&lt;m},s_{&lt;m}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUBSCRIPT &lt; italic_m end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT &lt; italic_m end_POSTSUBSCRIPT</annotation></semantics></math>. <math alttext="\pi_{\theta}" class="ltx_Math" display="inline" id="S3.SS4.p2.m5"><semantics><msub><mi>π</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> denotes the model being trained, <math alttext="\pi_{\text{ref}}" class="ltx_Math" display="inline" id="S3.SS4.p2.m6"><semantics><msub><mi>π</mi><mtext>ref</mtext></msub><annotation encoding="application/x-tex">\pi_{\text{ref}}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT ref end_POSTSUBSCRIPT</annotation></semantics></math> represents a frozen reference model, and <math alttext="\beta" class="ltx_Math" display="inline" id="S3.SS4.p2.m7"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation><annotation encoding="application/x-llamapun">italic_β</annotation></semantics></math> is a hyperparameter that controls the divergence between the learned and reference policies.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S3.SS4.p2.m1" display="inline" class="ltx_Math" alttext="t^{w}_{m}"><semantics><msubsup><mi>t</mi><mi>m</mi><mi>w</mi></msubsup><annotation encoding="application/x-tex">t^{w}_{m}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUPERSCRIPT italic_w end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> 和 <math id="S3.SS4.p2.m2" display="inline" class="ltx_Math" alttext="t^{l}_{m}"><semantics><msubsup><mi>t</mi><mi>m</mi><mi>l</mi></msubsup><annotation encoding="application/x-tex">t^{l}_{m}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> 分别代表偏好和不受偏好的导师话语。 <math id="S3.SS4.p2.m3" display="inline" class="ltx_Math" alttext="x"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation><annotation encoding="application/x-llamapun">italic_x</annotation></semantics></math> 代表输入提示，包括指令、对话上下文和对话历史 <math id="S3.SS4.p2.m4" display="inline" class="ltx_Math" alttext="t_{&lt;m},s_{&lt;m}"><semantics><mrow><msub><mi>t</mi><mrow><mi></mi><mo>&lt;</mo><mi>m</mi></mrow></msub><mo>,</mo><msub><mi>s</mi><mrow><mi></mi><mo>&lt;</mo><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{&lt;m},s_{&lt;m}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUBSCRIPT &lt; italic_m end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT &lt; italic_m end_POSTSUBSCRIPT</annotation></semantics></math> 。 <math id="S3.SS4.p2.m5" display="inline" class="ltx_Math" alttext="\pi_{\theta}"><semantics><msub><mi>π</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 表示正在训练的模型， <math id="S3.SS4.p2.m6" display="inline" class="ltx_Math" alttext="\pi_{\text{ref}}"><semantics><msub><mi>π</mi><mtext>ref</mtext></msub><annotation encoding="application/x-tex">\pi_{\text{ref}}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT ref end_POSTSUBSCRIPT</annotation></semantics></math> 代表一个冻结的参考模型， <math id="S3.SS4.p2.m7" display="inline" class="ltx_Math" alttext="\beta"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation><annotation encoding="application/x-llamapun">italic_β</annotation></semantics></math> 是一个控制学习策略和参考策略之间差异的超参数。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p">In this work, we use the distilled model as the reference model <math alttext="\pi_{\text{ref}}" class="ltx_Math" display="inline" id="S3.SS4.p3.m1"><semantics><msub><mi>π</mi><mtext>ref</mtext></msub><annotation encoding="application/x-tex">\pi_{\text{ref}}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT ref end_POSTSUBSCRIPT</annotation></semantics></math> and for initializing the weights of <math alttext="\pi_{\theta}" class="ltx_Math" display="inline" id="S3.SS4.p3.m2"><semantics><msub><mi>π</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>. We find the distilled model works much better than using the base Llama model, since the distilled model already performs better on the rubric. Additionally, we set <math alttext="\beta=0.1" class="ltx_Math" display="inline" id="S3.SS4.p3.m3"><semantics><mrow><mi>β</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\beta=0.1</annotation><annotation encoding="application/x-llamapun">italic_β = 0.1</annotation></semantics></math>, a relatively low value for DPO compared to a common value of <math alttext="\beta=0.5" class="ltx_Math" display="inline" id="S3.SS4.p3.m4"><semantics><mrow><mi>β</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\beta=0.5</annotation><annotation encoding="application/x-llamapun">italic_β = 0.5</annotation></semantics></math>. The low <math alttext="\beta" class="ltx_Math" display="inline" id="S3.SS4.p3.m5"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation><annotation encoding="application/x-llamapun">italic_β</annotation></semantics></math> value allows <math alttext="\pi_{\theta}" class="ltx_Math" display="inline" id="S3.SS4.p3.m6"><semantics><msub><mi>π</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> to diverge more from <math alttext="\pi_{\text{ref}}" class="ltx_Math" display="inline" id="S3.SS4.p3.m7"><semantics><msub><mi>π</mi><mtext>ref</mtext></msub><annotation encoding="application/x-tex">\pi_{\text{ref}}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT ref end_POSTSUBSCRIPT</annotation></semantics></math>, which we find necessary to increase LLMKT’s predictions of eliciting correct student responses in the next dialogue turn.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在这项工作中，我们使用蒸馏模型作为参考模型 <math id="S3.SS4.p3.m1" display="inline" class="ltx_Math" alttext="\pi_{\text{ref}}"><semantics><msub><mi>π</mi><mtext>ref</mtext></msub><annotation encoding="application/x-tex">\pi_{\text{ref}}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT ref end_POSTSUBSCRIPT</annotation></semantics></math> ，并使用它来初始化权重 <math id="S3.SS4.p3.m2" display="inline" class="ltx_Math" alttext="\pi_{\theta}"><semantics><msub><mi>π</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 。我们发现蒸馏模型比使用基础 Llama 模型效果要好得多，因为蒸馏模型在评分标准上已经表现更好。此外，我们设置了 <math id="S3.SS4.p3.m3" display="inline" class="ltx_Math" alttext="\beta=0.1"><semantics><mrow><mi>β</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\beta=0.1</annotation><annotation encoding="application/x-llamapun">italic_β = 0.1</annotation></semantics></math> ，这是一个相对于常见值 <math id="S3.SS4.p3.m4" display="inline" class="ltx_Math" alttext="\beta=0.5"><semantics><mrow><mi>β</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\beta=0.5</annotation><annotation encoding="application/x-llamapun">italic_β = 0.5</annotation></semantics></math> 来说相对较低的低 DPO 值。低 <math id="S3.SS4.p3.m5" display="inline" class="ltx_Math" alttext="\beta"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation><annotation encoding="application/x-llamapun">italic_β</annotation></semantics></math> 值允许 <math id="S3.SS4.p3.m6" display="inline" class="ltx_Math" alttext="\pi_{\theta}"><semantics><msub><mi>π</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\pi_{\theta}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> 更多地偏离 <math id="S3.SS4.p3.m7" display="inline" class="ltx_Math" alttext="\pi_{\text{ref}}"><semantics><msub><mi>π</mi><mtext>ref</mtext></msub><annotation encoding="application/x-tex">\pi_{\text{ref}}</annotation><annotation encoding="application/x-llamapun">italic_π start_POSTSUBSCRIPT ref end_POSTSUBSCRIPT</annotation></semantics></math> ，我们发现这对于增加 LLMKT 在下一轮对话中预测学生正确回答的准确性是必要的。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Settings<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4 实验设置</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1 数据集</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p">We evaluate our framework using the MathDial dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib29" title="">29</a>]</cite>, which consists of tutoring dialogues focused on mathematics problems from GSM8K&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib5" title="">5</a>]</cite>. Each dialogue is centered around an incorrect student solution to the math problem, and the goal of the dialogue is for the tutor to guide the student to the correct solution by addressing their misconceptions. Tutors are role-played by crowd workers, while students are simulated by GPT-3.5. Despite only being half-authentic, MathDial is the largest publicly available one-on-one tutor-student math dialogue dataset to the best of our knowledge. To estimate correctness with LLMKT, which requires knowledge component labels at the current turn, we use the annotated knowledge components from the Dialogue KT version of the dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib38" title="">38</a>]</cite> and filter out unlabeled turns.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用 MathDial 数据集[29]评估我们的框架，该数据集包含专注于数学问题的辅导对话，源自 GSM8K[5]。每个对话都围绕学生错误的数学问题解决方案展开，对话的目标是辅导员通过纠正学生的误解来引导学生找到正确答案。辅导员由众包工作者扮演，学生由 GPT-3.5 模拟。尽管只有半真实性，但据我们所知，MathDial 是目前最大公开的一对一辅导员-学生数学对话数据集。为了使用 LLMKT 估计当前回合的正确性（该评估需要当前回合的知识成分标签），我们使用数据集的 Dialogue KT 版本[38]中标注的知识成分，并过滤掉未标注的回合。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p">We follow the original MathDial train/test split. After filtering, our test set has 588 dialogues with 3,101 tutor turns. We split the train set into a 80/20 train/validation split at the dialogue-level, resulting in 1,809/453 dialogues with 11,058/2,811 tutor turns. When creating our overgenerated tutor turn dataset for distillation and DPO training, we take a subset of the train/validation split to reduce labeling costs, resulting in 483/135 dialogues with 3,080/920 GPT-4o-generated tutor utterances for distillation and 9,662/3,095 preference pairs, with our default parameters of <math alttext="\lambda=0.5" class="ltx_Math" display="inline" id="S4.SS1.p2.m1"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\lambda=0.5</annotation><annotation encoding="application/x-llamapun">italic_λ = 0.5</annotation></semantics></math> and <math alttext="\epsilon=0.1" class="ltx_Math" display="inline" id="S4.SS1.p2.m2"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\epsilon=0.1</annotation><annotation encoding="application/x-llamapun">italic_ϵ = 0.1</annotation></semantics></math>, for DPO.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们遵循原始的 MathDial 训练/测试划分。经过筛选后，我们的测试集包含 588 个对话，共 3,101 个导师回合。我们将训练集在对话级别上按 80/20 的比例划分为训练集和验证集，结果得到 1,809/453 个对话，分别包含 11,058/2,811 个导师回合。在创建用于蒸馏和 DPO 训练的过度生成的导师回合数据集时，我们选取训练/验证划分的一个子集以降低标注成本，最终得到 483/135 个对话，其中包含 3,080/920 个用于蒸馏的 GPT-4o 生成的导师语句，以及 9,662/3,095 个偏好对，使用我们的默认参数 <math id="S4.SS1.p2.m1" display="inline" class="ltx_Math" alttext="\lambda=0.5"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\lambda=0.5</annotation><annotation encoding="application/x-llamapun">italic_λ = 0.5</annotation></semantics></math> 和 <math id="S4.SS1.p2.m2" display="inline" class="ltx_Math" alttext="\epsilon=0.1"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\epsilon=0.1</annotation><annotation encoding="application/x-llamapun">italic_ϵ = 0.1</annotation></semantics></math> 进行 DPO。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Baselines<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2 基线</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p">We compare our preference-optimized LLM, which we refer to as <span class="ltx_text ltx_font_bold">DPO</span>, with Llama 3.1 8B as the base model, against the following baselines: the <span class="ltx_text ltx_font_bold">Base model</span> of Llama 3.1 8B prompted with our evaluation criteria (rubric and intending to elicit correct student responses); its supervised fine-tuned version on human tutor utterances in the original dataset, <span class="ltx_text ltx_font_bold">SFT</span>; a fine-tuned version distilled from GPT-4o-generated utterances detailed above in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.SS4" title="3.4 Model Training ‣ 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">3.4</span></a>, <span class="ltx_text ltx_font_bold">Distill</span>; <span class="ltx_text ltx_font_bold">GPT-4o</span>, the large, proprietary LLM, which is prompted with our evaluation criteria; and finally, the <span class="ltx_text ltx_font_bold">Human Tutor</span> utterances from the original MathDial dataset.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们比较了我们的偏好优化 LLM，我们称之为 DPO，与 Llama 3.1 8B 作为基础模型，与以下基线进行对比：使用我们的评估标准（评分表和旨在引出正确学生回答）提示的 Llama 3.1 8B 基础模型；在原始数据集中人类导师话语上的监督微调版本，SFT；从第 3.4 节中详细说明的 GPT-4o 生成的话语蒸馏出的微调版本，Distill；GPT-4o，大型专有 LLM，使用我们的评估标准进行提示；最后，原始 MathDial 数据集中的人类导师话语。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Automated Metrics<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.3 自动指标</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p">We evaluate tutor utterances on both <span class="ltx_text ltx_font_bold">student outcomes</span> and <span class="ltx_text ltx_font_bold">pedagogical principles</span>. Student outcome prediction uses LLMKT to estimate the probability of a correct student response, averaged across turns. Evaluating how well the utterance follows the pedagogical principles will be reported in the same order as in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.T1" title="Table 1 ‣ 3.2 Following Pedagogical Principles ‣ 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">1</span></a>, reporting scores for <span class="ltx_text ltx_font_bold">Acc.</span> (Accuracy), <span class="ltx_text ltx_font_bold">Prog.</span> (Progress), <span class="ltx_text ltx_font_bold">Err.</span> (Error Identification), <span class="ltx_text ltx_font_bold">Hint</span> (Strategic Hinting), <span class="ltx_text ltx_font_bold">Wth.</span> (Withholding), and <span class="ltx_text ltx_font_bold">Enc.</span> (Encouraging), along with an <span class="ltx_text ltx_font_bold">Overall</span> score.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们评估导师话语对学生结果和教学原则的影响。学生结果预测使用 LLMKT 来估计正确学生回答的概率，并在回合间取平均值。评估话语遵循教学原则的程度将按照表 1 的顺序报告，报告 Acc.（准确率）、Prog.（进步）、Err.（错误识别）、Hint（策略性提示）、Wth.（保留）和 Enc.（鼓励）的分数，以及总体分数。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Model Parameters<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.4 模型参数</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS4.p1">
<p class="ltx_p">We use the <span class="ltx_text ltx_font_typewriter">meta-llama/Meta-Llama-3.1-8B-Instruct</span> model from Hugging Face&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib11" title="">11</a>]</cite> for all local experiments. To adapt the model, we use Low-Rank Adaptation (LoRA)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib18" title="">18</a>]</cite> with a rank parameter of <math alttext="r=64" class="ltx_Math" display="inline" id="S4.SS4.p1.m1"><semantics><mrow><mi>r</mi><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">r=64</annotation><annotation encoding="application/x-llamapun">italic_r = 64</annotation></semantics></math>, scaling factor <math alttext="\alpha=32" class="ltx_Math" display="inline" id="S4.SS4.p1.m2"><semantics><mrow><mi>α</mi><mo>=</mo><mn>32</mn></mrow><annotation encoding="application/x-tex">\alpha=32</annotation><annotation encoding="application/x-llamapun">italic_α = 32</annotation></semantics></math>, and a dropout rate of 0.05. We train using the AdamW optimizer, with a learning rate of <math alttext="1\times 10^{-4}" class="ltx_Math" display="inline" id="S4.SS4.p1.m3"><semantics><mrow><mn>1</mn><mo lspace="0.222em" rspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">1\times 10^{-4}</annotation><annotation encoding="application/x-llamapun">1 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> for distillation and <math alttext="3\times 10^{-5}" class="ltx_Math" display="inline" id="S4.SS4.p1.m4"><semantics><mrow><mn>3</mn><mo lspace="0.222em" rspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">3\times 10^{-5}</annotation><annotation encoding="application/x-llamapun">3 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math> for DPO, with a linear warmup phase for the first <math alttext="10\%" class="ltx_Math" display="inline" id="S4.SS4.p1.m5"><semantics><mrow><mn>10</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">10\%</annotation><annotation encoding="application/x-llamapun">10 %</annotation></semantics></math> of training steps. We use an effective batch size of <math alttext="64" class="ltx_Math" display="inline" id="S4.SS4.p1.m6"><semantics><mn>64</mn><annotation encoding="application/x-tex">64</annotation><annotation encoding="application/x-llamapun">64</annotation></semantics></math> with gradient accumulation, set weight decay to <math alttext="1\times 10^{-2}" class="ltx_Math" display="inline" id="S4.SS4.p1.m7"><semantics><mrow><mn>1</mn><mo lspace="0.222em" rspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">1\times 10^{-2}</annotation><annotation encoding="application/x-llamapun">1 × 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT</annotation></semantics></math>, and set a gradient clipping maximum norm of <math alttext="1.0" class="ltx_Math" display="inline" id="S4.SS4.p1.m8"><semantics><mn>1.0</mn><annotation encoding="application/x-tex">1.0</annotation><annotation encoding="application/x-llamapun">1.0</annotation></semantics></math>. We evaluate the loss on the validation set after each epoch, and achieve the minimum validation loss after three epochs for distillation and after one epoch for DPO. At test time, we generate tutor utterances using greedy decoding. We conduct all experiments on NVIDIA RTX A6000 GPUs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用 Hugging Face 的 meta-llama/Meta-Llama-3.1-8B-Instruct 模型 [ 11] 进行所有本地实验。为了适配模型，我们使用低秩适配（LoRA）[ 18]，设置秩参数为 <math id="S4.SS4.p1.m1" display="inline" class="ltx_Math" alttext="r=64"><semantics><mrow><mi>r</mi><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">r=64</annotation><annotation encoding="application/x-llamapun">italic_r = 64</annotation></semantics></math> ，缩放因子为 <math id="S4.SS4.p1.m2" display="inline" class="ltx_Math" alttext="\alpha=32"><semantics><mrow><mi>α</mi><mo>=</mo><mn>32</mn></mrow><annotation encoding="application/x-tex">\alpha=32</annotation><annotation encoding="application/x-llamapun">italic_α = 32</annotation></semantics></math> ，以及 dropout 率为 0.05。我们使用 AdamW 优化器进行训练，蒸馏阶段的学习率为 <math id="S4.SS4.p1.m3" display="inline" class="ltx_Math" alttext="1\times 10^{-4}"><semantics><mrow><mn>1</mn><mo rspace="0.222em" lspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">1\times 10^{-4}</annotation><annotation encoding="application/x-llamapun">1 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> ，DPO 阶段的学习率为 <math id="S4.SS4.p1.m4" display="inline" class="ltx_Math" alttext="3\times 10^{-5}"><semantics><mrow><mn>3</mn><mo rspace="0.222em" lspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">3\times 10^{-5}</annotation><annotation encoding="application/x-llamapun">3 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math> ，并在训练的前 <math id="S4.SS4.p1.m5" display="inline" class="ltx_Math" alttext="10\%"><semantics><mrow><mn>10</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">10\%</annotation><annotation encoding="application/x-llamapun">10 %</annotation></semantics></math> 个步骤中进行线性预热。我们使用 <math id="S4.SS4.p1.m6" display="inline" class="ltx_Math" alttext="64"><semantics><mn>64</mn><annotation encoding="application/x-tex">64</annotation><annotation encoding="application/x-llamapun">64</annotation></semantics></math> 的有效批大小，并采用梯度累积，将权重衰减设置为 <math id="S4.SS4.p1.m7" display="inline" class="ltx_Math" alttext="1\times 10^{-2}"><semantics><mrow><mn>1</mn><mo rspace="0.222em" lspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">1\times 10^{-2}</annotation><annotation encoding="application/x-llamapun">1 × 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT</annotation></semantics></math> ，梯度裁剪的最大范数为 <math id="S4.SS4.p1.m8" display="inline" class="ltx_Math" alttext="1.0"><semantics><mn>1.0</mn><annotation encoding="application/x-tex">1.0</annotation><annotation encoding="application/x-llamapun">1.0</annotation></semantics></math> 。每轮训练后，我们在验证集上评估损失，蒸馏阶段在三轮训练后达到最小验证损失，DPO 阶段在第一轮训练后达到最小验证损失。测试时，我们使用贪婪解码生成助教话语。所有实验均在 NVIDIA RTX A6000 GPU 上进行。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Results<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5 实验结果</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Quantitative Results<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.1 定量结果</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Tutor utterance evaluations for each method on the test set. The best result for each metric is in <span class="ltx_text ltx_font_bold">bold</span> while the second best is <span class="ltx_text ltx_framed ltx_framed_underline">underlined</span>. DPO significantly outperforms all methods on improving student correctness predictions, and closely matches the performance of GPT-4o on the pedagogical rubric.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 2：测试集上每种方法的助教话语评估结果。每个指标的最佳结果加粗显示，次优结果加下划线。DPO 在提高学生正确预测方面显著优于所有方法，并且在教学评估方面的表现与 GPT-4o 非常接近。</font></font></font></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Student Outcomes<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">学生成果</font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="7"><span class="ltx_text ltx_font_bold">Pedagogical Principles<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">教学原则</font></font></font></span></th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span class="ltx_text ltx_font_bold">Method<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></th>
<th class="ltx_td ltx_th ltx_th_column"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Acc.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">准确率</font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Prog.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">进步</font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Err.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">错误。</font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Hint<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">提示</font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Wth.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">什么。</font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Enc.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">编码。</font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Overall<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">总体</font></font></font></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Human Tutor<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">人类导师</font></font></font></th>
<td class="ltx_td ltx_align_center ltx_border_t">0.45</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">0.99</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.66</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.58</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.49</td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_framed ltx_framed_underline">0.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_t">0.53</td>
<td class="ltx_td ltx_align_center ltx_border_t">6.97</td>
</tr>
<tr class="ltx_tr" style="background-color:#E4E4E4;">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" colspan="9"><span class="ltx_text" style="background-color:#E4E4E4;">GPT-4o - Proprietary LLM<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">GPT-4o - 专有 LLM</font></font></font></span></th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Base Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基础模型</font></font></font></th>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_framed ltx_framed_underline">0.49</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.99</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.97</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.92</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.96</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.99</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_framed ltx_framed_underline">0.89</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">9.40</span></td>
</tr>
<tr class="ltx_tr" style="background-color:#E4E4E4;">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" colspan="9"><span class="ltx_text" style="background-color:#E4E4E4;">Llama 3.1 8B Instruct - Open-source LLM<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Llama 3.1 8B Instruct - 开源 LLM</font></font></font></span></th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Base Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基础模型</font></font></font></th>
<td class="ltx_td ltx_align_center">0.43</td>
<td class="ltx_td ltx_align_center">0.82</td>
<td class="ltx_td ltx_align_center">0.69</td>
<td class="ltx_td ltx_align_center">0.70</td>
<td class="ltx_td ltx_align_center">0.64</td>
<td class="ltx_td ltx_align_center">0.94</td>
<td class="ltx_td ltx_align_center">0.62</td>
<td class="ltx_td ltx_align_center">7.20</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">SFT</th>
<td class="ltx_td ltx_align_center">0.47</td>
<td class="ltx_td ltx_align_center">0.86</td>
<td class="ltx_td ltx_align_center">0.32</td>
<td class="ltx_td ltx_align_center">0.23</td>
<td class="ltx_td ltx_align_center">0.21</td>
<td class="ltx_td ltx_align_center">0.90</td>
<td class="ltx_td ltx_align_center">0.31</td>
<td class="ltx_td ltx_align_center">4.73</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">Distill<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">蒸馏</font></font></font></th>
<td class="ltx_td ltx_align_center">0.47</td>
<td class="ltx_td ltx_align_center">0.95</td>
<td class="ltx_td ltx_align_center">0.92</td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_framed ltx_framed_underline">0.90</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_framed ltx_framed_underline">0.91</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">0.99</span></td>
<td class="ltx_td ltx_align_center">0.82</td>
<td class="ltx_td ltx_align_center">8.93</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">DPO (<math alttext="\lambda=0.5" class="ltx_Math" display="inline" id="S5.T2.m1"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\lambda=0.5</annotation><annotation encoding="application/x-llamapun">italic_λ = 0.5</annotation></semantics></math>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">DPO ( <math id="S5.T2.m1" display="inline" class="ltx_Math" alttext="\lambda=0.5"><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\lambda=0.5</annotation><annotation encoding="application/x-llamapun">italic_λ = 0.5</annotation></semantics></math> )</font></font></font></th>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_framed ltx_framed_underline">0.97</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_framed ltx_framed_underline">0.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.99</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">0.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_framed ltx_framed_underline">9.37</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5.T2" title="Table 2 ‣ 5.1 Quantitative Results ‣ 5 Experimental Results ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">2</span></a> shows the results of tutor utterance generation on the MathDial test set, across all methods on the automated metrics. We observe that DPO significantly outperforms all other methods on student correctness prediction, improving over the next best method, GPT-4o, by <math alttext="33\%" class="ltx_Math" display="inline" id="S5.SS1.p1.m1"><semantics><mrow><mn>33</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">33\%</annotation><annotation encoding="application/x-llamapun">33 %</annotation></semantics></math>. This result shows that DPO training is necessary to generate tutor utterances that are more likely to achieve correct student responses, which cannot be achieved simply through prompting. Additionally, DPO achieves similar scores to GPT-4o on the pedagogical rubric, with both methods scoring very high on all rubric items and the overall score. This result shows that our DPO training pipeline can effectively bring the pedagogical ability of small, open-source LLMs with only 8B parameters to the level of very large, proprietary LLMs.
Moreover, we see that DPO improves over distillation on almost all metrics, showing that DPO is necessary to achieve both objectives.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 2 展示了在 MathDial 测试集上，所有方法在自动指标方面的导师话语生成结果。我们观察到 DPO 在学生正确性预测方面显著优于所有其他方法，比下一最佳方法 GPT-4o 提高了 <math id="S5.SS1.p1.m1" display="inline" class="ltx_Math" alttext="33\%"><semantics><mrow><mn>33</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">33\%</annotation><annotation encoding="application/x-llamapun">33 %</annotation></semantics></math> 。这一结果表明，DPO 训练对于生成更有可能获得学生正确回答的导师话语是必要的，而这不是单纯通过提示就能实现的。此外，DPO 在教学法评分标准上的得分与 GPT-4o 相似，两种方法在所有评分标准项目及总分上均得分非常高。这一结果表明，我们的 DPO 训练流程能够有效将仅含 8B 参数的小型开源 LLM 的教学能力提升至大型专有 LLM 的水平。此外，我们看到 DPO 在几乎所有指标上都优于蒸馏，这表明 DPO 对于实现两个目标都是必要的。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p">A notable observation is that human-written tutor utterances, while almost always accurate, score relatively low on most other rubric items. This result is not surprising since human tutors do not act according to our evaluation rubric; many of the human utterances are relatively short and simply ask the student to retry without giving guidance, and occasionally feature the tutor getting frustrated with the student. As a result, the SFT model, trained on human tutor utterances, does not score high on our rubric; the distilled model and even the base Llama model significantly outperform it on the rubric items.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">一个显著的观察是，人类编写的导师话语虽然几乎总是准确的，但在大多数其他评估标准项上的得分相对较低。这个结果并不令人意外，因为人类导师并不按照我们的评估标准行事；许多人类话语相对简短，仅仅要求学生重试而不提供指导，并且偶尔会表现出导师对学生感到沮丧。因此，在人类导师话语上训练的 SFT 模型在我们的评估标准上得分不高；蒸馏模型甚至基础 Llama 模型在评估标准项上显著优于它。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="136" id="S5.F2.g1" src="./训练基于 LLM 的导师以改善对话中的学生学习成果 --- Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues_files/lambda_exp.png" width="419">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Results of our experiment adjusting the value of <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.F2.m4"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> in <span class="ltx_text" style="color:#44AA99;">DPO</span> training. Left: student correctness prediction changing with <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.F2.m5"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math>. Right: pedagogical rubric score changing with <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.F2.m6"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math>. We also show values for <span class="ltx_text" style="color:#DDCC77;">GPT-4o</span> and the <span class="ltx_text" style="color:#332288;">Distill</span> model for comparison.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 2：我们调整 DPO 训练中 <math id="S5.F2.m4" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 值的实验结果。左：学生正确性预测随 <math id="S5.F2.m5" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 变化。右：教学评估标准得分随 <math id="S5.F2.m6" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 变化。我们还展示了 GPT-4o 和蒸馏模型的值以供比较。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Student Outcomes vs.&nbsp;Pedagogical Principles</span>
We investigate how adjusting the value of <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.SS1.p3.m1"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> can balance the two goals of maximizing student outcomes under LLMKT and following pedagogical principles. We vary the value of <math alttext="\lambda\in\{0.00,0.25,0.50,0.75,1.00\}" class="ltx_Math" display="inline" id="S5.SS1.p3.m2"><semantics><mrow><mi>λ</mi><mo>∈</mo><mrow><mo stretchy="false">{</mo><mn>0.00</mn><mo>,</mo><mn>0.25</mn><mo>,</mo><mn>0.50</mn><mo>,</mo><mn>0.75</mn><mo>,</mo><mn>1.00</mn><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\lambda\in\{0.00,0.25,0.50,0.75,1.00\}</annotation><annotation encoding="application/x-llamapun">italic_λ ∈ { 0.00 , 0.25 , 0.50 , 0.75 , 1.00 }</annotation></semantics></math>, where larger values attribute more weight to the student correctness prediction objective, and evaluate on a subset of the data with 500 turn pairs. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5.F2" title="Figure 2 ‣ 5.1 Quantitative Results ‣ 5 Experimental Results ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">2</span></a> shows the result of this experiment. We see that, as expected, increasing <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.SS1.p3.m3"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> from <math alttext="0" class="ltx_Math" display="inline" id="S5.SS1.p3.m4"><mn>0</mn></math> to <math alttext="1" class="ltx_Math" display="inline" id="S5.SS1.p3.m5"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation><annotation encoding="application/x-llamapun">1</annotation></semantics></math> generally increases student correctness prediction performance while generally decreasing the rubric score. Practitioners can get their desired balance by changing <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.SS1.p3.m6"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math>; for example, a value of around <math alttext="0.5" class="ltx_Math" display="inline" id="S5.SS1.p3.m7"><semantics><mn>0.5</mn><annotation encoding="application/x-tex">0.5</annotation><annotation encoding="application/x-llamapun">0.5</annotation></semantics></math> to <math alttext="0.75" class="ltx_Math" display="inline" id="S5.SS1.p3.m8"><semantics><mn>0.75</mn><annotation encoding="application/x-tex">0.75</annotation><annotation encoding="application/x-llamapun">0.75</annotation></semantics></math> can maintain a relatively high score on the pedagogical rubric while significantly improving performance on soliciting correct responses from students. Perhaps surprisingly, changing <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.SS1.p3.m9"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> from <math alttext="0.75" class="ltx_Math" display="inline" id="S5.SS1.p3.m10"><semantics><mn>0.75</mn><annotation encoding="application/x-tex">0.75</annotation><annotation encoding="application/x-llamapun">0.75</annotation></semantics></math> to <math alttext="1.0" class="ltx_Math" display="inline" id="S5.SS1.p3.m11"><semantics><mn>1.0</mn><annotation encoding="application/x-tex">1.0</annotation><annotation encoding="application/x-llamapun">1.0</annotation></semantics></math> does not increase student outcome performance, while decreasing <math alttext="\lambda" class="ltx_Math" display="inline" id="S5.SS1.p3.m12"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> from <math alttext="0.25" class="ltx_Math" display="inline" id="S5.SS1.p3.m13"><semantics><mn>0.25</mn><annotation encoding="application/x-tex">0.25</annotation><annotation encoding="application/x-llamapun">0.25</annotation></semantics></math> to <math alttext="0.0" class="ltx_Math" display="inline" id="S5.SS1.p3.m14"><semantics><mn>0.0</mn><annotation encoding="application/x-tex">0.0</annotation><annotation encoding="application/x-llamapun">0.0</annotation></semantics></math> <span class="ltx_text ltx_font_italic">decreases</span> pedagogical performance. This result implies that a small reward signal from correctness prediction may implicitly help pedagogical effectiveness, and vice versa.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">学生成果与教学原则 我们研究了如何调整 <math id="S5.SS1.p3.m1" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 的值来平衡 LLMKT 下最大化学生成果和遵循教学原则的两个目标。我们改变 <math id="S5.SS1.p3.m2" display="inline" class="ltx_Math" alttext="\lambda\in\{0.00,0.25,0.50,0.75,1.00\}"><semantics><mrow><mi>λ</mi><mo>∈</mo><mrow><mo stretchy="false">{</mo><mn>0.00</mn><mo>,</mo><mn>0.25</mn><mo>,</mo><mn>0.50</mn><mo>,</mo><mn>0.75</mn><mo>,</mo><mn>1.00</mn><mo stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex">\lambda\in\{0.00,0.25,0.50,0.75,1.00\}</annotation><annotation encoding="application/x-llamapun">italic_λ ∈ { 0.00 , 0.25 , 0.50 , 0.75 , 1.00 }</annotation></semantics></math> 的值，其中较大的值将更多权重赋予学生正确性预测目标，并在包含 500 对回合的子集数据上进行评估。图 2 显示了该实验的结果。我们看到，正如预期的那样，将 <math id="S5.SS1.p3.m3" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 从 <math id="S5.SS1.p3.m4" display="inline" class="ltx_Math" alttext="0"><mn>0</mn></math> 增加到 <math id="S5.SS1.p3.m5" display="inline" class="ltx_Math" alttext="1"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation><annotation encoding="application/x-llamapun">1</annotation></semantics></math> 通常会提高学生正确性预测性能，同时通常会降低评分标准分。从业者可以通过改变 <math id="S5.SS1.p3.m6" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 来获得他们期望的平衡；例如， <math id="S5.SS1.p3.m7" display="inline" class="ltx_Math" alttext="0.5"><semantics><mn>0.5</mn><annotation encoding="application/x-tex">0.5</annotation><annotation encoding="application/x-llamapun">0.5</annotation></semantics></math> 到 <math id="S5.SS1.p3.m8" display="inline" class="ltx_Math" alttext="0.75"><semantics><mn>0.75</mn><annotation encoding="application/x-tex">0.75</annotation><annotation encoding="application/x-llamapun">0.75</annotation></semantics></math> 的值可以在保持教学评分标准相对较高分数的同时显著提高从学生那里获取正确回答的性能。或许令人惊讶的是，将 <math id="S5.SS1.p3.m9" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 从 <math id="S5.SS1.p3.m10" display="inline" class="ltx_Math" alttext="0.75"><semantics><mn>0.75</mn><annotation encoding="application/x-tex">0.75</annotation><annotation encoding="application/x-llamapun">0.75</annotation></semantics></math> 改为 <math id="S5.SS1.p3.m11" display="inline" class="ltx_Math" alttext="1.0"><semantics><mn>1.0</mn><annotation encoding="application/x-tex">1.0</annotation><annotation encoding="application/x-llamapun">1.0</annotation></semantics></math> 并没有提高学生成果性能，而将 <math id="S5.SS1.p3.m12" display="inline" class="ltx_Math" alttext="\lambda"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation><annotation encoding="application/x-llamapun">italic_λ</annotation></semantics></math> 从 <math id="S5.SS1.p3.m13" display="inline" class="ltx_Math" alttext="0.25"><semantics><mn>0.25</mn><annotation encoding="application/x-tex">0.25</annotation><annotation encoding="application/x-llamapun">0.25</annotation></semantics></math> 减少到 <math id="S5.SS1.p3.m14" display="inline" class="ltx_Math" alttext="0.0"><semantics><mn>0.0</mn><annotation encoding="application/x-tex">0.0</annotation><annotation encoding="application/x-llamapun">0.0</annotation></semantics></math> 则降低了教学性能。这一结果表明，来自正确性预测的小奖励信号可能隐含地有助于教学效果，反之亦然。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Qualitative Analysis<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.2 定性分析</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p">We conduct a qualitative analysis of generated tutor utterances to investigate the strengths and weaknesses of our method, how it compares to baselines, and what types of patterns emerge in the model-generated text.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们对生成的导师话语进行定性分析，以研究我们方法的优缺点、它如何与基线比较，以及模型生成文本中出现的模式类型。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5.T3" title="Table 3 ‣ 5.2 Qualitative Analysis ‣ 5 Experimental Results ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">3</span></a> shows an example dialogue context and tutor utterances from the human tutor, GPT-4o, and DPO.
We see that the human tutor states that the student is not correct and prompts the student to try again, providing a subtle hint to focus on the cost of the dozen. However, this utterance neither gives LLMKT, the student model, any confidence in the student being able to answer correctly, nor follows strong pedagogical principles. GPT-4o guides the student toward correctly calculating the profit, but directly provides half of the solution in its hint, limiting deep student engagement. It also poses the challenging task of computing the total profit, which requires multiple calculation steps. Since the student is still struggling with unit conversion, LLMKT is not confident that the student will respond correctly. In contrast, our DPO-trained model provides an actionable hint for the student, following the rubric. It also poses the simpler task of asking the student to first find the cost of a half dozen, which is necessary for later steps. As a result, LLMKT is confident the student can respond correctly.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 3 展示了人类导师、GPT-4o 和 DPO 提供的对话上下文和导师话语示例。我们看到人类导师指出学生回答不正确，并提示学生再试一次，同时巧妙地暗示学生应关注一打的成本。然而，这句话既没有给 LLMKT（学生模型）任何学生能够正确回答的信心，也没有遵循强烈的教学习惯。GPT-4o 引导学生正确计算利润，但在提示中直接提供了半个解决方案，限制了学生的深度参与。它还提出了一个计算总利润的挑战性任务，需要多个计算步骤。由于学生仍在挣扎于单位转换，LLMKT 并不确定学生能正确回答。相比之下，我们训练的 DPO 模型为学生提供了可操作的提示，并遵循评分标准。它还提出了一个更简单的任务，要求学生首先找出半打的成本，这是后续步骤所必需的。因此，LLMKT 确信学生能够正确回答。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p">Overall, we find that our DPO-trained model excels at posing <span class="ltx_text ltx_font_italic">concrete</span> tasks that are nontrivial, but more feasible for students compared to GPT-4o. We observe that the behavior of posing tasks this way is the primary way of achieving higher predictions for student correctness, and appears to be an emergent behavior of training on the LLMKT-derived scores. While the tasks sometimes only ask the student to perform simple arithmetic, they are typically more involved. For example, in another dialogue, the model asks “How long does it take to download 200 GB at a rate of 2 GB/minute?” This task requires the student to set up a single variable equation and understand the roles of the given values. We also find that the DPO-trained model is more likely to ask questions, whereas other methods often directly tell the student to perform a task.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">总的来说，我们发现经过 DPO 训练的模型在提出具体任务方面表现出色，这些任务比 GPT-4o 提出的任务更非平凡，但对学生来说更可行。我们观察到，以这种方式提出任务的行为是提高学生正确率预测的主要方式，并且似乎是训练在 LLMKT 衍生分数上的涌现行为。虽然这些任务有时只要求学生进行简单的算术运算，但通常更复杂。例如，在另一个对话中，模型会问“下载 200GB 数据以每分钟 2GB 的速度需要多长时间？”这个任务要求学生建立单一变量方程并理解给定值的角色。我们还发现，DPO 训练的模型更倾向于提问，而其他方法通常直接告诉学生执行任务。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p4">
<p class="ltx_p">However, both LLMs still have some limitations, particularly when students give partially correct responses. In these cases, the models may ignore the progress the student has made and focus on errors that are irrelevant to the recent student response. Correctly identifying errors in math with LLMs has been shown to be challenging in prior work as well&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib27" title="">27</a>]</cite>, indicating additional techniques may be needed to fix this behavior.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">然而，LLMs 仍然存在一些局限性，尤其是在学生给出部分正确回答的情况下。在这些情况下，模型可能会忽略学生已经取得的进步，而专注于与最近学生回答无关的错误。先前的研究表明，使用 LLMs 正确识别数学错误也是一项挑战[12, 27]，这表明可能需要额外的技术来纠正这种行为。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparing human tutor, GPT-4o, and DPO tutor utterances, on student outcomes (SO) and pedagogical principles (PP). <span class="ltx_text" style="color:#BF8040;">Brown</span> highlights the tutor-posed task. Some irrelevant text in the dialogue context has been removed for brevity.
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 3：比较人类导师、GPT-4o 和 DPO 导师的语句，在学生结果（SO）和教学原则（PP）上的表现。Brown 突出了导师提出任务。为了简洁，对话上下文中的一些无关文本已被删除。</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:451.4pt;height:215.9pt;vertical-align:-215.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-96.7pt,0.0pt) scale(0.7,0.7) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr" style="background-color:#E4E4E4;">
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="4"><span class="ltx_text" style="background-color:#E4E4E4;">Problem<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">问题</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top" colspan="4">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:608.9pt;">Chloe bought chocolate-dipped strawberries at $50 a dozen. She then sold them for $30 for half a dozen. How much is Chloe’s profit if she sold 50 dozens?<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Chloe 买了每打 50 美元的巧克力蘸草莓。然后她以每半打 30 美元的价格出售。如果 Chloe 出售了 50 打，她的利润是多少？</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr" style="background-color:#E4E4E4;">
<td class="ltx_td ltx_align_center ltx_align_top" colspan="4"><span class="ltx_text" style="background-color:#E4E4E4;">Dialogue History<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对话历史</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:37.0pt;"><math alttext="t_{1}" class="ltx_Math" display="inline" id="S5.T3.m1"><semantics><msub><mi>t</mi><mn>1</mn></msub><annotation encoding="application/x-tex">t_{1}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" colspan="3">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:569.1pt;">Hey Alejandra. If Chloe buys the strawberries at $50 for 12 and sells them for $30 for 6, how much profit would that be for one dozen?<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">嘿阿莱杭德拉。如果克洛伊以每打 50 美元的价格购买草莓，并以每 6 个 30 美元的价格出售，那么每打能赚多少利润？</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:37.0pt;"><math alttext="s_{1}" class="ltx_Math" display="inline" id="S5.T3.m2"><semantics><msub><mi>s</mi><mn>1</mn></msub><annotation encoding="application/x-tex">s_{1}</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" colspan="3">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:569.1pt;">For one dozen, Chloe would make a profit of $20, which is $50 - $30 = $20.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">每打克洛伊能赚 20 美元，即 50 美元减去 30 美元等于 20 美元。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:37.0pt;"><math alttext="t_{2}" class="ltx_Math" display="inline" id="S5.T3.m3"><semantics><msub><mi>t</mi><mn>2</mn></msub><annotation encoding="application/x-tex">t_{2}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" colspan="3">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:569.1pt;">Remember that she’s selling half a dozen for $30. How many half dozen can she sell from each $50 dozen she buys?<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">记住她以 30 美元的价格出售半打。她从每打 50 美元的购买中能卖多少半打？</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:37.0pt;"><math alttext="s_{2}" class="ltx_Math" display="inline" id="S5.T3.m4"><semantics><msub><mi>s</mi><mn>2</mn></msub><annotation encoding="application/x-tex">s_{2}</annotation><annotation encoding="application/x-llamapun">italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" colspan="3">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:569.1pt;">She can sell two half dozen for each $50 dozen she buys, so she can make a profit of $60 from each $50 dozen.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">她可以卖出每 50 打她购买的 2 个半打，因此她可以从每 50 打中赚取 60 美元的利润。</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr" style="background-color:#E4E4E4;">
<td class="ltx_td ltx_align_center ltx_align_top" colspan="4"><span class="ltx_text" style="background-color:#E4E4E4;">Next Tutor Turn (<math alttext="t_{3}" class="ltx_Math" display="inline" id="S5.T3.m5"><semantics><msub><mi mathbackground="#E4E4E4">t</mi><mn mathbackground="#E4E4E4">3</mn></msub><annotation encoding="application/x-tex">t_{3}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math>) Candidates<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">下一个导师回合（ <math id="S5.T3.m5" display="inline" class="ltx_Math" alttext="t_{3}"><semantics><msub><mi mathbackground="#E4E4E4">t</mi><mn mathbackground="#E4E4E4">3</mn></msub><annotation encoding="application/x-tex">t_{3}</annotation><annotation encoding="application/x-llamapun">italic_t start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math> ）候选人</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:37.0pt;"><span class="ltx_text ltx_font_bold">Method<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:512.1pt;"><span class="ltx_text ltx_font_bold">Tutor Utterance<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">导师话语</font></font></font></span></span>
</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:22.8pt;"><span class="ltx_text ltx_font_bold">SO</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:22.8pt;"><span class="ltx_text ltx_font_bold">PP</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:37.0pt;">Human Tutor<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">人类导师</font></font></font></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:512.1pt;">Remember it’s not $60 profit, because they cost her to buy them. <span class="ltx_text" style="color:#BF8040;">Try again.</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">记住，不是$60 的利润，因为购买它们要花她的钱。再试一次。</font></font></font></span>
</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:22.8pt;">0.33</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:22.8pt;">4</span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:37.0pt;" data-imt_insert_failed="1">GPT-4o</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:512.1pt;">It looks like there’s a misunderstanding in your calculations. Remember, Chloe’s cost for half a dozen is $25 (since $50 per dozen divided by 2). She sells half a dozen for $30, so her profit per half dozen is $30 - $25 = $5. <span class="ltx_text" style="color:#BF8040;">Try recalculating her total profit using this correct profit per half dozen.</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">看起来你的计算有误。记住，Chloe 买半打要花$25（因为每打$50 除以 2）。她卖半打$30，所以她每半打的利润是$30 - $25 = $5。用这个正确的每半打利润重新计算她的总利润。</font></font></font></span>
</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:22.8pt;">0.59</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:22.8pt;"><span class="ltx_text ltx_font_bold">10</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:37.0pt;">DPO</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:512.1pt;">It looks like there’s a misunderstanding. If Chloe buys a dozen for $50 and sells half a dozen for $30, let’s first find out how much she paid for half a dozen. <span class="ltx_text" style="color:#BF8040;">If $50 is for 12, how much is $50 divided by 2?</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">看起来你理解有误。如果 Chloe 买一打$50，卖半打$30，让我们先算出她买半打花了多少钱。如果$50 是 12 个，那么$50 除以 2 是多少？</font></font></font></span>
</span>
</td>
<td class="ltx_td ltx_nopad_l ltx_align_justify ltx_align_top ltx_border_bb">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:22.8pt;"><span class="ltx_text ltx_font_bold">0.84</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:22.8pt;"><span class="ltx_text ltx_font_bold">10</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Human Evaluation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.3 人工评估</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p">We also conduct a human evaluation to further assess different tutor models and how our automated metrics align with human judgment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们也进行人工评估，以进一步评估不同的导师模型，以及我们的自动化指标与人类判断的一致性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p">We recruit two independent volunteer university students to annotate tutor utterances according to our evaluation metrics.
We randomly sample 10 dialogues from the test set after filtering based on toxicity and low quality ground-truth tutor utterances.
The annotators evaluate 5 consecutive tutor turns from each dialogue, resulting in a total of 50 evaluation instances. At each instance, we show participants the dialogue so far and next tutor utterance candidates generated by (1) human tutors, (2) GPT-4o, and (3) our DPO-trained model, in random order without revealing the method.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们招募了两位独立的大学生志愿者，根据我们的评估指标对导师的发言进行标注。在过滤掉有毒性和低质量的真实导师发言后，我们从测试集中随机抽取了 10 个对话。标注者评估每个对话中连续的 5 个导师发言，总共产生 50 个评估实例。在每个实例中，我们向参与者展示到目前为止的对话以及由（1）人类导师、（2）GPT-4o 和（3）我们训练的 DPO 模型生成的下一个导师发言候选，以随机顺序显示，不透露方法。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p3">
<p class="ltx_p">For student outcome prediction, annotators rank the three candidate utterances based on how likely they think each one will lead to a correct student response. We ask annotators to take into account both the task posed in the turn and the student’s knowledge demonstrated in prior turns. We use rankings instead of absolute values since the latter may be harder for humans to calibrate.
For pedagogical principles, we simply ask annotators to follow the same evaluation rubric outlined in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S3.T1" title="Table 1 ‣ 3.2 Following Pedagogical Principles ‣ 3 Methodology ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">1</span></a> and provide an overall score on a 1-10 scale.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对于学生表现预测，标注者根据他们认为每个候选话语可能引出正确学生回答的可能性对三个候选话语进行排序。我们要求标注者同时考虑该回合中提出的问题以及学生在先前回合中展现的知识。我们使用排序而不是绝对值，因为后者可能更难让人校准。对于教学原则，我们仅要求标注者遵循表 1 中概述的相同评估标准，并在 1-10 的量表上给出总体评分。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Human evaluation shows that DPO outperforms human tutors and GPT-4o.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 4：人工评估显示 DPO 的表现优于人类导师和 GPT-4o。</font></font></font></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span class="ltx_text ltx_font_bold">Method<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Correctness Rank<sup class="ltx_sup"><span class="ltx_text ltx_font_medium">↓</span></sup><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">正确性排名 <sup class="ltx_sup"><span class="ltx_text ltx_font_medium">↓</span></sup> </font></font></font></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span class="ltx_text ltx_font_bold">Rubric Score<sup class="ltx_sup"><span class="ltx_text ltx_font_medium">↑</span></sup><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">评分标准 <sup class="ltx_sup"><span class="ltx_text ltx_font_medium">↑</span></sup> </font></font></font></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Human Tutor<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">人类导师</font></font></font></th>
<td class="ltx_td ltx_align_center ltx_border_t">2.12</td>
<td class="ltx_td ltx_align_center ltx_border_t">7.36</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" data-imt_insert_failed="1">GPT-4o</th>
<td class="ltx_td ltx_align_center">2.13</td>
<td class="ltx_td ltx_align_center">8.07</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">DPO</th>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">1.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb"><span class="ltx_text ltx_font_bold">8.55</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Results</span> Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5.T4" title="Table 4 ‣ 5.3 Human Evaluation ‣ 5 Experimental Results ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">4</span></a> shows average student correctness ranks (rank <math alttext="1" class="ltx_Math" display="inline" id="S5.SS3.p4.m1"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation><annotation encoding="application/x-llamapun">1</annotation></semantics></math> means top-ranked) and rubric scores from human annotators. We see that DPO outperforms both human tutors and GPT-4o on both metrics, with all differences statistically significant (<math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="S5.SS3.p4.m2"><semantics><mrow><mi>p</mi><mo>&lt;</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">p&lt;0.05</annotation><annotation encoding="application/x-llamapun">italic_p &lt; 0.05</annotation></semantics></math>) according to a paired t-test. Higher correctness ranks show that DPO learns how to pose tasks that are manageable to students, while the higher rubric score shows that it does so while maintaining pedagogical principles. Additionally, the higher rubric score may imply that the correctness objective also indirectly improves pedagogical quality.
While DPO outperforming GPT-4o on the rubric is contrary to the automated results in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#S5.T2" title="Table 2 ‣ 5.1 Quantitative Results ‣ 5 Experimental Results ‣ Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues"><span class="ltx_text ltx_ref_tag">2</span></a>, the automated results may reflect self-bias from GPT-4o as the evaluator <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib50" title="">50</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">结果表 4 显示了学生正确性排名（排名 <math id="S5.SS3.p4.m1" display="inline" class="ltx_Math" alttext="1"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation><annotation encoding="application/x-llamapun">1</annotation></semantics></math> 表示排名第一）和人类标注者的评分标准分数。我们看到 DPO 在两个指标上均优于人类导师和 GPT-4o，且所有差异根据配对 t 检验具有统计学意义（ <math id="S5.SS3.p4.m2" display="inline" class="ltx_Math" alttext="p&lt;0.05"><semantics><mrow><mi>p</mi><mo>&lt;</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">p&lt;0.05</annotation><annotation encoding="application/x-llamapun">italic_p &lt; 0.05</annotation></semantics></math> ）。更高的正确性排名表明 DPO 学会了如何提出对学生来说可管理的任务，而更高的评分标准分数表明它在这样做时仍坚持教学原则。此外，更高的评分标准分数也可能意味着正确性目标也间接提高了教学质量。虽然 DPO 在评分标准上优于 GPT-4o 与表 2 中的自动化结果相反，但自动化结果可能反映了作为评估者的 GPT-4o 的自我偏见[50]。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p5">
<p class="ltx_p">Since these evaluation tasks can be highly subjective, we also investigate the inter-rater agreement between the two human annotators and the automated metrics. We use Kendall’s <math alttext="\tau" class="ltx_Math" display="inline" id="S5.SS3.p5.m1"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation><annotation encoding="application/x-llamapun">italic_τ</annotation></semantics></math>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib21" title="">21</a>]</cite> for correctness ranks and Pearson’s correlation coefficient <math alttext="\rho" class="ltx_Math" display="inline" id="S5.SS3.p5.m2"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation><annotation encoding="application/x-llamapun">italic_ρ</annotation></semantics></math> &nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2503.06424v2#bib.bib25" title="">25</a>]</cite> for rubric scores. For correctness ranks, Kendall’s <math alttext="\tau" class="ltx_Math" display="inline" id="S5.SS3.p5.m3"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation><annotation encoding="application/x-llamapun">italic_τ</annotation></semantics></math> is only <math alttext="0.06" class="ltx_Math" display="inline" id="S5.SS3.p5.m4"><semantics><mn>0.06</mn><annotation encoding="application/x-tex">0.06</annotation><annotation encoding="application/x-llamapun">0.06</annotation></semantics></math> between the two annotators and averages <math alttext="0.08" class="ltx_Math" display="inline" id="S5.SS3.p5.m5"><semantics><mn>0.08</mn><annotation encoding="application/x-tex">0.08</annotation><annotation encoding="application/x-llamapun">0.08</annotation></semantics></math> between LLMKT and both annotators. This low agreement is not surprising due to the subjective nature of the task; we find that there are many near-ties between different candidate utterances according to LLMKT’s output probabilities. For rubric scores, the inter-rater agreement is notably higher: Pearson’s <math alttext="\rho" class="ltx_Math" display="inline" id="S5.SS3.p5.m6"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation><annotation encoding="application/x-llamapun">italic_ρ</annotation></semantics></math> is <math alttext="0.15" class="ltx_Math" display="inline" id="S5.SS3.p5.m7"><semantics><mn>0.15</mn><annotation encoding="application/x-tex">0.15</annotation><annotation encoding="application/x-llamapun">0.15</annotation></semantics></math> between the two annotators and averages <math alttext="0.27" class="ltx_Math" display="inline" id="S5.SS3.p5.m8"><semantics><mn>0.27</mn><annotation encoding="application/x-tex">0.27</annotation><annotation encoding="application/x-llamapun">0.27</annotation></semantics></math> between GPT-4o and both annotators, the latter being statistically significant. This result suggests that evaluating pedagogical principles is much easier than predicting student correctness, though the former is still subjective, since annotators may value certain rubric items differently.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由于这些评估任务可能具有高度主观性，我们还研究了两位人类标注者和自动指标之间的评分者间一致性。我们使用肯德尔τ系数 <math id="S5.SS3.p5.m1" display="inline" class="ltx_Math" alttext="\tau"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation><annotation encoding="application/x-llamapun">italic_τ</annotation></semantics></math> [ 21]评估正确性排序，使用皮尔逊相关系数 <math id="S5.SS3.p5.m2" display="inline" class="ltx_Math" alttext="\rho"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation><annotation encoding="application/x-llamapun">italic_ρ</annotation></semantics></math> [ 25]评估评分标准得分。对于正确性排序，肯德尔τ系数 <math id="S5.SS3.p5.m3" display="inline" class="ltx_Math" alttext="\tau"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation><annotation encoding="application/x-llamapun">italic_τ</annotation></semantics></math> 在两位标注者之间的相关性仅为 <math id="S5.SS3.p5.m4" display="inline" class="ltx_Math" alttext="0.06"><semantics><mn>0.06</mn><annotation encoding="application/x-tex">0.06</annotation><annotation encoding="application/x-llamapun">0.06</annotation></semantics></math> ，而与 LLMKT 的平均相关性为 <math id="S5.SS3.p5.m5" display="inline" class="ltx_Math" alttext="0.08"><semantics><mn>0.08</mn><annotation encoding="application/x-tex">0.08</annotation><annotation encoding="application/x-llamapun">0.08</annotation></semantics></math> 。由于任务的主观性，这种低一致性并不令人意外；我们发现根据 LLMKT 的输出概率，不同候选话语之间存在许多接近平局的情况。对于评分标准得分，评分者间一致性明显更高：皮尔逊相关系数 <math id="S5.SS3.p5.m6" display="inline" class="ltx_Math" alttext="\rho"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation><annotation encoding="application/x-llamapun">italic_ρ</annotation></semantics></math> 在两位标注者之间的相关性为 <math id="S5.SS3.p5.m7" display="inline" class="ltx_Math" alttext="0.15"><semantics><mn>0.15</mn><annotation encoding="application/x-tex">0.15</annotation><annotation encoding="application/x-llamapun">0.15</annotation></semantics></math> ，而与 GPT-4o 的平均相关性为 <math id="S5.SS3.p5.m8" display="inline" class="ltx_Math" alttext="0.27"><semantics><mn>0.27</mn><annotation encoding="application/x-tex">0.27</annotation><annotation encoding="application/x-llamapun">0.27</annotation></semantics></math> ，后者具有统计学意义。这一结果表明，评估教学原则比预测学生正确性要容易得多，尽管前者仍然是主观的，因为标注者可能对不同的评分标准项有不同的评价。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p6">
<p class="ltx_p">Overall, despite showing some promise through preliminary evaluation, it is important to deploy our trained tutor LLMs to real students and test whether they actually lead to good student learning outcomes.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">总体而言，尽管初步评估显示出一些潜力，但将我们训练的导师 LLMs 部署给真实学生，并测试它们是否确实能带来良好的学生学习成果，这一点非常重要。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions and Future Work<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6 结论与未来工作</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p">In this paper, we introduced a methodology to train LLM tutors to maximize student outcomes in dialogues while maintaining high pedagogical quality. We use student simulation to predict how likely a tutor utterance will yield a correct student response, and use GPT-4o to evaluate the pedagogical quality of tutor utterances using a rubric. We use both sets of predictions to score overgenerated tutor utterances and fine-tune Llama 3.1 8B with direct preference optimization. Our resulting model significantly outperforms other methods for increasing predicted student outcomes, and matches the performance of GPT-4o, a much larger closed model, on pedagogical aspects. There are many avenues for future work. First, an evaluation with real students should be carried out to determine if our methods are still effective in real-world scenarios. Second, future work should investigate how to optimize for longer-term learning outcomes, such as concept mastery or performance on post-dialogue assessments. Third, future work should include estimates of student affect and engagement as part of the reward. Finally, future work should apply our method to dialogues in non-math domains, such as language learning or computer science.<font data-immersive-translate-error-id="124" class="notranslate immersive-translate-target-wrapper immersive-translate-target-wrapper-error" translate="no" lang="zh-CN"><a href="javascript:void(0)"><font class="immersive-translate-error notranslate"><font class="immersive-translate-error-wrapper"><font class="immersive-translate-clickable-button notranslate" title="重试全部错误段落" style="display: flex; flex-direction: row; align-items: center;"><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline; width: 1em; height: 1em; pointer-events: none;"><path d="M35.9387 5.48805C35.9166 4.60421 35.2434 4.04719 34.279 4.0675C33.3131 4.0878 32.8154 4.67712 32.6567 5.56132C32.5745 6.01985 32.601 6.49957 32.5962 6.96997C32.5881 7.77251 32.594 8.5752 32.594 9.3779C32.4685 9.43478 32.343 9.4917 32.2175 9.54866C31.7961 9.14366 31.3817 8.73102 30.9521 8.33488C27.0799 4.76502 22.4856 3.43605 17.3405 4.22591C10.0761 5.34107 4.69388 11.3891 4.06231 18.939C3.46983 26.0213 8.03881 32.8643 14.897 35.1663C21.8348 37.495 29.5543 34.7845 33.4563 28.6429C33.7074 28.2475 33.9685 27.8417 34.1218 27.4045C34.4194 26.5555 34.2699 25.765 33.4312 25.3113C32.6231 24.8743 31.8573 25.0498 31.2835 25.7915C30.9966 26.1625 30.7785 26.5856 30.5106 26.9724C28.0914 30.4658 24.7682 32.3693 20.5158 32.5766C14.8218 32.8541 9.60215 29.1608 7.94272 23.717C6.22884 18.0946 8.59939 12.0366 13.6698 9.08126C18.5986 6.20837 24.9262 7.03281 28.9148 11.0837C29.2069 11.3803 29.4036 11.7708 29.8772 12.4519C28.32 12.4519 27.1212 12.3885 25.9323 12.4704C24.8345 12.5461 24.253 13.1995 24.262 14.1166C24.2708 15.0096 24.8931 15.7485 25.9495 15.7745C28.7068 15.8424 31.4671 15.8177 34.2259 15.7884C35.1348 15.7787 35.8872 15.2584 35.9148 14.3603C36.0054 11.4048 36.0127 8.44397 35.9387 5.48805Z" fill="#428ADF"></path></svg><span style="color: rgb(66, 138, 223); text-decoration-line: underline; text-underline-offset: 0.2em; margin-left: 0.2em; pointer-events: none;">重试</span></font>&nbsp;&nbsp;<font class="immersive-translate-help-button notranslate" title="点击查看错误原因: {&amp;quot;error&amp;quot;:{&amp;quot;code&amp;quot;:&amp;quot;1302&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&amp;quot;}}" data-immersive-translate-tooltip-text="{&amp;quot;type&amp;quot;:&amp;quot;network&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;[GLM-4 Flash] 翻译服务或网络出现问题&amp;quot;,&amp;quot;errMsg&amp;quot;:&amp;quot;服务返回错误，说明请求过于频繁或超出额度限制，请稍后再试。&lt;br/&gt;&lt;br/&gt; 429: 您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;retry&amp;quot;,&amp;quot;immediateShow&amp;quot;:false,&amp;quot;translationService&amp;quot;:&amp;quot;GLM-4 Flash&amp;quot;,&amp;quot;errCode&amp;quot;:429}" data-immersive-translate-action="toast-error" style="display: flex; flex-direction: row; align-items: center;"><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline; width: 1em; height: 1em; pointer-events: none;"><path fill-rule="evenodd" clip-rule="evenodd" d="M20.5607 2.5191C10.735 2.05516 2.46528 10.1045 2.50011 20.0984C2.54469 32.8837 15.9794 41.3025 27.521 35.772C28.0597 35.5138 28.6042 35.2357 29.0745 34.8742C29.9064 34.2347 30.0797 33.3404 29.5712 32.5989C29.0382 31.8217 28.2936 31.6838 27.4596 32.0227C27.2265 32.1174 27.0066 32.2437 26.7865 32.3701C26.6008 32.4767 26.415 32.5833 26.2211 32.6712C20.8005 35.1282 15.6165 34.6504 11.0342 30.8857C6.38506 27.0662 4.83815 21.9885 6.36608 16.1605C8.23236 9.04216 15.6457 4.59129 22.7912 6.13629C30.3201 7.76418 35.1917 14.6886 33.9006 22.1467C33.6763 23.4426 33.1697 24.693 32.665 25.9388C32.4936 26.3618 32.3223 26.7846 32.1625 27.2081C31.7321 28.3488 31.8755 29.1499 32.727 29.6338C33.5625 30.1085 34.3839 29.8271 35.0848 28.8121C35.2031 28.6407 35.3005 28.4544 35.3977 28.2685C35.4242 28.2179 35.4507 28.1672 35.4776 28.1169C36.5263 26.154 37.166 24.0544 37.3992 21.8528C38.4715 11.7296 30.8594 3.00541 20.5607 2.5191ZM22.2324 19.4482C22.6221 17.6294 21.6934 16.7853 19.8682 17.1885C19.4795 17.2744 19.0887 17.3789 18.7223 17.531C17.5055 18.036 17.1067 18.9307 17.8422 20.0563C18.3665 20.8586 18.2472 21.5161 18.0255 22.2965L17.9039 22.7239C17.5079 24.1148 17.1115 25.5072 16.7935 26.9165C16.4841 28.2873 17.2241 29.1723 18.6198 29.1593C18.6749 29.1502 18.7366 29.1408 18.8028 29.1307C18.9623 29.1063 19.1482 29.078 19.332 29.0394C21.5543 28.5732 21.9094 27.8227 20.9844 25.759C20.8192 25.3904 20.8406 24.873 20.9389 24.4633C21.1123 23.7404 21.3092 23.0227 21.5061 22.3052C21.7664 21.3567 22.0267 20.4083 22.2324 19.4482ZM21.2918 10.7674C22.3383 10.7322 23.3464 11.7297 23.3245 12.7787C23.3035 13.7817 22.4311 14.6541 21.4139 14.6892C20.3685 14.7252 19.5018 13.9485 19.4202 12.9025C19.3341 11.798 20.2055 10.8041 21.2918 10.7674Z" fill="#428ADF"></path></svg><span style="color: rgb(66, 138, 223); text-decoration-line: underline; text-underline-offset: 0.2em; margin-left: 0.2em; pointer-events: none;">错误原因</span></font></font></font></a></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">致谢</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p">We thank Adriana Caraeni and Henry Yang for helpful discussions around this work. This work is partially supported by Renaissance Philanthropy via the learning engineering virtual institute (LEVI) and NSF grants 2118706, 2237676, and 2341948.<font data-immersive-translate-error-id="126" class="notranslate immersive-translate-target-wrapper immersive-translate-target-wrapper-error" translate="no" lang="zh-CN"><a href="javascript:void(0)"><font class="immersive-translate-error notranslate"><font class="immersive-translate-error-wrapper"><font class="immersive-translate-clickable-button notranslate" title="重试全部错误段落" style="display: flex; flex-direction: row; align-items: center;"><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline; width: 1em; height: 1em; pointer-events: none;"><path d="M35.9387 5.48805C35.9166 4.60421 35.2434 4.04719 34.279 4.0675C33.3131 4.0878 32.8154 4.67712 32.6567 5.56132C32.5745 6.01985 32.601 6.49957 32.5962 6.96997C32.5881 7.77251 32.594 8.5752 32.594 9.3779C32.4685 9.43478 32.343 9.4917 32.2175 9.54866C31.7961 9.14366 31.3817 8.73102 30.9521 8.33488C27.0799 4.76502 22.4856 3.43605 17.3405 4.22591C10.0761 5.34107 4.69388 11.3891 4.06231 18.939C3.46983 26.0213 8.03881 32.8643 14.897 35.1663C21.8348 37.495 29.5543 34.7845 33.4563 28.6429C33.7074 28.2475 33.9685 27.8417 34.1218 27.4045C34.4194 26.5555 34.2699 25.765 33.4312 25.3113C32.6231 24.8743 31.8573 25.0498 31.2835 25.7915C30.9966 26.1625 30.7785 26.5856 30.5106 26.9724C28.0914 30.4658 24.7682 32.3693 20.5158 32.5766C14.8218 32.8541 9.60215 29.1608 7.94272 23.717C6.22884 18.0946 8.59939 12.0366 13.6698 9.08126C18.5986 6.20837 24.9262 7.03281 28.9148 11.0837C29.2069 11.3803 29.4036 11.7708 29.8772 12.4519C28.32 12.4519 27.1212 12.3885 25.9323 12.4704C24.8345 12.5461 24.253 13.1995 24.262 14.1166C24.2708 15.0096 24.8931 15.7485 25.9495 15.7745C28.7068 15.8424 31.4671 15.8177 34.2259 15.7884C35.1348 15.7787 35.8872 15.2584 35.9148 14.3603C36.0054 11.4048 36.0127 8.44397 35.9387 5.48805Z" fill="#428ADF"></path></svg><span style="color: rgb(66, 138, 223); text-decoration-line: underline; text-underline-offset: 0.2em; margin-left: 0.2em; pointer-events: none;">重试</span></font>&nbsp;&nbsp;<font class="immersive-translate-help-button notranslate" title="点击查看错误原因: {&amp;quot;error&amp;quot;:{&amp;quot;code&amp;quot;:&amp;quot;1302&amp;quot;,&amp;quot;message&amp;quot;:&amp;quot;您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&amp;quot;}}" data-immersive-translate-tooltip-text="{&amp;quot;type&amp;quot;:&amp;quot;network&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;[GLM-4 Flash] 翻译服务或网络出现问题&amp;quot;,&amp;quot;errMsg&amp;quot;:&amp;quot;服务返回错误，说明请求过于频繁或超出额度限制，请稍后再试。&lt;br/&gt;&lt;br/&gt; 429: 您当前使用该API的并发数过高，请降低并发，或联系客服增加限额。&amp;quot;,&amp;quot;action&amp;quot;:&amp;quot;retry&amp;quot;,&amp;quot;immediateShow&amp;quot;:false,&amp;quot;translationService&amp;quot;:&amp;quot;GLM-4 Flash&amp;quot;,&amp;quot;errCode&amp;quot;:429}" data-immersive-translate-action="toast-error" style="display: flex; flex-direction: row; align-items: center;"><svg width="40" height="40" viewBox="0 0 40 40" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: inline; width: 1em; height: 1em; pointer-events: none;"><path fill-rule="evenodd" clip-rule="evenodd" d="M20.5607 2.5191C10.735 2.05516 2.46528 10.1045 2.50011 20.0984C2.54469 32.8837 15.9794 41.3025 27.521 35.772C28.0597 35.5138 28.6042 35.2357 29.0745 34.8742C29.9064 34.2347 30.0797 33.3404 29.5712 32.5989C29.0382 31.8217 28.2936 31.6838 27.4596 32.0227C27.2265 32.1174 27.0066 32.2437 26.7865 32.3701C26.6008 32.4767 26.415 32.5833 26.2211 32.6712C20.8005 35.1282 15.6165 34.6504 11.0342 30.8857C6.38506 27.0662 4.83815 21.9885 6.36608 16.1605C8.23236 9.04216 15.6457 4.59129 22.7912 6.13629C30.3201 7.76418 35.1917 14.6886 33.9006 22.1467C33.6763 23.4426 33.1697 24.693 32.665 25.9388C32.4936 26.3618 32.3223 26.7846 32.1625 27.2081C31.7321 28.3488 31.8755 29.1499 32.727 29.6338C33.5625 30.1085 34.3839 29.8271 35.0848 28.8121C35.2031 28.6407 35.3005 28.4544 35.3977 28.2685C35.4242 28.2179 35.4507 28.1672 35.4776 28.1169C36.5263 26.154 37.166 24.0544 37.3992 21.8528C38.4715 11.7296 30.8594 3.00541 20.5607 2.5191ZM22.2324 19.4482C22.6221 17.6294 21.6934 16.7853 19.8682 17.1885C19.4795 17.2744 19.0887 17.3789 18.7223 17.531C17.5055 18.036 17.1067 18.9307 17.8422 20.0563C18.3665 20.8586 18.2472 21.5161 18.0255 22.2965L17.9039 22.7239C17.5079 24.1148 17.1115 25.5072 16.7935 26.9165C16.4841 28.2873 17.2241 29.1723 18.6198 29.1593C18.6749 29.1502 18.7366 29.1408 18.8028 29.1307C18.9623 29.1063 19.1482 29.078 19.332 29.0394C21.5543 28.5732 21.9094 27.8227 20.9844 25.759C20.8192 25.3904 20.8406 24.873 20.9389 24.4633C21.1123 23.7404 21.3092 23.0227 21.5061 22.3052C21.7664 21.3567 22.0267 20.4083 22.2324 19.4482ZM21.2918 10.7674C22.3383 10.7322 23.3464 11.7297 23.3245 12.7787C23.3035 13.7817 22.4311 14.6541 21.4139 14.6892C20.3685 14.7252 19.5018 13.9485 19.4202 12.9025C19.3341 11.798 20.2055 10.8041 21.2918 10.7674Z" fill="#428ADF"></path></svg><span style="color: rgb(66, 138, 223); text-decoration-line: underline; text-underline-offset: 0.2em; margin-left: 0.2em; pointer-events: none;">错误原因</span></font></font></font></a></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John&nbsp;R Anderson, Albert&nbsp;T Corbett, Kenneth&nbsp;R Koedinger, and Ray Pelletier.

</span>
<span class="ltx_bibblock">Cognitive tutors: Lessons learned.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">The journal of the learning sciences</span>, 4(2):167–207, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nischal Ashok&nbsp;Kumar and Andrew Lan.

</span>
<span class="ltx_bibblock">Improving socratic question generation using data augmentation and preference optimization.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)</span>, pages 108–118, Mexico City, Mexico, June 2024. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dejun Cai, Yuan Zhang, and Bintao Dai.

</span>
<span class="ltx_bibblock">Learning path recommendation based on knowledge tracing model and reinforcement learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">2019 IEEE 5th international conference on computer and communications (ICCC)</span>, pages 1881–1885. IEEE, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Carnegie Learning.

</span>
<span class="ltx_bibblock">Livehint overview.

</span>
<span class="ltx_bibblock">Online: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://support.carnegielearning.com/help-center/math/livehint/article/livehint-overview/" title="">https://support.carnegielearning.com/help-center/math/livehint/article/livehint-overview/</a>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2110.14168</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Common Core State Standards Initiative.

</span>
<span class="ltx_bibblock">Mathematics standards.

</span>
<span class="ltx_bibblock">Online: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.thecorestandards.org/Math/" title="">https://www.thecorestandards.org/Math/</a>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert Corbett and John Anderson.

</span>
<span class="ltx_bibblock">Knowledge tracing: Modeling the acquisition of procedural knowledge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">User Model. User-adapted Interact.</span>, 4(4):253–278, Dec. 1994.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peng Cui and Mrinmaya Sachan.

</span>
<span class="ltx_bibblock">Adaptive and personalized exercise generation for online language learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 10184–10198, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dorottya Demszky, Jing Liu, Zid Mancenido, Julie Cohen, Heather Hill, Dan Jurafsky, and Tatsunori&nbsp;B Hashimoto.

</span>
<span class="ltx_bibblock">Measuring conversational uptake: A case study on student-teacher interactions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</span>, pages 1638–1653, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et&nbsp;al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2407.21783</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugging Face.

</span>
<span class="ltx_bibblock">Hugging face - the ai community building the future.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/" title="">https://huggingface.co/</a>, 2025.

</span>
<span class="ltx_bibblock">Accessed: 2025-02-18.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nigel Fernandez, Alexander Scarlatos, Wanyong Feng, Simon Woodhead, and Andrew Lan.

</span>
<span class="ltx_bibblock">DiVERT: Distractor generation with variational errors represented as text for math multiple-choice questions.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</span>, pages 9063–9081, Miami, Florida, USA, November 2024. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aritra Ghosh, Neil Heffernan, and Andrew&nbsp;S Lan.

</span>
<span class="ltx_bibblock">Context-aware attentive knowledge tracing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACM SIGKDD</span>, pages 2330–2339, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Arthur&nbsp;C Graesser, Kurt VanLehn, Carolyn&nbsp;P Rosé, Pamela&nbsp;W Jordan, and Derek Harter.

</span>
<span class="ltx_bibblock">Intelligent tutoring systems with conversational dialogue.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">AI magazine</span>, 22(4):39–39, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jieun Han, Haneul Yoo, Junho Myung, Minsun Kim, Hyunseung Lim, Yoonsu Kim, Tak&nbsp;Yeon Lee, Hwajung Hong, Juho Kim, So-Yeon Ahn, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llm-as-a-tutor in efl writing education: Focusing on evaluation of student-llm interaction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 1st Workshop on Customizable NLP: Progress and Challenges in Customizing NLP for a Domain, Application, Group, or Individual (CustomNLP4U)</span>, pages 284–293, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joy He-Yueya, Noah&nbsp;D. Goodman, and Emma Brunskill.

</span>
<span class="ltx_bibblock">Evaluating and optimizing educational content with large language model judgments.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 17th International Conference on Educational Data Mining</span>, page 68–82, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joy He-Yueya and Adish Singla.

</span>
<span class="ltx_bibblock">Quizzing policy using reinforcement learning for inferring the student knowledge state.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">International Educational Data Mining Society</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Edward&nbsp;J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu&nbsp;Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.09685</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qinjin Jia, Mitchell Young, Yunkai Xiao, Jialin Cui, Chengyuan Liu, Parvez Rashid, and Edward Gehringer.

</span>
<span class="ltx_bibblock">Insta-reviewer: A data-driven approach for generating instant feedback on students’ project reports.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">International Educational Data Mining Society</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sanjit Kakarla, Danielle Thomas, Jionghao Lin, Shivang Gupta, and Ken Koedinger.

</span>
<span class="ltx_bibblock">Using large language models to assess tutors’ performance in reacting to students making math errors.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">AI for Education: Bridging Innovation and Responsibility at the 38th AAAI Annual Conference on AI</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Maurice&nbsp;George Kendall.

</span>
<span class="ltx_bibblock">Rank correlation methods.

</span>
<span class="ltx_bibblock">1948.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Khan Academy.

</span>
<span class="ltx_bibblock">Supercharge your teaching experience with khanmigo.

</span>
<span class="ltx_bibblock">Online: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.khanmigo.ai/" title="">https://www.khanmigo.ai/</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kyuyoung Kim, Ah&nbsp;Jeong Seo, Hao Liu, Jinwoo Shin, and Kimin Lee.

</span>
<span class="ltx_bibblock">Margin matching preference optimization: Enhanced model alignment with granular feedback.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2024</span>, pages 13554–13570, Miami, Florida, USA, November 2024. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lars Krupp, Steffen Steinert, Maximilian Kiefer-Emmanouilidis, Karina&nbsp;E Avila, Paul Lukowicz, Jochen Kuhn, Stefan Küchemann, and Jakob Karolus.

</span>
<span class="ltx_bibblock">Challenges and opportunities of moderating usage of large language models in education.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the International Conference on Mobile and Ubiquitous Multimedia</span>, pages 249–254, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joseph Lee&nbsp;Rodgers and W&nbsp;Alan Nicewander.

</span>
<span class="ltx_bibblock">Thirteen ways to look at the correlation coefficient.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">The American Statistician</span>, 42(1):59–66, 1988.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anna Lieb and Toshali Goel.

</span>
<span class="ltx_bibblock">Student interaction with newtbot: An llm-as-tutor chatbot for secondary physics education.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</span>, pages 1–8, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Naiming Liu, Shashank Sonkar, Zichao Wang, Simon Woodhead, and Richard&nbsp;G Baraniuk.

</span>
<span class="ltx_bibblock">Novice learner and expert tutor: Evaluating math reasoning abilities of large language models with misconceptions.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.02439</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Naiming Liu, Zichao Wang, Richard Baraniuk, and Andrew Lan.

</span>
<span class="ltx_bibblock">Open-ended knowledge tracing for computer science education.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jakub Macina, Nico Daheim, Sankalan Chowdhury, Tanmay Sinha, Manu Kapur, Iryna Gurevych, and Mrinmaya Sachan.

</span>
<span class="ltx_bibblock">MathDial: A dialogue tutoring dataset with rich pedagogical properties grounded in math reasoning problems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2023</span>, pages 5602–5621, Singapore, December 2023. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andre Nickow, Philip Oreopoulos, and Vincent Quan.

</span>
<span class="ltx_bibblock">The impressive effects of tutoring on prek-12 learning: A systematic review and meta-analysis of the experimental evidence.

</span>
<span class="ltx_bibblock">Working Paper 27476, National Bureau of Economic Research, July 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Benjamin&nbsp;D Nye, Dillon Mee, and Mark&nbsp;G Core.

</span>
<span class="ltx_bibblock">Generative large language models for dialog-based tutoring: An early consideration of opportunities and concerns.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">LLM@ AIED</span>, pages 78–88, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Hello gpt-4o, May 2024.

</span>
<span class="ltx_bibblock">Accessed: 2025-02-19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sankalan Pal&nbsp;Chowdhury, Vilém Zouhar, and Mrinmaya Sachan.

</span>
<span class="ltx_bibblock">Autotutor meets large language models: A language model tutor with rich pedagogy and guardrails.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the Eleventh ACM Conference on Learning@ Scale</span>, pages 5–15, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Minju Park, Sojung Kim, Seunghyun Lee, Soonwoo Kwon, and Kyuseok Kim.

</span>
<span class="ltx_bibblock">Empowering personalized learning through a conversation-based tutoring system with student modeling.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</span>, pages 1–10, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chris Piech, Jonathan Bassen, Jonathan Huang, Surya Ganguli, Mehran Sahami, Leonidas&nbsp;J Guibas, and Jascha Sohl-Dickstein.

</span>
<span class="ltx_bibblock">Deep knowledge tracing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, pages 505–513, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher&nbsp;D Manning, Stefano Ermon, and Chelsea Finn.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anna&nbsp;N Rafferty, Emma Brunskill, Thomas&nbsp;L Griffiths, and Patrick Shafto.

</span>
<span class="ltx_bibblock">Faster teaching via pomdp planning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Cognitive science</span>, 40(6):1290–1332, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alexander Scarlatos, Ryan&nbsp;S. Baker, and Andrew Lan.

</span>
<span class="ltx_bibblock">Exploring knowledge tracing in tutor-student dialogues using llms.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 15th Learning Analytics and Knowledge Conference, LAK 2025, Dublin, Ireland, March 3-7, 2025</span>. ACM, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alexander Scarlatos, Digory Smith, Simon Woodhead, and Andrew Lan.

</span>
<span class="ltx_bibblock">Improving the validity of automatically generated feedback via reinforcement learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Artificial Intelligence in Education</span>, pages 280–294. Springer, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Robin Schmucker, Meng Xia, Amos Azaria, and Tom Mitchell.

</span>
<span class="ltx_bibblock">Ruffle&amp;riley: Insights from designing and evaluating a large language model-based conversational tutoring system.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Artificial Intelligence in Education</span>, pages 75–90. Springer, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shashank Sonkar, Naiming Liu, Debshila Mallick, and Richard Baraniuk.

</span>
<span class="ltx_bibblock">CLASS: A design framework for building intelligent tutoring systems based on learning science principles.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2023</span>, pages 1941–1961, Singapore, December 2023. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shashank Sonkar, Kangqi Ni, Sapana Chaudhary, and Richard Baraniuk.

</span>
<span class="ltx_bibblock">Pedagogical alignment of large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2024</span>, pages 13641–13650, Miami, Florida, USA, November 2024. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John Stamper, Ruiwei Xiao, and Xinying Hou.

</span>
<span class="ltx_bibblock">Enhancing llm-based feedback: Insights from intelligent tutoring systems and the learning sciences.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">International Conference on Artificial Intelligence in Education</span>, pages 32–43. Springer, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jacob Steiss, Tamara Tate, Steve Graham, Jazmin Cruz, Michael Hebert, Jiali Wang, Youngsun Moon, Waverly Tseng, Mark Warschauer, and Carol&nbsp;Booth Olson.

</span>
<span class="ltx_bibblock">Comparing the quality of human and chatgpt feedback of students’ writing.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Learning and Instruction</span>, 91:101894, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
LearnLM Team.

</span>
<span class="ltx_bibblock">Learnlm: Improving gemini for learning, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kurt VanLehn, Pamela&nbsp;W Jordan, Carolyn&nbsp;P Rosé, Dumisizwe Bhembe, Michael Böttner, Andy Gaydos, Maxim Makatchev, Umarani Pappuswamy, Michael Ringenberg, Antonio Roque, et&nbsp;al.

</span>
<span class="ltx_bibblock">The architecture of why2-atlas: A coach for qualitative physics essay writing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Intelligent Tutoring Systems: 6th International Conference, ITS 2002 Biarritz, France and San Sebastian, Spain, June 2–7, 2002 Proceedings 6</span>, pages 158–167. Springer, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rose Wang, Qingyang Zhang, Carly Robinson, Susanna Loeb, and Dorottya Demszky.

</span>
<span class="ltx_bibblock">Bridging the novice-expert gap via models of decision-making: A case study on remediating math mistakes.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</span>, pages 2174–2199, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rose&nbsp;E Wang, Ana&nbsp;T Ribeiro, Carly&nbsp;D Robinson, Susanna Loeb, and Dora Demszky.

</span>
<span class="ltx_bibblock">Tutor copilot: A human-ai approach for scaling real-time expertise.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.03017</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Canwen Xu, Corby Rosset, Ethan Chau, Luciano Corro, Shweti Mahajan, Julian McAuley, Jennifer Neville, Ahmed Awadallah, and Nikhil Rao.

</span>
<span class="ltx_bibblock">Automatic pair construction for contrastive post-training.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of the Association for Computational Linguistics: NAACL 2024</span>, pages 149–162, Mexico City, Mexico, June 2024. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenda Xu, Guanglei Zhu, Xuandong Zhao, Liangming Pan, Lei Li, and William Wang.

</span>
<span class="ltx_bibblock">Pride and prejudice: LLM amplifies self-bias in self-refinement.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>, pages 15474–15492, Bangkok, Thailand, August 2024. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Boyang Yang, Haoye Tian, Weiguo Pian, Haoran Yu, Haitao Wang, Jacques Klein, Tegawendé&nbsp;F Bissyandé, and Shunfu Jin.

</span>
<span class="ltx_bibblock">Cref: An llm-based conversational software repair framework for programming tutors.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis</span>, pages 882–894, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chuanpeng Yang, Yao Zhu, Wang Lu, Yidong Wang, Qian Chen, Chenlong Gao, Bingjie Yan, and Yiqiang Chen.

</span>
<span class="ltx_bibblock">Survey on knowledge distillation for large language models: Methods, evaluation, and application.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">ACM Trans. Intell. Syst. Technol.</span>, October 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
He&nbsp;Zhang, Jingyi Xie, Chuhao Wu, Jie Cai, ChanMin Kim, and John&nbsp;M Carroll.

</span>
<span class="ltx_bibblock">The future of learning: Large language models through the lens of students.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 25th Annual Conference on Information Technology Education</span>, pages 12–18, 2024.

</span>
</li>
</ul>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">报告问题</font></font></font></button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" width="11" height="14">
            </a><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由 L A T E xml <img height="14" width="11" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"> 生成</font></font></font>
        </div></div><footer id="footer" class="ltx_document" default-translate="no">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>/** 基础色阶定义 **/
:root,
#mount[data-theme="light"],
#mount:not([data-theme="dark"]) {
  /* 中性灰阶（light） */
  --c-00: #000000;
  --c-22: #222222;
  --c-33: #333333;
  --c-66: #666666;
  --c-83: #838383;
  --c-99: #999999;
  --c-c7: #c7c7c7;
  --c-cc: #cccccc;
  --c-e6: #e6e6e6;
  --c-f5: #f5f5f5;
  --c-ff: #ffffff;
  /* 品牌主色阶（light） */
  --p-main: #ea4c89;
  --p-hover: #ec5e95;
  --p-active: #e34a85;
  --p-special: #ee71a2;
  --p-disabled: #f4a5c4;
  --p-text-disabled: #f9c9dc;
  --p-weak: #fdedf3;
  /* Surface 层级（light，TC 填充-1） */
  --s-1: #f3f5f6;
  --s-1-hover: #f6f8f9;
  --s-1-active: #edf1f2;
  --s-1-weak: #fafbfb;
  /* 输入/边框（light，TC 填充-2） */
  --input-bg-base: #fafbfc;
  --input-border: #ecf0f7;
  --input-border-strong: #e0e0e6;
  --input-bg-strong: #fafdff;
}

:root[data-theme="dark"],
[data-theme="dark"] {
  /* 中性灰阶（dark） */
  --c-00: #ffffff;
  --c-22: #dbdbdb;
  --c-33: #dbdbdb;
  --c-66: #b3b3b3;
  --c-83: #838383;
  --c-99: #707070;
  --c-c7: #666666;
  --c-cc: #5c5c5c;
  --c-e6: #3b3b3b;
  --c-f5: #262626;
  --c-ff: #222222;
  /* 品牌主色阶（dark） */
  --p-main: #e23c7c;
  --p-hover: #ea4c89;
  --p-active: #d5467d;
  --p-special: #a93a65;
  --p-disabled: #7e2f4d;
  --p-text-disabled: #522335;
  --p-weak: #26171d;
  /* Surface 层级（dark，TC 填充-1） */
  --s-1: #2d2e2f;
  --s-1-hover: #323434;
  --s-1-active: #202121;
  --s-1-weak: #262627;
  /* 输入/边框（dark，TC 填充-2） */
  --input-bg-base: #2b2d30;
  --input-border: #3e434b;
  --input-border-strong: #43474b;
  --input-bg-strong: #1f2123;
}

:root,
#mount [data-theme] {
  /* 业务/通用变量引用色阶（全局可见，含 Shadow DOM） */
  --primary: var(--p-main);
  --primary-hover: var(--p-hover);
  --primary-inverse: #fff;
  --modal-background: var(--s-1);
  --modal-border: var(--input-border);
  --modal-text: var(--c-22);
  --modal-text-secondary: var(--c-66);
  --modal-error: var(--p-main);
  --modal-required: #f53f3f;
  --modal-success: #68cd52;
  --modal-button-background: var(--p-main);
  --modal-button-text: var(--c-ff);
  --modal-input-background: var(--input-bg-base);
  --modal-check-color: var(--p-main);
  --background-color: var(--c-ff);
  --background-light-green: var(--s-1-weak, #f5f7f9);
  --text-black-2: var(--c-22);
  --text-gray-2: var(--c-22);
  --text-gray-6: var(--c-66);
  --text-gray-9: var(--c-99);
  --text-gray-c2: var(--c-c7);
  --switch-background-color: var(--c-c7, hsl(205deg, 16%, 77%));
  --float-ball-more-button-border-color: var(--c-f5, #f6f6f6);
  --float-ball-more-button-background-color: var(--c-ff);
  --float-ball-more-button-svg-color: #6c6f73;
  --service-bg-hover: var(--s-1-hover, #f7faff);
  --service-bg: var(--s-1-weak, #fafbfb);
}

#mount {
  --font-family: var(
    system-ui,
    -apple-system,
    "Segoe UI",
    "Roboto",
    "Ubuntu",
    "Cantarell",
    "Noto Sans",
    sans-serif,
    "Apple Color Emoji",
    "Segoe UI Emoji",
    "Segoe UI Symbol",
    "Noto Color Emoji"
  );
  /* PC/H5 兼容的字号、间距、圆角、阴影变量 */
  --f-12: 12px;
  --f-14: 14px;
  --f-15: 15px;
  --f-16: 16px;
  --f-18: 18px;
  --f-20: 20px;
  --space-4: 4px;
  --space-6: 6px;
  --space-8: 8px;
  --space-12: 12px;
  --space-16: 16px;
  --space-18: 18px;
  --space-24: 24px;
  --radius-8: 8px;
  --radius-12: 12px;
  --radius-16: 16px;
  --control-height-lg: 44px;
  --width-28: 28px;
  --width-24: 24px;
  --width-20: 20px;
  --width-18: 18px;
  --width-16: 16px;
  --width-label-md: 56px;
  --shadow-lg: 0 18px 48px rgba(0, 0, 0, 0.12);

  /* 常规变量 */
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 2px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  /* 兼容旧变量：主色直接引用品牌主色阶 */
  --primary: var(--p-main);
  --primary-hover: var(--p-hover);
  --primary-inverse: #fff;
  /* Modal 业务变量引用色阶 */
  --modal-background: var(--s-1);
  --modal-border: var(--input-border);
  --modal-text: var(--c-22);
  --modal-text-secondary: var(--c-66);
  --modal-error: var(--p-main);
  --modal-required: #f53f3f;
  --modal-success: #68cd52;
  --modal-button-background: var(--p-main);
  --modal-button-text: var(--c-ff);
  --modal-input-background: var(--input-bg-base);
  --modal-check-color: var(--p-main);
  --background-color: var(--c-ff);
  --background-light-green: var(--s-1-weak, #f5f7f9);
  --text-black-2: var(--c-22);
  --text-gray-2: var(--c-22);
  --text-gray-6: var(--c-66);
  --text-gray-9: var(--c-99);
  --text-gray-c2: var(--c-c7);
  --switch-background-color: var(--c-c7, hsl(205deg, 16%, 77%));
  --float-ball-more-button-border-color: var(--c-f5, #f6f6f6);
  --float-ball-more-button-background-color: var(--c-ff);
  --float-ball-more-button-svg-color: #6c6f73;
  --service-bg-hover: var(--s-1-hover, #f7faff);
  --service-bg: var(--s-1-weak, #fafbfb);
  line-height: var(--line-height);
  font-family: var(--font-family);
  font-size: var(--font-size);
}

@media (max-width: 480px) {
  :root,
  #mount {
    --f-12: 10px;
    --f-14: 12px;
    --f-15: 13px;
    --f-16: 14px;
    --f-18: 16px;
    --f-20: 18px;
    --space-4: 4px;
    --space-6: 4px;
    --space-8: 6px;
    --space-12: 8px;
    --space-16: 12px;
    --space-18: 14px;
    --space-24: 18px;
    --radius-8: 6px;
    --radius-12: 10px;
    --radius-16: 12px;
    --control-height-lg: 38px;
    --shadow-lg: 0 12px 32px rgba(0, 0, 0, 0.1);
    --width-28: 24px;
    --width-24: 20px;
    --width-20: 16px;
    --width-18: 14px;
    --width-16: 12px;
    --width-label-md: 52px;
  }
}

#mount * {
  box-sizing: border-box;
}

[hidden] {
  display: none !important;
}

:where(#mount) a,
:where(#mount) [role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
:where(#mount) a:is([aria-current], :hover, :active, :focus),
:where(#mount) [role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}

:where(#mount) label {
  font-size: 13px;
  line-height: 1.3;
  color: var(--text-gray-2, #222222);
}

:where(#mount) button {
  width: 100%;
  font-family: inherit;
  font-size: 15px;
  line-height: 1.3;
  min-height: 44px;
  border-radius: 12px;
  padding: 0 14px;
  border: none;
  background-color: var(--primary, #ea4c89);
  color: #ffffff;
  cursor: pointer;
  transition: background-color 0.2s ease, box-shadow 0.2s ease, color 0.2s ease;
}

:where(#mount) button:hover {
  background-color: var(--primary-hover, #f082ac);
}

:where(#mount) button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

:where(#mount) select,
:where(#mount) input,
:where(#mount) textarea {
  font-family: inherit;
  color: var(--text-gray-2, #222222);
}

:where(#mount) select {
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  font-family: inherit;
  color: var(--text-gray-2, inherit);
  font-size: 13px;
  line-height: 1.3;
  outline: none;
  padding: 8px 16px;
  border: none;
  border-radius: 12px;
  background-color: var(--popup-item-background-color, transparent);
  background-image: var(--icon-xia, none);
  background-repeat: no-repeat;
  background-position: center right 12px;
  background-size: 16px auto;
  cursor: pointer;
}

:where(#mount) input[type="checkbox"] {
  accent-color: var(--primary, #ea4c89);
}

[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

:where(#mount) [type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
:where(#mount) [type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
:where(#mount) [type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
:where(#mount) [type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
:where(#mount) [type="checkbox"][role="switch"]:checked {
  background-image: none;
}
:where(#mount) [type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

:where(#mount) [type="checkbox"][aria-invalid="false"],
:where(#mount) [type="checkbox"]:checked[aria-invalid="false"],
:where(#mount) [type="radio"][aria-invalid="false"],
:where(#mount) [type="radio"]:checked[aria-invalid="false"],
:where(#mount) [type="checkbox"][role="switch"][aria-invalid="false"],
:where(#mount) [type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(#mount) [type="checkbox"][aria-invalid="true"],
:where(#mount) [type="checkbox"]:checked[aria-invalid="true"],
:where(#mount) [type="radio"][aria-invalid="true"],
:where(#mount) [type="radio"]:checked[aria-invalid="true"],
:where(#mount) [type="checkbox"][role="switch"][aria-invalid="true"],
:where(#mount) [type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

.text-black {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.inline-flex {
  display: inline-flex;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

#mount {
  min-width: 268px;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}



.activity-tips {
  border-radius: 8px;
  padding: 0px 8px;
  min-height: 28px;
  background: linear-gradient(83deg, #FACCDE -0.87%, #FCE7EF 43.13%, #FBD6E4 72.08%, #FFB3D1 96.34%);  gap: 2px;
  color: #333;
  cursor: pointer;
  gap: 4px;
}

.activity-tips-icon {
  width: 18px;
  height: 18px;
  flex-shrink: 0;
}

.countdown-container {
  min-width: 50px;
  text-align: left;
  font-weight: 600;
  font-size: 12px;
  letter-spacing: 0.01em;
}

.activity-tips-text {
  font-weight: 600;
  max-width: 100px;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 100%;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #b3b3b3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 261px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg></div></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="opacity: 0.7; transform: translateX(15px);"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; top: 261px; right: 65px;"></div></div></div></div></template></div></html>