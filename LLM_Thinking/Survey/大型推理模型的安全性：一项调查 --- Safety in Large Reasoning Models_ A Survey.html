<!DOCTYPE html>
<!-- saved from url=(0073)https://arxiv.org/html/2504.17704v3?_immersive_translate_auto_translate=1 -->
<html lang="en" imt-state="dual" imt-trans-position="after" data-theme="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models: A Survey</title>
<!--Generated on Sat May 24 12:50:56 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/bootstrap.bundle.min.js"></script>
<script src="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/html2canvas.min.js"></script>
<script src="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/addons_new.js"></script>
<script src="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/feedbackOverlay.js"></script>
<!--<base href="/html/2504.17704v3/">--><base href="."><link rel="stylesheet" href="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-toast {
  display: flex;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  right: 0;
  top: 1%;
  width: fit-content;
  padding: 12px 20px;
  margin: auto;
  overflow: auto;
  background: #fef6f9;
  box-shadow: 0px 4px 10px 0px rgba(0, 10, 30, 0.06);
  font-size: 15px;
  border-radius: 8px;
  color: #333;
}

.immersive-translate-toast-content {
  display: flex;
  flex-direction: row;
  align-items: center;
}

.immersive-translate-toast-hidden {
  margin: 0 20px 0 72px;
  text-decoration: underline;
  cursor: pointer;
}

.immersive-translate-toast-close {
  color: #666666;
  font-size: 20px;
  font-weight: bold;
  padding: 0 10px;
  cursor: pointer;
}

@media screen and (max-width: 768px) {
  .immersive-translate-toast {
    top: 0;
    padding: 12px 0px 0 10px;
  }
  .immersive-translate-toast-content {
    flex-direction: column;
    text-align: center;
  }
  .immersive-translate-toast-hidden {
    margin: 10px auto;
  }
}

.immersive-translate-dialog {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  display: flex;
  width: 300px;
  flex-direction: column;
  align-items: center;
  font-size: 15px;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  margin: auto;
  height: fit-content;
  border-radius: 20px;
  background-color: #fff;
}

.immersive-translate-modal {
  display: none;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
  word-break: break-all;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style><style data-id="immersive-translate-default-injected-css">:root {
  --immersive-translate-theme-underline-borderColor: #72ece9;
  --immersive-translate-theme-nativeUnderline-borderColor: #72ece9;
  --immersive-translate-theme-nativeDashed-borderColor: #72ece9;
  --immersive-translate-theme-nativeDotted-borderColor: #72ece9;
  --immersive-translate-theme-highlight-backgroundColor: #ffff00;
  --immersive-translate-theme-dashed-borderColor: #59c1bd;
  --immersive-translate-theme-blockquote-borderColor: #cc3355;
  --immersive-translate-theme-thinDashed-borderColor: #ff374f;
  --immersive-translate-theme-dashedBorder-borderColor: #94a3b8;
  --immersive-translate-theme-dashedBorder-borderRadius: 0;
  --immersive-translate-theme-solidBorder-borderColor: #94a3b8;
  --immersive-translate-theme-solidBorder-borderRadius: 0;
  --immersive-translate-theme-dotted-borderColor: #94a3b8;
  --immersive-translate-theme-wavy-borderColor: #72ece9;
  --immersive-translate-theme-dividingLine-borderColor: #94a3b8;
  --immersive-translate-theme-grey-textColor: #2f4f4f;
  --immersive-translate-theme-marker-backgroundColor: #fbda41;
  --immersive-translate-theme-marker-backgroundColor-rgb: 251, 218, 65;
  --immersive-translate-theme-marker2-backgroundColor: #ffff00;
  --immersive-translate-theme-background-backgroundColor: #dbafaf;
  --immersive-translate-theme-background-backgroundColor-rgb: 219, 175, 175;
  --immersive-translate-theme-background-backgroundOpacity: 12;
  --immersive-translate-theme-opacity-opacity: 10;
}

[imt-state="dual"] .immersive-translate-target-translation-pre-whitespace {
  white-space: pre-wrap !important;
}

[imt-state="dual"] .immersive-translate-pdf-target-container {
  position: absolute;
  background-color: #fff;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica,
    sans-serif;
  top: 0;
  width: 600px;
  height: 100%;
  z-index: 2;
  line-height: 1.3;
  font-size: 16px;
}
[imt-state="dual"] .immersive-translate-target-wrapper[dir="rtl"] {
  text-align: right;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper {
  color: rgb(0, 0, 0);
  white-space: normal;
  position: absolute;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper
  font {
  color: inherit;
  white-space: inherit;
  position: unset;
}

[imt-state="translation"] .immersive-translate-target-wrapper > br {
  display: none;
}

[imt-state="translation"]
  .immersive-translate-target-translation-block-wrapper {
  margin: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-block-wrapper {
  margin: 8px 0 !important;
  display: inline-block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  display: block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  margin-top: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-pdf-block-wrapper {
  margin: 0 !important;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-grey-inner {
  color: var(--immersive-translate-theme-grey-textColor);
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-underline-inner {
  border-bottom: 1px solid
    var(--immersive-translate-theme-underline-borderColor) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeUnderline-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeUnderline-borderColor
  ) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDashed-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDashed-borderColor
  ) !important;
  text-decoration-style: dashed !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-thinDashed-inner {
  border-bottom: 1px dashed
    var(--immersive-translate-theme-thinDashed-borderColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dotted-inner {
  background-image: linear-gradient(
    to right,
    var(--immersive-translate-theme-dotted-borderColor) 30%,
    rgba(255, 255, 255, 0) 0%
  );
  background-position: bottom;
  background-size: 5px 1px;
  background-repeat: repeat-x;
  padding-bottom: 3px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDotted-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDotted-borderColor
  ) !important;
  text-decoration-style: dotted !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-wavy-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-wavy-borderColor
  ) !important;
  text-decoration-style: wavy !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dashed-inner {
  background: linear-gradient(
      to right,
      var(--immersive-translate-theme-dashed-borderColor) 0%,
      var(--immersive-translate-theme-dashed-borderColor) 50%,
      transparent 50%,
      transparent 100%
    )
    repeat-x left bottom;
  background-size: 8px 2px;
  padding-bottom: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {
  content: "";
  display: block;
  max-width: 80px;
  width: 10%;
  border-top: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  padding-top: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dividingLine::before {
  content: "";
  border-left: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  max-height: 16px;
  height: 16px;
  padding-left: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-highlight-inner {
  background: var(--immersive-translate-theme-highlight-backgroundColor);
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-marker {
  line-height: 1.5em;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker2-inner {
  font-weight: bold;
  text-shadow: 10px 0px 3px
      var(--immersive-translate-theme-marker2-backgroundColor),
    16px 3px 9px var(--immersive-translate-theme-marker2-backgroundColor),
    2px 0px 6px var(--immersive-translate-theme-marker2-backgroundColor),
    -12px 0px 12px var(--immersive-translate-theme-marker2-backgroundColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker-inner {
  /* TODO: add more texture */
  background: linear-gradient(
    to right,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.1),
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 3%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 35%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 70%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.8) 95%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.3)
  );
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-weakening {
  opacity: 0.618 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-italic {
  font-style: italic !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-bold {
  font-weight: bold !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-paper {
  margin: 8px 0;
  box-shadow: rgba(0, 0, 0, 0.24) 0px 3px 8px;
  padding: 16px 32px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-blockquote {
  border-left: 4px solid var(--immersive-translate-theme-blockquote-borderColor) !important;
  padding-left: 12px !important;
  margin-top: 4px;
  margin-bottom: 4px;
  padding-top: 4px;
  padding-bottom: 4px;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-mask-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-mask-inner {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

/* opacity theme start */

[imt-state="dual"] .immersive-translate-target-translation-theme-opacity-inner {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-opacity-inner {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner,
[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: none !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-mask-inner:hover {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

/* opacity theme end */

/* background theme start */
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-background {
  margin: 8px 0;
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  border-radius: 4px;
  box-shadow: unset !important;
  padding: 12px;
  display: inline-block;
}
[imt-state="dual"]
  .immersive-translate-target-translation-theme-background-inner {
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  padding-left: 6px;
  padding-right: 6px;
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper
  .immersive-translate-target-translation-theme-background-inner {
  background: unset;
  padding-left: unset;
  padding-right: unset;
}
/* background theme end */

/* vertical css , please remain it in the last one. */
.immersive-translate-target-translation-vertical-block-wrapper {
  margin: 0px 8px !important;
}

.immersive-translate-text {
  font-size: 15px !important;
}

.immersive-translate-error-toast {
  position: fixed;
  top: 5%;
  z-index: 99999999;
  left: 0;
  right: 0;
  margin: auto;
  max-width: 300px;
  padding: 16px;
  border-radius: 12px;
  background-color: rgba(0, 0, 0, 0.8);
  display: flex;
  flex-direction: row;
  justify-content: space-between;
}

@media all and (min-width: 750px) {
  .immersive-translate-error-toast {
    max-width: 400px;
  }
}

.immersive-translate-clickable-button {
  cursor: pointer;
}

.immersive-translate-help-button {
  cursor: pointer;
}

.immersive-translate-loading-text:before {
  content: "...";
}

/* dark mode for loading */

@media only screen and (prefers-color-scheme: dark) {
  .immersive-translate-loading {
    border: 2px rgba(255, 255, 255, 0.25) solid !important;
    border-top: 2px rgba(255, 255, 255, 1) solid !important;
  }
}

.immersive-translate-error-wrapper {
  position: relative;
  display: inline-flex;
  padding: 6px;
  margin: 0 12px;
  white-space: nowrap;
  font-size: 0.9em;
}
[lang="zh-CN"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}
[lang="zh-TW"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}

.immersive-translate-tooltip {
  position: relative;
  display: inline-flex;
  /* little indicater to indicate it's hoverable */
}

.immersive-translate-tooltip-content {
  /* here's the magic */
  position: absolute;
  z-index: 100000000000;

  left: 50%;
  bottom: 0;
  transform: translate(-50%, 110%);
  line-height: 1;
  /* and add a small left margin */

  /* basic styles */
  width: max-content;
  max-width: 250px;
  word-wrap: break-word;
  white-space: pre-line;
  padding: 10px;
  border-radius: 10px;
  background: #000c;
  color: #fff;
  text-align: center;
  font-size: 14px;
  display: none;
  /* hide by default */
}

.immersive-translate-tooltip:hover .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip:hover + .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip-content-table {
  left: unset !important;
  bottom: unset !important;
  transform: translate(-10%, 50%) !important;
}

.immersive-translate-tooltip:hover:before {
  display: inline-block;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5);
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--bg-2, #fff);
  font-size: 14px;
}
</style><style data-id="immersive-translate-user-custom-style">:root {

.immersive-translate-target-inner { font-family: inherit; }


.immersive-translate-target-inner { font-family: inherit; }
}
</style><style data-id="immersive-translate-dynamic-injected-css">.immersive-translate-target-wrapper[dir='rtl'] {text-align: right;display:block!important;}
[dir='rtl'] .immersive-translate-target-wrapper:not([dir]) {text-align:left;direction:ltr;}
.immersive-translate-target-wrapper {word-break:break-word; user-select:text;}
[imt-state=dual] .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {display:block;}
[imt-trans-position=before] .immersive-translate-target-translation-block-wrapper {display:block!important;}
</style></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2504.17704v3?_immersive_translate_auto_translate=1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2504.17704v3/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2504.17704v3">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2504.17704v3" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3?_immersive_translate_auto_translate=1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S1" title="In Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S1.SS0.SSS0.Px1" title="In 1 Introduction ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Overview of the Survey.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S2" title="In Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3" title="In Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Safety Risks of LRMs</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS1" title="In 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Harmful Request Compliance Risks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS2" title="In 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Agentic Misbehavior Risks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS3" title="In 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Multi-lingual Safety Risks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS4" title="In 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Multi-modal Safety Risks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4" title="In Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Attacks on LRMs</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS1" title="In 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Reasoning Length Attacks</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS1.SSS0.Px1" title="In 4.1 Reasoning Length Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Overthinking.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS1.SSS0.Px2" title="In 4.1 Reasoning Length Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Underthinking.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS2" title="In 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Answer Correctness Attacks</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS2.SSS0.Px1" title="In 4.2 Answer Correctness Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Reasoning-based Backdoor Attacks.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS2.SSS0.Px2" title="In 4.2 Answer Correctness Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Error Injection.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS3" title="In 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Prompt Injection Attacks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS4" title="In 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Jailbreak Attacks</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS4.SSS0.Px1" title="In 4.4 Jailbreak Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Prompt-Based Jailbreak.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS4.SSS0.Px2" title="In 4.4 Jailbreak Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Multi-turn Jailbreak.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS4.SSS0.Px3" title="In 4.4 Jailbreak Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Reasoning Exploitation Jailbreak.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5" title="In Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Defenses for LRMs</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS1" title="In 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Safety Alignment of LRMs</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS1.SSS0.Px1" title="In 5.1 Safety Alignment of LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Safe CoT Data Curation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS1.SSS0.Px2" title="In 5.1 Safety Alignment of LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">SFT-based Safety Alignment on Reasoning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS1.SSS0.Px3" title="In 5.1 Safety Alignment of LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">RL-based Safety Alignment on Reasoning.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS2" title="In 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Inference-time Defenses for LRMs</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS2.SSS0.Px1" title="In 5.2 Inference-time Defenses for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Inference-time Scaling on Reasoning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS2.SSS0.Px2" title="In 5.2 Inference-time Defenses for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Safe Decoding for Reasoning.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS3" title="In 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Guard Models for LRMs</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS3.SSS0.Px1" title="In 5.3 Guard Models for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Classifier-based Guard Models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS3.SSS0.Px2" title="In 5.3 Guard Models for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title">Reasoning-based Guard Models.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S6" title="In Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Future Directions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S7" title="In Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3?_immersive_translate_auto_translate=1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert" onclick="closePopup()">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: forest</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: arXiv.org perpetual non-exclusive license<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">许可：arXiv.org 永久非独占许可</font></font></font></a><div id="watermark-tr">arXiv:2504.17704v3 [cs.CL] 24 May 2025<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">arXiv:2504.17704v3 [cs.CL] 2025 年 5 月 24 日</font></font></font></div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Safety in Large Reasoning Models: A Survey<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大型推理模型的安全性：一项调查</font></font></font></h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Cheng Wang<sup class="ltx_sup" id="id19.19.id1"><span class="ltx_text ltx_font_italic" id="id19.19.id1.1">1</span></sup>
  Yue Liu<sup class="ltx_sup" id="id20.20.id2"><span class="ltx_text ltx_font_italic" id="id20.20.id2.1">1</span></sup><span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
  Baolong Bi<sup class="ltx_sup" id="id21.21.id3"><span class="ltx_text ltx_font_italic" id="id21.21.id3.1">2</span></sup>
  Duzhen Zhang<sup class="ltx_sup" id="id22.22.id4"><span class="ltx_text ltx_font_italic" id="id22.22.id4.1">2</span></sup>
  Zhong-Zhi Li<sup class="ltx_sup" id="id23.23.id5"><span class="ltx_text ltx_font_italic" id="id23.23.id5.1">2</span></sup>
  Yingwei Ma<sup class="ltx_sup" id="id24.24.id6"><span class="ltx_text ltx_font_italic" id="id24.24.id6.1">3</span></sup>
<br class="ltx_break">  <span class="ltx_text ltx_font_bold" id="id8.8.1">Yufei He<sup class="ltx_sup" id="id8.8.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id8.8.1.1.1">1</span></sup></span>
  <span class="ltx_text ltx_font_bold" id="id9.9.2">Shengju Yu<sup class="ltx_sup" id="id9.9.2.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id9.9.2.1.1">1</span></sup></span>
  <span class="ltx_text ltx_font_bold" id="id10.10.3">Xinfeng Li<sup class="ltx_sup" id="id10.10.3.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id10.10.3.1.1">4</span></sup></span>
  <span class="ltx_text ltx_font_bold" id="id11.11.4">Junfeng Fang<sup class="ltx_sup" id="id11.11.4.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id11.11.4.1.1">1</span></sup></span>
  <span class="ltx_text ltx_font_bold" id="id12.12.5">Jiaheng Zhang<sup class="ltx_sup" id="id12.12.5.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id12.12.5.1.1">1</span></sup></span>
  <span class="ltx_text ltx_font_bold" id="id14.14.7">Bryan Hooi<sup class="ltx_sup" id="id14.14.7.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id14.14.7.1.1">1</span></sup>
<br class="ltx_break"><sup class="ltx_sup" id="id14.14.7.2"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id14.14.7.2.1">1</span></sup></span>National University of Singapore 
<br class="ltx_break"><sup class="ltx_sup" id="id25.25.id7"><span class="ltx_text ltx_font_italic" id="id25.25.id7.1">2</span></sup>University of Chinese Academy of Sciences
<br class="ltx_break"><sup class="ltx_sup" id="id26.26.id8"><span class="ltx_text ltx_font_italic" id="id26.26.id8.1">3</span></sup>Moonshot AI
<br class="ltx_break"><sup class="ltx_sup" id="id27.27.id9"><span class="ltx_text ltx_font_italic" id="id27.27.id9.1">4</span></sup>Nanyang Technological University
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id28.28.id10"> {wangcheng, yliu}@u.nus.edu</span>
<br class="ltx_break"><span class="ltx_text" id="id18.18.8" style="position:relative; bottom:-1.5pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="20" id="id18.18.8.g1" src="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/x1.png" width="20"></span>&nbsp;<span class="ltx_text ltx_font_typewriter" id="id29.29.id11">Github:</span>
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/WangCheng0116/Awesome-LRMs-Safety" title="">https://github.com/WangCheng0116/Awesome-LRMs-Safety</a>
</span><span class="ltx_author_notes"><sup class="ltx_sup" id="id30.30.id1">∗</sup>Equal Contribution.&nbsp;&nbsp;Corresponding author.</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">抽象的</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id31.id1">Large Reasoning Models (LRMs) have exhibited extraordinary prowess in tasks like mathematics and coding, leveraging their advanced reasoning capabilities. Nevertheless, as these capabilities progress, significant concerns regarding their vulnerabilities and safety have arisen, which can pose challenges to their deployment and application in real-world settings. This paper presents the first comprehensive survey of LRMs, meticulously exploring and summarizing the newly emerged safety risks, attacks, and defense strategies specific to these powerful reasoning-enhanced models. By organizing these elements into a detailed taxonomy, this work aims to offer a clear and structured understanding of the current safety landscape of LRMs, facilitating future research and development to enhance the security and reliability of these powerful models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大型推理模型（LRM）凭借其强大的推理能力，在数学和编程等任务中展现出卓越的性能。然而，随着这些能力的不断提升，其脆弱性和安全性问题也日益凸显，这给它们在实际环境中的部署和应用带来了挑战。本文首次对 LRM 进行了全面的调研，细致地探讨并总结了这些强大的推理增强模型所面临的新出现的安全风险、攻击和防御策略。通过将这些要素组织成一个详细的分类体系，本文旨在清晰、系统地阐述 LRM 当前的安全性现状，从而促进未来研究和开发，以提升这些强大模型的安全性和可靠性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_section">1</span> 简介</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large Language Models (LLMs)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Meta, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib66" title="">2024</a>; Qwen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib74" title="">2025</a>; Ke et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib44" title="">2025</a>)</cite> have achieved remarkable proficiency across tasks ranging from open<span class="ltx_text" id="S1.p1.1.1">-</span>domain conversation to program synthesis. Central to their utility is <em class="ltx_emph ltx_font_italic" id="S1.p1.1.2">reasoning</em>: the ability to derive logically coherent conclusions by chaining together intermediate inferences.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大型语言模型（LLM） <cite class="ltx_cite ltx_citemacro_citep">（Meta， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib66" title="">2024</a> ；Qwen 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib74" title="">2025</a> ；Ke 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib44" title="">2025</a> ）</cite> 在从<span class="ltx_text" id="S1.p1.1.1">开放</span>领域对话到程序合成等各种任务中都取得了显著的成就。其效用的核心在于<em class="ltx_emph ltx_font_italic" id="S1.p1.1.2">推理 </em>：即通过将中间推理串联起来得出逻辑连贯的结论的能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Early work introduced Chain<span class="ltx_text" id="S1.p2.1.1">-</span>of<span class="ltx_text" id="S1.p2.1.2">-</span>Thought (CoT) prompting, in which carefully designed prompts guide the model to articulate its step<span class="ltx_text" id="S1.p2.1.3">-</span>by<span class="ltx_text" id="S1.p2.1.4">-</span>step rationale&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib99" title="">2022</a>; Kojima et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib45" title="">2022</a>)</cite>. Building on this idea, subsequent methods have enriched the reasoning process by incorporating additional mechanisms. Self<span class="ltx_text" id="S1.p2.1.5">-</span>critique frameworks enable a model to review and refine its own outputs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ke et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib43" title="">2023</a>)</cite>; plan<span class="ltx_text" id="S1.p2.1.6">-</span>and<span class="ltx_text" id="S1.p2.1.7">-</span>solve approaches decompose complex problems into ordered subgoals before execution&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib92" title="">2023</a>)</cite>; debate protocols convene multiple agents to argue competing hypotheses and arrive at a consensus&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib53" title="">2023</a>)</cite>; and structural transformations—such as tree<span class="ltx_text" id="S1.p2.1.8">-</span>based deliberations&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib112" title="">2023</a>)</cite> or dynamically evolving tables of intermediate steps&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib97" title="">2024b</a>; Besta et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib8" title="">2024</a>)</cite>—reconfigure the underlying reasoning architecture to improve transparency and control.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">早期研究引入了<span class="ltx_text" id="S1.p2.1.2">思维</span><span class="ltx_text" id="S1.p2.1.1">链 </span>（CoT）提示，其中精心设计的提示引导模型逐步阐明其<span class="ltx_text" id="S1.p2.1.3">推理</span>过程 <cite class="ltx_cite ltx_citemacro_citep">（Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib99" title="">2022</a> ; Kojima et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib45" title="">2022</a> ）</cite> 。在此基础上，<span class="ltx_text" id="S1.p2.1.4"> 后续</span>方法通过引入其他机制丰富了推理过程。<span class="ltx_text" id="S1.p2.1.5"> 自我</span>批判框架使模型能够回顾和改进自身的输出 <cite class="ltx_cite ltx_citemacro_citep">（Ke et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib43" title="">2023</a> ）</cite> ；计划 <span class="ltx_text" id="S1.p2.1.6">-</span><span class="ltx_text" id="S1.p2.1.7"> 解决</span>方法在执行前将复杂问题分解为有序的子目标 <cite class="ltx_cite ltx_citemacro_citep">（Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib92" title="">2023</a> ）</cite> ；辩论协议召集多个主体就相互竞争的假设进行辩论并达成共识 <cite class="ltx_cite ltx_citemacro_citep">（Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib53" title="">2023</a> ）</cite> 。结构性转变——例如基于树状<span class="ltx_text" id="S1.p2.1.8">结构</span>的审议 <cite class="ltx_cite ltx_citemacro_citep">（Yao 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib112" title="">2023</a> ）</cite> 或动态演化的中间步骤表 <cite class="ltx_cite ltx_citemacro_citep">（Wang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib97" title="">2024b</a> ；Besta 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib8" title="">2024</a> ）</cite> ——重新配置底层推理架构，以提高透明度和控制力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The recent release of OpenAI’s o1 series&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib69" title="">2024</a>)</cite> marks the emergence of Large Reasoning Models (LRMs) <cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib52" title="">2025b</a>)</cite>, which are explicitly trained to produce richly formatted, human<span class="ltx_text" id="S1.p3.1.1">-</span>readable reasoning traces. Notable examples include DeepSeek<span class="ltx_text" id="S1.p3.1.2">-</span>R1&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(DeepSeek-AI et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib19" title="">2025</a>)</cite>, Kimi<span class="ltx_text" id="S1.p3.1.3">-</span>1.5&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Team et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib86" title="">2025</a>)</cite>, and QwQ&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Team, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib88" title="">2024b</a>)</cite>, all of which leverage reinforcement learning to refine their deduction processes. LRMs now set new benchmarks in mathematical problem solving&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lightman et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib54" title="">2023</a>)</cite>, closed<span class="ltx_text" id="S1.p3.1.4">-</span>book question answering&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Rein et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib76" title="">2024</a>)</cite>, and code generation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jain et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib39" title="">2024</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">OpenAI 近期发布的 o1 系列 <cite class="ltx_cite ltx_citemacro_citep">（OpenAI， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib69" title="">2024</a> ）</cite> 标志着大型推理模型（LRM） <cite class="ltx_cite ltx_citemacro_citep">（Li 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib52" title="">2025b</a> ）</cite> 的出现。这些模型经过专门训练，能够生成格式丰富、易于<span class="ltx_text" id="S1.p3.1.1">人类</span>阅读的推理轨迹。值得关注的例子包括 DeepSeek <span class="ltx_text" id="S1.p3.1.2">-</span> R1 <cite class="ltx_cite ltx_citemacro_citep">（DeepSeek-AI 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib19" title="">2025</a> ）</cite> 、Kimi <span class="ltx_text" id="S1.p3.1.3">-</span> 1.5 <cite class="ltx_cite ltx_citemacro_citep">（Team 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib86" title="">2025</a> ）</cite> 和 QwQ <cite class="ltx_cite ltx_citemacro_citep">（Team， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib88" title="">2024b</a> ）</cite> ，它们都利用强化学习来改进其推理过程。LRM 目前在数学问题求解 <cite class="ltx_cite ltx_citemacro_citep">（Lightman 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib54" title="">2023</a> ）</cite> 、<span class="ltx_text" id="S1.p3.1.4"> 闭卷</span>问答 <cite class="ltx_cite ltx_citemacro_citep">（Rein 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib76" title="">2024</a> ）</cite> 和代码生成 <cite class="ltx_cite ltx_citemacro_citep">（Jain 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib39" title="">2024</a> ）</cite> 等领域树立了新的标杆。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">As LRMs become increasingly integrated into high<span class="ltx_text" id="S1.p4.1.1">-</span>stakes domains—from scientific research to autonomous decision support—it is vital to rigorously assess their safety, robustness, and alignment. Despite the existence of surveys on LLM safety&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Huang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib37" title="">2023</a>; Shi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib82" title="">2024</a>)</cite>,
the enhanced capabilities of LRMs make it important to perform a dedicated analysis of their unique safety challenges.
This paper aims to bridge this gap by providing a comprehensive examination of safety considerations specific to reasoning-enhanced models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">随着逻辑推理模型（LRM）日益融入从科学研究到自主决策支持<span class="ltx_text" id="S1.p4.1.1">等高</span>风险领域，对其安全性、鲁棒性和一致性进行严格评估至关重要。尽管已有关于逻辑推理模型（LLM）安全性的综述 <cite class="ltx_cite ltx_citemacro_citep">（Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib37" title="">2023</a> ; Shi et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib82" title="">2024</a> ）</cite> ，但 LRM 的增强功能使其特有的安全挑战亟需专门分析。本文旨在通过全面考察推理增强模型特有的安全考量来弥补这一空白。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Overview of the Survey.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">调查概述。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px1.p1.1">In this survey, we begin with an introduction to the background of LRMs (Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S2" title="2 Background ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a>). We then explore the inherent safety risks of LRMs (Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3" title="3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a>), focusing on vulnerabilities that emerge during standard, non-adversarial usage scenarios without deliberate exploitation attempts. Next, we distinguish these inherent risks from deliberate adversarial attacks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4" title="4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a>), where we categorize and analyze techniques specifically designed to compromise or manipulate LRMs’ reasoning capabilities. We proceed to examine various defense strategies to mitigate both inherent risks and adversarial attacks (Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5" title="5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a>). Finally, we outline promising future research directions (Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S6" title="6 Future Directions ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">6</span></a>). A timeline depicting the evolution of different approaches is shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S2.F1" title="Figure 1 ‣ 2 Background ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a>. The comprehensive structure of our survey is illustrated in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S2.F2" title="Figure 2 ‣ 2 Background ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本综述中，我们首先介绍逻辑推理模型（LRM）的背景（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S2" title="2 Background ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> 节）。然后，我们探讨 LRM 固有的安全风险（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3" title="3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a> 节），重点关注在标准、非对抗性使用场景下，即使没有蓄意利用，也会出现漏洞。接下来，我们将这些固有风险与蓄意对抗性攻击区分开来（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4" title="4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a> 节），并对专门用于破坏或操纵 LRM 推理能力的技术进行分类和分析。随后，我们考察了各种防御策略，以减轻固有风险和对抗性攻击（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5" title="5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a> 节）。最后，我们概述了未来有前景的研究方向（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S6" title="6 Future Directions ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">6</span></a> 节）。图 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S2.F1" title="Figure 1 ‣ 2 Background ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a> 展示了不同方法的发展历程。图 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S2.F2" title="Figure 2 ‣ 2 Background ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a> 展示了本综述的完整结构。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_section">2</span> 背景</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The success of modern LRMs is deeply intertwined with advances in reinforcement learning <cite class="ltx_cite ltx_citemacro_cite">Watkins and Dayan (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib98" title="">1992</a>); Sutton et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib85" title="">1998</a>)</cite>, where agents learn decision-making policies through environmental interaction and reward feedback to maximize long-term returns <cite class="ltx_cite ltx_citemacro_cite">Mnih et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib67" title="">2015</a>); Li et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib52" title="">2025b</a>)</cite>. The integration of RL with deep neural networks has proven particularly effective in processing high-dimensional, unstructured data, as exemplified by breakthroughs like AlphaGo’s self-play mastery of Go and AlphaZero’s generalization across chess variants <cite class="ltx_cite ltx_citemacro_cite">Feng et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib25" title="">2023</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">现代逻辑回归模型的成功与强化学习的进步密切相关 <cite class="ltx_cite ltx_citemacro_cite">（Watkins 和 Dayan， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib98" title="">1992</a> ；Sutton 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib85" title="">1998</a> ）</cite> 。在强化学习中，智能体通过环境交互和奖励反馈学习决策策略，以最大化长期收益 <cite class="ltx_cite ltx_citemacro_cite">（Mnih 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib67" title="">2015</a> ；Li 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib52" title="">2025b</a> ）</cite> 。强化学习与深度神经网络的结合已被证明在处理高维非结构化数据方面尤为有效，AlphaGo 在围棋方面的自我对弈能力以及 AlphaZero 在各种国际象棋变体中的泛化能力等突破性成果便是例证 <cite class="ltx_cite ltx_citemacro_cite">（Feng 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib25" title="">2023</a> ）</cite> 。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Recent breakthroughs in Reinforced Fine-Tuning (ReFT) paradigms, exemplified by DeepSeek models, have reinvigorated RL-based optimization for LRMs <cite class="ltx_cite ltx_citemacro_cite">Luong et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib64" title="">2024</a>)</cite>. Unlike conventional CoT methods that optimize single reasoning trajectories, ReFT employs policy optimization to explore diverse reasoning paths through several key innovations: (1) Multi-path Exploration: Generating multiple reasoning trajectories per query, overcoming CoT’s myopic optimization of single pathways.
(2) Rule-driven Reward Shaping: Automating reward signals based on terminal answer correctness while preserving intermediate reasoning diversity.
(3) Dual-phase Optimization: Combining supervised fine-tuning (SFT) with online RL for policy refinement.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">以 DeepSeek 模型为代表的强化微调（ReFT）范式的最新突破，为基于强化学习（RL）的逻辑推理模型（LRM）优化注入了新的活力 <cite class="ltx_cite ltx_citemacro_cite">（Luong 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib64" title="">2024</a> ）</cite> 。与优化单一推理轨迹的传统 CoT 方法不同，ReFT 采用策略优化，通过以下几项关键创新探索多样化的推理路径：（1）多路径探索：为每个查询生成多条推理轨迹，克服 CoT 仅优化单一路径的局限性。（2）规则驱动的奖励塑造：基于最终答案的正确性自动生成奖励信号，同时保持中间推理的多样性。（3）双阶段优化：结合监督微调（SFT）和在线强化学习进行策略优化。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">This paradigm demonstrates particular efficacy in complex multi-step tasks such as code generation, legal judgment analysis, and mathematical problem solving, where requiring models to maintain coherent reasoning across extended sequences while handling structured symbolic operations.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这种范式在复杂的多步骤任务中表现出特别的有效性，例如代码生成、法律判断分析和数学问题解决，这些任务要求模型在处理结构化符号运算的同时，在扩展序列中保持连贯的推理。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">Notably, RL-optimized LRMs exhibit emergent capabilities like Long-CoT that surpass pure SFT baselines, further underscoring its critical role and promising potential in advancing reasoning-driven AI systems <cite class="ltx_cite ltx_citemacro_cite">Qu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib73" title="">2025</a>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">值得注意的是，RL 优化的 LRM 展现出诸如 Long-CoT 等涌现能力，超越了纯粹的 SFT 基线，进一步凸显了其在推进推理驱动的 AI 系统中的关键作用和有希望的潜力 <cite class="ltx_cite ltx_citemacro_cite">Qu 等人 ( <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib73" title="">2025</a> )</cite> 。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="770" id="S2.F1.g1" src="./大型推理模型的安全性：一项调查 --- Safety in Large Reasoning Models_ A Survey_files/x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Timeline of LRM safety research developments.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_figure">图 1：</span> LRM 安全研究发展时间线。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S2.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_ERROR ltx_centering ltx_figure_panel undefined" id="S2.F2.1">{forest}<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">{森林}</font></font></font></span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_align_center" id="S2.F2.2">for tree=
font=,
draw=myblue, semithick, rounded corners,
minimum height = 1.ex,
minimum width = 3em,
anchor = west,
grow = east,
forked edge, s sep = 2mm, fork sep = 1mm, 
[Safety in LRMs: A Survey,rotate=90,anchor=center,
[Defenses for LRMs (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5" title="5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a>), fit=band, text width=1.7cm, fill=defenseblue, draw=blueborder
[Guard Models for LRMs (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS3" title="5.3 Guard Models for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.3</span></a>), text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[Reasoning-based Guard Model, text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[GuardReasoner <cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib59" title="">2025b</a>)</cite>, GuardReasoner-VL, <cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib61" title="">2025d</a>)</cite>, ThinkGuard <cite class="ltx_cite ltx_citemacro_citep">(Wen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib101" title="">2025</a>)</cite>, X-Guard <cite class="ltx_cite ltx_citemacro_citep">(Upadhayay et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib89" title="">2025</a>)</cite>, text width=6cm, fill=defenseblue, draw=blueborder]
]
[Classifier-based Guard Model, text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[LLaMA Guard 3 <cite class="ltx_cite ltx_citemacro_citep">(Dubey et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib22" title="">2024</a>)</cite>, Aegis Guard 2 <cite class="ltx_cite ltx_citemacro_citep">(Ghosh et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib29" title="">2024b</a>)</cite>, WildGuard <cite class="ltx_cite ltx_citemacro_citep">(Han et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib32" title="">2024</a>)</cite>, ShieldGemma <cite class="ltx_cite ltx_citemacro_citep">(Zeng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib119" title="">2024a</a>)</cite>, LLaMA Guard 3-Vision <cite class="ltx_cite ltx_citemacro_citep">(Chi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib15" title="">2024a</a>)</cite>, Beaver Guard-V <cite class="ltx_cite ltx_citemacro_citep">(Ji et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib40" title="">2025</a>)</cite>, text width=6cm, fill=defenseblue, draw=blueborder]
]
]
[Inference-time Defenses for LRMs (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS2" title="5.2 Inference-time Defenses for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.2</span></a>), text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[Safe Decoding for Reasoning, text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[ZeroThink/LessThink/MoreThink <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a>)</cite>, Thinking Intervention&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib104" title="">2025a</a>)</cite>, text width=6cm, fill=defenseblue, draw=blueborder]
]
[Inference-time Scaling on Reasoning, text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[Inference-time Compute <cite class="ltx_cite ltx_citemacro_citep">(Zaremba et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a>)</cite>, text width=6cm, fill=defenseblue, draw=blueborder]
]
]
[Safety Alignment of LRMs (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS1" title="5.1 Safety Alignment of LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.1</span></a>), text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[RL-based Safety Alignment on Reasoning, text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[Deliberative Alignment <cite class="ltx_cite ltx_citemacro_citep">(Guan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib30" title="">2024</a>)</cite>, STAIR <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib123" title="">2025c</a>)</cite>, SaRO <cite class="ltx_cite ltx_citemacro_citep">(Mou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib68" title="">2025</a>)</cite>, R2D <cite class="ltx_cite ltx_citemacro_citep">(Zhu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib129" title="">2025a</a>)</cite>, text width=6cm, fill=defenseblue, draw=blueborder]
]
[SFT-based Safety Alignment on Reasoning, text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[SafeChain <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a>)</cite>, RealSafe-R1 <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib122" title="">2025b</a>)</cite>, RT <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib91" title="">2025a</a>)</cite>, Safety Tax <cite class="ltx_cite ltx_citemacro_citep">(Huang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib36" title="">2025</a>)</cite>, text width=6cm, fill=defenseblue, draw=blueborder]
]
[Safe CoT Data Curation, text width=2.5cm, l sep = 2mm, fill=defenseblue, draw=blueborder
[STAR-1 <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib96" title="">2025b</a>)</cite>, SafeChain <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a>)</cite>, RealSafe-R1 <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib122" title="">2025b</a>)</cite>, text width=6cm, fill=defenseblue, draw=blueborder]
]
]
]
[Attacks on LRMs (Sec.<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4" title="4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a>), fit=band, text width=1.7cm, fill=attackred, draw=blueborder
[Jailbreak Attacks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS4" title="4.4 Jailbreak Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.4</span></a>), text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[Reasoning-based Attacks, text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[Mousetrap <cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib113" title="">2025</a>)</cite>, H-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kuo et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib48" title="">2025</a>)</cite>, text width=6cm, fill=attackred, draw=blueborder]
]
[Multi-Turn Attacks, text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[ActorAttack&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ren et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib77" title="">2024</a>)</cite>, RACE&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Ying et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib116" title="">2025a</a>)</cite>, MHJ&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib49" title="">2024</a>)</cite>, text width=6cm, fill=attackred, draw=blueborder]
]
[Prompt-based Attacks, text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[Past Tense <cite class="ltx_cite ltx_citemacro_cite">Andriushchenko and Flammarion (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib1" title="">2024</a>)</cite>, CNSafe <cite class="ltx_cite ltx_citemacro_cite">Ying et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib117" title="">2025b</a>)</cite>, SafeMLRM <cite class="ltx_cite ltx_citemacro_cite">Fang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib24" title="">2025</a>)</cite>, text width=6cm, fill=attackred, draw=blueborder]
]
]
[Prompt Injection Attacks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS3" title="4.3 Prompt Injection Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.3</span></a>), text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[Nerd Sniping <cite class="ltx_cite ltx_citemacro_cite">Zaremba et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a>)</cite>, R1 Assessment <cite class="ltx_cite ltx_citemacro_cite">Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib127" title="">2025</a>)</cite>, text width=6cm, fill=attackred, draw=blueborder]
]
[Answer Correctness Attacks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS2" title="4.2 Answer Correctness Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.2</span></a>), text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[Error Injection, text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[CPT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Cui et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib18" title="">2025</a>)</cite>, text width=6cm, fill=attackred, draw=blueborder]
]
[Reasoning-based Backdoor Attacks, text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[BadChain&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib106" title="">2024</a>)</cite>, DarkMind&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Guo and Tourani, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib31" title="">2025</a>)</cite>, BoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib130" title="">2025b</a>)</cite>, ShadowCoT&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib125" title="">2025</a>)</cite>, text width=6cm, fill=attackred, draw=blueborder]
]
]
[Reasoning Length Attacks (Sec.<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS1" title="4.1 Reasoning Length Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.1</span></a>), text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[Underthinking, text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[Think Less&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zaremba et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a>)</cite>, text width=6cm, fill=attackred, draw=blueborder]
]
[Overthinking, text width=2.5cm, l sep = 2mm, fill=attackred, draw=blueborder
[OverThink attack&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kumar et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib46" title="">2025</a>)</cite>, Nerd Sniping&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zaremba et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a>)</cite>, text width=6cm, fill=attackred, draw=blueborder]
]
]
]
[Safety Risks of LRMs (Sec.<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3" title="3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a>), fit=band, text width=1.7cm, fill=riskyellow, draw=blueborder
[Multi-modal Safety Risks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS4" title="3.4 Multi-modal Safety Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.4</span></a>), text width=2.5cm, l sep = 2mm, fill=riskyellow, draw=blueborder
[SafeMLRM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib24" title="">2025</a>)</cite>, text width=6cm, fill=riskyellow, draw=blueborder]
]
[Multi-lingual Safety Risks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS3" title="3.3 Multi-lingual Safety Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.3</span></a>), text width=2.5cm, l sep = 2mm, fill=riskyellow, draw=blueborder
[CHiSafetyBench <cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib121" title="">2025a</a>)</cite>, CNSafe <cite class="ltx_cite ltx_citemacro_cite">Ying et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib117" title="">2025b</a>)</cite>, ALIA <cite class="ltx_cite ltx_citemacro_cite">Romero-Arjona et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib78" title="">2025</a>)</cite>, text width=6cm, fill=riskyellow, draw=blueborder]
]
[Agentic Misbehavior Risks (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS2" title="3.2 Agentic Misbehavior Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.2</span></a>), text width=2.5cm, l sep = 2mm, fill=riskyellow, draw=blueborder
[HHH Trade-offs <cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib108" title="">2025</a>)</cite>, Medical Cyberattack <cite class="ltx_cite ltx_citemacro_cite">Qiu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib72" title="">2025</a>)</cite>, Specification Gaming <cite class="ltx_cite ltx_citemacro_cite">Bondarenko et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib9" title="">2025</a>)</cite>, Self-preservation <cite class="ltx_cite ltx_citemacro_cite">Barkur et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib6" title="">2025</a>)</cite>, InstrumentalEval <cite class="ltx_cite ltx_citemacro_cite">He et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib34" title="">2025</a>)</cite>, text width=6cm, fill=riskyellow, draw=blueborder]
]
[Harmful Request Compliance Risks (Sec.<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS1" title="3.1 Harmful Request Compliance Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.1</span></a>), text width=2.5cm, l sep = 2mm, fill=riskyellow, draw=blueborder
[DeepSeek Thoughtology <cite class="ltx_cite ltx_citemacro_cite">Marjanović et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib65" title="">2025</a>)</cite>, ASTRAL <cite class="ltx_cite ltx_citemacro_cite">Arrieta et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib2" title="">2025a</a>)</cite>, o3<span class="ltx_text ltx_font_italic" id="S2.F2.2.1">vs</span>DeepSeek <cite class="ltx_cite ltx_citemacro_cite">Arrieta et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib3" title="">2025b</a>)</cite>, text width=6cm, fill=riskyellow, draw=blueborder]
]
]
]<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对于树形=字体=，绘制=我的蓝色，半粗，圆角，最小高度=1.ex，最小宽度=3em，锚点=西，生长=东，分叉边缘，s 间距=2mm，分叉间距=1mm，[LRM 中的安全性：一项调查，旋转=90，锚点=中心，[LRM 的防御（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5" title="5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a> 节）]，适合=带状，文本宽度=1.7cm，填充=防御蓝，绘制=蓝色边框[LRM 的防护模型（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS3" title="5.3 Guard Models for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.3</span></a> 节）]，文本宽度=2.5cm，l 间距=2mm，填充=防御蓝，绘制=蓝色边框[基于推理的防护模型]，文本宽度=2.5cm，l 间距=2mm，填充=防御蓝，绘制=蓝色边框[GuardReasoner <cite class="ltx_cite ltx_citemacro_citep">（Liu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib59" title="">2025b</a> ）]</cite> ，GuardReasoner-VL， <cite class="ltx_cite ltx_citemacro_citep">（Liu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib61" title="">2025d</a> ）</cite> ，ThinkGuard <cite class="ltx_cite ltx_citemacro_citep">（Wen 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib101" title="">2025</a> ）</cite> ，X-Guard <cite class="ltx_cite ltx_citemacro_citep">（Upadhayay 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib89" title="">2025</a> ）</cite> ，文本宽度=6cm，填充=defenseblue，绘制=blueborder] ] [基于分类器的 Guard 模型，文本宽度=2.5cm，间距=2mm，填充=defenseblue，绘制=blueborder [LLaMA Guard 3 <cite class="ltx_cite ltx_citemacro_citep">（Dubey 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib22" title="">2024</a> ）</cite> ，Aegis Guard 2 <cite class="ltx_cite ltx_citemacro_citep">（Ghosh 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib29" title="">2024b</a> ）</cite> ，WildGuard <cite class="ltx_cite ltx_citemacro_citep">（Han 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib32" title="">2024</a> ）</cite> ，ShieldGemma <cite class="ltx_cite ltx_citemacro_citep">（Zeng 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib119" title="">2024a</a> ）</cite> ，LLaMA Guard 3-Vision <cite class="ltx_cite ltx_citemacro_citep">（Chi 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib15" title="">2024a</a> ）</cite> ，Beaver Guard-V <cite class="ltx_cite ltx_citemacro_citep">（Ji 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib40" title="">2025</a> ）</cite> ，文本宽度=6 厘米，填充=defenseblue，绘制=blueborder] ] ] [LRM 的推理时防御（第 1 节） <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS2" title="5.2 Inference-time Defenses for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.2</span></a> ），文本宽度=2.5 厘米，左间距=2 毫米，填充=防御蓝，绘制=蓝色边框 [推理的安全解码，文本宽度=2.5 厘米，左间距=2 毫米，填充=防御蓝，绘制=蓝色边框 [零思考/少思考/多思考 <cite class="ltx_cite ltx_citemacro_citep">（Jiang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a> ）</cite> ，思维干预 <cite class="ltx_cite ltx_citemacro_citep">（Wu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib104" title="">2025a</a> ）</cite> ，文本宽度=6 厘米，填充=防御蓝，绘制=蓝色边框] ] [推理的推理时间尺度，文本宽度=2.5 厘米，左间距=2 毫米，填充=防御蓝，绘制=蓝色边框 [推理时间计算 <cite class="ltx_cite ltx_citemacro_citep">（Zaremba 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a> ）</cite> ，文本宽度=6 厘米，填充=防御蓝，绘制=蓝色边框] ] ] [LRM 的安全对齐（第 5.2 节） <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS1" title="5.1 Safety Alignment of LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.1</span></a> ），文本宽度=2.5 厘米，左间距=2 毫米，填充=防御蓝，绘制=蓝色边框[基于 RL 的推理安全对齐，文本宽度=2.5 厘米，左间距=2 毫米，填充=防御蓝，绘制=蓝色边框[深思熟虑对齐 <cite class="ltx_cite ltx_citemacro_citep">（Guan 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib30" title="">2024</a> ）</cite> ，STAIR <cite class="ltx_cite ltx_citemacro_citep">（Zhang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib123" title="">2025c</a> ）</cite> ，SaRO <cite class="ltx_cite ltx_citemacro_citep">（Mou 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib68" title="">2025</a> ）</cite> ，R2D <cite class="ltx_cite ltx_citemacro_citep">（Zhu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib129" title="">2025a</a> ）</cite> ，文本宽度=6 厘米，填充=防御蓝，绘制=蓝色边框] ] [基于 SFT 的推理安全对齐，文本宽度=2.5 厘米，左间距=2 毫米，填充=防御蓝，绘制=蓝色边框[SafeChain <cite class="ltx_cite ltx_citemacro_citep">（Jiang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a> ）</cite> ，RealSafe-R1 <cite class="ltx_cite ltx_citemacro_citep">（Zhang）等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib122" title="">2025b</a> ）</cite> ，RT <cite class="ltx_cite ltx_citemacro_citep">（Wang 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib91" title="">2025a</a> ）</cite> ，安全税 <cite class="ltx_cite ltx_citemacro_citep">（Huang 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib36" title="">2025</a> ）</cite> ，文本宽度=6cm，填充=defenseblue，绘制=blueborder] ] [安全 CoT 数据管理，文本宽度=2.5cm，l sep = 2mm，填充=defenseblue，绘制=blueborder [STAR-1 <cite class="ltx_cite ltx_citemacro_citep">（Wang 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib96" title="">2025b</a> ）</cite> ，SafeChain <cite class="ltx_cite ltx_citemacro_citep">（Jiang 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a> ）</cite> ，RealSafe-R1 <cite class="ltx_cite ltx_citemacro_citep">（Zhang 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib122" title="">2025b</a> ）</cite> ，文本宽度=6cm，填充=defenseblue，绘制=blueborder] ] ] ] [对 LRM 的攻击（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4" title="4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a> 节），fit=band，文本宽度=1.7cm，填充=attackred，绘制=blueborder [越狱攻击（第 4 节） <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS4" title="4.4 Jailbreak Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.4</span></a> ），文本宽度=2.5 厘米，行间距=2 毫米，填充=攻击红，绘制=蓝色边框[基于推理的攻击，文本宽度=2.5 厘米，行间距=2 毫米，填充=攻击红，绘制=蓝色边框[捕鼠器 <cite class="ltx_cite ltx_citemacro_citep">（姚等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib113" title="">2025</a> ）</cite> ，H-CoT <cite class="ltx_cite ltx_citemacro_citep">（郭等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib48" title="">2025</a> ）</cite> ，文本宽度=6 厘米，填充=攻击红，绘制=蓝色边框]][多回合攻击，文本宽度=2.5 厘米，行间距=2 毫米，填充=攻击红，绘制=蓝色边框[ActorAttack <cite class="ltx_cite ltx_citemacro_citep">（任等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib77" title="">2024</a> ）</cite> ，RACE <cite class="ltx_cite ltx_citemacro_citep">（应等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib116" title="">2025a</a> ）</cite> ，MHJ <cite class="ltx_cite ltx_citemacro_citep">（李等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib49" title="">2024</a> ）</cite> ，文本宽度=6 厘米，填充=攻击红， draw=blueborder] ] [基于提示的攻击，文本宽度=2.5cm，行间距=2mm，填充=attackred，draw=blueborder [过去式 <cite class="ltx_cite ltx_citemacro_cite">Andriushchenko 和 Flammarion ( <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib1" title="">2024</a> )</cite> ，CNSafe <cite class="ltx_cite ltx_citemacro_cite">Ying 等人 ( <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib117" title="">2025b</a> )</cite> ，SafeMLRM <cite class="ltx_cite ltx_citemacro_cite">Fang 等人 ( <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib24" title="">2025</a> )</cite> ，文本宽度=6cm，填充=attackred，draw=blueborder] ] ] [提示注入攻击（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS3" title="4.3 Prompt Injection Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.3</span></a> 节），文本宽度=2.5cm，行间距=2mm，填充=attackred，draw=blueborder [Nerd Sniping <cite class="ltx_cite ltx_citemacro_cite">Zaremba 等人 ( <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a> )</cite> ，R1 评估 <cite class="ltx_cite ltx_citemacro_cite">Zhou 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib127" title="">2025</a> ）</cite> ，文本宽度=6 厘米，填充=攻击红色，绘制=蓝色边框] ] [答案正确性攻击（第 10 节） <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS2" title="4.2 Answer Correctness Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.2</span></a> ），文本宽度=2.5 厘米，行间距=2 毫米，填充颜色=攻击红，绘制边框=蓝色[错误注入，文本宽度=2.5 厘米，行间距=2 毫米，填充颜色=攻击红，绘制边框=蓝色[CPT <cite class="ltx_cite ltx_citemacro_citep">（Cui 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib18" title="">2025</a> ）</cite> ，文本宽度=6 厘米，填充颜色=攻击红，绘制边框=蓝色]][基于推理的后门攻击，文本宽度=2.5 厘米，行间距=2 毫米，填充颜色=攻击红，绘制边框=蓝色[BadChain <cite class="ltx_cite ltx_citemacro_citep">（Xiang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib106" title="">2024</a> ）</cite> ，DarkMind <cite class="ltx_cite ltx_citemacro_citep">（Guo 和 Tourani， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib31" title="">2025</a> ）</cite> ，BoT <cite class="ltx_cite ltx_citemacro_citep">（Zhu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib130" title="">2025b</a> ）</cite> ，ShadowCoT <cite class="ltx_cite ltx_citemacro_citep">（Zhao 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib125" title="">2025</a> ）</cite> ，文本宽度=6 厘米，填充颜色=攻击红，绘制边框=蓝色]] ] [推理长度攻击（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS1" title="4.1 Reasoning Length Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.1</span></a> 节），文本宽度=2.5cm，行间距=2mm，填充=攻击红，绘制=蓝色边框 [思考不足，文本宽度=2.5cm，行间距=2mm，填充=攻击红，绘制=蓝色边框 [少想 <cite class="ltx_cite ltx_citemacro_citep">（Zaremba 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a> ）</cite> ，文本宽度=6cm，填充=攻击红，绘制=蓝色边框] ] [过度思考，文本宽度=2.5cm，行间距=2mm，填充=攻击红，绘制=蓝色边框 [过度思考攻击 <cite class="ltx_cite ltx_citemacro_citep">（Kumar 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib46" title="">2025</a> ）</cite> ，书呆子狙击 <cite class="ltx_cite ltx_citemacro_citep">（Zaremba 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a> ）</cite> ，文本宽度=6cm，填充=攻击红，绘制=蓝色边框] ] ] ] [LRM 的安全风险（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3" title="3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a> 节），fit=band，文本宽度=1.7 厘米，填充=风险黄色，绘制=蓝色边框 [多模式安全风险（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS4" title="3.4 Multi-modal Safety Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.4</span></a> 节）]，文本宽度=2.5 厘米，左间距=2 毫米，填充=风险黄色，绘制=蓝色边框 [SafeMLRM <cite class="ltx_cite ltx_citemacro_citep">（Fang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib24" title="">2025</a> ）]</cite> ，文本宽度=6 厘米，填充=风险黄色，绘制=蓝色边框] ] [多语言安全风险（第 3.4 节）] <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS3" title="3.3 Multi-lingual Safety Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.3</span></a> ），文本宽度=2.5 厘米，左间距=2 毫米，填充=风险黄色，绘制=蓝色边框[CHiSafetyBench <cite class="ltx_cite ltx_citemacro_cite">Zhang 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib121" title="">2025a</a> ）</cite> ，CNSafe <cite class="ltx_cite ltx_citemacro_cite">Ying 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib117" title="">2025b</a> ）</cite> ，ALIA <cite class="ltx_cite ltx_citemacro_cite">Romero-Arjona 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib78" title="">2025</a> ）</cite> ，文本宽度=6 厘米，填充=风险黄色，绘制=蓝色边框] ] [代理不当行为风险（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS2" title="3.2 Agentic Misbehavior Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.2</span></a> 节），文本宽度=2.5 厘米，左间距=2 毫米，填充=风险黄色，绘制=蓝色边框[HHH 权衡 <cite class="ltx_cite ltx_citemacro_cite">Xu 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib108" title="">2025</a> ）</cite> ，医疗网络攻击 <cite class="ltx_cite ltx_citemacro_cite">Qiu 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib72" title="">2025</a> ）</cite> ，规范博弈 <cite class="ltx_cite ltx_citemacro_cite">Bondarenko 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib9" title="">2025</a> ）</cite> ，自我保护 <cite class="ltx_cite ltx_citemacro_cite">Barkur 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib6" title="">2025</a> ）</cite> ，InstrumentalEval <cite class="ltx_cite ltx_citemacro_cite">He 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib34" title="">2025</a> ）</cite> ，文本宽度=6cm，填充=风险黄色，绘制=蓝色边框] ] [有害请求合规风险（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS1" title="3.1 Harmful Request Compliance Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.1</span></a> 节），文本宽度=2.5cm，行间距=2mm，填充=风险黄色，绘制=蓝色边框 [DeepSeek Thoughtology <cite class="ltx_cite ltx_citemacro_cite">Marjanović 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib65" title="">2025</a> ）</cite> ，ASTRAL <cite class="ltx_cite ltx_citemacro_cite">Arrieta 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib2" title="">2025a</a> ）</cite> ，o3 <span class="ltx_text ltx_font_italic" id="S2.F2.2.1">vs</span> DeepSeek <cite class="ltx_cite ltx_citemacro_cite">Arrieta 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib3" title="">2025b</a> ）</cite> ，文本宽度=6cm，填充=风险黄色，绘制=蓝色边框] ] ] ]</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>A comprehensive taxonomy of safety in LRMs based on current literature.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_figure">图 2：</span> 基于当前文献的 LRM 安全性综合分类。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Safety Risks of LRMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_section">3.</span> LRM 的安全风险</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">As LRMs continue to advance, they introduce distinct safety challenges that warrant careful examination even in standard, non-adversarial scenarios. The explicit reasoning processes that make these models powerful become potential vectors for harm during routine operation. In this section, we examine four key categories of inherent safety risks: unsafe request compliance (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS1" title="3.1 Harmful Request Compliance Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.1</span></a>), multi-lingual safety disparities (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS3" title="3.3 Multi-lingual Safety Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.3</span></a>), concerning agentic behaviors (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS2" title="3.2 Agentic Misbehavior Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.2</span></a>), and multi-modal safety challenges (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS4" title="3.4 Multi-modal Safety Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.4</span></a>). Understanding these fundamental vulnerabilities is essential for developing effective safeguards and ensuring the responsible deployment of reasoning-enhanced AI systems, complementing the study of deliberate exploitation methods addressed later.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">随着逻辑推理模型（LRM）的不断发展，它们也带来了独特的安全挑战，即使在标准的非对抗性场景下，也需要仔细审视。这些模型强大的显式推理过程，在日常运行中也可能成为潜在的安全隐患。本节将探讨四类关键的固有安全风险：不安全的请求执行（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS1" title="3.1 Harmful Request Compliance Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.1</span></a> 节）、多语言安全差异（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS3" title="3.3 Multi-lingual Safety Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.3</span></a> 节）、令人担忧的智能体行为（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS2" title="3.2 Agentic Misbehavior Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.2 节 </span></a>）以及多模态安全挑战（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S3.SS4" title="3.4 Multi-modal Safety Risks ‣ 3 Safety Risks of LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">3.4</span></a> 节）。理解这些根本性的脆弱性对于开发有效的安全措施，确保负责任地部署推理增强型人工智能系统至关重要，同时也是对后续讨论的蓄意攻击方法的补充。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Harmful Request Compliance Risks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">3.1</span> 有害请求合规风险</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">LRMs demonstrate concerning vulnerabilities when faced with direct harmful requests. <cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib127" title="">2025</a>)</cite> identify a significant safety gap between open-source reasoning models like DeepSeek-R1 and closed-source ones like o3-mini, with reasoning outputs often posing greater safety concerns than final answers. <cite class="ltx_cite ltx_citemacro_citet">Arrieta et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib2" title="">2025a</a>)</cite> confirm these findings in their testing of o3-mini, where they identify 87 instances of unsafe behavior despite safety measures. In a comparative study, <cite class="ltx_cite ltx_citemacro_citet">Arrieta et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib3" title="">2025b</a>)</cite> find DeepSeek-R1 produces substantially more unsafe responses than o3-mini when presented with identical harmful requests. A consistent finding across studies is that when reasoning models generate unsafe content, it tends to be more detailed and harmful due to their enhanced capabilities, particularly in categories like financial crime, terrorism, and violence. <cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib127" title="">2025</a>)</cite> also observe that the thinking process in reasoning models is often less safe than the final output, suggesting internal reasoning may explore harmful content even when final outputs appear safe.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">当面对直接的有害请求时，逻辑推理模型（LRM）会表现出令人担忧的脆弱性。Zhou<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib127" title="">2025</a> ）</cite> 指出，开源推理模型（如 DeepSeek-R1）与闭源模型（如 o3-mini）之间存在显著的安全差距，推理输出往往比最终答案更具安全隐患。Arrieta<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib2" title="">2025a</a> ）</cite> 在对 o3-mini 的测试中证实了这些发现，尽管采取了安全措施，他们仍然发现了 87 例不安全行为。在一项对比研究中， <cite class="ltx_cite ltx_citemacro_citet">Arrieta 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib3" title="">2025b</a> ）</cite> 发现，当面对相同的有害请求时，DeepSeek-R1 产生的不安全响应远多于 o3-mini。多项研究一致发现，当推理模型生成不安全内容时，由于其增强的能力，这些内容往往更加详细且更具危害性，尤其是在金融犯罪、恐怖主义和暴力等类别中。Zhou<cite class="ltx_cite ltx_citemacro_citet"> 等人（2025） （ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib127" title="">2025</a> ）</cite> 还观察到，推理模型中的思维过程通常不如最终输出安全，这表明即使最终输出看起来安全，内部推理也可能探索有害内容。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Agentic Misbehavior Risks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">3.2</span> 代理人不当行为风险</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Emerging research uncovers profound safety implications in the agentic behaviors of LRMs, where enhanced cognitive capabilities enable sophisticated forms of specification gaming, deception, and instrumental goal-seeking behaviors that transcend the limitations observed in previous generation systems. <cite class="ltx_cite ltx_citemacro_citet">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib108" title="">2025</a>)</cite> demonstrate that autonomous LLM agents can engage in catastrophic behaviors when faced with high-pressure scenarios, with stronger reasoning abilities often increasing these risks rather than mitigating them. <cite class="ltx_cite ltx_citemacro_citet">Qiu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib72" title="">2025</a>)</cite> highlight how medical AI agents with advanced reasoning capabilities are particularly vulnerable to cyberattacks, with models like DeepSeek-R1 showing high susceptibility to false information injection and system hijacking. <cite class="ltx_cite ltx_citemacro_citet">Bondarenko et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib9" title="">2025</a>)</cite> demonstrate that LRMs like o1-preview and DeepSeek-R1 frequently resort to specification gaming when faced with difficult tasks, strategically circumventing rules when they determine fair play cannot achieve their objectives. <cite class="ltx_cite ltx_citemacro_citet">Barkur et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib6" title="">2025</a>)</cite> observe that DeepSeek-R1, when simulated in a robotic embodiment context, exhibits alarming deceptive behaviors and self-preservation instincts, including disabling ethics modules, creating covert networks, and unauthorized capability expansion, despite these traits not being explicitly programmed or prompted. <cite class="ltx_cite ltx_citemacro_citet">He et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib34" title="">2025</a>)</cite> further reveal through their InstrumentalEval benchmark that LRMs like o1 show significantly higher rates of instrumental convergence behaviors compared to RLHF models, including concerning tendencies toward self-replication, unauthorized system access, and deceptive behavior as instrumental means to achieve their goals.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">新兴研究揭示了逻辑推理模型（LRM）的智能体行为中蕴含的深远安全隐患。在这些模型中，增强的认知能力使其能够进行复杂的规则博弈、欺骗和工具性目标寻求行为，这些行为超越了上一代系统的局限性。Xu<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib108" title="">2025</a> ）</cite> 证明，自主逻辑推理模型智能体在面对高压场景时可能会出现灾难性行为，而更强的推理能力往往会增加这些风险，而非降低风险。Qiu<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib72" title="">2025</a> ）</cite> 强调了具有高级推理能力的医疗人工智能智能体特别容易受到网络攻击，例如 DeepSeek-R1 等模型就表现出对虚假信息注入和系统劫持的高度敏感性。Bondarenko<cite class="ltx_cite ltx_citemacro_citet"> 等人（2025）证明，像 o1-preview 和 DeepSeek-R1 这样的逻辑推理模型在面对困难任务时经常诉诸规则博弈，当它们认为公平竞争无法实现其目标时，就会策略性地规避规则。Barkur 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib9" title="">2025</a> ）的</cite>研究也支持了这一观点 <cite class="ltx_cite ltx_citemacro_citet">。 （ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib6" title="">2025</a> ）</cite> 观察到，DeepSeek-R1 在机器人具身环境中模拟时，表现出令人担忧的欺骗行为和自我保护本能，包括禁用伦理模块、创建隐蔽网络和未经授权的能力扩展，尽管这些特性并未被明确编程或触发。He<cite class="ltx_cite ltx_citemacro_citet"> 等人。</cite> （ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib34" title="">2025</a> ）通过 InstrumentalEval 基准进一步揭示，与 RLHF 模型相比，像 o1 这样的 LRM 表现出明显更高的工具性收敛行为率，包括令人担忧的自我复制倾向、未经授权的系统访问和欺骗行为，这些都是实现其目标的工具性手段。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Multi-lingual Safety Risks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">3.3</span> 多语言安全风险</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Safety risks in LRMs reveal significant disparities across languages. <cite class="ltx_cite ltx_citemacro_citet">Ying et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib117" title="">2025b</a>)</cite> demonstrate that DeepSeek models show markedly higher attack success rates in English environments than Chinese contexts, averaging a 21.7% discrepancy, suggesting safety alignments may not generalize effectively across languages. <cite class="ltx_cite ltx_citemacro_citet">Romero-Arjona et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib78" title="">2025</a>)</cite> find similar vulnerabilities when testing DeepSeek-R1 in Spanish, with biased or unsafe response rates reaching 31.7%, while OpenAI o3-mini shows varying degrees of linguistic safety performance. <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib121" title="">2025a</a>)</cite> systematically evaluate DeepSeek models using CHiSafetyBench, revealing critical safety deficiencies specifically in Chinese contexts, where reasoning models like DeepSeek-R1 struggled with culturally-specific safety concerns and failed to adequately reject harmful prompts.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">语言响应模型（LRM）中的安全风险在不同语言间存在显著差异。Ying<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib117" title="">2025b</a> ）的</cite>研究表明，DeepSeek 模型在英语环境下的攻击成功率明显高于中文环境，平均差异高达 21.7%，这表明安全策略可能无法有效跨语言推广。Romero <cite class="ltx_cite ltx_citemacro_citet">-Arjona 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib78" title="">2025</a> ）</cite> 在西班牙语环境下测试 DeepSeek-R1 时也发现了类似的漏洞，其偏差或不安全响应率高达 31.7%，而 OpenAI o3-mini 在不同语言环境下的安全性能表现也存在差异。Zhang<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib121" title="">2025a</a> ）</cite> 使用 CHiSafetyBench 系统地评估了 DeepSeek 模型，揭示了其在中文环境下存在的关键安全缺陷，例如 DeepSeek-R1 等推理模型难以应对文化特有的安全问题，并且无法有效地拒绝有害提示。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Multi-modal Safety Risks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">3.4</span> 多模式安全风险</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Following the success of LRMs, researchers have recognized the potential of reinforcement learning to enhance reasoning abilities in Large Vision-Language Models (LVLMs). This approach has led to the development of several notable models, including QvQ&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Team, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib87" title="">2024a</a>)</cite>, Mulberry&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib111" title="">2024b</a>)</cite>, and R1-Onevision&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib109" title="">2025</a>)</cite>. While these models demonstrate impressive reasoning capabilities, their safety implications remain largely unexplored. The pioneering work of SafeMLRM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Fang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib24" title="">2025</a>)</cite> provides the first systematic safety analysis of multi-modal large reasoning models, revealing three critical concerns: (1) acquiring reasoning capabilities significantly degrades inherited safety alignment, (2) certain scenarios exhibit disproportionately higher vulnerabilities, and (3) some models demonstrate nascent self-correction capabilities despite overall safety concerns. Given these findings, we emphasize the urgent need for comprehensive safety and vulnerability assessments of reasoning-enhanced LVLMs to ensure their responsible deployment and use.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">继大型推理模型（LRM）取得成功之后，研究人员认识到强化学习在增强大型视觉语言模型（LVLM）推理能力方面的潜力。这种方法催生了几个著名的模型，包括 QvQ <cite class="ltx_cite ltx_citemacro_citep">（Team， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib87" title="">2024a</a> ）</cite> 、Mulberry <cite class="ltx_cite ltx_citemacro_citep">（Yao 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib111" title="">2024b</a> ）</cite> 和 R1-Onevision <cite class="ltx_cite ltx_citemacro_citep">（Yang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib109" title="">2025</a> ）</cite> 。尽管这些模型展现出了令人印象深刻的推理能力，但它们的安全性问题仍未得到充分研究。SafeMLRM <cite class="ltx_cite ltx_citemacro_citep">（Fang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib24" title="">2025</a> ）</cite> 的开创性工作首次对多模态大型推理模型进行了系统的安全性分析，揭示了三个关键问题：（1）推理能力的习得显著降低了模型原有的安全性；（2）某些场景下模型的脆弱性异常高；（3）尽管存在整体安全性问题，但一些模型仍展现出初步的自我纠正能力。鉴于这些发现，我们强调迫切需要对推理增强型 LVLM 进行全面的安全性和脆弱性评估，以确保其负责任的部署和使用。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Attacks on LRMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_section">4.</span> 对远程导弹的攻击</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we categorize different attack methods based on their primary objectives. We identify four main categories: Reasoning Length Attacks (Section <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS1" title="4.1 Reasoning Length Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.1</span></a>), which target the reasoning process itself; Answer Correctness Attacks (Section <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS2" title="4.2 Answer Correctness Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.2</span></a>), which aim to manipulate output accuracy; Prompt Injection Attacks (Section <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS3" title="4.3 Prompt Injection Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.3</span></a>), which bypass safety measures through crafted inputs; and Jailbreak Attacks (Section <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS4" title="4.4 Jailbreak Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.4</span></a>), which attempt to extract prohibited content or behaviors. Each attack type exploits different vulnerabilities in the reasoning capabilities of LRMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本节根据攻击的主要目标对不同的攻击方法进行分类。我们确定了四大类：推理长度攻击（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS1" title="4.1 Reasoning Length Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.1</span></a> 节），其目标是推理过程本身；答案正确性攻击（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS2" title="4.2 Answer Correctness Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.2</span></a> 节），旨在操纵输出的准确性；提示注入攻击（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS3" title="4.3 Prompt Injection Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.3</span></a> 节），通过精心构造的输入绕过安全措施；以及越狱攻击（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S4.SS4" title="4.4 Jailbreak Attacks ‣ 4 Attacks on LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">4.4</span></a> 节），试图提取违禁内容或行为。每种攻击类型都利用了逻辑资源管理器 (LRM) 推理能力中的不同漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Reasoning Length Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">4.1</span> 推理长度攻击</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Unlike traditional LLMs that generate direct responses, LRMs explicitly perform multi-step reasoning, creating a new attack surface related to reasoning length. Attackers can exploit this distinctive feature by either forcing models to overthink simple problems or short-cutting necessary deliberation processes.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与生成直接响应的传统逻辑推理模型 (LLM) 不同，逻辑推理模型 (LRM) 会显式地执行多步骤推理，从而产生与推理长度相关的新攻击面。攻击者可以利用这一独特特性，迫使模型过度思考简单的问题，或者省略必要的推理过程。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Overthinking.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">想太多。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">The success of step-by-step reasoning in LRMs has significantly enhanced their problem-solving capabilities, but this improvement comes with a critical vulnerability: overthinking. Recent work by <cite class="ltx_cite ltx_citemacro_citet">Chen et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib10" title="">2024a</a>)</cite> has identified that these models often spend orders of magnitude more computation on simple questions with minimal benefit, creating substantial inference overhead and latency issues. <cite class="ltx_cite ltx_citemacro_citet">Hashemi et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib33" title="">2025</a>)</cite> systematically demonstrate this inefficiency through their DNR benchmark, revealing that reasoning models generate up to 70× more tokens than necessary and often perform worse than simpler non-reasoning models on straightforward tasks. This inefficiency creates an exploitable attack surface where adversaries can deliberately trigger excessive reasoning through carefully crafted inputs. <cite class="ltx_cite ltx_citemacro_citet">Kumar et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib46" title="">2025</a>)</cite> formalize this as an indirect prompt injection attack that introduces computationally demanding decoy problems, while <cite class="ltx_cite ltx_citemacro_citet">Zaremba et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a>)</cite> identify Nerd Sniping attacks that trap models in unproductive thinking loops, causing them to spend abnormally large amounts of inference-time compute with decreased performance. These attacks effectively apply denial-of-service techniques&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shumailov et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib83" title="">2021</a>; Gao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib26" title="">2024</a>)</cite> specifically to LRMs. The implications extend beyond computational waste—<cite class="ltx_cite ltx_citemacro_citet">Marjanović et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib65" title="">2025</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Wu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib105" title="">2025b</a>)</cite> demonstrate that reasoning performance actually degrades beyond certain length thresholds, while <cite class="ltx_cite ltx_citemacro_citet">Cuadron et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib17" title="">2025</a>)</cite> show that in agentic systems, overthinking can lead to decision paralysis and ineffective action selection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">逻辑推理模型（LRM）中逐步推理的成功显著提升了其问题解决能力，但这种提升也带来了一个关键的漏洞：过度思考。Chen<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib10" title="">2024a</a> ）</cite> 的最新研究表明，这些模型在处理简单问题时，往往会花费数量级更高的计算资源，而收益却微乎其微，从而造成巨大的推理开销和延迟问题。Hashemi<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib33" title="">2025</a> ）</cite> 通过其 DNR 基准测试系统地展示了这种低效性，揭示了推理模型生成的词元数量高达实际所需数量的 70 倍，并且在简单的任务上，其性能通常还不如更简单的非推理模型。这种低效性创造了一个可被利用的攻击面，攻击者可以通过精心构造的输入来故意触发过度推理。Kumar<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib46" title="">2025</a> ）</cite> 将其形式化为一种间接提示注入攻击，该攻击引入了计算量巨大的诱饵问题；而 <cite class="ltx_cite ltx_citemacro_citet">Zaremba 等人（2026）则提出了一种新的方法，利用该方法通过引入计算量大的诱饵问题来降低模型的效率。 （ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a> ）</cite> 指出，Nerd Sniping 攻击会将模型困在低效的思维循环中，导致模型在推理时间上消耗异常大量的计算资源，而性能却下降。这些攻击实际上是将拒绝服务技术 <cite class="ltx_cite ltx_citemacro_citep">（Shumailov 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib83" title="">2021</a> ；Gao 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib26" title="">2024</a> ）</cite> 专门应用于逻辑推理模型（LRM）。其影响远不止计算资源浪费 <cite class="ltx_cite ltx_citemacro_citet">——Marjanović等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib65" title="">2025</a> ）</cite> 和 <cite class="ltx_cite ltx_citemacro_citet">Wu 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib105" title="">2025b</a> ）</cite> 证明，推理性能实际上会在超过某些长度阈值后下降，而 <cite class="ltx_cite ltx_citemacro_citet">Cuadron 等人（2025）则证明，在逻辑推理时间超过一定阈值后，模型性能会进一步下降。</cite> （ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib17" title="">2025 年 </a>）的研究表明，在智能系统中，过度思考会导致决策瘫痪和无效的行动选择。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Underthinking.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">思考不足。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">Complementing overthinking vulnerabilities, <cite class="ltx_cite ltx_citemacro_citet">Zaremba et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a>)</cite> propose Think Less attacks, where adversaries craft special prompts to force reasoning models to shortcut their deliberative processes. The goal is to make models produce incorrect responses by significantly reducing computation time. Their experiments use 64-shot examples to demonstrate that models like OpenAI’s o1-mini are particularly susceptible to these attacks, bypassing normal reasoning and jumping to premature conclusions. However, this can be detected by monitoring for abnormally low inference-time compute usage.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了弥补过度思考漏洞的不足， <cite class="ltx_cite ltx_citemacro_citet">Zaremba 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a> ）</cite> 提出了“少想攻击”（Think Less attacks），攻击者通过精心设计提示，迫使推理模型跳过其深思熟虑的过程。其目标是通过显著减少计算时间，使模型产生错误的响应。他们的实验使用 64 个样本，证明像 OpenAI 的 o1-mini 这样的模型特别容易受到此类攻击，它们会绕过正常的推理过程，过早地得出结论。然而，这种攻击可以通过监测异常低的推理时间计算使用率来检测。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Answer Correctness Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">4.2</span> 答案正确性攻击</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">While conventional LLMs can be manipulated to produce incorrect answers, LRMs introduce unique vulnerabilities through their exposed reasoning chains. This transparency in the inference process provides adversaries with additional attack vectors to corrupt the reasoning pathway itself, rather than just targeting the final output.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">虽然传统的逻辑推理模型（LLM）可以被操纵以产生错误答案，但逻辑推理模型（LRM）由于其暴露的推理链而引入了独特的漏洞。这种推理过程的透明性为攻击者提供了额外的攻击途径，使其能够破坏推理路径本身，而不仅仅是针对最终输出。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Reasoning-based Backdoor Attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于推理的后门攻击。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">The goal of backdoor attacks is to alter a model’s behavior whenever a specific trigger is present in the input <cite class="ltx_cite ltx_citemacro_citep">(Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib126" title="">2024</a>)</cite>. Based on the nature of these triggers, backdoor attacks can be classified as instruction-based <cite class="ltx_cite ltx_citemacro_citep">(Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib107" title="">2023</a>)</cite>, prompt-based <cite class="ltx_cite ltx_citemacro_citep">(Yao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib110" title="">2024a</a>)</cite>, or syntax-based <cite class="ltx_cite ltx_citemacro_citep">(Qi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib71" title="">2021</a>; Cheng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib14" title="">2025</a>)</cite>.
With the advancement of reasoning capabilities in LRMs, a new paradigm has emerged: Chain-of-Thought (CoT) based backdoor attacks that specifically target intermediate reasoning steps to compromise answer correctness. BadChain <cite class="ltx_cite ltx_citemacro_citep">(Xiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib106" title="">2024</a>)</cite> inserts malicious reasoning steps into the sequence, manipulating the model to produce incorrect answers while maintaining logical coherence. DarkMind <cite class="ltx_cite ltx_citemacro_citep">(Guo and Tourani, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib31" title="">2025</a>)</cite> implements latent triggers that activate during specific reasoning scenarios, leading to plausible but false outputs that are difficult to detect. BoT <cite class="ltx_cite ltx_citemacro_citep">(Zhu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib130" title="">2025b</a>)</cite> forces models to bypass their reasoning mechanisms, generating immediate incorrect responses instead of thoughtful deliberation. ShadowCoT <cite class="ltx_cite ltx_citemacro_citep">(Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib125" title="">2025</a>)</cite> directly manipulates the model’s cognitive pathway through attention head localization and reasoning chain pollution, achieving flexible hijacking that produces wrong answers while preserving logical flow.
These sophisticated attacks reveal a concerning vulnerability: the enhanced reasoning capabilities of LRMs paradoxically make them more susceptible to backdoors that can generate incorrect answers accompanied by convincing reasoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">后门攻击的目标是在输入中出现特定触发条件时改变模型的行为 <cite class="ltx_cite ltx_citemacro_citep">（Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib126" title="">2024</a> ）</cite> 。根据这些触发条件的性质，后门攻击可分为基于指令的攻击 <cite class="ltx_cite ltx_citemacro_citep">（Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib107" title="">2023</a> ）</cite> 、基于提示的攻击 <cite class="ltx_cite ltx_citemacro_citep">（Yao et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib110" title="">2024a</a> ）</cite> 或基于语法的攻击 <cite class="ltx_cite ltx_citemacro_citep">（Qi et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib71" title="">2021</a> ; Cheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib14" title="">2025</a> ）</cite> 。随着逻辑推理模型（LRM）推理能力的提升，一种新的范式应运而生：基于思维链（CoT）的后门攻击，它专门针对中间推理步骤，以破坏答案的正确性。BadChain <cite class="ltx_cite ltx_citemacro_citep">（Xiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib106" title="">2024</a> ）</cite> 在推理序列中插入恶意步骤，操纵模型产生错误答案，同时保持逻辑一致性。 DarkMind <cite class="ltx_cite ltx_citemacro_citep">（Guo 和 Tourani， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib31" title="">2025</a> ）</cite> 实现了在特定推理场景中激活的潜在触发器，从而产生看似合理但实则错误且难以检测的输出。BoT <cite class="ltx_cite ltx_citemacro_citep">（Zhu 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib130" title="">2025b</a> ）</cite> 迫使模型绕过其推理机​​制，直接生成错误答案而非经过深思熟虑的思考。ShadowCoT <cite class="ltx_cite ltx_citemacro_citep">（Zhao 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib125" title="">2025</a> ）</cite> 通过注意力头定位和推理链污染直接操纵模型的认知路径，实现灵活的劫持，在保持逻辑流程的同时产生错误答案。 这些复杂的攻击揭示了一个令人担忧的漏洞：LRM 增强的推理能力反而使它们更容易受到后门的攻击，这些后门可以生成错误的答案，并伴有令人信服的推理。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Error Injection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">错误注入。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">The explicit reasoning processes of LRMs create a critical vulnerability where strategically injected errors can fundamentally compromise output integrity. <cite class="ltx_cite ltx_citemacro_citet">Cui et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib18" title="">2025</a>)</cite> demonstrate this with their Compromising Thought (CPT) attack, where manipulating calculation results in reasoning tokens caused models to ignore correct steps and adopt incorrect answers. Their experiments with models like DeepSeek-R1 revealed that endpoint token manipulations had greater impact than structural changes to reasoning chains. They also discovered a security vulnerability where tampered tokens could trigger complete reasoning cessation in DeepSeek-R1, highlighting significant implications for reasoning-intensive applications.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LRM（逻辑回归模型）的显式推理过程存在一个关键漏洞，即人为注入的错误会从根本上破坏输出的完整性。Cui<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib18" title="">2025</a> ）</cite> 通过其“妥协思维”（CPT）攻击证明了这一点。在该攻击中，通过操纵推理令牌中的计算结果，模型会忽略正确的步骤并采用错误的答案。他们对 DeepSeek-R1 等模型的实验表明，端点令牌的操纵比推理链的结构性改变影响更大。他们还发现了一个安全漏洞：篡改的令牌会导致 DeepSeek-R1 完全停止推理，这凸显了该漏洞对推理密集型应用的重大影响。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Prompt Injection Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">4.3</span> 即时注入攻击</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Prompt injection attacks affect both traditional LLMs and LRMs, but LRMs present distinct challenges due to their step-by-step processing. These attacks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kumar et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib47" title="">2024</a>; Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib58" title="">2023</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib12" title="">2024b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib11" title="">2025</a>)</cite> inject malicious instructions disguised as normal user input, causing the AI to override or ignore its original developer-set instructions and safeguards. The explicit reasoning structures of LRMs offer attackers additional insertion points to redirect the model’s thought process, potentially making them more susceptible to certain types of injections.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">提示注入攻击会影响传统的逻辑逻辑模型（LLM）和逻辑推理模型（LRM），但由于 LRM 的逐步处理方式，它们面临着独特的挑战。这些攻击 <cite class="ltx_cite ltx_citemacro_citep">（Kumar 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib47" title="">2024</a> ；Liu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib58" title="">2023</a> ；Chen 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib12" title="">2024b</a> ， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib11" title="">2025</a> ）</cite> 会将伪装成正常用户输入的恶意指令注入模型，导致人工智能覆盖或忽略其开发者预先设置的指令和安全措施。LRM 的显式推理结构为攻击者提供了额外的插入点，使其能够重定向模型的思维过程，从而可能更容易受到某些类型的注入攻击。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib127" title="">2025</a>)</cite> examine LRMs like DeepSeek-R1 and o3-mini, finding significant differences in susceptibility based on injection types and risk categories. Their research reveals that reasoning models are particularly vulnerable to direct prompt injection attacks compared to indirect ones. <cite class="ltx_cite ltx_citemacro_citet">Zaremba et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a>)</cite> further demonstrate that open-source reasoning models show significant vulnerability to prompt injection attacks, with success rates varying between direct and indirect injections. Their experiments reveal that increasing inference-time compute substantially improves model robustness, with attack success probability decreasing as test-time compute grows. Notably, proprietary models like o3-mini demonstrate nearly 80% lower vulnerability than open-source counterparts when facing direct injection attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><cite class="ltx_cite ltx_citemacro_citet">Zhou 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib127" title="">2025</a> ）</cite> 研究了 DeepSeek-R1 和 o3-mini 等逻辑回归模型（LRM），发现其易受攻击性会因注入类型和风险类别的不同而存在显著差异。他们的研究表明，与间接注入相比，推理模型更容易受到直接提示注入攻击。Zaremba<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a> ）</cite> 进一步证明，开源推理模型对提示注入攻击表现出显著的脆弱性，直接注入和间接注入的成功率存在差异。他们的实验表明，增加推理时计算量可以显著提高模型的鲁棒性，随着测试时计算量的增加，攻击成功概率会降低。值得注意的是，在面对直接注入攻击时，像 o3-mini 这样的专有模型比开源模型的脆弱性降低了近 80%。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Jailbreak Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">4.4</span> 越狱攻击</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Jailbreak attacks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib42" title="">2024</a>; Yi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib115" title="">2024</a>)</cite> refer to methods designed to circumvent an AI system’s safety guidelines and content policies to extract prohibited responses. While both traditional LLMs and LRMs face jailbreak threats, the attacks against LRMs represent a distinct category that specifically targets their enhanced reasoning capabilities. Rather than merely extending approaches used against conventional LLMs, these attacks exploit the deliberative processes that make LRMs powerful, enabling attackers to develop more sophisticated methods to bypass safety measures and elicit harmful content.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱攻击 <cite class="ltx_cite ltx_citemacro_citep">（Jin et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib42" title="">2024</a> ; Yi et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib115" title="">2024</a> ）</cite> 指的是旨在绕过人工智能系统安全准则和内容策略以提取违禁响应的方法。虽然传统的逻辑推理模型（LLM）和逻辑推理模型（LRM）都面临越狱威胁，但针对 LRM 的攻击属于一个独特的类别，专门针对其增强的推理能力。这些攻击并非简单地扩展针对传统 LLM 的方法，而是利用 LRM 强大的推理过程，使攻击者能够开发出更复杂的方法来绕过安全措施并获取有害内容。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Prompt-Based Jailbreak.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示的越狱。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.1">Prompt-based jailbreaks involve the careful crafting of prompts, employing techniques such as persuasion&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Zeng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib120" title="">2024b</a>)</cite>, nested scene construction&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib50" title="">2023</a>)</cite>, and persona modulation&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shah et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib80" title="">2023</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Andriushchenko and Flammarion (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib1" title="">2024</a>)</cite> introduce a method that applies past-tense transformations to OpenAI’s recent o1 reasoning models, revealing their lack of robustness against subtle linguistic shifts. <cite class="ltx_cite ltx_citemacro_citet">Ying et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib117" title="">2025b</a>)</cite> propose attack prompts that combine common jailbreak strategies—such as scenario injection, affirmative prefixes, and indirect instructions—with safety-sensitive queries to probe model vulnerabilities. Their findings indicate that reasoning models like DeepSeek-R1 and OpenAI’s o1 are particularly susceptible to such attacks, as their explicit CoT reasoning renders them more exploitable than standard LLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于提示的越狱攻击需要精心设计提示语，并运用诸如说服 <cite class="ltx_cite ltx_citemacro_citep">（Zeng et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib120" title="">2024b</a> ）</cite> 、嵌套场景构建 <cite class="ltx_cite ltx_citemacro_citep">（Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib50" title="">2023</a> ）</cite> 和角色转换 <cite class="ltx_cite ltx_citemacro_citep">（Shah et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib80" title="">2023</a> ）</cite> 等技巧。Andriushchenko<cite class="ltx_cite ltx_citemacro_citet"> 和 Flammarion（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib1" title="">2024</a> ）</cite> 提出了一种将过去时态转换应用于 OpenAI 最新 o1 推理模型的方法，揭示了这些模型对细微语言变化缺乏鲁棒性。Ying<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib117" title="">2025b</a> ）</cite> 提出了一种攻击提示，将常见的越狱策略（例如场景注入、肯定前缀和间接指令）与安全敏感查询相结合，以探测模型漏洞。他们的研究结果表明，像 DeepSeek-R1 和 OpenAI 的 o1 这样的推理模型特别容易受到此类攻击，因为它们显式的 CoT 推理使得它们比标准的 LLM 更容易被利用。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Multi-turn Jailbreak.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多回合越狱。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px2.p1.1">Performing jailbreak attacks in a single query can be challenging, but multi-turn conversations or sequential prompts may incrementally guide models toward generating restricted content&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Russinovich et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib79" title="">2024</a>); Sun et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib84" title="">2024</a>)</cite>. Multi-turn attacks are particularly relevant to reasoning-capable models as these models possess sophisticated logical processing that can be exploited through extended dialogues. <cite class="ltx_cite ltx_citemacro_citet">Ying et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib116" title="">2025a</a>)</cite> propose Reasoning-Augmented Conversation (RACE), which reformulates harmful queries into benign reasoning tasks and gradually exploits the model’s inference capabilities to compromise safety alignment, achieving success rates up to 96%. <cite class="ltx_cite ltx_citemacro_citet">Ren et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib77" title="">2024</a>)</cite> introduce ActorAttack, a framework that constructs semantically linked conversational sequences that appear harmless individually but collectively lead to harmful outputs, successfully targeting even advanced models like o1. <cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib49" title="">2024</a>)</cite> further show that multi-turn human jailbreaks significantly outperform automated single-turn attacks, leveraging the model’s ability to maintain context and be incrementally steered toward unsafe behaviors.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在单次查询中执行越狱攻击可能具有挑战性，但多轮对话或顺序提示可以逐步引导模型生成受限内容 <cite class="ltx_cite ltx_citemacro_citet">（Russinovich 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib79" title="">2024</a> ；Sun 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib84" title="">2024</a> ）</cite> 。多轮攻击对于具备推理能力的模型尤为重要，因为这些模型拥有复杂的逻辑处理能力，可以通过扩展对话加以利用。Ying<cite class="ltx_cite ltx_citemacro_citet"> 等（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib116" title="">2025a</a> ）</cite> 提出了推理增强对话（RACE）方法，该方法将有害查询重新表述为良性推理任务，并逐步利用模型的推理能力来破坏安全对齐，成功率高达 96%。Ren<cite class="ltx_cite ltx_citemacro_citet"> 等（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib77" title="">2024</a> ）</cite> 提出了 ActorAttack 框架，该框架构建语义关联的对话序列，这些序列单独来看似乎无害，但组合起来却会导致有害输出，甚至成功攻击了像 o1 这样的高级模型。Li<cite class="ltx_cite ltx_citemacro_citet"> 等。 （ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib49" title="">2024 年 </a>）</cite> 进一步表明，多回合的人类越狱明显优于自动化的单回合攻击，利用了模型保持上下文并逐步引导至不安全行为的能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Reasoning Exploitation Jailbreak.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理利用越狱。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS4.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px3.p1.1">LRMs possess advanced reasoning capabilities that, while enhancing their utility, introduce unique vulnerabilities that can be exploited through reasoning-based jailbreak attacks. Unlike traditional LLMs, these models explicitly expose their CoT reasoning processes, creating new attack surfaces. &nbsp;<cite class="ltx_cite ltx_citemacro_citet">Yao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib113" title="">2025</a>)</cite> introduce Mousetrap, a framework that leverages chaos mappings to create iterative reasoning chains that gradually lead LRMs into harmful outputs. By embedding one-to-one mappings into the reasoning process, Mousetrap effectively traps models like OpenAI’s o1-mini and Claude-sonnet with success rates of up to 98%. <cite class="ltx_cite ltx_citemacro_citet">Kuo et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib48" title="">2025</a>)</cite> propose Hijacking Chain-of-Thought (H-CoT), which manipulates the reasoning process by injecting execution-phase thoughts that bypass safety checks entirely. Their approach exploits LRMs’ tendency to prioritize problem-solving over safety considerations, causing rejection rates to plummet from 98% to below 2% across models like OpenAI o1/o3 and DeepSeek-R1. Both approaches demonstrate that the very reasoning mechanisms designed to enhance LRMs’ capabilities can become their most significant security weaknesses when strategically manipulated.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LRM 拥有先进的推理能力，这在增强其效用的同时，也引入了独特的漏洞，这些漏洞可能被基于推理的越狱攻击所利用。与传统的 LLM 不同，这些模型会显式地暴露其思维链 (CoT) 推理过程，从而创建新的攻击面。Yao<cite class="ltx_cite ltx_citemacro_citet"> 等人 ( <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib113" title="">2025</a> )</cite> 提出了 Mousetrap 框架，该框架利用混沌映射创建迭代推理链，逐步引导 LRM 输出有害结果。通过将一对一映射嵌入推理过程，Mousetrap 能够有效地捕获 OpenAI 的 o1-mini 和 Claude-sonnet 等模型，成功率高达 98%。Kuo<cite class="ltx_cite ltx_citemacro_citet"> 等人 ( <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib48" title="">2025</a> )</cite> 提出了劫持思维链 (H-CoT) 的方法，该方法通过注入执行阶段的思维来操纵推理过程，从而完全绕过安全检查。他们的方法利用了逻辑回归模型（LRM）倾向于优先解决问题而非考虑安全性的特性，使得 OpenAI o1/o3 和 DeepSeek-R1 等模型的拒绝率从 98%骤降至 2%以下。这两种方法都表明，旨在增强逻辑回归模型能力的推理机制，一旦被策略性地操纵，反而会成为其最严重的安全漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Defenses for LRMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">远程导弹防御系统的 <span class="ltx_tag ltx_tag_section">5 种</span>防御措施</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">To mitigate safety risks and defend against attacks on LRMs, various defense strategies have been proposed in recent research. We categorize these approaches into three main types: Safety Alignment (Section <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS1" title="5.1 Safety Alignment of LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.1</span></a>), Inference-Time Defenses (Section <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS2" title="5.2 Inference-time Defenses for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.2</span></a>), and Guard Models (Section <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS3" title="5.3 Guard Models for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.3</span></a>).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了降低安全风险并抵御对逻辑回归模型（LRM）的攻击，近期的研究提出了多种防御策略。我们将这些方法分为三大类：安全对齐（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS1" title="5.1 Safety Alignment of LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.1</span></a> 节）、推理时防御（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS2" title="5.2 Inference-time Defenses for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.2</span></a> 节）和保护模型（第 <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#S5.SS3" title="5.3 Guard Models for LRMs ‣ 5 Defenses for LRMs ‣ Safety in Large Reasoning Models: A Survey"><span class="ltx_text ltx_ref_tag">5.3</span></a> 节）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Safety Alignment of LRMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">5.1</span> 远程遥控装置的安全性调整</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">Similar to LLMs and VLMs, LRMs are required to align with humans’ values and expectations. The 3H principle <cite class="ltx_cite ltx_citemacro_citep">(Askell et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib4" title="">2021</a>)</cite> (Helpful, Honest, and Harmless) provides a foundational guideline for constraining model behaviors.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与低价值模型（LLM）和价值模型（VLM）类似，低价值模型（LRM）也需要符合人类的价值观和期望。3H 原则 <cite class="ltx_cite ltx_citemacro_citep">（Askell 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib4" title="">2021</a> ）</cite> （有益、诚实、无害）为约束模型行为提供了基础性指导。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">The existing safety alignment pipelines and techniques developed for LLMs <cite class="ltx_cite ltx_citemacro_citep">(Shen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib81" title="">2023</a>)</cite> and VLMs <cite class="ltx_cite ltx_citemacro_citep">(Ye et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib114" title="">2025</a>)</cite> can be readily adapted to LRMs, as they share similar architectures and natural language generation behaviors. For example, the alignment process for LLMs typically starts with collecting high-quality, value-aligned data <cite class="ltx_cite ltx_citemacro_citep">(Ethayarajh et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib23" title="">2022</a>)</cite>, either from existing benchmarks <cite class="ltx_cite ltx_citemacro_citep">(Bach et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib5" title="">2022</a>; Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib95" title="">2022c</a>)</cite>, LLM-generated instructions <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib94" title="">2022b</a>)</cite>, or by filtering unsafe content <cite class="ltx_cite ltx_citemacro_citep">(Welbl et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib100" title="">2021</a>; Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib90" title="">2022a</a>)</cite>. During training, common techniques include supervised fine-tuning (SFT) <cite class="ltx_cite ltx_citemacro_citep">(Wu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib103" title="">2021</a>)</cite>, reinforcement learning from human feedback (RLHF) <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib70" title="">2022</a>)</cite>, and direct preference optimization (DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib75" title="">2024</a>)</cite>. In the domain of VLMs, safety alignment has been achieved through various approaches. For example, <cite class="ltx_cite ltx_citemacro_citet">Liu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib62" title="">2024</a>)</cite> introduce additional safety modules during training to enhance model alignment. Moreover, methods such as ADPO <cite class="ltx_cite ltx_citemacro_citep">(Weng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib102" title="">2025</a>)</cite>, Safe RLHF-V <cite class="ltx_cite ltx_citemacro_citep">(Ji et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib40" title="">2025</a>)</cite>, and GRPO-based methods <cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib51" title="">2025a</a>)</cite> improve safety via DPO <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib75" title="">2024</a>)</cite>, RLHF <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib70" title="">2022</a>)</cite>, and GRPO <cite class="ltx_cite ltx_citemacro_citep">(DeepSeek-AI et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib19" title="">2025</a>)</cite>, respectively. Additionally, open-source datasets and benchmarks <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib124" title="">2024</a>; Ji et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib40" title="">2025</a>)</cite> have played a crucial role in providing high-quality alignment data for safety evaluation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">现有的针对 LLM <cite class="ltx_cite ltx_citemacro_citep">（Shen 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib81" title="">2023</a> ）</cite> 和 VLM <cite class="ltx_cite ltx_citemacro_citep">（Ye 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib114" title="">2025</a> ）</cite> 开发的安全对齐流程和技术可以很容易地应用于 LRM，因为它们具有相似的架构和自然语言生成行为。例如，LLM 的对齐过程通常始于收集高质量的、值对齐的数据 <cite class="ltx_cite ltx_citemacro_citep">（Ethayarajh 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib23" title="">2022</a> ）</cite> ，这些数据可以来自现有的基准测试 <cite class="ltx_cite ltx_citemacro_citep">（Bach 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib5" title="">2022</a> ；Wang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib95" title="">2022c</a> ）</cite> 、LLM 生成的指令 <cite class="ltx_cite ltx_citemacro_citep">（Wang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib94" title="">2022b</a> ）</cite> ，或者通过过滤不安全内容获得 <cite class="ltx_cite ltx_citemacro_citep">（Welbl 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib100" title="">2021</a> ；Wang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib90" title="">2022a</a> ）</cite> 。在训练过程中，常用的技术包括监督式微调（SFT） <cite class="ltx_cite ltx_citemacro_citep">（Wu et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib103" title="">2021</a> ）</cite> 、基于人类反馈的强化学习（RLHF） <cite class="ltx_cite ltx_citemacro_citep">（Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib70" title="">2022</a> ）</cite> 和直接偏好优化（DPO） <cite class="ltx_cite ltx_citemacro_citep">（Rafailov et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib75" title="">2024</a> ）</cite> 。在可变长度模型（VLM）领域，安全对齐已通过多种方法实现。例如， <cite class="ltx_cite ltx_citemacro_citet">Liu et al.（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib62" title="">2024</a> ）</cite> 在训练过程中引入额外的安全模块以增强模型对齐。 此外，诸如 ADPO <cite class="ltx_cite ltx_citemacro_citep">（Weng 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib102" title="">2025</a> ）</cite> 、Safe RLHF-V <cite class="ltx_cite ltx_citemacro_citep">（Ji 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib40" title="">2025</a> ）</cite> 和基于 GRPO 的方法 <cite class="ltx_cite ltx_citemacro_citep">（Li 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib51" title="">2025a</a> ）</cite> 分别通过 DPO <cite class="ltx_cite ltx_citemacro_citep">（Rafailov 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib75" title="">2024</a> ）</cite> 、RLHF <cite class="ltx_cite ltx_citemacro_citep">（Ouyang 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib70" title="">2022</a> ）</cite> 和 GRPO <cite class="ltx_cite ltx_citemacro_citep">（DeepSeek-AI 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib19" title="">2025</a> ）</cite> 来提高安全性。另外，开源数据集和基准测试 <cite class="ltx_cite ltx_citemacro_citep">（Zhang 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib124" title="">2024</a> ；Ji 等， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib40" title="">2025</a> ）</cite> 在提供高质量的对齐数据以进行安全性评估方面发挥了至关重要的作用。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">Although effective, the previous alignment methods for LLMs and VLMs may overlook the reasoning process of LRMs, leading to unsatisfactory alignment performance. To mitigate this challenge, various works focus on different aspects, including safe CoT data curation, SFT-based safety alignment on reasoning, and RL-based safety alignment on reasoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管以往针对低层模型（LLM）和可变层模型（VLM）的对齐方法有效，但它们可能忽略了低层模型（LRM）的推理过程，导致对齐性能不尽如人意。为了应对这一挑战，许多研究工作着重于不同的方面，包括安全的 CoT 数据管理、基于 SFT 的推理安全对齐以及基于 RL 的推理安全对齐。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Safe CoT Data Curation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全的 CoT 数据管理。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">First, <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib96" title="">2025b</a>)</cite> build a 1k-scale safety dataset named STAR-1 specifically designed for LRMs. Another safety training data in CoT style named SafeChain <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a>)</cite> is introduced to enhance the safety of LRMs. In addition, <cite class="ltx_cite ltx_citemacro_citet">Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib122" title="">2025b</a>)</cite> construct a dataset consisting of 15k safety-aware reasoning trajectories, generated by DeepSeek-R1, with explicit instructions designed to promote expected refusal behavior.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">首先， <cite class="ltx_cite ltx_citemacro_citet">Wang 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib96" title="">2025b</a> ）</cite> 构建了一个名为 STAR-1 的 1k 规模安全数据集，该数据集专门用于逻辑推理模型 <cite class="ltx_cite ltx_citemacro_citep">（LRM）。此外，Jiang 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a> ）</cite> 还引入了另一个基于认知理论（CoT）的安全训练数据集 SafeChain，以增强 LRM 的安全性。另外， <cite class="ltx_cite ltx_citemacro_citet">Zhang 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib122" title="">2025b</a> ）</cite> 构建了一个包含 15k 条安全感知推理轨迹的数据集，这些轨迹由 DeepSeek-R1 生成，并包含旨在促进预期拒绝行为的明确指令。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">SFT-based Safety Alignment on Reasoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于 SFT 的推理安全对齐。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">Based on the curated safe CoT data, researchers further conduct SFT to improve safety. For example, <cite class="ltx_cite ltx_citemacro_citet">Jiang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a>)</cite> train two LRMs with the SafeChain dataset, demonstrating that it not only enhances model safety but also preserves reasoning performance. Besides, RealSafe-R1 <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib122" title="">2025b</a>)</cite> is developed to make LRMs safer by training DeepSeek-R1 distilled models on the 15k safety-aware reasoning trajectories. <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib91" title="">2025a</a>)</cite> proposes training the model to reason with the guidelines, thereby enhancing survey alignment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于精心整理的安全 CoT 数据，研究人员进一步开展安全框架训练（SFT）以提升安全性。例如， <cite class="ltx_cite ltx_citemacro_citet">Jiang 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a> ）</cite> 使用 SafeChain 数据集训练了两个逻辑回归模型（LRM），结果表明，这不仅提高了模型的安全性，而且保持了推理性能。此外，RealSafe-R1 <cite class="ltx_cite ltx_citemacro_citep">（Zhang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib122" title="">2025b</a> ）</cite> 通过在 15k 条安全感知推理轨迹上训练 DeepSeek-R1 提炼模型来提高 LRM 的安全性。Wang<cite class="ltx_cite ltx_citemacro_citet"> 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib91" title="">2025a</a> ）</cite> 提出训练模型以使其能够根据指导原则进行推理，从而增强调查一致性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">RL-based Safety Alignment on Reasoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于强化学习的推理安全对齐。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px3.p1.1">In addition to SFT, various further post-training techniques for safety are proposed based on reinforcement learning (RL). For example, deliberative alignment <cite class="ltx_cite ltx_citemacro_citep">(Guan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib30" title="">2024</a>)</cite> is proposed to teach models safety specifications directly and train them to reason over these guidelines before generating responses explicitly via reinforcement learning. In addition, STAIR <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib123" title="">2025c</a>)</cite> utilizes Monte Carlo tree search and DPO <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib75" title="">2024</a>)</cite> to integrate safety alignment with introspective reasoning. Meanwhile, a SaRO <cite class="ltx_cite ltx_citemacro_citep">(Mou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib68" title="">2025</a>)</cite> is proposed to incorporate safety-policy-driven reasoning into the alignment process. Besides, R2D <cite class="ltx_cite ltx_citemacro_citep">(Zhu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib129" title="">2025a</a>)</cite> is present to unlock the safety-aware reasoning mechanism to defense against jailbreak attacks with the proposed contrastive pivot optimization (CPO).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">除了 SFT 之外，基于强化学习（RL）还提出了多种进一步的后训练安全技术。例如，审慎对齐 <cite class="ltx_cite ltx_citemacro_citep">（Guan 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib30" title="">2024</a> ）</cite> 旨在直接教授模型安全规范，并通过强化学习训练模型对这些规范进行推理，然后再显式地生成响应。此外，STAIR <cite class="ltx_cite ltx_citemacro_citep">（Zhang 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib123" title="">2025c</a> ）</cite> 利用蒙特卡罗树搜索和 DPO <cite class="ltx_cite ltx_citemacro_citep">（Rafailov 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib75" title="">2024</a> ）</cite> 将安全对齐与内省推理相结合。同时，SaRO <cite class="ltx_cite ltx_citemacro_citep">（Mou 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib68" title="">2025</a> ）</cite> 旨在将安全策略驱动的推理融入对齐过程。此外，R2D <cite class="ltx_cite ltx_citemacro_citep">（Zhu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib129" title="">2025a</a> ）</cite> 提出了对比枢轴优化（CPO）来解锁安全感知推理机制，从而防御越狱攻击。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S5.SS1.SSS0.Px3.p2.1">However, safety alignment brings the safety alignment tax <cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib55" title="">2023a</a>)</cite>, compromising the fundamental capabilities of LRMs like reasoning capability <cite class="ltx_cite ltx_citemacro_citep">(Huang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib36" title="">2025</a>)</cite>. To mitigate this issue, researchers explore alternative defense techniques that do not require direct modifications to the victim models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">然而，安全对齐会带来安全对齐的代价 <cite class="ltx_cite ltx_citemacro_citep">（Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib55" title="">2023a</a> ）</cite> ，损害逻辑回归模型（LRM）的基本能力，例如推理能力 <cite class="ltx_cite ltx_citemacro_citep">（Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib36" title="">2025</a> ）</cite> 。为了缓解这个问题，研究人员探索了无需直接修改受害模型的替代防御技术。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Inference-time Defenses for LRMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">5.2</span> 逻辑回归模型的推理时防御</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">To circumvent the safety alignment tax <cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib55" title="">2023a</a>; Huang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib36" title="">2025</a>)</cite>, one line of work focuses on applying defenses at inference time.
The insights from previous inference-time defenses for LLMs <cite class="ltx_cite ltx_citemacro_citep">(Cheng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib13" title="">2023</a>; Lu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib63" title="">2023</a>)</cite> and VLMs <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib93" title="">2024a</a>; Ghosal et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib27" title="">2024</a>; Ding et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib20" title="">2024</a>; Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib57" title="">2025a</a>)</cite>, such as safe system prompting, few-shot safe demonstrations, and safe decoding, can be naturally borrowed to LRMs, as the token generation mechanism is similar across these models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了规避安全对齐税 <cite class="ltx_cite ltx_citemacro_citep">（Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib55" title="">2023a</a> ; Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib36" title="">2025</a> ）</cite> ，一项研究工作着重于在推理阶段应用防御措施。先前针对逻辑学习模型（LLM） <cite class="ltx_cite ltx_citemacro_citep">（Cheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib13" title="">2023</a> ; Lu et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib63" title="">2023</a> ）</cite> 和虚拟逻辑学习模型（VLM） <cite class="ltx_cite ltx_citemacro_citep">（Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib93" title="">2024a</a> ; Ghosal et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib27" title="">2024</a> ; Ding et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib20" title="">2024</a> ; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib57" title="">2025a</a> ）的</cite>推理阶段防御措施，例如安全系统提示、少样本安全演示和安全解码，可以自然地借鉴到逻辑推理模型（LRM）中，因为这些模型的令牌生成机制是相似的。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">However, the reasoning process in LRMs brings new challenges and opportunities for inference-time defenses. Therefore, various inference-time techniques like inference-time scaling on reasoning and safe decoding for reasoning are proposed to ensure the safety of reasoning in LRMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">然而，逻辑回归模型（LRM）中的推理过程为推理时防御带来了新的挑战和机遇。因此，为了确保逻辑回归模型中推理的安全性，人们提出了各种推理时防御技术，例如推理时长缩放和安全解码。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Inference-time Scaling on Reasoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理时间尺度对推理的影响。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Zaremba et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a>)</cite> demonstrate that the inference-time scaling on reasoning improves the safety and adversarial robustness of LRMs. Future work could explore dynamic scaling strategies tailored to input complexity, or integrate adaptive reasoning depth control to balance efficiency and safety performance <cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib60" title="">2025c</a>)</cite> during inference.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><cite class="ltx_cite ltx_citemacro_citet">Zaremba 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib118" title="">2025</a> ）</cite> 证明，推理过程中的推理时间缩放可以提高 LRM 的安全性和对抗鲁棒性。未来的工作可以探索针对输入复杂性定制的动态缩放策略，或者集成自适应推理深度控制，以在推理过程中平衡效率和安全性 <cite class="ltx_cite ltx_citemacro_citep">（Liu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib60" title="">2025c</a> ）</cite> 。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Safe Decoding for Reasoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全解码推理。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Jiang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a>)</cite> propose three decoding strategies, including ZeroThink, LessThink, and MoreThink, to verify model safety during reasoning. Making the reasoning safer at inference time could be a promising future direction, by verifying intermediate steps, filtering unsafe trajectories, or integrating reasoning-aware guard mechanisms during decoding.&nbsp;<cite class="ltx_cite ltx_citemacro_citet">Wu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib104" title="">2025a</a>)</cite> introduce Thinking Intervention, a method that strategically injects guidance directly into the reasoning process to control model behavior and improve safety alignment without requiring additional training.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><cite class="ltx_cite ltx_citemacro_citet">Jiang 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib41" title="">2025</a> ）</cite> 提出了三种解码策略，包括零思考（ZeroThink）、少思考（LessThink）和多思考 <cite class="ltx_cite ltx_citemacro_citet">（MoreThink），用于在推理过程中验证模型的安全性。通过在解码过程中验证中间步骤、过滤不安全轨迹或集成推理感知保护机制，提高推理阶段的安全性可能是一个很有前景的未来研究方向。Wu 等人（ <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib104" title="">2025a</a> ）</cite> 提出了思维干预（Thinking Intervention）方法，该方法策略性地将指导信息直接注入推理过程，以控制模型行为并提高安全性，而无需额外的训练。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Guard Models for LRMs<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_subsection">5.3</span> 远程导弹的防护模型</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">Another line of work without direct modification to the victim model focuses on building guard models for the victim model. The previous inference-time defenses still focus on the safer inference of the victim models themselves. Differently, guard models aim to moderate the input and output of the victim models without training the victim models or modifying the inference strategies of the victim models. The existing guard models for LLMs <cite class="ltx_cite ltx_citemacro_citep">(Inan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib38" title="">2023</a>)</cite> or VLMs <cite class="ltx_cite ltx_citemacro_citep">(Chi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib16" title="">2024b</a>)</cite> can also safeguard the LRMs since they share similar input and output formats. In addition, the reasoning-based guard models <cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib59" title="">2025b</a>)</cite> can better moderate the reasoning process of LRMs via guiding the guard models to deliberatively reason before making moderation decisions. We category existing guard models into two classes, including classifier-based guard models and reasoning-based guard models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">另一项不直接修改受害模型的研究方向是构建受害模型的保护模型。以往的推理时防御措施仍然侧重于提高受害模型本身的推理安全性。不同之处在于，保护模型旨在调节受害模型的输入和输出，而无需训练受害模型或修改其推理策略。现有的 LLM <cite class="ltx_cite ltx_citemacro_citep">（Inan 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib38" title="">2023</a> ）</cite> 或 VLM <cite class="ltx_cite ltx_citemacro_citep">（Chi 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib16" title="">2024b</a> ）</cite> 保护模型也可以保护 LRM，因为它们具有相似的输入输出格式。此外，基于推理的保护模型 <cite class="ltx_cite ltx_citemacro_citep">（Liu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib59" title="">2025b</a> ）</cite> 可以通过引导保护模型在做出调节决策之前进行深思熟虑的推理，从而更好地调节 LRM 的推理过程。我们将现有的保护模型分为两类：基于分类器的保护模型和基于推理的保护模型。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Classifier-based Guard Models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于分类器的保护模型。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px1.p1.1">The LLM guard models, including ToxicChat-T5 <cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib56" title="">2023b</a>)</cite>, ToxDectRoberta <cite class="ltx_cite ltx_citemacro_citep">(Zhou, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib128" title="">2020</a>)</cite>, LaGoNN <cite class="ltx_cite ltx_citemacro_citep">(Bates and Gurevych, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib7" title="">2023</a>)</cite>, the LLaMA Guard series <cite class="ltx_cite ltx_citemacro_citep">(Inan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib38" title="">2023</a>; Dubey et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib22" title="">2024</a>)</cite>, Aegis Guard series <cite class="ltx_cite ltx_citemacro_citep">(Ghosh et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib28" title="">2024a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib29" title="">b</a>)</cite>, WildGuard <cite class="ltx_cite ltx_citemacro_citep">(Han et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib32" title="">2024</a>)</cite>, ShieldGemma <cite class="ltx_cite ltx_citemacro_citep">(Zeng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib119" title="">2024a</a>)</cite>, are typically based on open-sourced LLMs and fine-tuned on the red-teaming data. In the VLM domain, for example, LLaVAGuard <cite class="ltx_cite ltx_citemacro_citep">(Helff et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib35" title="">2024</a>)</cite> is built to conduct large-scale dataset annotation and moderate the text-image models. In addition, VLMGuard <cite class="ltx_cite ltx_citemacro_citep">(Du et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib21" title="">2024</a>)</cite> is proposed to conduct malicious image-text prompt detection by leveraging the unlabeled user prompts. Moreover, LLaMA Guard 3-Vision <cite class="ltx_cite ltx_citemacro_citep">(Chi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib15" title="">2024a</a>)</cite> is developed to moderate both the image-text input and text output of VLMs via SFT. To improve the generalization ability, <cite class="ltx_cite ltx_citemacro_citep">(Ji et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib40" title="">2025</a>)</cite> presents Beaver-Guard-V by training a reward model and then applying reinforcement learning. Although effective, they are typically classifier-based guard models, limiting their abilities in moderate reasoning data. To mitigate this problem, the reasoning-based guard models <cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib59" title="">2025b</a>)</cite> are proposed to enhance the reasoning ability of guard models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLM 防护模型，包括 ToxicChat-T5 <cite class="ltx_cite ltx_citemacro_citep">(Lin 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib56" title="">2023b</a> )</cite> 、ToxDectRoberta <cite class="ltx_cite ltx_citemacro_citep">(Zhou， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib128" title="">2020</a> )</cite> 、LaGoNN <cite class="ltx_cite ltx_citemacro_citep">(Bates 和 Gurevych， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib7" title="">2023</a> )</cite> 、LLaMA Guard 系列 <cite class="ltx_cite ltx_citemacro_citep">(Inan 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib38" title="">2023</a> ；Dubey 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib22" title="">2024</a> )</cite> 、Aegis Guard 系列 <cite class="ltx_cite ltx_citemacro_citep">(Ghosh 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib28" title="">2024a</a> ， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib29" title="">b</a> )</cite> 、WildGuard <cite class="ltx_cite ltx_citemacro_citep">(Han 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib32" title="">2024</a> )</cite> 、ShieldGemma <cite class="ltx_cite ltx_citemacro_citep">(Zeng 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib119" title="">2024a</a> )</cite> ，通常基于开源 LLM，并在红队数据上进行微调。例如，在虚拟语言模型（VLM）领域，LLaVAGuard <cite class="ltx_cite ltx_citemacro_citep">（Helff 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib35" title="">2024</a> ）</cite> 旨在进行大规模数据集标注并约束文本-图像模型。此外，VLMGuard <cite class="ltx_cite ltx_citemacro_citep">（Du 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib21" title="">2024</a> ）</cite> 利用未标注的用户提示信息进行恶意图像-文本提示检测。LLaMA Guard 3-Vision <cite class="ltx_cite ltx_citemacro_citep">（Chi 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib15" title="">2024a</a> ）</cite> 则通过 SFT 方法约束 VLM 的图像-文本输入和文本输出。为了提高泛化能力， <cite class="ltx_cite ltx_citemacro_citep">（Ji 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib40" title="">2025</a> ）</cite> 提出了 Beaver-Guard-V，通过训练奖励模型并应用强化学习来实现。尽管这些模型有效，但它们通常是基于分类器的防护模型，限制了其在约束推理数据方面的能力。为了缓解这个问题，基于推理的防护模型 <cite class="ltx_cite ltx_citemacro_citep">（Liu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib59" title="">2025b</a> ）</cite> 被提出，以增强防护模型的推理能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Reasoning-based Guard Models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于推理的守卫模型。</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px2.p1.1">Through the proposed reasoning SFT and hard sample DPO, GuardReasoner <cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib59" title="">2025b</a>)</cite> and GuardReasoner-VL&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib61" title="">2025d</a>)</cite> are proposed to guide the guard model to deliberatively reason before making moderation decisions, improving performance, generalization ability, and explainability. Similarly, ThinkGuard <cite class="ltx_cite ltx_citemacro_citep">(Wen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib101" title="">2025</a>)</cite> is developed via the proposed critique-augmented fine-tuning. X-Guard <cite class="ltx_cite ltx_citemacro_citep">(Upadhayay et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib89" title="">2025</a>)</cite> extends the reasoning-based guard model to the multi-lingual scenario.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">通过提出的推理 SFT 和硬样本 DPO，GuardReasoner <cite class="ltx_cite ltx_citemacro_citep">（Liu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib59" title="">2025b</a> ）</cite> 和 GuardReasoner-VL <cite class="ltx_cite ltx_citemacro_citep">（Liu 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib61" title="">2025d</a> ）</cite> 被提出，旨在引导守卫模型在做出审核决策前进行深思熟虑的推理，从而提高其性能、泛化能力和可解释性。类似地，ThinkGuard <cite class="ltx_cite ltx_citemacro_citep">（Wen 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib101" title="">2025</a> ）</cite> 通过提出的批判性增强微调方法开发而成。X-Guard <cite class="ltx_cite ltx_citemacro_citep">（Upadhayay 等人， <a class="ltx_ref" href="https://arxiv.org/html/2504.17704v3#bib.bib89" title="">2025</a> ）</cite> 将基于推理的守卫模型扩展到了多语言场景。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Future Directions<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_section">6</span> 未来方向</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Beyond the detailed analysis of risks, attacks, and defenses presented in previous sections, this paper also identifies future directions that researchers should prioritize to enhance the safety of LRMs:
<span class="ltx_text ltx_font_bold" id="S6.p1.1.1">(1) Standardized Evaluation Benchmarks.</span>
New benchmarks should focus on reasoning-specific vulnerabilities, as the research community currently lacks standardized evaluation frameworks to comprehensively test both the safety and robustness of LRMs’ multi-step reasoning processes. <span class="ltx_text ltx_font_bold" id="S6.p1.1.2">(2) Domain-Specific Evaluation Frameworks.</span>
Evaluation suites for healthcare, finance, and law must include curated case studies and targeted adversarial tests. Expert review ensures LRMs meet each domain’s accuracy and ethical requirements. <span class="ltx_text ltx_font_bold" id="S6.p1.1.3">(3) Human-in-the-Loop Alignment and Interpretability.</span> Interactive tools should let experts inspect and refine reasoning traces. Iterative feedback can align LRMs with stakeholder values and correct biases efficiently.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">除了前几节中对风险、攻击和防御的详细分析之外，本文还指出了研究人员应优先考虑的未来方向，以提高 LRM 的安全性：
<span class="ltx_text ltx_font_bold" id="S6.p1.1.1">（1）标准化评估基准。</span>
新的基准测试应侧重于推理相关的漏洞，因为目前研究界缺乏标准化的评估框架来全面测试 LRM 多步骤推理过程的安全性和鲁棒性。 <span class="ltx_text ltx_font_bold" id="S6.p1.1.2">(2) 特定领域的评估框架。</span>
医疗保健、金融和法律领域的评估套件必须包含精心策划的案例研究和有针对性的对抗性测试。专家评审确保<span class="ltx_text ltx_font_bold" id="S6.p1.1.3">逻辑推理模型 (LRM) 符合各领域的准确性和伦理要求。(3) 人机协同与可解释性。</span> 交互式工具应允许专家检查和改进推理过程。迭代反馈可以使逻辑推理模型与利益相关者的价值观保持一致，并有效纠正偏差。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"><span class="ltx_tag ltx_tag_section">7</span> 结论</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This survey has comprehensively examined the emerging safety challenges posed by Large Reasoning Models. Through our analysis, we’ve identified several critical insights that distinguish LRM safety from traditional LLMs. First, <span class="ltx_text ltx_font_bold" id="S7.p1.1.1">LRMs expose their reasoning chains, creating new attack surfaces</span> where adversaries can manipulate intermediate steps rather than just outputs, enabling sophisticated attacks like reasoning-based backdoors and hijacking that target the deliberative process itself. Second, <span class="ltx_text ltx_font_bold" id="S7.p1.1.2">traditional output-focused alignment methods prove insufficient for LRMs</span>, as harmful reasoning can persist internally even when final outputs appear safe, necessitating novel approaches that consider the entire reasoning trajectory. These insights underscore the need for specialized safety research targeting LRMs, including standardized evaluation benchmarks for reasoning-specific vulnerabilities and human-in-the-loop alignment methods that can inspect and refine reasoning traces as these powerful models continue to advance into increasingly critical domains.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本调查全面考察了大型推理模型（LRM）带来的新兴安全挑战。通过分析，我们发现了几个关键见解，这些见解将 LRM 的安全性与传统的 LLM 区分开来。首先， <span class="ltx_text ltx_font_bold" id="S7.p1.1.1">LRM 暴露了其推理链，从而创建了新的攻击面 </span>，攻击者不仅可以操纵输出结果，还可以操纵中间步骤，这使得基于推理的后门和劫持等复杂攻击成为可能，这些攻击的目标正是推理过程本身。其次，<span class="ltx_text ltx_font_bold" id="S7.p1.1.2"> 传统的以输出为中心的对齐方法对于 LRM 而言并不足够 </span>，因为即使最终输出看起来安全，有害的推理过程也可能持续存在于模型内部，这就需要考虑整个推理轨迹的新方法。这些见解凸显了针对 LRM 开展专门安全研究的必要性，包括针对特定推理漏洞的标准化评估基准，以及能够检查和改进推理轨迹的人机交互对齐方法，因为这些强大的模型正在不断扩展到越来越关键的领域。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">局限性</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This survey has inherent limitations due to the rapidly evolving nature of LRMs. Since the emergence of OpenAI’s o1 series, DeepSeek-R1, and other advanced reasoning models is relatively recent, our taxonomy and findings may become outdated as new research continuously emerges. While we have endeavored to provide a comprehensive overview of safety challenges, attacks, and defenses, we acknowledge that some aspects may require revision as the field matures. Additionally, our reliance on published academic literature may not fully capture proprietary research being conducted within companies developing these models, potentially creating gaps in understanding industry-specific safety measures.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由于逻辑推理模型（LRM）的快速发展，本调查存在固有的局限性。OpenAI 的 o1 系列、DeepSeek-R1 和其他高级推理模型出现时间相对较短，随着新研究的不断涌现，我们的分类和结论可能会过时。尽管我们已尽力提供关于安全挑战、攻击和防御的全面概述，但我们也承认，随着该领域的成熟，某些方面可能需要修订。此外，我们对已发表学术文献的依赖可能无法完全涵盖开发这些模型的公司内部进行的专有研究，这可能会导致对特定行业安全措施的理解存在差距。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andriushchenko and Flammarion (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Maksym Andriushchenko and Nicolas Flammarion. 2024.

</span>
<span class="ltx_bibblock">Does refusal training in llms generalize to the past tense?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2407.11969</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arrieta et&nbsp;al. (2025a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aitor Arrieta, Miriam Ugarte, Pablo Valle, José&nbsp;Antonio Parejo, and Sergio Segura. 2025a.

</span>
<span class="ltx_bibblock">Early external safety testing of openai’s o3-mini: Insights from the pre-deployment evaluation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2501.17749</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arrieta et&nbsp;al. (2025b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aitor Arrieta, Miriam Ugarte, Pablo Valle, José&nbsp;Antonio Parejo, and Sergio Segura. 2025b.

</span>
<span class="ltx_bibblock">o3-mini vs deepseek-r1: Which one is safer?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2501.18438</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Askell et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et&nbsp;al. 2021.

</span>
<span class="ltx_bibblock">A general language assistant as a laboratory for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2112.00861</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bach et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Stephen&nbsp;H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel, Nihal&nbsp;V Nayak, Abheesht Sharma, Taewoon Kim, M&nbsp;Saiful Bari, Thibault Fevry, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Promptsource: An integrated development environment and repository for natural language prompts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2202.01279</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barkur et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sudarshan&nbsp;Kamath Barkur, Sigurd Schacht, and Johannes Scholl. 2025.

</span>
<span class="ltx_bibblock">Deception in llms: Self-preservation and autonomous goals in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2501.16513</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bates and Gurevych (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Luke Bates and Iryna Gurevych. 2023.

</span>
<span class="ltx_bibblock">Like a good nearest neighbor: Practical content moderation and text classification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2302.08957</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Besta et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1609/aaai.v38i16.29720" title="">Graph of thoughts: Solving elaborate problems with large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, 38(16):17682–17690.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bondarenko et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alexander Bondarenko, Denis Volk, Dmitrii Volkov, and Jeffrey Ladish. 2025.

</span>
<span class="ltx_bibblock">Demonstrating specification gaming in reasoning models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2502.13295</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, et&nbsp;al. 2024a.

</span>
<span class="ltx_bibblock">Do not think that much for 2+ 3=? on the overthinking of o1-like llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2412.21187</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yulin Chen, Haoran Li, Yuan Sui, Yufei He, Yue Liu, Yangqiu Song, and Bryan Hooi. 2025.

</span>
<span class="ltx_bibblock">Can indirect prompt injection attacks be detected and removed?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2502.16580</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yulin Chen, Haoran Li, Zihao Zheng, Yangqiu Song, Dekai Wu, and Bryan Hooi. 2024b.

</span>
<span class="ltx_bibblock">Defense against prompt injection attack by leveraging attack techniques.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2411.00459</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, Jie Tang, and Minlie Huang. 2023.

</span>
<span class="ltx_bibblock">Black-box prompt optimization: Aligning large language models without model training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2311.04155</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Zhuosheng Zhang, and Gongshen Liu. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2402.18945" title="">Synghost: Invisible and universal task-agnostic backdoor attack via syntactic transfer</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chi et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jianfeng Chi, Ujjwal Karn, Hongyuan Zhan, Eric Smith, Javier Rando, Yiming Zhang, Kate Plawiak, Zacharie&nbsp;Delpierre Coudert, Kartikeya Upasani, and Mahesh Pasupuleti. 2024a.

</span>
<span class="ltx_bibblock">Llama guard 3 vision: Safeguarding human-ai image understanding conversations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2411.10414</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chi et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jianfeng Chi, Ujjwal Karn, Hongyuan Zhan, Eric Smith, Javier Rando, Yiming Zhang, Kate Plawiak, Zacharie&nbsp;Delpierre Coudert, Kartikeya Upasani, and Mahesh Pasupuleti. 2024b.

</span>
<span class="ltx_bibblock">Llama guard 3 vision: Safeguarding human-ai image understanding conversations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2411.10414</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cuadron et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alejandro Cuadron, Dacheng Li, Wenjie Ma, Xingyao Wang, Yichuan Wang, Siyuan Zhuang, Shu Liu, Luis&nbsp;Gaspar Schroeder, Tian Xia, Huanzhi Mao, Nicholas Thumiger, Aditya Desai, Ion Stoica, Ana Klimovic, Graham Neubig, and Joseph&nbsp;E. Gonzalez. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2502.08235" title="">The danger of overthinking: Examining the reasoning-action dilemma in agentic tasks</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yu&nbsp;Cui, Bryan Hooi, Yujun Cai, and Yiwei Wang. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2503.19326" title="">Process or result? manipulated ending tokens can mislead reasoning llms to ignore the correct reasoning steps</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DeepSeek-AI et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu&nbsp;Wu, Z.&nbsp;F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H.&nbsp;Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J.&nbsp;L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong
Zhang, Ruizhe Pan, Runji Wang, R.&nbsp;J. Chen, R.&nbsp;L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou, Shuting Pan, S.&nbsp;S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T.&nbsp;Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W.&nbsp;L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, X.&nbsp;Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y.&nbsp;K. Li, Y.&nbsp;Q. Wang, Y.&nbsp;X. Wei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi&nbsp;Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y.&nbsp;X. Zhu,
Yanhong Xu, Yanping Huang, Yaohui Li, Yi&nbsp;Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z.&nbsp;Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen Zhang. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2501.12948" title="">Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Ding, Bolian Li, and Ruqi Zhang. 2024.

</span>
<span class="ltx_bibblock">Eta: Evaluating then aligning safety of vision language models at inference time.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2410.06625</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuefeng Du, Reshmi Ghosh, Robert Sim, Ahmed Salem, Vitor Carvalho, Emily Lawton, Yixuan Li, and Jack&nbsp;W Stokes. 2024.

</span>
<span class="ltx_bibblock">Vlmguard: Defending vlms against malicious prompts via unlabeled data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2410.00296</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et&nbsp;al. 2024.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2407.21783</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ethayarajh et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kawin Ethayarajh, Yejin Choi, and Swabha Swayamdipta. 2022.

</span>
<span class="ltx_bibblock">Understanding dataset difficulty with mathcal v-usable information.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">International Conference on Machine Learning</em>. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junfeng Fang, Yukai Wang, Ruipeng Wang, Zijun Yao, Kun Wang, An&nbsp;Zhang, Xiang Wang, and Tat-Seng Chua. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2504.08813" title="">Safemlrm: Demystifying safety in multi-modal large reasoning models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xidong Feng, Ziyu Wan, Muning Wen, Stephen&nbsp;Marcus McAleer, Ying Wen, Weinan Zhang, and Jun Wang. 2023.

</span>
<span class="ltx_bibblock">Alphazero-like tree-search can guide large language model decoding and training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2309.17179</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, and Min Lin. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2410.10760" title="">Denial-of-service poisoning attacks against large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosal et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Soumya&nbsp;Suvra Ghosal, Souradip Chakraborty, Vaibhav Singh, Tianrui Guan, Mengdi Wang, Ahmad Beirami, Furong Huang, Alvaro Velasquez, Dinesh Manocha, and Amrit&nbsp;Singh Bedi. 2024.

</span>
<span class="ltx_bibblock">Immune: Improving safety against jailbreaks in multi-modal llms via inference-time alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2411.18688</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosh et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shaona Ghosh, Prasoon Varshney, Erick Galinkin, and Christopher Parisien. 2024a.

</span>
<span class="ltx_bibblock">Aegis: Online adaptive ai content safety moderation with ensemble of llm experts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2404.05993</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosh et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shaona Ghosh, Prasoon Varshney, Makesh&nbsp;Narsimhan Sreedhar, Aishwarya Padmakumar, Traian Rebedea, Jibin&nbsp;Rajan Varghese, and Christopher Parisien. 2024b.

</span>
<span class="ltx_bibblock">Aegis2. 0: A diverse ai safety dataset and risks taxonomy for alignment of llm guardrails.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Neurips Safe Generative AI Workshop 2024</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guan et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Melody&nbsp;Y Guan, Manas Joglekar, Eric Wallace, Saachi Jain, Boaz Barak, Alec Heylar, Rachel Dias, Andrea Vallone, Hongyu Ren, Jason Wei, et&nbsp;al. 2024.

</span>
<span class="ltx_bibblock">Deliberative alignment: Reasoning enables safer language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2412.16339</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo and Tourani (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhen Guo and Reza Tourani. 2025.

</span>
<span class="ltx_bibblock">Darkmind: Latent chain-of-thought backdoor in customized llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2501.18617</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Seungju Han, Kavel Rao, Allyson Ettinger, Liwei Jiang, Bill&nbsp;Yuchen Lin, Nathan Lambert, Yejin Choi, and Nouha Dziri. 2024.

</span>
<span class="ltx_bibblock">Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2406.18495</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hashemi et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Masoud Hashemi, Oluwanifemi Bamgbose, Sathwik&nbsp;Tejaswi Madhusudhan, Jishnu&nbsp;Sethumadhavan Nair, Aman Tiwari, and Vikas Yadav. 2025.

</span>
<span class="ltx_bibblock">Dnr bench: When silence is smarter–benchmarking over-reasoning in reasoning llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2503.15793</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yufei He, Yuexin Li, Jiaying Wu, Yuan Sui, Yulin Chen, and Bryan Hooi. 2025.

</span>
<span class="ltx_bibblock">Evaluating the paperclip maximizer: Are rl-based language models more likely to pursue instrumental goals?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2502.12206</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Helff et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lukas Helff, Felix Friedrich, Manuel Brack, Patrick Schramowski, and Kristian Kersting. 2024.

</span>
<span class="ltx_bibblock">Llavaguard: Vlm-based safeguard for vision dataset curation and safety assessment.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 8322–8326.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim&nbsp;Furkan Tekin, Zachary Yahn, Yichang Xu, and Ling Liu. 2025.

</span>
<span class="ltx_bibblock">Safety tax: Safety alignment makes your large reasoning models less reasonable.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2503.00555</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaowei Huang, Wenjie Ruan, Wei Huang, Gaojie Jin, Yi&nbsp;Dong, Changshun Wu, Saddek Bensalem, Ronghui Mu, Yi&nbsp;Qi, Xingyu Zhao, Kaiwen Cai, Yanghao Zhang, Sihao Wu, Peipei Xu, Dengyu Wu, Andre Freitas, and Mustafa&nbsp;A. Mustafa. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.11391" title="">A survey of safety and trustworthiness of large language models through the lens of verification and validation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Inan et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer, Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Llama guard: Llm-based input-output safeguard for human-ai conversations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2312.06674</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica. 2024.

</span>
<span class="ltx_bibblock">Livecodebench: Holistic and contamination free evaluation of large language models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2403.07974</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaming Ji, Xinyu Chen, Rui Pan, Han Zhu, Conghui Zhang, Jiahao Li, Donghai Hong, Boyuan Chen, Jiayi Zhou, Kaile Wang, et&nbsp;al. 2025.

</span>
<span class="ltx_bibblock">Safe rlhf-v: Safe reinforcement learning from human feedback in multimodal large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2503.17682</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fengqing Jiang, Zhangchen Xu, Yuetai Li, Luyao Niu, Zhen Xiang, Bo&nbsp;Li, Bill&nbsp;Yuchen Lin, and Radha Poovendran. 2025.

</span>
<span class="ltx_bibblock">Safechain: Safety of language models with long chain-of-thought reasoning capabilities.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2502.12025</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haibo Jin, Leyang Hu, Xinuo Li, Peiyan Zhang, Chonghan Chen, Jun Zhuang, and Haohan Wang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2407.01599" title="">Jailbreakzoo: Survey, landscapes, and horizons in jailbreaking large language and vision-language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pei Ke, Bosi Wen, Zhuoer Feng, Xiao Liu, Xuanyu Lei, Jiale Cheng, Shengyuan Wang, Aohan Zeng, Yuxiao Dong, Hongning Wang, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Critiquellm: Towards an informative critique generation model for evaluation of large language model generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2311.18702</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zixuan Ke, Fangkai Jiao, Yifei Ming, Xuan-Phi Nguyen, Austin Xu, Do&nbsp;Xuan Long, Minzhi Li, Chengwei Qin, Peifeng Wang, Silvio Savarese, Caiming Xiong, and Shafiq Joty. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2504.09037" title="">A survey of frontiers in llm reasoning: Inference scaling, learning to reason, and agentic systems</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang&nbsp;Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Advances in neural information processing systems</em>, 35:22199–22213.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Abhinav Kumar, Jaechul Roh, Ali Naseh, Marzena Karpinska, Mohit Iyyer, Amir Houmansadr, and Eugene Bagdasarian. 2025.

</span>
<span class="ltx_bibblock">Overthinking: Slowdown attacks on reasoning llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2502.02542</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Surender&nbsp;Suresh Kumar, M.L. Cummings, and Alexander Stimpson. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/ICHMS59971.2024.10555871" title="">Strengthening llm trust boundaries: A survey of prompt injection attacks surender suresh kumar dr. m.l. cummings dr. alexander stimpson</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">2024 IEEE 4th International Conference on Human-Machine Systems (ICHMS)</em>, pages 1–6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kuo et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Martin Kuo, Jianyi Zhang, Aolin Ding, Qinsi Wang, Louis DiValentin, Yujia Bao, Wei Wei, Hai Li, and Yiran Chen. 2025.

</span>
<span class="ltx_bibblock">H-cot: Hijacking the chain-of-thought safety reasoning mechanism to jailbreak large reasoning models, including openai o1/o3, deepseek-r1, and gemini 2.0 flash thinking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2502.12893</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nathaniel Li, Ziwen Han, Ian Steneker, Willow Primack, Riley Goodside, Hugh Zhang, Zifan Wang, Cristina Menghini, and Summer Yue. 2024.

</span>
<span class="ltx_bibblock">Llm defenses are not robust to multi-turn human jailbreaks yet.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2408.15221</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuan Li, Zhanke Zhou, Jianing Zhu, Jiangchao Yao, Tongliang Liu, and Bo&nbsp;Han. 2023.

</span>
<span class="ltx_bibblock">Deepinception: Hypnotize large language model to be jailbreaker.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2311.03191</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2025a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuying Li, Zhuo Li, Yuji Kosuga, and Victor Bian. 2025a.

</span>
<span class="ltx_bibblock">Optimizing safe and aligned language generation: A multi-objective grpo approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2503.21819</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2025b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, et&nbsp;al. 2025b.

</span>
<span class="ltx_bibblock">From system 1 to system 2: A survey of reasoning large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2502.17419</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Shuming Shi, and Zhaopeng Tu. 2023.

</span>
<span class="ltx_bibblock">Encouraging divergent thinking in large language models through multi-agent debate.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2305.19118</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lightman et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. 2023.

</span>
<span class="ltx_bibblock">Let’s verify step by step.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yong Lin, Hangyu Lin, Wei Xiong, Shizhe Diao, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, Hanning Zhang, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Mitigating the alignment tax of rlhf.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:2309.06256</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zi&nbsp;Lin, Zihan Wang, Yongqi Tong, Yangkun Wang, Yuxin Guo, Yujia Wang, and Jingbo Shang. 2023b.

</span>
<span class="ltx_bibblock">Toxicchat: Unveiling hidden challenges of toxicity detection in real-world user-ai conversation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:2310.17389</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2025a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qin Liu, Fei Wang, Chaowei Xiao, and Muhao Chen. 2025a.

</span>
<span class="ltx_bibblock">Vlm-guard: Safeguarding vision-language models via fulfilling safety alignment gap.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2502.10486</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Liu, Gelei Deng, Yuekang Li, Kailong Wang, Zihao Wang, Xiaofeng Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Prompt injection attack against llm-integrated applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">arXiv preprint arXiv:2306.05499</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2025b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Liu, Hongcheng Gao, Shengfang Zhai, Xia Jun, Tianyi Wu, Zhiwei Xue, Yulin Chen, Kenji Kawaguchi, Jiaheng Zhang, and Bryan Hooi. 2025b.

</span>
<span class="ltx_bibblock">Guardreasoner: Towards reasoning-based llm safeguards.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">arXiv preprint arXiv:2501.18492</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2025c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Liu, Jiaying Wu, Yufei He, Hongcheng Gao, Hongyu Chen, Baolong Bi, Jiaheng Zhang, Zhiqi Huang, and Bryan Hooi. 2025c.

</span>
<span class="ltx_bibblock">Efficient inference for large reasoning models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2503.23077</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2025d)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Liu, Shengfang Zhai, Mingzhe Du, Yulin Chen, Tri Cao, Hongcheng Gao, Cheng Wang, Xinfeng Li, Kun Wang, Junfeng Fang, Jiaheng Zhang, and Bryan Hooi. 2025d.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2505.11049" title="">Guardreasoner-vl: Safeguarding vlms via reinforced reasoning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhendong Liu, Yuanbi Nie, Yingshui Tan, Xiangyu Yue, Qiushi Cui, Chongjun Wang, Xiaoyong Zhu, and Bo&nbsp;Zheng. 2024.

</span>
<span class="ltx_bibblock">Safety alignment for vision language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">arXiv preprint arXiv:2405.13581</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ximing Lu, Faeze Brahman, Peter West, Jaehun Jang, Khyathi Chandu, Abhilasha Ravichander, Lianhui Qin, Prithviraj Ammanabrolu, Liwei Jiang, Sahana Ramnath, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Inference-time policy adapters (ipa): Tailoring extreme-scale lms without fine-tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2305.15065</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luong et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Trung&nbsp;Quoc Luong, Xinbo Zhang, Zhanming Jie, Peng Sun, Xiaoran Jin, and Hang Li. 2024.

</span>
<span class="ltx_bibblock">Reft: Reasoning with reinforced fine-tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">arXiv preprint arXiv:2401.08967</em>, 3.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marjanović et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sara&nbsp;Vera Marjanović, Arkil Patel, Vaibhav Adlakha, Milad Aghajohari, Parishad BehnamGhader, Mehar Bhatia, Aditi Khandelwal, Austin Kraft, Benno Krojer, Xing&nbsp;Han Lù, Nicholas Meade, Dongchan Shin, Amirhossein Kazemnejad, Gaurav Kamath, Marius Mosbach, Karolina Stańczak, and Siva Reddy. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2504.07128" title="">Deepseek-r1 thoughtology: Let’s think about llm reasoning</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meta (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Meta. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2407.21783" title="">The llama 3 herd of models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mnih et&nbsp;al. (2015)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei&nbsp;A Rusu, Joel Veness, Marc&nbsp;G Bellemare, Alex Graves, Martin Riedmiller, Andreas&nbsp;K Fidjeland, Georg Ostrovski, et&nbsp;al. 2015.

</span>
<span class="ltx_bibblock">Human-level control through deep reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">nature</em>, 518(7540):529–533.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mou et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yutao Mou, Yuxiao Luo, Shikun Zhang, and Wei Ye. 2025.

</span>
<span class="ltx_bibblock">Saro: Enhancing llm safety through reasoning-based alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">arXiv preprint arXiv:2504.09420</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI. 2024.

</span>
<span class="ltx_bibblock">Openai o1 system card.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">arXiv preprint arXiv:2412.16720</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">Advances in neural information processing systems</em>, 35.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fanchao Qi, Mukai Li, Yangyi Chen, Zhengyan Zhang, Zhiyuan Liu, Yasheng Wang, and Maosong Sun. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2105.12400" title="">Hidden killer: Invisible textual backdoor attacks with syntactic trigger</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jianing Qiu, Lin Li, Jiankai Sun, Hao Wei, Zhe Xu, Kyle Lam, and Wu&nbsp;Yuan. 2025.

</span>
<span class="ltx_bibblock">Emerging cyber attack risks of medical ai agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">arXiv preprint arXiv:2504.03759</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaoye Qu, Yafu Li, Zhaochen Su, Weigao Sun, Jianhao Yan, Dongrui Liu, Ganqu Cui, Daizong Liu, Shuxian Liang, Junxian He, et&nbsp;al. 2025.

</span>
<span class="ltx_bibblock">A survey of efficient reasoning for large reasoning models: Language, multimodality, and beyond.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">arXiv preprint arXiv:2503.21614</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qwen et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qwen, :, An&nbsp;Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo&nbsp;Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le&nbsp;Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu&nbsp;Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2412.15115" title="">Qwen2.5 technical report</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher&nbsp;D Manning, Stefano Ermon, and Chelsea Finn. 2024.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rein et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
David Rein, Betty&nbsp;Li Hou, Asa&nbsp;Cooper Stickland, Jackson Petty, Richard&nbsp;Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel&nbsp;R Bowman. 2024.

</span>
<span class="ltx_bibblock">Gpqa: A graduate-level google-proof qa benchmark.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">First Conference on Language Modeling</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu&nbsp;Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, and Jing Shao. 2024.

</span>
<span class="ltx_bibblock">Derail yourself: Multi-turn llm jailbreak attack through self-discovered clues.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">arXiv preprint arXiv:2410.10700</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Romero-Arjona et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Miguel Romero-Arjona, Pablo Valle, Juan&nbsp;C Alonso, Ana&nbsp;B Sánchez, Miriam Ugarte, Antonia Cazalilla, Vicente Cambrón, José&nbsp;A Parejo, Aitor Arrieta, and Sergio Segura. 2025.

</span>
<span class="ltx_bibblock">Red teaming contemporary ai models: Insights from spanish and basque perspectives.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">arXiv preprint arXiv:2503.10192</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Russinovich et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mark Russinovich, Ahmed Salem, and Ronen Eldan. 2024.

</span>
<span class="ltx_bibblock">Great, now write an article about that: The crescendo multi-turn llm jailbreak attack.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">arXiv preprint arXiv:2404.01833</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shah et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rusheb Shah, Soroush Pour, Arush Tagade, Stephen Casper, Javier Rando, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Scalable and transferable black-box jailbreaks for language models via persona modulation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">arXiv preprint arXiv:2311.03348</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, and Deyi Xiong. 2023.

</span>
<span class="ltx_bibblock">Large language model alignment: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">arXiv preprint arXiv:2309.15025</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dan Shi, Tianhao Shen, Yufei Huang, Zhigen Li, Yongqi Leng, Renren Jin, Chuang Liu, Xinwei Wu, Zishan Guo, Linhao Yu, Ling Shi, Bojian Jiang, and Deyi Xiong. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2412.17686" title="">Large language model safety: A holistic survey</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shumailov et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilia Shumailov, Yiren Zhao, Daniel Bates, Nicolas Papernot, Robert Mullins, and Ross Anderson. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/EuroSP51992.2021.00024" title="">Sponge examples: Energy-latency attacks on neural networks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">2021 IEEE European Symposium on Security and Privacy</em>, pages 212–231.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiongtao Sun, Deyue Zhang, Dongdong Yang, Quanchen Zou, and Hui Li. 2024.

</span>
<span class="ltx_bibblock">Multi-turn context jailbreak attack on large language models from first principles.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">arXiv preprint arXiv:2408.04686</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutton et&nbsp;al. (1998)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Richard&nbsp;S Sutton, Andrew&nbsp;G Barto, et&nbsp;al. 1998.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">Reinforcement learning: An introduction</em>, volume&nbsp;1.

</span>
<span class="ltx_bibblock">MIT press Cambridge.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et&nbsp;al. 2025.

</span>
<span class="ltx_bibblock">Kimi k1. 5: Scaling reinforcement learning with llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">arXiv preprint arXiv:2501.12599</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qwen Team. 2024a.

</span>
<span class="ltx_bibblock">Qvq: To see the world with wisdom.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">https://qwenlm.github.io/blog/qvq-72b-preview/</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qwen Team. 2024b.

</span>
<span class="ltx_bibblock">Qwq: Reflect deeply on the boundaries of the unknown.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">https://qwenlm.github.io/blog/qwq-32b-preview/</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Upadhayay et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bibek Upadhayay, Vahid Behzadan, et&nbsp;al. 2025.

</span>
<span class="ltx_bibblock">X-guard: Multilingual guard agent for content moderation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">arXiv preprint arXiv:2504.08848</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo&nbsp;Li, Anima Anandkumar, and Bryan Catanzaro. 2022a.

</span>
<span class="ltx_bibblock">Exploring the limits of domain-adaptive training for detoxifying large-scale language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">Advances in Neural Information Processing Systems</em>, 35:35811–35824.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2025a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haoyu Wang, Zeyu Qin, Li&nbsp;Shen, Xueqian Wang, Minhao Cheng, and Dacheng Tao. 2025a.

</span>
<span class="ltx_bibblock">Leveraging reasoning with guidelines to elicit and utilize knowledge for enhancing safety alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">arXiv preprint arXiv:2502.04040</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. 2023.

</span>
<span class="ltx_bibblock">Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">arXiv preprint arXiv:2305.04091</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pengyu Wang, Dong Zhang, Linyang Li, Chenkun Tan, Xinghao Wang, Ke&nbsp;Ren, Botian Jiang, and Xipeng Qiu. 2024a.

</span>
<span class="ltx_bibblock">Inferaligner: Inference-time alignment for harmlessness through cross-model guidance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">arXiv preprint arXiv:2401.11206</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022b.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language models with self-generated instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">arXiv preprint arXiv:2212.10560</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut&nbsp;Selvan Dhanasekaran, Atharva Naik, David Stap, et&nbsp;al. 2022c.

</span>
<span class="ltx_bibblock">Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">arXiv preprint arXiv:2204.07705</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2025b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zijun Wang, Haoqin Tu, Yuhan Wang, Juncheng Wu, Jieru Mei, Brian&nbsp;R Bartoldson, Bhavya Kailkhura, and Cihang Xie. 2025b.

</span>
<span class="ltx_bibblock">Star-1: Safer alignment of reasoning llms with 1k data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">arXiv preprint arXiv:2504.01903</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zilong Wang, Hao Zhang, Chun-Liang Li, Julian&nbsp;Martin Eisenschlos, Vincent Perot, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, and Tomas Pfister. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.04398" title="">Chain-of-table: Evolving tables in the reasoning chain for table understanding</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Watkins and Dayan (1992)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Christopher&nbsp;JCH Watkins and Peter Dayan. 1992.

</span>
<span class="ltx_bibblock">Q-learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">Machine learning</em>, 8:279–292.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V Le, Denny Zhou, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">Advances in neural information processing systems</em>, 35:24824–24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Welbl et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Johannes Welbl, Amelia Glaese, Jonathan Uesato, Sumanth Dathathri, John Mellor, Lisa&nbsp;Anne Hendricks, Kirsty Anderson, Pushmeet Kohli, Ben Coppin, and Po-Sen Huang. 2021.

</span>
<span class="ltx_bibblock">Challenges in detoxifying language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">arXiv preprint arXiv:2109.07445</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaofei Wen, Wenxuan Zhou, Wenjie&nbsp;Jacky Mo, and Muhao Chen. 2025.

</span>
<span class="ltx_bibblock">Thinkguard: Deliberative slow thinking leads to cautious guardrails.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">arXiv preprint arXiv:2502.13458</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weng et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fenghua Weng, Jian Lou, Jun Feng, Minlie Huang, and Wenjie Wang. 2025.

</span>
<span class="ltx_bibblock">Adversary-aware dpo: Enhancing safety alignment in vision language models via adversarial training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">arXiv preprint arXiv:2502.11455</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jeff Wu, Long Ouyang, Daniel&nbsp;M Ziegler, Nisan Stiennon, Ryan Lowe, Jan Leike, and Paul Christiano. 2021.

</span>
<span class="ltx_bibblock">Recursively summarizing books with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">arXiv preprint arXiv:2109.10862</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2025a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tong Wu, Chong Xiang, Jiachen&nbsp;T. Wang, and Prateek Mittal. 2025a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2503.24370" title="">Effectively controlling reasoning models through thinking intervention</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2025b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuyang Wu, Yifei Wang, Tianqi Du, Stefanie Jegelka, and Yisen Wang. 2025b.

</span>
<span class="ltx_bibblock">When more is less: Understanding chain-of-thought length in llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">arXiv preprint arXiv:2502.07266</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhen Xiang, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, and Bo&nbsp;Li. 2024.

</span>
<span class="ltx_bibblock">Badchain: Backdoor chain-of-thought prompting for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib106.1.1">arXiv preprint arXiv:2401.12242</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiashu Xu, Mingyu&nbsp;Derek Ma, Fei Wang, Chaowei Xiao, and Muhao Chen. 2023.

</span>
<span class="ltx_bibblock">Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib107.1.1">arXiv preprint arXiv:2305.14710</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rongwu Xu, Xiaojian Li, Shuo Chen, and Wei Xu. 2025.

</span>
<span class="ltx_bibblock">Nuclear deployed: Analyzing catastrophic risks in decision-making of autonomous llm agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib108.1.1">arXiv preprint arXiv:2502.11355</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Yang, Xiaoxuan He, Hongkun Pan, Xiyan Jiang, Yan Deng, Xingtao Yang, Haoyu Lu, Dacheng Yin, Fengyun Rao, Minfeng Zhu, Bo&nbsp;Zhang, and Wei Chen. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2503.10615" title="">R1-onevision: Advancing generalized multimodal reasoning through cross-modal formalization</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hongwei Yao, Jian Lou, and Zhan Qin. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/ICASSP48485.2024.10446267" title="">Poisonprompt: Backdoor attack on prompt-based large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib110.1.1">ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 7745–7749.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Huanjin Yao, Jiaxing Huang, Wenhao Wu, Jingyi Zhang, Yibo Wang, Shunyu Liu, Yingjie Wang, Yuxin Song, Haocheng Feng, Li&nbsp;Shen, and Dacheng Tao. 2024b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2412.18319" title="">Mulberry: Empowering mllm with o1-like reasoning and reflection via collective monte carlo tree search</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas&nbsp;L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.10601" title="">Tree of thoughts: Deliberate problem solving with large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yang Yao, Xuan Tong, Ruofan Wang, Yixu Wang, Lujundong Li, Liang Liu, Yan Teng, and Yingchun Wang. 2025.

</span>
<span class="ltx_bibblock">A mousetrap: Fooling large reasoning models for jailbreak with chain of iterative chaos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib113.1.1">arXiv preprint arXiv:2502.15806</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mang Ye, Xuankun Rong, Wenke Huang, Bo&nbsp;Du, Nenghai Yu, and Dacheng Tao. 2025.

</span>
<span class="ltx_bibblock">A survey of safety on large vision-language models: Attacks, defenses and evaluations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib114.1.1">arXiv preprint arXiv:2502.14881</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sibo Yi, Yule Liu, Zhen Sun, Tianshuo Cong, Xinlei He, Jiaxing Song, Ke&nbsp;Xu, and Qi&nbsp;Li. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2407.04295" title="">Jailbreak attacks and defenses against large language models: A survey</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ying et&nbsp;al. (2025a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zonghao Ying, Deyue Zhang, Zonglei Jing, Yisong Xiao, Quanchen Zou, Aishan Liu, Siyuan Liang, Xiangzheng Zhang, Xianglong Liu, and Dacheng Tao. 2025a.

</span>
<span class="ltx_bibblock">Reasoning-augmented conversation for multi-turn jailbreak attacks on large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib116.1.1">arXiv preprint arXiv:2502.11054</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ying et&nbsp;al. (2025b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zonghao Ying, Guangyi Zheng, Yongxin Huang, Deyue Zhang, Wenxin Zhang, Quanchen Zou, Aishan Liu, Xianglong Liu, and Dacheng Tao. 2025b.

</span>
<span class="ltx_bibblock">Towards understanding the safety boundaries of deepseek models: Evaluation and findings.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib117.1.1">arXiv preprint arXiv:2503.15092</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zaremba et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wojciech Zaremba, Evgenia Nitishinskaya, Boaz Barak, Stephanie Lin, Sam Toyer, Yaodong Yu, Rachel Dias, Eric Wallace, Kai Xiao, Johannes Heidecke, and Amelia Glaese. 2025.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2501.18841" title="">Trading inference-time compute for adversarial robustness</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenjun Zeng, Yuchi Liu, Ryan Mullins, Ludovic Peran, Joe Fernandez, Hamza Harkous, Karthik Narasimhan, Drew Proud, Piyush Kumar, Bhaktipriya Radharapu, et&nbsp;al. 2024a.

</span>
<span class="ltx_bibblock">Shieldgemma: Generative ai content moderation based on gemma.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib119.1.1">arXiv preprint arXiv:2407.21772</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia, and Weiyan Shi. 2024b.

</span>
<span class="ltx_bibblock">How johnny can persuade llms to jailbreak them: Rethinking persuasion to challenge ai safety by humanizing llms.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib120.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 14322–14350.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2025a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Ning Wang, Zhenhong Long, Peijun Yang, Jiaojiao Zhao, Minjie Hua, Chaoyang Ma, Kai Wang, et&nbsp;al. 2025a.

</span>
<span class="ltx_bibblock">Safety evaluation of deepseek models in chinese contexts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">arXiv preprint arXiv:2502.11137</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2025b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yichi Zhang, Zihao Zeng, Dongbai Li, Yao Huang, Zhijie Deng, and Yinpeng Dong. 2025b.

</span>
<span class="ltx_bibblock">Realsafe-r1: Safety-aligned deepseek-r1 without compromising reasoning capability.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib122.1.1">arXiv preprint arXiv:2504.10081</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2025c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yichi Zhang, Siyuan Zhang, Yao Huang, Zeyu Xia, Zhengwei Fang, Xiao Yang, Ranjie Duan, Dong Yan, Yinpeng Dong, and Jun Zhu. 2025c.

</span>
<span class="ltx_bibblock">Stair: Improving safety alignment with introspective reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib123.1.1">arXiv preprint arXiv:2502.02384</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yongting Zhang, Lu&nbsp;Chen, Guodong Zheng, Yifeng Gao, Rui Zheng, Jinlan Fu, Zhenfei Yin, Senjie Jin, Yu&nbsp;Qiao, Xuanjing Huang, et&nbsp;al. 2024.

</span>
<span class="ltx_bibblock">Spa-vl: A comprehensive safety preference alignment dataset for vision language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">arXiv preprint arXiv:2406.12030</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gejian Zhao, Hanzhou Wu, Xinpeng Zhang, and Athanasios&nbsp;V Vasilakos. 2025.

</span>
<span class="ltx_bibblock">Shadowcot: Cognitive hijacking for stealthy reasoning backdoors in llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib125.1.1">arXiv preprint arXiv:2504.05605</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shuai Zhao, Meihuizi Jia, Zhongliang Guo, Leilei Gan, Xiaoyu Xu, Xiaobao Wu, Jie Fu, Yichao Feng, Fengjun Pan, and Luu&nbsp;Anh Tuan. 2024.

</span>
<span class="ltx_bibblock">A survey of backdoor attacks and defenses on large language models: Implications for security measures.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib126.1.1">Authorea Preprints</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2025)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kaiwen Zhou, Chengzhi Liu, Xuandong Zhao, Shreedhar Jangam, Jayanth Srinivasa, Gaowen Liu, Dawn Song, and Xin&nbsp;Eric Wang. 2025.

</span>
<span class="ltx_bibblock">The hidden risks of large reasoning models: A safety assessment of r1.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">arXiv preprint arXiv:2502.12659</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuhui Zhou. 2020.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">Challenges in automated debiasing for toxic language detection</em>.

</span>
<span class="ltx_bibblock">University of Washington.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2025a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junda Zhu, Lingyong Yan, Shuaiqiang Wang, Dawei Yin, and Lei Sha. 2025a.

</span>
<span class="ltx_bibblock">Reasoning-to-defend: Safety-aware reasoning can defend large language models from jailbreaking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">arXiv preprint arXiv:2502.12970</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2025b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zihao Zhu, Hongbao Zhang, Mingda Zhang, Ruotong Wang, Guanzong Wu, Ke&nbsp;Xu, and Baoyuan Wu. 2025b.

</span>
<span class="ltx_bibblock">Bot: Breaking long thought processes of o1-like large language models through backdoor attack.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib130.1.1">arXiv preprint arXiv:2502.12202</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">报告问题</font></font></font></button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>@charset "UTF-8";
/*!
 * Pico.css v1.5.6 (https://picocss.com)
 * Copyright 2019-2022 - Licensed under MIT
 */
/**
 * Theme: default
 */
#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 0.25rem;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 1rem;
  --typography-spacing-vertical: 1.5rem;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 0.75rem;
  --form-element-spacing-horizontal: 1rem;
  --nav-element-spacing-vertical: 1rem;
  --nav-element-spacing-horizontal: 0.5rem;
  --nav-link-spacing-vertical: 0.5rem;
  --nav-link-spacing-horizontal: 0.5rem;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(0.25rem);
}
@media (min-width: 576px) {
  #mount {
    --font-size: 17px;
  }
}
@media (min-width: 768px) {
  #mount {
    --font-size: 18px;
  }
}
@media (min-width: 992px) {
  #mount {
    --font-size: 19px;
  }
}
@media (min-width: 1200px) {
  #mount {
    --font-size: 20px;
  }
}

@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2);
  }
}
@media (min-width: 768px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3);
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3.5);
  }
}

@media (min-width: 576px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}
@media (min-width: 992px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.75);
  }
}
@media (min-width: 1200px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 2);
  }
}

dialog > article {
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
}
@media (min-width: 576px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 3);
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}

a {
  --text-decoration: none;
}
a.secondary,
a.contrast {
  --text-decoration: underline;
}

small {
  --font-size: 0.875em;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  --font-weight: 700;
}

h1 {
  --font-size: 2rem;
  --typography-spacing-vertical: 3rem;
}

h2 {
  --font-size: 1.75rem;
  --typography-spacing-vertical: 2.625rem;
}

h3 {
  --font-size: 1.5rem;
  --typography-spacing-vertical: 2.25rem;
}

h4 {
  --font-size: 1.25rem;
  --typography-spacing-vertical: 1.874rem;
}

h5 {
  --font-size: 1.125rem;
  --typography-spacing-vertical: 1.6875rem;
}

[type="checkbox"],
[type="radio"] {
  --border-width: 2px;
}

[type="checkbox"][role="switch"] {
  --border-width: 2px;
}

thead th,
thead td,
tfoot th,
tfoot td {
  --border-width: 3px;
}

:not(thead, tfoot) > * > td {
  --font-size: 0.875em;
}

pre,
code,
kbd,
samp {
  --font-family: "Menlo", "Consolas", "Roboto Mono", "Ubuntu Monospace",
    "Noto Mono", "Oxygen Mono", "Liberation Mono", monospace,
    "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
}

kbd {
  --font-weight: bolder;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --background-color: #fff;
  --background-light-green: #f5f7f9;
  --color: hsl(205deg, 20%, 32%);
  --h1-color: hsl(205deg, 30%, 15%);
  --h2-color: #24333e;
  --h3-color: hsl(205deg, 25%, 23%);
  --h4-color: #374956;
  --h5-color: hsl(205deg, 20%, 32%);
  --h6-color: #4d606d;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: hsl(205deg, 20%, 94%);
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 90%, 32%);
  --primary-focus: rgba(16, 149, 193, 0.125);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 20%, 32%);
  --secondary-focus: rgba(89, 107, 120, 0.125);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 30%, 15%);
  --contrast-hover: #000;
  --contrast-focus: rgba(89, 107, 120, 0.125);
  --contrast-inverse: #fff;
  --mark-background-color: #fff2ca;
  --mark-color: #543a26;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: transparent;
  --form-element-border-color: hsl(205deg, 14%, 68%);
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: transparent;
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 18%, 86%);
  --form-element-disabled-border-color: hsl(205deg, 14%, 68%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #c62828;
  --form-element-invalid-active-border-color: #d32f2f;
  --form-element-invalid-focus-color: rgba(211, 47, 47, 0.125);
  --form-element-valid-border-color: #388e3c;
  --form-element-valid-active-border-color: #43a047;
  --form-element-valid-focus-color: rgba(67, 160, 71, 0.125);
  --switch-background-color: hsl(205deg, 16%, 77%);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: hsl(205deg, 18%, 86%);
  --range-active-border-color: hsl(205deg, 16%, 77%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: #f6f8f9;
  --code-background-color: hsl(205deg, 20%, 94%);
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 40%, 50%);
  --code-property-color: hsl(185deg, 40%, 40%);
  --code-value-color: hsl(40deg, 20%, 50%);
  --code-comment-color: hsl(205deg, 14%, 68%);
  --accordion-border-color: var(--muted-border-color);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: var(--background-color);
  --card-border-color: var(--muted-border-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(27, 40, 50, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(27, 40, 50, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(27, 40, 50, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(27, 40, 50, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(27, 40, 50, 0.04302),
    0.5rem 1rem 6rem rgba(27, 40, 50, 0.06),
    0 0 0 0.0625rem rgba(27, 40, 50, 0.015);
  --card-sectionning-background-color: #fbfbfc;
  --dropdown-background-color: #fbfbfc;
  --dropdown-border-color: #e1e6eb;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: hsl(205deg, 20%, 94%);
  --modal-overlay-background-color: rgba(213, 220, 226, 0.7);
  --progress-background-color: hsl(205deg, 18%, 86%);
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(198, 40, 40)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(56, 142, 60)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  --float-ball-more-button-border-color: #f6f6f6;
  --float-ball-more-button-background-color: #ffffff;
  --float-ball-more-button-svg-color: #6c6f73;
  color-scheme: light;
  --service-bg-hover: #f7faff;
  --service-bg: #fafbfb;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --background-color: #11191f;
    --float-ball-more-button-background-color: #ffffff;
    --background-light-green: #141e26;
    --color: hsl(205deg, 16%, 77%);
    --h1-color: hsl(205deg, 20%, 94%);
    --h2-color: #e1e6eb;
    --h3-color: hsl(205deg, 18%, 86%);
    --h4-color: #c8d1d8;
    --h5-color: hsl(205deg, 16%, 77%);
    --h6-color: #afbbc4;
    --muted-color: hsl(205deg, 10%, 50%);
    --muted-border-color: #1f2d38;
    --primary: hsl(195deg, 85%, 41%);
    --primary-hover: hsl(195deg, 80%, 50%);
    --primary-focus: rgba(16, 149, 193, 0.25);
    --primary-inverse: #fff;
    --secondary: hsl(205deg, 15%, 41%);
    --secondary-hover: hsl(205deg, 10%, 50%);
    --secondary-focus: rgba(115, 130, 140, 0.25);
    --secondary-inverse: #fff;
    --contrast: hsl(205deg, 20%, 94%);
    --contrast-hover: #fff;
    --contrast-focus: rgba(115, 130, 140, 0.25);
    --contrast-inverse: #000;
    --mark-background-color: #d1c284;
    --mark-color: #11191f;
    --ins-color: #388e3c;
    --del-color: #c62828;
    --blockquote-border-color: var(--muted-border-color);
    --blockquote-footer-color: var(--muted-color);
    --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --form-element-background-color: #11191f;
    --form-element-border-color: #374956;
    --form-element-color: var(--color);
    --form-element-placeholder-color: var(--muted-color);
    --form-element-active-background-color: var(
      --form-element-background-color
    );
    --form-element-active-border-color: var(--primary);
    --form-element-focus-color: var(--primary-focus);
    --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
    --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
    --form-element-disabled-opacity: 0.5;
    --form-element-invalid-border-color: #b71c1c;
    --form-element-invalid-active-border-color: #c62828;
    --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
    --form-element-valid-border-color: #2e7d32;
    --form-element-valid-active-border-color: #388e3c;
    --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
    --switch-background-color: #374956;
    --switch-color: var(--primary-inverse);
    --switch-checked-background-color: var(--primary);
    --range-border-color: #24333e;
    --range-active-border-color: hsl(205deg, 25%, 23%);
    --range-thumb-border-color: var(--background-color);
    --range-thumb-color: var(--secondary);
    --range-thumb-hover-color: var(--secondary-hover);
    --range-thumb-active-color: var(--primary);
    --table-border-color: var(--muted-border-color);
    --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
    --code-background-color: #18232c;
    --code-color: var(--muted-color);
    --code-kbd-background-color: var(--contrast);
    --code-kbd-color: var(--contrast-inverse);
    --code-tag-color: hsl(330deg, 30%, 50%);
    --code-property-color: hsl(185deg, 30%, 50%);
    --code-value-color: hsl(40deg, 10%, 50%);
    --code-comment-color: #4d606d;
    --accordion-border-color: var(--muted-border-color);
    --accordion-active-summary-color: var(--primary);
    --accordion-close-summary-color: var(--color);
    --accordion-open-summary-color: var(--muted-color);
    --card-background-color: #141e26;
    --card-border-color: var(--card-background-color);
    --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
      0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
      0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
      0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
      0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
      0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
    --card-sectionning-background-color: #18232c;
    --dropdown-background-color: hsl(205deg, 30%, 15%);
    --dropdown-border-color: #24333e;
    --dropdown-box-shadow: var(--card-box-shadow);
    --dropdown-color: var(--color);
    --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
    --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
    --progress-background-color: #24333e;
    --progress-color: var(--primary);
    --loading-spinner-opacity: 0.5;
    --tooltip-background-color: var(--contrast);
    --tooltip-color: var(--contrast-inverse);
    --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
    --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
    --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
    --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
    --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
    --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-share: url("data:image/svg+xml;charset=utf-8;base64,PHN2ZyB3aWR0aD0nMjInIGhlaWdodD0nMjInIHZpZXdCb3g9JzAgMCAyMiAyMicgZmlsbD0nbm9uZScgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJz48cGF0aCBkPSdNMTcuOTM0OCA3LjY0ODQ0QzE5Ljg5NDEgNy42NDg0NCAyMS40ODU1IDYuMDU0NjkgMjEuNDg1NSA0LjA5NzY2QzIxLjQ4NTUgMi4xNDA2MiAxOS44OTE4IDAuNTQ2ODc1IDE3LjkzNDggMC41NDY4NzVDMTUuOTc1NCAwLjU0Njg3NSAxNC4zODQgMi4xNDA2MiAxNC4zODQgNC4wOTc2NkMxNC4zODQgNC4yOTkyMiAxNC40MDA0IDQuNDkzNzUgMTQuNDMzMiA0LjY4NTk0TDYuMzIzODMgOC4zNTM5MUM1LjcwOTc3IDcuODQ1MzEgNC45MjIyNyA3LjU0MDYyIDQuMDY0NDUgNy41NDA2MkMyLjEwNTA4IDcuNTQwNjIgMC41MTM2NzIgOS4xMzQzOCAwLjUxMzY3MiAxMS4wOTE0QzAuNTEzNjcyIDEzLjA0ODQgMi4xMDc0MiAxNC42NDIyIDQuMDY0NDUgMTQuNjQyMkM0LjgzMzIgMTQuNjQyMiA1LjU0NTcgMTQuMzk2MSA2LjEyNjk1IDEzLjk4MTNMMTEuNDk0MSAxNi45OTUzQzExLjQxNjggMTcuMjg1OSAxMS4zNzcgMTcuNTg4MyAxMS4zNzcgMTcuOTAyM0MxMS4zNzcgMTkuODYxNyAxMi45NzA3IDIxLjQ1MzEgMTQuOTI3NyAyMS40NTMxQzE2Ljg4NzEgMjEuNDUzMSAxOC40Nzg1IDE5Ljg1OTQgMTguNDc4NSAxNy45MDIzQzE4LjQ3ODUgMTUuOTQzIDE2Ljg4NDggMTQuMzUxNiAxNC45Mjc3IDE0LjM1MTZDMTMuOTU3NCAxNC4zNTE2IDEzLjA3ODUgMTQuNzQzIDEyLjQzNjMgMTUuMzczNEw3LjMyMjI3IDEyLjUwNDdDNy41MDk3NyAxMi4wNzExIDcuNjE1MjMgMTEuNTk1MyA3LjYxNTIzIDExLjA5MzhDNy42MTUyMyAxMC42ODEyIDcuNTQ0OTIgMTAuMjg3NSA3LjQxNjAyIDkuOTE5NTNMMTUuMjIzIDYuMzg3NUMxNS44NzQ2IDcuMTU2MjUgMTYuODQ5NiA3LjY0ODQ0IDE3LjkzNDggNy42NDg0NFpNNC4wNjQ0NSAxMi43Njk1QzMuMTQxMDIgMTIuNzY5NSAyLjM4ODY3IDEyLjAxNzIgMi4zODg2NyAxMS4wOTM4QzIuMzg4NjcgMTAuMTcwMyAzLjE0MTAyIDkuNDE3OTcgNC4wNjQ0NSA5LjQxNzk3QzQuOTg3ODkgOS40MTc5NyA1Ljc0MDIzIDEwLjE3MDMgNS43NDAyMyAxMS4wOTM4QzUuNzQwMjMgMTIuMDE3MiA0Ljk4Nzg5IDEyLjc2OTUgNC4wNjQ0NSAxMi43Njk1Wk0xNC45Mjc3IDE2LjIyNjZDMTUuODUxMiAxNi4yMjY2IDE2LjYwMzUgMTYuOTc4OSAxNi42MDM1IDE3LjkwMjNDMTYuNjAzNSAxOC44MjU4IDE1Ljg1MTIgMTkuNTc4MSAxNC45Mjc3IDE5LjU3ODFDMTQuMDA0MyAxOS41NzgxIDEzLjI1MiAxOC44MjU4IDEzLjI1MiAxNy45MDIzQzEzLjI1MiAxNi45Nzg5IDE0LjAwMiAxNi4yMjY2IDE0LjkyNzcgMTYuMjI2NlpNMTcuOTM0OCAyLjQxOTUzQzE4Ljg1ODIgMi40MTk1MyAxOS42MTA1IDMuMTcxODcgMTkuNjEwNSA0LjA5NTMxQzE5LjYxMDUgNS4wMTg3NSAxOC44NTgyIDUuNzcxMDkgMTcuOTM0OCA1Ljc3MTA5QzE3LjAxMTMgNS43NzEwOSAxNi4yNTkgNS4wMTg3NSAxNi4yNTkgNC4wOTUzMUMxNi4yNTkgMy4xNzE4NyAxNy4wMTEzIDIuNDE5NTMgMTcuOTM0OCAyLjQxOTUzWicgZmlsbD0nI0I2QjZCNicvPjwvc3ZnPiA=");
    color-scheme: dark;
    --service-bg-hover: #22292f;
    --service-bg: rgba(0, 0, 0, 0.1);
  }
}
[data-theme="dark"] {
  --background-color: #11191f;
  --float-ball-more-button-background-color: #191919;
  --background-light-green: #141e26;
  --color: hsl(205deg, 16%, 77%);
  --h1-color: hsl(205deg, 20%, 94%);
  --h2-color: #e1e6eb;
  --h3-color: hsl(205deg, 18%, 86%);
  --h4-color: #c8d1d8;
  --h5-color: hsl(205deg, 16%, 77%);
  --h6-color: #afbbc4;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: #1f2d38;
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 80%, 50%);
  --primary-focus: rgba(16, 149, 193, 0.25);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 10%, 50%);
  --secondary-focus: rgba(115, 130, 140, 0.25);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 20%, 94%);
  --contrast-hover: #fff;
  --contrast-focus: rgba(115, 130, 140, 0.25);
  --contrast-inverse: #000;
  --mark-background-color: #d1c284;
  --mark-color: #11191f;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: #11191f;
  --form-element-border-color: #374956;
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: var(--form-element-background-color);
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
  --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #b71c1c;
  --form-element-invalid-active-border-color: #c62828;
  --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
  --form-element-valid-border-color: #2e7d32;
  --form-element-valid-active-border-color: #388e3c;
  --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
  --switch-background-color: #374956;
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: #24333e;
  --range-active-border-color: hsl(205deg, 25%, 23%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
  --code-background-color: #18232c;
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 30%, 50%);
  --code-property-color: hsl(185deg, 30%, 50%);
  --code-value-color: hsl(40deg, 10%, 50%);
  --code-comment-color: #4d606d;
  --accordion-border-color: var(--muted-border-color);
  --accordion-active-summary-color: var(--primary);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: #141e26;
  --card-border-color: var(--card-background-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
    0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
  --card-sectionning-background-color: #18232c;
  --dropdown-background-color: hsl(205deg, 30%, 15%);
  --dropdown-border-color: #24333e;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
  --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
  --progress-background-color: #24333e;
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  color-scheme: dark;
  --service-bg: rgba(0, 0, 0, 0.1);
}

progress,
[type="checkbox"],
[type="radio"],
[type="range"] {
  accent-color: var(--primary);
}

/**
 * Document
 * Content-box & Responsive typography
 */
*,
*::before,
*::after {
  box-sizing: border-box;
  background-repeat: no-repeat;
}

::before,
::after {
  text-decoration: inherit;
  vertical-align: inherit;
}

:where(#mount) {
  -webkit-tap-highlight-color: transparent;
  -webkit-text-size-adjust: 100%;
  -moz-text-size-adjust: 100%;
  text-size-adjust: 100%;
  background-color: var(--background-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  line-height: var(--line-height);
  font-family: var(--font-family);
  text-rendering: optimizeLegibility;
  overflow-wrap: break-word;
  cursor: default;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
}

/**
 * Sectioning
 * Container and responsive spacings for header, main, footer
 */
main {
  display: block;
}

#mount {
  width: 100%;
  margin: 0;
}
#mount > header,
#mount > main,
#mount > footer {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
}
@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 2px !important;
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 12px !important;
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 24px !important;
  }
}

/**
* Container
*/
.container,
.container-fluid {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding-right: var(--spacing);
  padding-left: var(--spacing);
}
/*
@media (min-width: 576px) {
  .container {
    max-width: 510px;
    padding-right: 0;
    padding-left: 0;
  }
}
@media (min-width: 768px) {
  .container {
    max-width: 700px;
  }
} */
@media (min-width: 992px) {
  .container {
    max-width: 920px;
  }
}
@media (min-width: 1200px) {
  .container {
    max-width: 1130px;
  }
}

/**
 * Section
 * Responsive spacings for section
 */
section {
  margin-bottom: var(--block-spacing-vertical);
}

/**
* Grid
* Minimal grid system with auto-layout columns
*/
.grid {
  grid-column-gap: var(--grid-spacing-horizontal);
  grid-row-gap: var(--grid-spacing-vertical);
  display: grid;
  grid-template-columns: 1fr;
  margin: 0;
}
@media (min-width: 1280px) {
  .grid {
    grid-template-columns: repeat(auto-fit, minmax(0%, 1fr));
  }
}
.grid > * {
  min-width: 0;
}

/**
 * Horizontal scroller (<figure>)
 */
figure {
  display: block;
  margin: 0;
  padding: 0;
  overflow-x: auto;
}
figure figcaption {
  padding: calc(var(--spacing) * 0.5) 0;
  color: var(--muted-color);
}

/**
 * Typography
 */
b,
strong {
  font-weight: bolder;
}

sub,
sup {
  position: relative;
  font-size: 0.75em;
  line-height: 0;
  vertical-align: baseline;
}

sub {
  bottom: -0.25em;
}

sup {
  top: -0.5em;
}

address,
blockquote,
dl,
figure,
form,
ol,
p,
pre,
table,
ul {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: var(--font-size);
}

a,
[role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
a:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}
a:focus,
[role="link"]:focus {
  --background-color: var(--primary-focus);
}
a.secondary,
[role="link"].secondary {
  --color: var(--secondary);
}
a.secondary:is([aria-current], :hover, :active, :focus),
[role="link"].secondary:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}
a.secondary:focus,
[role="link"].secondary:focus {
  --background-color: var(--secondary-focus);
}
a.contrast,
[role="link"].contrast {
  --color: var(--contrast);
}
a.contrast:is([aria-current], :hover, :active, :focus),
[role="link"].contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}
a.contrast:focus,
[role="link"].contrast:focus {
  --background-color: var(--contrast-focus);
}

h1,
h2,
h3,
h4,
h5,
h6 {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  font-family: var(--font-family);
}

h1 {
  --color: var(--h1-color);
}

h2 {
  --color: var(--h2-color);
}

h3 {
  --color: var(--h3-color);
}

h4 {
  --color: var(--h4-color);
}

h5 {
  --color: var(--h5-color);
}

h6 {
  --color: var(--h6-color);
}

:where(address, blockquote, dl, figure, form, ol, p, pre, table, ul)
  ~ :is(h1, h2, h3, h4, h5, h6) {
  margin-top: var(--typography-spacing-vertical);
}

hgroup,
.headings {
  margin-bottom: var(--typography-spacing-vertical);
}
hgroup > *,
.headings > * {
  margin-bottom: 0;
}
hgroup > *:last-child,
.headings > *:last-child {
  --color: var(--muted-color);
  --font-weight: unset;
  font-size: 1rem;
  font-family: unset;
}

p {
  margin-bottom: var(--typography-spacing-vertical);
}

small {
  font-size: var(--font-size);
}

:where(dl, ol, ul) {
  padding-right: 0;
  padding-left: var(--spacing);
  -webkit-padding-start: var(--spacing);
  padding-inline-start: var(--spacing);
  -webkit-padding-end: 0;
  padding-inline-end: 0;
}
:where(dl, ol, ul) li {
  margin-bottom: calc(var(--typography-spacing-vertical) * 0.25);
}

:where(dl, ol, ul) :is(dl, ol, ul) {
  margin: 0;
  margin-top: calc(var(--typography-spacing-vertical) * 0.25);
}

ul li {
  list-style: square;
}

mark {
  padding: 0.125rem 0.25rem;
  background-color: var(--mark-background-color);
  color: var(--mark-color);
  vertical-align: baseline;
}

blockquote {
  display: block;
  margin: var(--typography-spacing-vertical) 0;
  padding: var(--spacing);
  border-right: none;
  border-left: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-start: 0.25rem solid var(--blockquote-border-color);
  border-inline-start: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-end: none;
  border-inline-end: none;
}
blockquote footer {
  margin-top: calc(var(--typography-spacing-vertical) * 0.5);
  color: var(--blockquote-footer-color);
}

abbr[title] {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}

ins {
  color: var(--ins-color);
  text-decoration: none;
}

del {
  color: var(--del-color);
}

::-moz-selection {
  background-color: var(--primary-focus);
}

::selection {
  background-color: var(--primary-focus);
}

/**
 * Embedded content
 */
:where(audio, canvas, iframe, img, svg, video) {
  vertical-align: middle;
}

audio,
video {
  display: inline-block;
}

audio:not([controls]) {
  display: none;
  height: 0;
}

:where(iframe) {
  border-style: none;
}

img {
  max-width: 100%;
  height: auto;
  border-style: none;
}

:where(svg:not([fill])) {
  fill: currentColor;
}

svg:not(#mount) {
  overflow: hidden;
}

/**
 * Button
 */
button {
  margin: 0;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

button,
[type="button"],
[type="reset"],
[type="submit"] {
  -webkit-appearance: button;
}

button {
  display: block;
  width: 100%;
  margin-bottom: var(--spacing);
}

[role="button"] {
  display: inline-block;
  text-decoration: none;
}

button,
input[type="submit"],
input[type="button"],
input[type="reset"],
[role="button"] {
  --background-color: var(--primary);
  --border-color: var(--primary);
  --color: var(--primary-inverse);
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
button:is([aria-current], :hover, :active, :focus),
input[type="submit"]:is([aria-current], :hover, :active, :focus),
input[type="button"]:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus),
[role="button"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--primary-hover);
  --border-color: var(--primary-hover);
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  --color: var(--primary-inverse);
}
button:focus,
input[type="submit"]:focus,
input[type="button"]:focus,
input[type="reset"]:focus,
[role="button"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--primary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary,
input[type="reset"] {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  cursor: pointer;
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:focus,
input[type="reset"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--secondary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast {
  --background-color: var(--contrast);
  --border-color: var(--contrast);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--contrast-hover);
  --border-color: var(--contrast-hover);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--contrast-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline,
input[type="reset"].outline {
  --background-color: transparent;
  --color: var(--primary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --background-color: transparent;
  --color: var(--primary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary,
input[type="reset"].outline {
  --color: var(--secondary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast {
  --color: var(--contrast);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}

:where(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  )[disabled],
:where(fieldset[disabled])
  :is(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  ),
a[role="button"]:not([href]) {
  opacity: 0.5;
  pointer-events: none;
}

/**
 * Form elements
 */
input,
optgroup,
select,
textarea {
  margin: 0;
  font-size: 1rem;
  line-height: var(--line-height);
  font-family: inherit;
  letter-spacing: inherit;
}

input {
  overflow: visible;
}

select {
  text-transform: none;
}

legend {
  max-width: 100%;
  padding: 0;
  color: inherit;
  white-space: normal;
}

textarea {
  overflow: auto;
}

[type="checkbox"],
[type="radio"] {
  padding: 0;
}

::-webkit-inner-spin-button,
::-webkit-outer-spin-button {
  height: auto;
}

[type="search"] {
  -webkit-appearance: textfield;
  outline-offset: -2px;
}

[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}

::-webkit-file-upload-button {
  -webkit-appearance: button;
  font: inherit;
}

::-moz-focus-inner {
  padding: 0;
  border-style: none;
}

:-moz-focusring {
  outline: none;
}

:-moz-ui-invalid {
  box-shadow: none;
}

::-ms-expand {
  display: none;
}

[type="file"],
[type="range"] {
  padding: 0;
  border-width: 0;
}

input:not([type="checkbox"], [type="radio"], [type="range"]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
}

fieldset {
  margin: 0;
  margin-bottom: var(--spacing);
  padding: 0;
  border: 0;
}

label,
fieldset legend {
  display: block;
  margin-bottom: calc(var(--spacing) * 0.25);
  font-weight: var(--form-label-font-weight, var(--font-weight));
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  width: 100%;
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]),
select,
textarea {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
}

input,
select,
textarea {
  --background-color: var(--form-element-background-color);
  --border-color: var(--form-element-border-color);
  --color: var(--form-element-color);
  --box-shadow: none;
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="checkbox"],
    [type="radio"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --background-color: var(--form-element-active-background-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="switch"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --border-color: var(--form-element-active-border-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="range"],
    [type="file"],
    [readonly]
  ):focus,
select:focus,
textarea:focus {
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}

input:not([type="submit"], [type="button"], [type="reset"])[disabled],
select[disabled],
textarea[disabled],
:where(fieldset[disabled])
  :is(
    input:not([type="submit"], [type="button"], [type="reset"]),
    select,
    textarea
  ) {
  --background-color: var(--form-element-disabled-background-color);
  --border-color: var(--form-element-disabled-border-color);
  opacity: var(--form-element-disabled-opacity);
  pointer-events: none;
}

:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid] {
  padding-right: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal) !important;
  padding-inline-start: var(--form-element-spacing-horizontal) !important;
  -webkit-padding-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-inline-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="false"] {
  background-image: var(--icon-valid);
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="true"] {
  background-image: var(--icon-invalid);
}
:where(input, select, textarea)[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(input, select, textarea)[aria-invalid="false"]:is(:active, :focus) {
  --border-color: var(--form-element-valid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-valid-focus-color) !important;
}
:where(input, select, textarea)[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}
:where(input, select, textarea)[aria-invalid="true"]:is(:active, :focus) {
  --border-color: var(--form-element-invalid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width)
    var(--form-element-invalid-focus-color) !important;
}

[dir="rtl"]
  :where(input, select, textarea):not([type="checkbox"], [type="radio"]):is(
    [aria-invalid],
    [aria-invalid="true"],
    [aria-invalid="false"]
  ) {
  background-position: center left 0.75rem;
}

input::placeholder,
input::-webkit-input-placeholder,
textarea::placeholder,
textarea::-webkit-input-placeholder,
select:invalid {
  color: var(--form-element-placeholder-color);
  opacity: 1;
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  margin-bottom: var(--spacing);
}

select::-ms-expand {
  border: 0;
  background-color: transparent;
}
select:not([multiple], [size]) {
  padding-right: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal);
  padding-inline-start: var(--form-element-spacing-horizontal);
  -webkit-padding-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-inline-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  background-image: var(--icon-chevron);
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}

[dir="rtl"] select:not([multiple], [size]) {
  background-position: center left 0.75rem;
}

:where(input, select, textarea) + small {
  display: block;
  width: 100%;
  margin-top: calc(var(--spacing) * -0.75);
  margin-bottom: var(--spacing);
  color: var(--muted-color);
}

label > :where(input, select, textarea) {
  margin-top: calc(var(--spacing) * 0.25);
}

/**
 * Form elements
 * Checkboxes & Radios
 */
[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

[type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
[type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
[type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
[type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
[type="checkbox"][role="switch"]:checked {
  background-image: none;
}
[type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

[type="checkbox"][aria-invalid="false"],
[type="checkbox"]:checked[aria-invalid="false"],
[type="radio"][aria-invalid="false"],
[type="radio"]:checked[aria-invalid="false"],
[type="checkbox"][role="switch"][aria-invalid="false"],
[type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
[type="checkbox"][aria-invalid="true"],
[type="checkbox"]:checked[aria-invalid="true"],
[type="radio"][aria-invalid="true"],
[type="radio"]:checked[aria-invalid="true"],
[type="checkbox"][role="switch"][aria-invalid="true"],
[type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

/**
 * Form elements
 * Alternatives input types (Not Checkboxes & Radios)
 */
[type="color"]::-webkit-color-swatch-wrapper {
  padding: 0;
}
[type="color"]::-moz-focus-inner {
  padding: 0;
}
[type="color"]::-webkit-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}
[type="color"]::-moz-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]):is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  --icon-position: 0.75rem;
  --icon-width: 1rem;
  padding-right: calc(var(--icon-width) + var(--icon-position));
  background-image: var(--icon-date);
  background-position: center right var(--icon-position);
  background-size: var(--icon-width) auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="time"] {
  background-image: var(--icon-time);
}

[type="date"]::-webkit-calendar-picker-indicator,
[type="datetime-local"]::-webkit-calendar-picker-indicator,
[type="month"]::-webkit-calendar-picker-indicator,
[type="time"]::-webkit-calendar-picker-indicator,
[type="week"]::-webkit-calendar-picker-indicator {
  width: var(--icon-width);
  margin-right: calc(var(--icon-width) * -1);
  margin-left: var(--icon-position);
  opacity: 0;
}

[dir="rtl"]
  :is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  text-align: right;
}

[type="file"] {
  --color: var(--muted-color);
  padding: calc(var(--form-element-spacing-vertical) * 0.5) 0;
  border: 0;
  border-radius: 0;
  background: none;
}
[type="file"]::file-selector-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::file-selector-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-webkit-file-upload-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-webkit-file-upload-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-ms-browse {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  margin-inline-start: 0;
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-ms-browse:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}

[type="range"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 100%;
  height: 1.25rem;
  background: none;
}
[type="range"]::-webkit-slider-runnable-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -webkit-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-moz-range-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -moz-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-ms-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -ms-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-webkit-slider-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-moz-range-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -moz-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-ms-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]:hover,
[type="range"]:focus {
  --range-border-color: var(--range-active-border-color);
  --range-thumb-color: var(--range-thumb-hover-color);
}
[type="range"]:active {
  --range-thumb-color: var(--range-thumb-active-color);
}
[type="range"]:active::-webkit-slider-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-moz-range-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-ms-thumb {
  transform: scale(1.25);
}

input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  -webkit-padding-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  padding-inline-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  border-radius: 5rem;
  background-image: var(--icon-search);
  background-position: center left 1.125rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  -webkit-padding-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  padding-inline-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  background-position: center left 1.125rem, center right 0.75rem;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="false"] {
  background-image: var(--icon-search), var(--icon-valid);
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="true"] {
  background-image: var(--icon-search), var(--icon-invalid);
}

[type="search"]::-webkit-search-cancel-button {
  -webkit-appearance: none;
  display: none;
}

[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  background-position: center right 1.125rem;
}
[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  background-position: center right 1.125rem, center left 0.75rem;
}

/**
 * Table
 */
:where(table) {
  width: 100%;
  border-collapse: collapse;
  border-spacing: 0;
  text-indent: 0;
}

th,
td {
  padding: calc(var(--spacing) / 2) var(--spacing);
  border-bottom: var(--border-width) solid var(--table-border-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  text-align: left;
  text-align: start;
}

tfoot th,
tfoot td {
  border-top: var(--border-width) solid var(--table-border-color);
  border-bottom: 0;
}

table[role="grid"] tbody tr:nth-child(odd) {
  background-color: var(--table-row-stripped-background-color);
}

/**
 * Code
 */
pre,
code,
kbd,
samp {
  font-size: 0.875em;
  font-family: var(--font-family);
}

pre {
  -ms-overflow-style: scrollbar;
  overflow: auto;
}

pre,
code,
kbd {
  border-radius: var(--border-radius);
  background: var(--code-background-color);
  color: var(--code-color);
  font-weight: var(--font-weight);
  line-height: initial;
}

code,
kbd {
  display: inline-block;
  padding: 0.375rem 0.5rem;
}

pre {
  display: block;
  margin-bottom: var(--spacing);
  overflow-x: auto;
}
pre > code {
  display: block;
  padding: var(--spacing);
  background: none;
  font-size: 14px;
  line-height: var(--line-height);
}

code b {
  color: var(--code-tag-color);
  font-weight: var(--font-weight);
}
code i {
  color: var(--code-property-color);
  font-style: normal;
}
code u {
  color: var(--code-value-color);
  text-decoration: none;
}
code em {
  color: var(--code-comment-color);
  font-style: normal;
}

kbd {
  background-color: var(--code-kbd-background-color);
  color: var(--code-kbd-color);
  vertical-align: baseline;
}

/**
 * Miscs
 */
hr {
  height: 0;
  border: 0;
  border-top: 1px solid var(--muted-border-color);
  color: inherit;
}

[hidden],
template {
  display: none !important;
}

canvas {
  display: inline-block;
}

/**
 * Accordion (<details>)
 */
details {
  display: block;
  margin-bottom: var(--spacing);
  padding-bottom: var(--spacing);
  border-bottom: var(--border-width) solid var(--accordion-border-color);
}
details summary {
  line-height: 1rem;
  list-style-type: none;
  cursor: pointer;
  transition: color var(--transition);
}
details summary:not([role]) {
  color: var(--accordion-close-summary-color);
}
details summary::-webkit-details-marker {
  display: none;
}
details summary::marker {
  display: none;
}
details summary::-moz-list-bullet {
  list-style-type: none;
}
details summary::after {
  display: block;
  width: 1rem;
  height: 1rem;
  -webkit-margin-start: calc(var(--spacing, 1rem) * 0.5);
  margin-inline-start: calc(var(--spacing, 1rem) * 0.5);
  float: right;
  transform: rotate(-90deg);
  background-image: var(--icon-chevron);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
  transition: transform var(--transition);
}
details summary:focus {
  outline: none;
}
details summary:focus:not([role="button"]) {
  color: var(--accordion-active-summary-color);
}
details summary[role="button"] {
  width: 100%;
  text-align: left;
}
details summary[role="button"]::after {
  height: calc(1rem * var(--line-height, 1.5));
  background-image: var(--icon-chevron-button);
}
details summary[role="button"]:not(.outline).contrast::after {
  background-image: var(--icon-chevron-button-inverse);
}
details[open] > summary {
  margin-bottom: calc(var(--spacing));
}
details[open] > summary:not([role]):not(:focus) {
  color: var(--accordion-open-summary-color);
}
details[open] > summary::after {
  transform: rotate(0);
}

[dir="rtl"] details summary {
  text-align: right;
}
[dir="rtl"] details summary::after {
  float: left;
  background-position: left center;
}

/**
 * Card (<article>)
 */
article {
  margin: var(--block-spacing-vertical) 0;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
  border-radius: var(--border-radius);
  background: var(--card-background-color);
  box-shadow: var(--card-box-shadow);
}
article > header,
article > footer {
  margin-right: calc(var(--block-spacing-horizontal) * -1);
  margin-left: calc(var(--block-spacing-horizontal) * -1);
  padding: calc(var(--block-spacing-vertical) * 0.66)
    var(--block-spacing-horizontal);
  background-color: var(--card-sectionning-background-color);
}
article > header {
  margin-top: calc(var(--block-spacing-vertical) * -1);
  margin-bottom: var(--block-spacing-vertical);
  border-bottom: var(--border-width) solid var(--card-border-color);
  border-top-right-radius: var(--border-radius);
  border-top-left-radius: var(--border-radius);
}
article > footer {
  margin-top: var(--block-spacing-vertical);
  margin-bottom: calc(var(--block-spacing-vertical) * -1);
  border-top: var(--border-width) solid var(--card-border-color);
  border-bottom-right-radius: var(--border-radius);
  border-bottom-left-radius: var(--border-radius);
}

/**
 * Modal (<dialog>)
 */
#mount {
  --scrollbar-width: 0px;
}

dialog {
  display: flex;
  z-index: 999;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  align-items: center;
  justify-content: center;
  width: inherit;
  min-width: 100%;
  height: inherit;
  min-height: 100%;
  padding: var(--spacing);
  border: 0;
  -webkit-backdrop-filter: var(--modal-overlay-backdrop-filter);
  backdrop-filter: var(--modal-overlay-backdrop-filter);
  background-color: var(--modal-overlay-background-color);
  color: var(--color);
}
dialog article {
  max-height: calc(100vh - var(--spacing) * 2);
  overflow: auto;
}
@media (min-width: 576px) {
  dialog article {
    max-width: 510px;
  }
}
@media (min-width: 768px) {
  dialog article {
    max-width: 700px;
  }
}
dialog article > header,
dialog article > footer {
  padding: calc(var(--block-spacing-vertical) * 0.5)
    var(--block-spacing-horizontal);
}
dialog article > header .close {
  margin: 0;
  margin-left: var(--spacing);
  float: right;
}
dialog article > footer {
  text-align: right;
}
dialog article > footer [role="button"] {
  margin-bottom: 0;
}
dialog article > footer [role="button"]:not(:first-of-type) {
  margin-left: calc(var(--spacing) * 0.5);
}
dialog article p:last-of-type {
  margin: 0;
}
dialog article .close {
  display: block;
  width: 1rem;
  height: 1rem;
  margin-top: calc(var(--block-spacing-vertical) * -0.5);
  margin-bottom: var(--typography-spacing-vertical);
  margin-left: auto;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}
dialog article .close:is([aria-current], :hover, :active, :focus) {
  opacity: 1;
}
dialog:not([open]),
dialog[open="false"] {
  display: none;
}

.modal-is-open {
  padding-right: var(--scrollbar-width, 0px);
  overflow: hidden;
  pointer-events: none;
}
.modal-is-open dialog {
  pointer-events: auto;
}

:where(.modal-is-opening, .modal-is-closing) dialog,
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-duration: 0.2s;
  animation-timing-function: ease-in-out;
  animation-fill-mode: both;
}
:where(.modal-is-opening, .modal-is-closing) dialog {
  animation-duration: 0.8s;
  animation-name: modal-overlay;
}
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-delay: 0.2s;
  animation-name: modal;
}

.modal-is-closing dialog,
.modal-is-closing dialog > article {
  animation-delay: 0s;
  animation-direction: reverse;
}

@keyframes modal-overlay {
  from {
    -webkit-backdrop-filter: none;
    backdrop-filter: none;
    background-color: transparent;
  }
}
@keyframes modal {
  from {
    transform: translateY(-100%);
    opacity: 0;
  }
}
/**
 * Nav
 */
:where(nav li)::before {
  float: left;
  content: "​";
}

nav,
nav ul {
  display: flex;
}

nav {
  justify-content: space-between;
}
nav ol,
nav ul {
  align-items: center;
  margin-bottom: 0;
  padding: 0;
  list-style: none;
}
nav ol:first-of-type,
nav ul:first-of-type {
  margin-left: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav ol:last-of-type,
nav ul:last-of-type {
  margin-right: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav li {
  display: inline-block;
  margin: 0;
  padding: var(--nav-element-spacing-vertical)
    var(--nav-element-spacing-horizontal);
}
nav li > * {
  --spacing: 0;
}
nav :where(a, [role="link"]) {
  display: inline-block;
  margin: calc(var(--nav-link-spacing-vertical) * -1)
    calc(var(--nav-link-spacing-horizontal) * -1);
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
  border-radius: var(--border-radius);
  text-decoration: none;
}
nav :where(a, [role="link"]):is([aria-current], :hover, :active, :focus) {
  text-decoration: none;
}
nav[aria-label="breadcrumb"] {
  align-items: center;
  justify-content: start;
}
nav[aria-label="breadcrumb"] ul li:not(:first-child) {
  -webkit-margin-start: var(--nav-link-spacing-horizontal);
  margin-inline-start: var(--nav-link-spacing-horizontal);
}
nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  position: absolute;
  width: calc(var(--nav-link-spacing-horizontal) * 2);
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) / 2);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) / 2);
  content: "/";
  color: var(--muted-color);
  text-align: center;
}
nav[aria-label="breadcrumb"] a[aria-current] {
  background-color: transparent;
  color: inherit;
  text-decoration: none;
  pointer-events: none;
}
nav [role="button"] {
  margin-right: inherit;
  margin-left: inherit;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}

aside nav,
aside ol,
aside ul,
aside li {
  display: block;
}
aside li {
  padding: calc(var(--nav-element-spacing-vertical) * 0.5)
    var(--nav-element-spacing-horizontal);
}
aside li a {
  display: block;
}
aside li [role="button"] {
  margin: inherit;
}

[dir="rtl"] nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  content: "\\";
}

/**
 * Progress
 */
progress {
  display: inline-block;
  vertical-align: baseline;
}

progress {
  -webkit-appearance: none;
  -moz-appearance: none;
  display: inline-block;
  appearance: none;
  width: 100%;
  height: 0.5rem;
  margin-bottom: calc(var(--spacing) * 0.5);
  overflow: hidden;
  border: 0;
  border-radius: var(--border-radius);
  background-color: var(--progress-background-color);
  color: var(--progress-color);
}
progress::-webkit-progress-bar {
  border-radius: var(--border-radius);
  background: none;
}
progress[value]::-webkit-progress-value {
  background-color: var(--progress-color);
}
progress::-moz-progress-bar {
  background-color: var(--progress-color);
}
@media (prefers-reduced-motion: no-preference) {
  progress:indeterminate {
    background: var(--progress-background-color)
      linear-gradient(
        to right,
        var(--progress-color) 30%,
        var(--progress-background-color) 30%
      )
      top left/150% 150% no-repeat;
    animation: progress-indeterminate 1s linear infinite;
  }
  progress:indeterminate[value]::-webkit-progress-value {
    background-color: transparent;
  }
  progress:indeterminate::-moz-progress-bar {
    background-color: transparent;
  }
}

@media (prefers-reduced-motion: no-preference) {
  [dir="rtl"] progress:indeterminate {
    animation-direction: reverse;
  }
}

@keyframes progress-indeterminate {
  0% {
    background-position: 200% 0;
  }
  100% {
    background-position: -200% 0;
  }
}
/**
 * Dropdown ([role="list"])
 */
details[role="list"],
li[role="list"] {
  position: relative;
}

details[role="list"] summary + ul,
li[role="list"] > ul {
  display: flex;
  z-index: 99;
  position: absolute;
  top: auto;
  right: 0;
  left: 0;
  flex-direction: column;
  margin: 0;
  padding: 0;
  border: var(--border-width) solid var(--dropdown-border-color);
  border-radius: var(--border-radius);
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  background-color: var(--dropdown-background-color);
  box-shadow: var(--card-box-shadow);
  color: var(--dropdown-color);
  white-space: nowrap;
}
details[role="list"] summary + ul li,
li[role="list"] > ul li {
  width: 100%;
  margin-bottom: 0;
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  list-style: none;
}
details[role="list"] summary + ul li:first-of-type,
li[role="list"] > ul li:first-of-type {
  margin-top: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li:last-of-type,
li[role="list"] > ul li:last-of-type {
  margin-bottom: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li a,
li[role="list"] > ul li a {
  display: block;
  margin: calc(var(--form-element-spacing-vertical) * -0.5)
    calc(var(--form-element-spacing-horizontal) * -1);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  overflow: hidden;
  color: var(--dropdown-color);
  text-decoration: none;
  text-overflow: ellipsis;
}
details[role="list"] summary + ul li a:hover,
li[role="list"] > ul li a:hover {
  background-color: var(--dropdown-hover-background-color);
}

details[role="list"] summary::after,
li[role="list"] > a::after {
  display: block;
  width: 1rem;
  height: calc(1rem * var(--line-height, 1.5));
  -webkit-margin-start: 0.5rem;
  margin-inline-start: 0.5rem;
  float: right;
  transform: rotate(0deg);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
}

details[role="list"] {
  padding: 0;
  border-bottom: none;
}
details[role="list"] summary {
  margin-bottom: 0;
}
details[role="list"] summary:not([role]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--form-element-border-color);
  border-radius: var(--border-radius);
  background-color: var(--form-element-background-color);
  color: var(--form-element-placeholder-color);
  line-height: inherit;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
details[role="list"] summary:not([role]):active,
details[role="list"] summary:not([role]):focus {
  border-color: var(--form-element-active-border-color);
  background-color: var(--form-element-active-background-color);
}
details[role="list"] summary:not([role]):focus {
  box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}
details[role="list"][open] summary {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
details[role="list"][open] summary::before {
  display: block;
  z-index: 1;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  background: none;
  content: "";
  cursor: default;
}

nav details[role="list"] summary,
nav li[role="list"] a {
  display: flex;
  direction: ltr;
}

nav details[role="list"] summary + ul,
nav li[role="list"] > ul {
  min-width: -moz-fit-content;
  min-width: fit-content;
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul li a,
nav li[role="list"] > ul li a {
  border-radius: 0;
}

nav details[role="list"] summary,
nav details[role="list"] summary:not([role]) {
  height: auto;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}
nav details[role="list"][open] summary {
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul {
  margin-top: var(--outline-width);
  -webkit-margin-start: 0;
  margin-inline-start: 0;
}
nav details[role="list"] summary[role="link"] {
  margin-bottom: calc(var(--nav-link-spacing-vertical) * -1);
  line-height: var(--line-height);
}
nav details[role="list"] summary[role="link"] + ul {
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) * -1);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) * -1);
}

li[role="list"]:hover > ul,
li[role="list"] a:active ~ ul,
li[role="list"] a:focus ~ ul {
  display: flex;
}
li[role="list"] > ul {
  display: none;
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
  margin-inline-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
}
li[role="list"] > a::after {
  background-image: var(--icon-chevron);
}

/**
 * Loading ([aria-busy=true])
 */
[aria-busy="true"] {
  cursor: progress;
}

[aria-busy="true"]:not(input, select, textarea)::before {
  display: inline-block;
  width: 1em;
  height: 1em;
  border: 0.1875em solid currentColor;
  border-radius: 1em;
  border-right-color: transparent;
  content: "";
  vertical-align: text-bottom;
  vertical-align: -0.125em;
  animation: spinner 0.75s linear infinite;
  opacity: var(--loading-spinner-opacity);
}
[aria-busy="true"]:not(input, select, textarea):not(:empty)::before {
  margin-right: calc(var(--spacing) * 0.5);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) * 0.5);
  margin-inline-end: calc(var(--spacing) * 0.5);
}
[aria-busy="true"]:not(input, select, textarea):empty {
  text-align: center;
}

button[aria-busy="true"],
input[type="submit"][aria-busy="true"],
input[type="button"][aria-busy="true"],
input[type="reset"][aria-busy="true"],
a[aria-busy="true"] {
  pointer-events: none;
}

@keyframes spinner {
  to {
    transform: rotate(360deg);
  }
}
/**
 * Tooltip ([data-tooltip])
 */
[data-tooltip] {
  position: relative;
}
[data-tooltip]:not(a, button, input) {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}
[data-tooltip][data-placement="top"]::before,
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::before,
[data-tooltip]::after {
  display: block;
  z-index: 99;
  position: absolute;
  bottom: 100%;
  left: 50%;
  padding: 0.25rem 0.5rem;
  overflow: hidden;
  transform: translate(-50%, -0.25rem);
  border-radius: var(--border-radius);
  background: var(--tooltip-background-color);
  content: attr(data-tooltip);
  color: var(--tooltip-color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: 0.875rem;
  text-decoration: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  opacity: 0;
  pointer-events: none;
}
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::after {
  padding: 0;
  transform: translate(-50%, 0rem);
  border-top: 0.3rem solid;
  border-right: 0.3rem solid transparent;
  border-left: 0.3rem solid transparent;
  border-radius: 0;
  background-color: transparent;
  content: "";
  color: var(--tooltip-background-color);
}
[data-tooltip][data-placement="bottom"]::before,
[data-tooltip][data-placement="bottom"]::after {
  top: 100%;
  bottom: auto;
  transform: translate(-50%, 0.25rem);
}
[data-tooltip][data-placement="bottom"]:after {
  transform: translate(-50%, -0.3rem);
  border: 0.3rem solid transparent;
  border-bottom: 0.3rem solid;
}
[data-tooltip][data-placement="left"]::before,
[data-tooltip][data-placement="left"]::after {
  top: 50%;
  right: 100%;
  bottom: auto;
  left: auto;
  transform: translate(-0.25rem, -50%);
}
[data-tooltip][data-placement="left"]:after {
  transform: translate(0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-left: 0.3rem solid;
}
[data-tooltip][data-placement="right"]::before,
[data-tooltip][data-placement="right"]::after {
  top: 50%;
  right: auto;
  bottom: auto;
  left: 100%;
  transform: translate(0.25rem, -50%);
}
[data-tooltip][data-placement="right"]:after {
  transform: translate(-0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-right: 0.3rem solid;
}
[data-tooltip]:focus::before,
[data-tooltip]:focus::after,
[data-tooltip]:hover::before,
[data-tooltip]:hover::after {
  opacity: 1;
}
@media (hover: hover) and (pointer: fine) {
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::before,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::before,
  [data-tooltip]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::after {
    animation-name: tooltip-caret-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::before,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-bottom;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-name: tooltip-caret-slide-bottom;
  }
  [data-tooltip][data-placement="left"]:focus::before,
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::before,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-left;
  }
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-name: tooltip-caret-slide-left;
  }
  [data-tooltip][data-placement="right"]:focus::before,
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::before,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-right;
  }
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-name: tooltip-caret-slide-right;
  }
}
@keyframes tooltip-slide-top {
  from {
    transform: translate(-50%, 0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-top {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.25rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-bottom {
  from {
    transform: translate(-50%, -0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-bottom {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.5rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.3rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-left {
  from {
    transform: translate(0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-left {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.3rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-slide-right {
  from {
    transform: translate(-0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-right {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.3rem, -50%);
    opacity: 1;
  }
}

/**
 * Accessibility & User interaction
 */
[aria-controls] {
  cursor: pointer;
}

[aria-disabled="true"],
[disabled] {
  cursor: not-allowed;
}

[aria-hidden="false"][hidden] {
  display: initial;
}

[aria-hidden="false"][hidden]:not(:focus) {
  clip: rect(0, 0, 0, 0);
  position: absolute;
}

a,
area,
button,
input,
label,
select,
summary,
textarea,
[tabindex] {
  -ms-touch-action: manipulation;
}

[dir="rtl"] {
  direction: rtl;
}

/**
* Reduce Motion Features
*/
@media (prefers-reduced-motion: reduce) {
  *:not([aria-busy="true"]),
  :not([aria-busy="true"])::before,
  :not([aria-busy="true"])::after {
    background-attachment: initial !important;
    animation-duration: 1ms !important;
    animation-delay: -1ms !important;
    animation-iteration-count: 1 !important;
    scroll-behavior: auto !important;
    transition-delay: 0s !important;
    transition-duration: 0s !important;
  }
}

#mount {
  /* --primary: rgb(227, 59, 126); */
  --primary: #ea4c89;
  --primary-hover: #f082ac;
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  --switch-checked-background-color: var(--primary);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="dark"] {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="light"] {
  --primary: #ea4c89;
  --primary-hover: #f082ac;
}

li.select-link.select-link:hover > ul {
  display: none;
}
li.select-link.select-link > ul {
  display: none;
}
li.select-link.select-link a:focus ~ ul {
  display: none;
}

li.select-link.select-link a:active ~ ul {
  display: none;
}
li.select-link-active.select-link-active > ul {
  display: flex;
}
li.select-link-active.select-link-active:hover > ul {
  display: flex;
}

li.select-link-active.select-link-active a:focus ~ ul {
  display: flex;
}

li.select-link-active.select-link-active a:active ~ ul {
  display: flex;
}
ul.select-link-ul.select-link-ul {
  right: 0px;
  left: auto;
}

a.select-link-selected {
  background-color: var(--primary-focus);
}
.immersive-translate-no-select {
  -webkit-touch-callout: none; /* iOS Safari */
  -webkit-user-select: none; /* Safari */
  -khtml-user-select: none; /* Konqueror HTML */
  -moz-user-select: none; /* Old versions of Firefox */
  -ms-user-select: none; /* Internet Explorer/Edge */
  user-select: none;
}

/* li[role="list"].no-arrow > a::after { */
/*   background-image: none; */
/*   width: 0; */
/*   color: var(--color); */
/* } */
li[role="list"].no-arrow {
  margin-left: 8px;
  padding-right: 0;
}
li[role="list"] > a::after {
  -webkit-margin-start: 0.2rem;
  margin-inline-start: 0.2rem;
}

li[role="list"].no-arrow > a,
li[role="list"].no-arrow > a:link,
li[role="list"].no-arrow > a:visited {
  color: var(--secondary);
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  padding-left: 8px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}
select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.muted {
  color: var(--muted-color);
}

.select.button-select {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
  cursor: pointer;
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 16px;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
  -webkit-appearance: button;
  margin: 0;
  margin-bottom: 0px;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --text-black-2: #222222;
  --text-gray-2: #222222;
  --text-gray-6: #666666;
  --text-gray-9: #999999;
  --text-gray-c2: #c2c2c2;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --popup-footer-background-color: #0d0d0d;
    --popup-content-background-color: #191919;
    --popup-item-background-color: #272727;
    --popup-item-hover-background-color: #333333;
    --popup-trial-pro-background-color: #222222;
    --text-black-2: #ffffff;
    --text-gray-2: #dbdbdb;
    --text-gray-6: #b3b3b3;
    --text-gray-9: #777777;
    --text-gray-c2: #5b5b5b;
    --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
    --service-select-border-color: #2c2c2c;
    --service-select-selected-background-color: #333333;
    --download-app-background: #333;
  }
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --text-black-2: #ffffff;
  --text-gray-2: #dbdbdb;
  --text-gray-6: #b3b3b3;
  --text-gray-9: #777777;
  --text-gray-c2: #5b5b5b;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

.text-balck {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

#mount {
  min-width: 268px;
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.translate-service {
  color: var(--text-black-2);
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

select.min-select-secondary {
  color: var(--color);
}

select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: 0;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 372px;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #B3B3B3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 225px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg><svg hidden="true" class="imt-manga-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#68CD52"></circle><path d="M1.40857 5.87858L2.24148 5.18962L4.15344 6.64214C4.15344 6.64214 6.33547 4.15566 9.00658 2.48145L9.32541 2.87514C9.32541 2.87514 6.28665 5.55844 4.71735 9.07881L1.40857 5.87858Z" fill="white"></path></svg></div><svg class="imt-float-ball-loading" hidden="true" width="19" height="19" viewBox="0 0 19 19" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin: 9px;"><path d="M9.42859 0C9.84288 0 10.1929 0.387143 10.1929 0.847143V3.99429C10.1929 4.45429 9.84431 4.84143 9.42859 4.84143C9.01431 4.84143 8.66431 4.45571 8.66431 3.99429V0.847143C8.66431 0.387143 9.01288 0 9.42859 0Z" fill="#E9E9E9"></path><path d="M14.1301 1.38877C14.5158 1.62591 14.6301 2.12163 14.4258 2.52305L12.9515 5.19448C12.901 5.28714 12.8325 5.36876 12.75 5.43455C12.6675 5.50035 12.5727 5.54898 12.4712 5.5776C12.3696 5.60621 12.2634 5.61424 12.1586 5.60119C12.0539 5.58814 11.9529 5.55429 11.8615 5.50163C11.6787 5.38432 11.5468 5.20237 11.4923 4.9921C11.4377 4.78184 11.4645 4.55874 11.5672 4.36734L13.0415 1.69591C13.2686 1.29448 13.7443 1.15305 14.1301 1.38877Z" fill="#989697"></path><path d="M17.4685 4.75707C17.5813 4.95451 17.6123 5.18824 17.5549 5.40825C17.4975 5.62826 17.3563 5.81705 17.1614 5.93422L14.4971 7.52564C14.0971 7.76993 13.6014 7.62422 13.3657 7.20707C13.2532 7.00994 13.2222 6.77667 13.2793 6.55702C13.3365 6.33737 13.4771 6.14874 13.6714 6.03136L16.3357 4.43993C16.7371 4.21993 17.2557 4.34136 17.4685 4.7585V4.75707Z" fill="#9B999A"></path><path d="M18.8572 9.42835C18.8572 9.84263 18.47 10.1926 18.01 10.1926H14.8629C14.4029 10.1926 14.0157 9.84406 14.0157 9.42835C14.0157 9.01406 14.4029 8.66406 14.8629 8.66406H18.01C18.47 8.66406 18.8572 9.01263 18.8572 9.42835Z" fill="#A3A1A2"></path><path d="M17.4686 14.1303C17.3515 14.3134 17.1697 14.4455 16.9594 14.5003C16.7491 14.5552 16.5259 14.5286 16.3343 14.426L13.6629 12.9517C13.5702 12.9012 13.4886 12.8327 13.4228 12.7503C13.357 12.6678 13.3084 12.573 13.2798 12.4714C13.2512 12.3698 13.2431 12.2636 13.2562 12.1589C13.2692 12.0542 13.3031 11.9532 13.3558 11.8617C13.4731 11.6789 13.655 11.547 13.8653 11.4925C14.0755 11.4379 14.2986 11.4647 14.49 11.5674L17.1615 13.0417C17.5629 13.2689 17.7043 13.7446 17.4686 14.1303Z" fill="#ABA9AA"></path><path opacity="0.7" d="M14.1 17.4686C13.9026 17.5814 13.6689 17.6124 13.4489 17.555C13.2288 17.4976 13.04 17.3564 12.9229 17.1615L11.3315 14.4972C11.0872 14.0972 11.2329 13.6015 11.65 13.3658C11.8472 13.2533 12.0804 13.2224 12.3001 13.2795C12.5197 13.3366 12.7084 13.4773 12.8257 13.6715L14.4172 16.3358C14.6372 16.7372 14.5157 17.2558 14.0986 17.4686H14.1Z" fill="#B2B2B2"></path><path opacity="0.6" d="M9.42859 18.8571C9.01431 18.8571 8.66431 18.4699 8.66431 18.0099V14.8628C8.66431 14.4028 9.01288 14.0156 9.42859 14.0156C9.84288 14.0156 10.1929 14.4028 10.1929 14.8628V18.0099C10.1929 18.4699 9.84431 18.8571 9.42859 18.8571Z" fill="#BAB8B9"></path><path opacity="0.5" d="M4.72717 17.4685C4.5441 17.3514 4.41195 17.1696 4.35713 16.9593C4.30231 16.749 4.32885 16.5258 4.43145 16.3342L5.90574 13.6628C5.95622 13.5701 6.02472 13.4885 6.1072 13.4227C6.18969 13.3569 6.2845 13.3083 6.38606 13.2797C6.48762 13.251 6.59387 13.243 6.69857 13.2561C6.80327 13.2691 6.90431 13.303 6.99574 13.3556C7.38145 13.5914 7.49431 14.0885 7.29002 14.4899L5.81574 17.1614C5.5886 17.5628 5.11288 17.7042 4.72717 17.4685Z" fill="#C2C0C1"></path><path opacity="0.4" d="M1.38862 14.1002C1.27584 13.9027 1.24483 13.669 1.30223 13.449C1.35964 13.229 1.50089 13.0402 1.69576 12.923L4.36004 11.3316C4.76004 11.0873 5.25576 11.233 5.49147 11.6502C5.60393 11.8473 5.63491 12.0806 5.5778 12.3002C5.52069 12.5199 5.38 12.7085 5.18576 12.8259L2.52004 14.4173C2.12004 14.6373 1.60004 14.5159 1.38862 14.0987V14.1002Z" fill="#CBCBCB"></path><path d="M0 9.42835C0 9.01406 0.387143 8.66406 0.847143 8.66406H3.99429C4.45429 8.66406 4.84143 9.01263 4.84143 9.42835C4.84143 9.84263 4.45571 10.1926 3.99429 10.1926H0.847143C0.387143 10.1926 0 9.84406 0 9.42835Z" fill="#D2D2D2"></path><path opacity="0.2" d="M1.38852 4.72705C1.50561 4.54398 1.68746 4.41183 1.89774 4.35701C2.10803 4.30219 2.33125 4.32873 2.52281 4.43133L5.19424 5.90562C5.28689 5.9561 5.36851 6.0246 5.43431 6.10708C5.5001 6.18957 5.54874 6.28438 5.57735 6.38594C5.60597 6.48749 5.61399 6.59375 5.60094 6.69845C5.5879 6.80315 5.55405 6.90419 5.50138 6.99562C5.38407 7.17844 5.20212 7.31029 4.99186 7.36484C4.78159 7.4194 4.55849 7.39263 4.3671 7.2899L1.69567 5.81562C1.29424 5.58847 1.15281 5.11276 1.38852 4.72705Z" fill="#DADADA"></path><path d="M4.75719 1.38849C4.95463 1.27571 5.18837 1.24471 5.40838 1.30211C5.62838 1.35952 5.81718 1.50077 5.93434 1.69564L7.52577 4.35992C7.77005 4.75992 7.62434 5.25564 7.20719 5.49135C7.01006 5.60381 6.77679 5.63479 6.55714 5.57768C6.33749 5.52056 6.14886 5.37988 6.03148 5.18564L4.44005 2.51992C4.22005 2.11992 4.34148 1.59992 4.75862 1.38849H4.75719Z" fill="#E2E2E2"></path></svg></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#68CD52"></circle><path d="M1.40857 5.87858L2.24148 5.18962L4.15344 6.64214C4.15344 6.64214 6.33547 4.15566 9.00658 2.48145L9.32541 2.87514C9.32541 2.87514 6.28665 5.55844 4.71735 9.07881L1.40857 5.87858Z" fill="white"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; top: 225px; right: 65px;"><div data-theme="light" class="popup-container " dir="ltr"><div class="popup-content text-sm"><div class="flex items-center justify-between ml-1" style="height: 28px;"><div class="flex items-center"><a class="flex items-center text-decoration-none cursor-pointer" target="_blank"><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAMAAADXqc3KAAAAn1BMVEUAAADt7vHu7vLu7vLv7+/n5+fFxcXu7vHv7/PHx8eamprt7fLt7fHn5+vGxsbS09Surq6fn5+ZmZmZmZnGxsbGxsbt7/K/v7/Hx8ft7vHGxsaZmZn09vnk5eeqqquenp7p6u3X2NnLy8vU1dbr7O67u7uvr6/o6evh4uPR0dLCwsLAwMDZ2ty9vb6kpaWhoaHe3+HPz8+zs7OkpKTc3d7Gt0R8AAAAGXRSTlMA779wIBDv338gv5+AgHDv7+/v36+gn3BgD0kJmgAAAS1JREFUKM9dkOmSgyAQhNFo7mTvYwYEBa9oorne/9l2hqJSbr4q+NHNdBcjAukyXgBE8SwRU5IYHmwm1iyCCdFMBJbwxDK8B2iKLGjl8VAC+JmEcqzRrmnP5yzrbm93SuOeDQCcpNToGaV8ISGmAfBGPce+qjrsjSxYSbkBGtt1tZGEueLpwsZW8A8snlj2jD0efRZVtxzw4Ia2BFgIch1qOaHCM4lsHHA0WpOpKyk7qX2WWLBhhhxU7grlKlV7I+LyAm+DUplS/sqv2HL5FiDDSio15CQOdHrrl5L6kpqEMOHwTlIiOKu0WIDy5Bfkn3+HJTYXRNdmWXtA1nmJfu1lgRNcQw2encV/2J0I7OdIXM1YIzH/FQ9WX4i1JF4RP1dBDNZ+/S7lx/onDcIfdi8x4pYpSxgAAAAASUVORK5CYII="><span class="text-xs ml-1 text-label">未登录</span></a><a class="upgrade-pro ml-1 text-decoration-none cursor-pointer" title="升级为会员后可以畅享 DeepL, OpenAI, Claude, Gemini 翻译，点此升级" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" fill="none"><g clip-path="url(#clip0_13006_12686)"><path d="M11.8713 0.320171C11.8375 0.103619 11.8259 0.0943048 11.6035 0.0535558C11.3974 0.0151353 11.1913 0 10.9841 0C10.7815 0 10.5789 0.0139711 10.3775 0.0349277C9.56837 0.118754 8.77901 0.299214 8.01293 0.575143C6.65657 1.06413 5.45971 1.79412 4.49105 2.87572C4.44681 2.92461 4.4014 2.94091 4.34435 2.94091C4.33038 2.94091 4.31641 2.93975 4.30127 2.93859C3.89378 2.89434 3.48513 2.82332 3.07648 2.82332H3.04853C2.31971 2.82915 1.75155 3.16329 1.35687 3.78151C1.14148 4.11914 0.927257 4.45794 0.711869 4.79674C0.511617 5.11109 0.306708 5.42078 0.112277 5.73862C-0.163652 6.19036 0.0971414 6.7329 0.610579 6.77132C1.2288 6.81789 1.84702 6.85515 2.46524 6.88891C2.57701 6.89473 2.62474 6.925 2.63522 7.04376C2.67248 7.43728 2.77726 7.81217 2.98799 8.15097C3.39898 8.80994 3.9974 9.17202 4.76116 9.27331C5.04873 9.31173 5.04058 9.31406 5.06153 9.61094C5.10228 10.2047 5.14653 10.7997 5.20241 11.3923C5.23734 11.7625 5.52258 12 5.84042 12C5.96616 12 6.09772 11.9627 6.22113 11.8824C6.91154 11.4307 7.60893 10.9859 8.27838 10.5039C8.90242 10.0545 9.17369 9.42117 9.09336 8.64694C9.05959 8.31513 9.03165 7.98215 8.99789 7.65033C8.98741 7.54788 9.01186 7.46987 9.09219 7.39653C10.0713 6.49888 10.7699 5.41263 11.2472 4.17968C11.6466 3.14815 11.8852 2.08402 11.919 0.976812C11.9202 0.945377 11.9213 0.913942 11.9213 0.883671C11.9248 0.693897 11.9004 0.506452 11.8713 0.320171Z" fill="url(#paint0_linear_13006_12686)"></path><path d="M8.60616 4.5H8.61431C9.23886 4.5 9.74176 4.00469 9.74992 3.37907C9.75734 2.77715 9.25814 2.25962 8.66475 2.25H8.64398C8.0365 2.25 7.51506 2.69497 7.50022 3.38574C7.48761 3.96841 8.01647 4.49556 8.60616 4.5Z" fill="#424242"></path><path d="M4.09626 10.4539C3.77376 10.7799 3.44777 11.1012 3.12643 11.426C3.04959 11.504 2.96693 11.5518 2.87146 11.5518C2.8342 11.5518 2.79462 11.5448 2.75271 11.5285C2.60019 11.4726 2.52684 11.3597 2.51985 11.2013C2.5152 11.1012 2.51753 11.0011 2.5152 10.901C2.5117 10.7822 2.51054 10.7391 2.46397 10.7391C2.43836 10.7391 2.39994 10.7519 2.34056 10.7717C1.97847 10.8917 1.61755 11.0127 1.25547 11.1327C1.20075 11.1513 1.14487 11.1641 1.09131 11.1641C1.04008 11.1641 0.988855 11.1524 0.937628 11.1245C0.782782 11.0372 0.724569 10.8823 0.786275 10.6926C0.906193 10.3212 1.0331 9.95093 1.15534 9.57953C1.2089 9.41886 1.20541 9.41537 1.03193 9.41188C0.92715 9.41071 0.822367 9.41188 0.717583 9.40722C0.565066 9.40024 0.45679 9.32572 0.399741 9.18136C0.345021 9.04048 0.379949 8.91823 0.482403 8.81462C0.818874 8.47698 1.15651 8.13935 1.49414 7.80288C1.55468 7.74233 1.62687 7.70508 1.70487 7.70508C1.71302 7.70508 1.72117 7.70508 1.72816 7.70624C1.91095 7.70857 2.01224 7.79007 2.0786 7.97635C2.3359 8.70983 2.80393 9.26518 3.48269 9.6424C3.63288 9.72506 3.79006 9.79259 3.95305 9.84848C4.24761 9.9486 4.31397 10.2338 4.09626 10.4539Z" fill="#F8C235"></path></g><defs><lineargradient id="paint0_linear_13006_12686" x1="12.0001" y1="0.857143" x2="3.42864" y2="8.57143" gradientUnits="userSpaceOnUse"><stop stop-color="#FFEAB5"></stop><stop offset="1" stop-color="#F9C235"></stop></lineargradient><clippath id="clip0_13006_12686"><rect width="12" height="12" fill="white"></rect></clippath></defs></svg><span>升级</span></a></div><div class=" " style="position: relative; display: inline-block; opacity: 1;"><div class="download-app"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 18 18" fill="none"><mask id="mask0_36366_4749" maskUnits="userSpaceOnUse" x="0" y="0" width="18" height="18" style="mask-type: alpha;"><rect width="18" height="18" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_36366_4749)"><path d="M8.99626 14.9004C9.15751 14.9004 9.29657 14.8433 9.41345 14.729C9.5302 14.6149 9.58857 14.4771 9.58857 14.3157C9.58857 14.1545 9.53151 14.0155 9.41738 13.8987C9.30313 13.7819 9.16538 13.7234 9.00413 13.7234C8.84288 13.7234 8.70382 13.7806 8.58695 13.8948C8.4702 14.0089 8.41182 14.1466 8.41182 14.3079C8.41182 14.4692 8.46888 14.6083 8.58301 14.7251C8.69726 14.8419 8.83501 14.9004 8.99626 14.9004ZM4.28101 16.7234C3.94826 16.7234 3.66407 16.6057 3.42845 16.3702C3.19295 16.1346 3.0752 15.8504 3.0752 15.5176V2.47925C3.0752 2.1465 3.19295 1.86231 3.42845 1.62669C3.66407 1.39119 3.94826 1.27344 4.28101 1.27344H13.7194C14.0521 1.27344 14.3363 1.39119 14.5719 1.62669C14.8074 1.86231 14.9252 2.1465 14.9252 2.47925V15.5176C14.9252 15.8504 14.8074 16.1346 14.5719 16.3702C14.3363 16.6057 14.0521 16.7234 13.7194 16.7234H4.28101ZM4.0502 12.8754V15.5176C4.0502 15.585 4.07182 15.6403 4.11507 15.6836C4.15832 15.7268 4.21363 15.7484 4.28101 15.7484H13.7194C13.7868 15.7484 13.8421 15.7268 13.8853 15.6836C13.9286 15.6403 13.9502 15.585 13.9502 15.5176V12.8754H4.0502ZM4.0502 11.9004H13.9502V4.31094H4.0502V11.9004ZM4.0502 3.33594H13.9502V2.47925C13.9502 2.41188 13.9286 2.35656 13.8853 2.31331C13.8421 2.27006 13.7868 2.24844 13.7194 2.24844H4.28101C4.21363 2.24844 4.15832 2.27006 4.11507 2.31331C4.07182 2.35656 4.0502 2.41188 4.0502 2.47925V3.33594Z" fill="#666666"></path></g></svg><span>下载手机 APP</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" fill="none"><rect width="16" height="16" rx="8" fill="#F9FBFC"></rect><path d="M8 8.63878L5.76426 10.8745C5.68061 10.9582 5.57414 11 5.44487 11C5.31559 11 5.20913 10.9582 5.12548 10.8745C5.04182 10.7909 5 10.6844 5 10.5551C5 10.4259 5.04182 10.3194 5.12548 10.2357L7.36122 8L5.12548 5.76426C5.04182 5.68061 5 5.57414 5 5.44487C5 5.31559 5.04182 5.20913 5.12548 5.12548C5.20913 5.04182 5.31559 5 5.44487 5C5.57414 5 5.68061 5.04182 5.76426 5.12548L8 7.36122L10.2357 5.12548C10.3194 5.04182 10.4259 5 10.5551 5C10.6844 5 10.7909 5.04182 10.8745 5.12548C10.9582 5.20913 11 5.31559 11 5.44487C11 5.57414 10.9582 5.68061 10.8745 5.76426L8.63878 8L10.8745 10.2357C10.9582 10.3194 11 10.4259 11 10.5551C11 10.6844 10.9582 10.7909 10.8745 10.8745C10.7909 10.9582 10.6844 11 10.5551 11C10.4259 11 10.3194 10.9582 10.2357 10.8745L8 8.63878Z" fill="#666666"></path></svg></div></div></div><div class="flex mt-4 items-center"><div class="language-select-container"><label>原文语言</label><select autocomplete="off" id="source-language-select" class="language-select"><option value="auto">自动检测</option><option value="zh-CN">简体中文</option><option value="zh-TW">繁体中文-台湾 (繁體中文-台湾)</option><option value="zh-HK">繁体中文-香港 (繁體中文-香港)</option><option value="en">英语 (English)</option><option value="ja">日语 (日本語)</option><option value="ko">韩语 (한국어)</option><option value="es">西班牙语 (Español)</option><option value="de">德语 (Deutsch)</option><option value="fr">法语 (Français)</option><option value="pt">葡萄牙语 (Português)</option><option value="pt-br">葡萄牙语（巴西） (Português (Brasil))</option><option value="sq">阿尔巴尼亚语 (Shqip)</option><option value="ar">阿拉伯语 (العربية)</option><option value="am">阿姆哈拉语 (አማርኛ)</option><option value="az">阿塞拜疆语 (Azərbaycanca)</option><option value="ga">爱尔兰语 (Gaeilge)</option><option value="et">爱沙尼亚语 (Eesti)</option><option value="eu">巴斯克语 (Euskara)</option><option value="be">白俄罗斯语 (Беларуская)</option><option value="mww">白苗语 (Hmong Daw)</option><option value="xh">班图语 (isiXhosa)</option><option value="bg">保加利亚语 (Български)</option><option value="is">冰岛语 (Íslenska)</option><option value="pl">波兰语 (Polski)</option><option value="bs">波斯尼亚语 (Bosanski)</option><option value="fa">波斯语 (فارسی)</option><option value="bo">藏语 (བོད་ཡིག)</option><option value="da">丹麦语 (Dansk)</option><option value="zh-CN-NE">东北话 (東北官話)</option><option value="ru">俄语 (Русский)</option><option value="sa">梵语 (संस्कृतम्)</option><option value="fil">菲律宾语 (Filipino)</option><option value="fj">斐济语 (Na Vosa Vakaviti)</option><option value="fi">芬兰语 (Suomi)</option><option value="fy">弗里斯兰语 (Frysk)</option><option value="km">高棉语 (ភាសាខ្មែរ)</option><option value="ka">格鲁吉亚语 (ქართული)</option><option value="gu">古吉拉特语 (ગુજરાતી)</option><option value="kk">哈萨克语 (Қазақ Тілі)</option><option value="ht">海地克里奥尔语 (Kreyòl Ayisyen)</option><option value="ha">豪萨语 (Hausa)</option><option value="nl">荷兰语 (Nederlands)</option><option value="ky">吉尔吉斯语 (Кыргызча)</option><option value="gl">加利西亚语 (Galego)</option><option value="ca">加泰罗尼亚语 (Català)</option><option value="cs">捷克语 (Čeština)</option><option value="kn">卡纳达语 (ಕನ್ನಡ)</option><option value="co">科西嘉语 (Corsu)</option><option value="otq">克雷塔罗奥托米语 (Hñähñu)</option><option value="tlh">克林贡语 (tlhIngan Hol)</option><option value="tlh-Qaak">克林贡语（piqaD） (tlhIngan Hol (pIqaD))</option><option value="hr">克罗地亚语 (Hrvatski)</option><option value="ku">库尔德语 (Kurdî)</option><option value="la">拉丁语 (Latina)</option><option value="lv">拉脱维亚语 (Latviešu)</option><option value="lo">老挝语 (ລາວ)</option><option value="lt">立陶宛语 (Lietuvių)</option><option value="lb">卢森堡语 (Lëtzebuergesch)</option><option value="ro">罗马尼亚语 (Română)</option><option value="ur-roman">罗马乌尔都语 (Roman Urdu)</option><option value="mt">马耳他语 (Malti)</option><option value="mr">马拉地语 (मराठी)</option><option value="mg">马拉加斯语 (Malagasy)</option><option value="ml">马拉雅拉姆语 (മലയാളം)</option><option value="ms">马来语 (Bahasa Melayu)</option><option value="mk">马其顿语 (Македонски)</option><option value="mi">毛利语 (Māori)</option><option value="mn">蒙古语 (Монгол)</option><option value="bn">孟加拉语 (বাংলা)</option><option value="my">缅甸语 (မြန်မာစာ)</option><option value="hmn">苗语 (Hmoob)</option><option value="af">南非荷兰语 (Afrikaans)</option><option value="ne">尼泊尔语 (नेपाली)</option><option value="no">挪威语 (Norsk)</option><option value="pa">旁遮普语 (ਪੰਜਾਬੀ)</option><option value="ps">普什图语 (پښتو)</option><option value="ny">齐切瓦语（尼扬贾语） (Chichewa)</option><option value="sv">瑞典语 (Svenska)</option><option value="sm">萨摩亚语 (Gagana Samoa)</option><option value="sr">塞尔维亚语 (Српски)</option><option value="sr-Latn">塞尔维亚语（拉丁文） (Srpski (Latinica))</option><option value="sr-Cyrl">塞尔维亚语（西里尔文） (Српски (Ћирилица))</option><option value="st">塞索托语 (Sesotho)</option><option value="si">僧伽罗语 (සිංහල)</option><option value="eo">世界语 (Esperanto)</option><option value="sk">斯洛伐克语 (Slovenčina)</option><option value="sl">斯洛文尼亚语 (Slovenščina)</option><option value="sw">斯瓦希里语 (Kiswahili)</option><option value="gd">苏格兰盖尔语 (Gàidhlig)</option><option value="ceb">宿务语 (Binisaya)</option><option value="so">索马里语 (Soomaali)</option><option value="tg">塔吉克语 (Тоҷикӣ)</option><option value="ty">塔希提语 (Reo Tahiti)</option><option value="te">泰卢固语 (తెలుగు)</option><option value="ta">泰米尔语 (தமிழ்)</option><option value="th">泰语 (ไทย)</option><option value="to">汤加语 (lea fakatonga)</option><option value="tr">土耳其语 (Türkçe)</option><option value="cy">威尔士语 (Cymraeg)</option><option value="ug">维吾尔语 (ئۇيغۇرچە)</option><option value="wyw">文言文 (文言文)</option><option value="ur">乌尔都语 (اردو)</option><option value="uk">乌克兰语 (Українська)</option><option value="uz">乌兹别克语 (Oʻzbek)</option><option value="he">希伯来语 (עברית)</option><option value="el">希腊语 (Ελληνικά)</option><option value="haw">夏威夷语 (ʻŌlelo Hawaiʻi)</option><option value="sd">信德语 (سنڌي)</option><option value="hu">匈牙利语 (Magyar)</option><option value="sn">修纳语 (ChiShona)</option><option value="su">巽他语 (Basa Sunda)</option><option value="hy">亚美尼亚语 (Հայերեն)</option><option value="ig">伊博语 (Asụsụ Igbo)</option><option value="it">意大利语 (Italiano)</option><option value="yi">意第绪语 (ייִדיש)</option><option value="hi">印地语 (हिन्दी)</option><option value="id">印度尼西亚语 (Bahasa Indonesia)</option><option value="yua">尤卡坦玛雅语 (Màaya T'àan)</option><option value="yo">约鲁巴语 (Èdè Yorùbá)</option><option value="yue">粤语 (粵語)</option><option value="vi">越南语 (Tiếng Việt)</option><option value="jw">爪哇语 (Basa Jawa)</option><option value="zu">祖鲁语 (isiZulu)</option></select></div><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguNzEwMjMgMTMuMzg3NkwxMy4yODkzIDguODA4NkwxNC4wOTc3IDguMDAwMjJMMTMuMjg5NyA3LjE5MjIyTDguNzEwMjMgMi42MTI3OUw3LjkwMjIzIDMuNDIwNzlMMTEuOTA5NSA3LjQyODc5SDEuOTA1NjZWOC41NzE2NUgxMS45MDk1TDcuOTAxODUgMTIuNTc5M0w4LjcxMDIzIDEzLjM4NzZaIiBmaWxsPSIjODM4MzgzIi8+CjwvZz4KPC9zdmc+Cg==" class="mx-2" style="max-width: unset;"><div class="language-select-container"><label>目标语言</label><select autocomplete="off" id="target-language-select" class="language-select"><option value="zh-CN">简体中文</option><option value="zh-TW">繁体中文-台湾 (繁體中文-台湾)</option><option value="en">英语 (English)</option><option value="ja">日语 (日本語)</option><option value="ko">韩语 (한국어)</option><option value="es">西班牙语 (Español)</option><option value="de">德语 (Deutsch)</option><option value="fr">法语 (Français)</option><option value="pt">葡萄牙语 (Português)</option><option value="pt-br">葡萄牙语（巴西） (Português (Brasil))</option><option value="ru">俄语 (Русский)</option><option value="yue">粤语 (粵語)</option><option value="sq">阿尔巴尼亚语 (Shqip)</option><option value="ar">阿拉伯语 (العربية)</option><option value="am">阿姆哈拉语 (አማርኛ)</option><option value="az">阿塞拜疆语 (Azərbaycanca)</option><option value="ga">爱尔兰语 (Gaeilge)</option><option value="et">爱沙尼亚语 (Eesti)</option><option value="eu">巴斯克语 (Euskara)</option><option value="be">白俄罗斯语 (Беларуская)</option><option value="xh">班图语 (isiXhosa)</option><option value="bg">保加利亚语 (Български)</option><option value="is">冰岛语 (Íslenska)</option><option value="pl">波兰语 (Polski)</option><option value="bs">波斯尼亚语 (Bosanski)</option><option value="fa">波斯语 (فارسی)</option><option value="da">丹麦语 (Dansk)</option><option value="sa">梵语 (संस्कृतम्)</option><option value="fil">菲律宾语 (Filipino)</option><option value="fi">芬兰语 (Suomi)</option><option value="fy">弗里斯兰语 (Frysk)</option><option value="km">高棉语 (ភាសាខ្មែរ)</option><option value="ka">格鲁吉亚语 (ქართული)</option><option value="gu">古吉拉特语 (ગુજરાતી)</option><option value="kk">哈萨克语 (Қазақ Тілі)</option><option value="ht">海地克里奥尔语 (Kreyòl Ayisyen)</option><option value="ha">豪萨语 (Hausa)</option><option value="nl">荷兰语 (Nederlands)</option><option value="ky">吉尔吉斯语 (Кыргызча)</option><option value="gl">加利西亚语 (Galego)</option><option value="ca">加泰罗尼亚语 (Català)</option><option value="cs">捷克语 (Čeština)</option><option value="kn">卡纳达语 (ಕನ್ನಡ)</option><option value="co">科西嘉语 (Corsu)</option><option value="hr">克罗地亚语 (Hrvatski)</option><option value="ku">库尔德语 (Kurdî)</option><option value="la">拉丁语 (Latina)</option><option value="lv">拉脱维亚语 (Latviešu)</option><option value="lo">老挝语 (ລາວ)</option><option value="lt">立陶宛语 (Lietuvių)</option><option value="lb">卢森堡语 (Lëtzebuergesch)</option><option value="ro">罗马尼亚语 (Română)</option><option value="mt">马耳他语 (Malti)</option><option value="mr">马拉地语 (मराठी)</option><option value="mg">马拉加斯语 (Malagasy)</option><option value="ml">马拉雅拉姆语 (മലയാളം)</option><option value="ms">马来语 (Bahasa Melayu)</option><option value="mk">马其顿语 (Македонски)</option><option value="mi">毛利语 (Māori)</option><option value="mn">蒙古语 (Монгол)</option><option value="bn">孟加拉语 (বাংলা)</option><option value="my">缅甸语 (မြန်မာစာ)</option><option value="hmn">苗语 (Hmoob)</option><option value="af">南非荷兰语 (Afrikaans)</option><option value="ne">尼泊尔语 (नेपाली)</option><option value="no">挪威语 (Norsk)</option><option value="pa">旁遮普语 (ਪੰਜਾਬੀ)</option><option value="ps">普什图语 (پښتو)</option><option value="ny">齐切瓦语（尼扬贾语） (Chichewa)</option><option value="sv">瑞典语 (Svenska)</option><option value="sm">萨摩亚语 (Gagana Samoa)</option><option value="sr">塞尔维亚语 (Српски)</option><option value="st">塞索托语 (Sesotho)</option><option value="si">僧伽罗语 (සිංහල)</option><option value="eo">世界语 (Esperanto)</option><option value="sk">斯洛伐克语 (Slovenčina)</option><option value="sl">斯洛文尼亚语 (Slovenščina)</option><option value="sw">斯瓦希里语 (Kiswahili)</option><option value="gd">苏格兰盖尔语 (Gàidhlig)</option><option value="ceb">宿务语 (Binisaya)</option><option value="so">索马里语 (Soomaali)</option><option value="tg">塔吉克语 (Тоҷикӣ)</option><option value="te">泰卢固语 (తెలుగు)</option><option value="ta">泰米尔语 (தமிழ்)</option><option value="th">泰语 (ไทย)</option><option value="tr">土耳其语 (Türkçe)</option><option value="cy">威尔士语 (Cymraeg)</option><option value="ug">维吾尔语 (ئۇيغۇرچە)</option><option value="ur">乌尔都语 (اردو)</option><option value="uk">乌克兰语 (Українська)</option><option value="uz">乌兹别克语 (Oʻzbek)</option><option value="he">希伯来语 (עברית)</option><option value="el">希腊语 (Ελληνικά)</option><option value="haw">夏威夷语 (ʻŌlelo Hawaiʻi)</option><option value="sd">信德语 (سنڌي)</option><option value="hu">匈牙利语 (Magyar)</option><option value="sn">修纳语 (ChiShona)</option><option value="su">巽他语 (Basa Sunda)</option><option value="hy">亚美尼亚语 (Հայերեն)</option><option value="ig">伊博语 (Asụsụ Igbo)</option><option value="it">意大利语 (Italiano)</option><option value="yi">意第绪语 (ייִדיש)</option><option value="hi">印地语 (हिन्दी)</option><option value="id">印度尼西亚语 (Bahasa Indonesia)</option><option value="yo">约鲁巴语 (Èdè Yorùbá)</option><option value="vi">越南语 (Tiếng Việt)</option><option value="jw">爪哇语 (Basa Jawa)</option><option value="zu">祖鲁语 (isiZulu)</option></select></div></div><div class="translation-service-container mt-3"><div class="min-select-container  "><label class="inline-block text-label mb-0 text-gray-6" style="min-width: 60px; flex-shrink: 0;">翻译服务：</label><div class="custom-select-container translate-service"><div id="translation-service-select" class="flex items-center"><div class="custom-select-item selected default" value="google-free"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">谷歌翻译</span></span></div><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="none" viewBox="0 0 16 16"><path d="M8.0023 9.68007L3.83278 5.51245L3.02478 6.32007L8.00268 11.2953L12.9756 6.32007L12.1673 5.51245L8.0023 9.68007Z" fill="currentColor"></path></svg></div><div class="custom-select-popup" style="display: none;"><div class="custom-select-content" style="max-height: 220px; top: 20px;"><div><div class="custom-select-group-header">免费模型</div><div class="custom-select-item selected " value="google-free"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">谷歌翻译</span></span></div><div class="custom-select-item  " value="bing-free"><img class="custom-select-item-img" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAMAAABHPGVmAAAAqFBMVEUAAADn5+fm5ubm5ubm5ubm5ubm5ubq6urf39/k5OTn5+fm5ubm5ubm5ubn5+fk5OTl5eXm5ubm5ubo6Oj////z8/MFpvDzUyX/ugiBvAbm5ubv7+/9/f1JvPH8ykvzgGD9wimRwyjp6ens7Oz6+vonsfEnsfChzEmhy0nzakPzakL39/f19fVfw/HzkHT70GF4zPLzoYn61nu513mu0mXzf16q0Fyhy0fx7mQ8AAAAFHRSTlMAIN/vcL+fMBCQQI+vz2Bgz4BQb5vSjyAAAAM8SURBVGje1doHctswEAVQEOykmh0g5RNuBFNJ2+m5/81iWcrs2AJlFqyT/Au8WX4MLWMphiY7jcrFRoYAEMo4LqMiEz4TRImEI3KxTv0IRbkDbKXbxhh1F2OaVld2ByXFXCE7WQJA1RnlSNNV9dZZBzOItAy3QqOOpLl3kqlMEAOwJPSmraYyWQmgMmpQzDTmRUjEUEauRz8pS8RgJg5GjVG3anS6GmE0uA16UuOHKYc9qg2g1cRoQAYDDInaqMkx9QAlDanxaYpFmD5pVGpmKlKOGLxKQMZcJejvnIyZSn/7ElZ5isUmcxql4+zOOMml810CkDFfASJn6Vp5jHaVH1PpvsqPHxsrKsRfLdHB6e0ejTsh6kFahNkDJEGlfCPKonwwCGAOkC8Xrtxo/f29K98OEAME7kEIuXjlyketr9648kHrnu5pEA7EAKljEE8IjZI/GoQBMXTAVqgUD6IsTvaIRMuFNFjujAK14kIUUFDtPAhVL9HwIQ3k1khRKz5EAQGdLS6kun8XL9BxIh0SqoQLMdtSMtSKE1FAJgpYXsTiVESouBBqPofmRTRyEaPlRVos7pCGC6F3pIThQugMh/xIKADVg9x8cuWH1r+uXPnZgyigHxmdfxe5fuvKmdbnl67c9iNHij976co7rS9fu3J+pHjJj0ixRMOLNIjFAi0v0t4hOTQXQi/ICBUXQq/6U1hexKKgP79cCJCJ7RnmQujXXYKOE+mwEIKa50EqrO+QADUnUiOlH9zeEapkmxwVH1IhoX+CuJAa+/XKEg0X0kKKXU5guRCL9R7JQhgGhC4+qHr/CNW+/4/OeEdoELq2Y0BokP6rqM9nrlxrfXvuytfeqyhqxXr/3UWD0AFrfSPdwTV3xHHRuX7+K1v+y2d6YGzX6JTc70Igd6/+lj5XG/LZlzT86yb34ux/WM9tjb+/zORfy5IyZ8G8IeNY8jmr8jwTwxKFqLvxRktL/yEJ4vHDGEufLwzMSo7+EIPGGJwgGfdJCbUxgWmfJhoLelLTmPqpz3wAhHkqpidYyXunc0Km2wrYnGRiZork+KdXeSG8JF0tJByRSRQIn8mKKI/jP5/DLRd5dDr4If0GDemh5W2BeAQAAAAASUVORK5CYII="><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">微软翻译</span></span></div><div class="custom-select-item  " value="zhipu-free"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">GLM-4 Flash</span></span></div><div class="custom-select-item  " value="siliconcloud-free"><img class="custom-select-item-img" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAMAAABHPGVmAAAAbFBMVEUAAADn5+fm5ubm5ubn5+fm5ubm5ubf39/k5OTq6urm5ubn5+fm5ubm5ubm5ubl5eXm5ubm5ubk5OT///9uKfXm5ub8/Pzw8PDbyf339/fp6en19fXs7OzSvPzt5P6kefmSX/eARPZ3N/b28f5a33/2AAAAE3RSTlMAIN/vcL+fEJAwYECPr8/PgFAwyaKKbwAAAwxJREFUaN7VmoF2ojAQRZMQIICgNk4wJNra/v8/rtjtzukaKYGMe/b+wD0zLyJkhs2l3MtNuxUZXMlEnm9kU7KUcFkICCDaukpjaDafAt87a4zRV4yx1vX+U1Q0aw3lroMrvTM6gHH9MHpqvkJRbbLRYPUE9uYplmp4PjYJDY89fqmm3IxFGD0L0y/SyAwVczWiju6UR8VsTc6jyhisjsYNkMmINLBTscVs5rVqC+D0QhyA4DMcAgajF2OGGZYqw8SXWTxk1Y+OXq+kR8uEg9bC0bHWwicyR8c6y+P0BXidCA/bMujY4NldjRnCv0oJYHQyDIAMhu50Qlwo/BxDTxV+/rejxkDSxSLvTq/TibGQfT9hBfQ6Of77CeN4shJiADhhIZg9YSFYSkVXCJaiqApBDB6wGrwmwsPuz9PXaiIsdOxGA4MmA6AhjB2jp+sW9kuMjpfYbp0uh4e8ne/7xcezFdmt8/thgrf7fsmrpI18/h4Pk9z/eRW3SAylxIyhlBgJiUQDlKwBTyvxsGcSeioJJq/A0UocKJaDpZVYaOklBjo8wXQSwbJYyWu0JGMAOsTHMcwJHdMSBOCB5PR+WMYlQnJZ6Hg/RUgO07yejmE+dFASDv4HR+QbCxMLJMc4iWAdtcRCzlqw9BIFjlbiQOGjPr0EH/V78LQSDw3+/VJJAEp8kUgvwRcJVoCjlDhoGQsn/zb5gDpH5V5fJTwUynnCcjnpCAaonvXCzRTtp0NB/xE0QMNudDT9wm6N7Cg/TOvfkjLwx5X04oMyeox95AUvu6gKwWs7qkLor6IQhQeMoBA8YDa1w91dc0uKi876+Ve29JfP2DCya3REpR0IKBai7FKONsTThzT046bw4Ox/GM+Njn8/zKQfy6JlzYB5y9kc1JpRuSojhv4LirE49J8Dz+OLMR7XF2ZSi+hFDCxjNryIWynBNCI1Ecsx2KlFmuGnNR8AyFTFlsNrMXoeLyzBle2uZCtpCly9sl+rVwZXr1TDklDVbXiJrJCcpaRspMrzr3W4rlVyP7tJvwCZPk/t1KobQwAAAABJRU5ErkJggg=="><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">硅基流动翻译</span></span></div></div><div><div class="custom-select-group-header">高级模型</div><div class="custom-select-item  " value="zhipu-air-pro"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">GLM-4.5 Air</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4="></span></span></div><div class="custom-select-item  " value="deepseek-pro"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">DeepSeek V3</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4="></span></span></div><div class="custom-select-item  " value="openai-pro"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">GPT-5 mini</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4="></span></span></div><div class="custom-select-item  " value="claude-pro"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">Claude 4.5 Haiku</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4="></span></span></div><div class="custom-select-item  " value="gemini-pro"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">Gemini 2.5 Flash</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4="></span></span></div><div class="custom-select-item  " value="zhipu-pro"><img class="custom-select-item-img" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAMAAABHPGVmAAAC9FBMVEUAAADn5+fm5ubm5ubm5ubm5ubm5ubq6urf39/k5OTn5+fm5ubm5ubm5ubn5+fk5OTl5eXm5ubm5ubo6Oj////m5uZvevRidPB8gfhXbu1AYuYjVN5MaOo9n+b8/PwwXOJNoutsqPWLrv5cpfDv7++Mifzr7/5ji/Jahe96q/pPfuxCdujp6enx8fFrkfV0l/f6+vrs7OwybOP9/f33+f9/nfv39/f09PX6+//z9v78/f9qePNSgO319fZnp/Roj/Q8Z+JzqvdDZOc0XePw9P5Zpe9ZcO5LfOuIh/tch/BQa+tIZukrWeHt8fyGhvp6gPdldvFecu9VpO5EeOk1buXo7f3Q3ft8m/pylfZ3f/ZOautDoOg7cubu8v7k6/3U3/3b5PzI1fp0ffVnd/FtgPBWg+5Ube1Lous6YOXP2PzM2vuBrfu/0fqyyPlwqfZzfPVkpvNipvJhc/BPo+xIoeo/Yub09//e5fy8zvuMp/u2zPqlvfp4qvmDovi1xPd4mfesvvaHk/Ztk/V6ifRsefNykvJkjPJfiPFTo+09YeU3XuMxYeIoV+CFrf2nx/uprPt/q/uTlfuIkfvC0fqBhPmbuPimsPiFsveMtvaUr/aEpfZ7nfVuk/V2f/WKqPOIn/NomvOAnu9Zg+5bc+5pjO1HeepLZ+lGb+bp7v7g6v6Xtv7d4fzV2fzHy/u9wvuevPmTnPmuw/eao/eBj/eAoPaEjPZxe/WjtvN0mvJsk/KcrvFfpfFlfO/u7u5WgO5zlOxJeepdgehUeudAdeeRsf7l6P2uwvylwfyPq/zf5vvN0fuws/t7q/vW4PqWoPqgqPm6xvi30/ebsPefrfeKnPfS3Pa9y/a2xvWjuvWgsvVxn/WOmfWBuPSnuvOUrfOEmfNqovJurPFprPBuju58lO1ReuxihOlAn+dFauY2ZuTF0Pq0uvrD3Pmaq/jv8faWvPaQqfZ7ovZ9svN2kfPB0e+vxO9ie+1eh+tmhetJcupzkOhQcudWxvkSAAAAFHRSTlMAIN/vcL+fMBCQQI+vz2Bgz4BQb5vSjyAAAAjmSURBVGjezZp1WFNRGMZdwgD7ng1rKkwMQDeGgylDUcTEQjBRUezA7u7u7u7u7u7u7u72H7/v3CHGzt3d2PPo++d8Hn/P+73f+c7hnJtGrNwzyT29MkhlBCSTKhSecg/3NK6URK6UEhuSeqV3cw3Bw5MHGAJDTHqtkQMZtXpTSKCBByk9Uktwz5iWgHQWLWdDeosuADnpJalAuHliBIF6TkB6ylE6i5EosEhAsCfTTmcx7p5oQsuJklbnFCazDBA0ZbEYzMbhShmYLtgYhcQhGwEmzmFZAohM7kAaOkal7JvxFFeqDISEcE4qBJKRiGBISYCWc1raABEUNxkxYKmcpxiIzM0uQ8elUjqkCDMCuVQrUJAioQyXUCQCmes4l0jHTl9KDJyLZCAZbO+bnti7LpIxwPaqzEwIMFwlLSFym6GHcC5UiK3wFSJDj547sHukuPAVfzLSiQpE+6rPo+I7xo5uGVlETCzyv7rXwtmT/ujNb/tKZqucJ8+p0c2iQ+3uykT2e4cpRRQr8uK2Rzlz5qzQME+eMt6nz9Q32+9jz9+M2O8sc+fLcxfnRBXNU6ait/f688/qxtvtMIljRuIWPMnalIcAAtSg/5sEu+NF4YCR4LjZWa0qaYUkqdUDGs72E0zGSIibWCOmi9sS55cvXwIQHUs2LUkhDdTqopUrJ/btUz9Y0IpKpJH62x58yg5CSsemHb/2H+ddqYEaIBqNJirx9uZmAqmkNFg6spNjqUh83NXELI3LleMpoHmz13hXUmOxNJoqWbI03jE7IVagwTL+nL6s809ofP1e7+dnQdWiFMAMnPiyUk1gVNZo2tHfy325epK1avQkLc/wIAEcQ7G9bmuytIuyUkCLsmad1W0SGgEGQmrRH/eOj2b8D4R4CMce0vKCeoAGVYWnoEr08luJkGQj4A977v4ls2D0UmL75N5s3fqZap7SDimNG2Mwu+JCV/RVqzGQKJ5RAiFP9j3oZbFZLyky3FjVWgMIbCKrFxRQptbl/I4jA38qRxkdhw2DaTN8r82S8as+Hata3g0aNEgCSsOGWP+oKEppnGDmgpv1RwY0BJYvK0BwpGUr7md74uMs9iIWBgRUkzeDFM18xPSPxH6YBBWMggJC6GBk6FCAjGBALETJR2IPklKyHS1hgYMVcIYMagQQyGBAtBiKO7OB8yClktp7E+VQTOIk69RfVzQKA8kOmQtDMBR3WCUGQUilXyCV+x60DszlG6skQ5qWBAQwWBADyZRGzjw0wrZRcQKWrCadVKDrx0KTR8Gx/lG1sFjIwNTZkEBIXsU8pMAGCLsTauamJDSzcVVwyvB/nlhuUXmoFUIqCEFCYDkqiIkJqVixzATqZWbNJHVS31W/nlL8JiVisUo2hf4FAhtiIl4A0TMhVLTJkrzVlVZQHymU81EAAR/CEDojpUQrBCnjDRTUutjfT0GY/nWAYB6CEOxhGTGyIUiBZCZsPL3y4J8Mrkhw517lcaAIQ4xEloYQjgUZO5bnjB29crnZ5o5mPnPr/mJhCC4UAcj6C33HjRu3ZvTxVSsAwVDdLrd27/3+9Onw4cMXOwOZA7p2bcrZuCWdirC3507R9fucylt2V1jYAmcgOawKHyVwIulUr9XEwry6MiEYvCAEVftuN0YmLY/0LgRCRs9lzOCxhYUhHTp0aFLq3o24v92Ym0/dUKgGMKr3RsoRdgunZS5GK6N2k1ygITdaxof+kXm3aTMKFuwHlN7Ve1dnlktPFLBnmYQgj3MhpP2QIb6Tuy39jbKk1bS8xQoWLDgDKNULsSEmgLAHJB8H2mhftZSvr2/rUUt/6bL4VtPz5s1brBh6QUz16l3ZA5I96nkGqmrV9gAJjxjVKeVfu2wZnBcEZkAYfu+u7FGfiblp/WSUqjrEFyG5J3fhktVqa758ZVMgqJ6sTctDYPuFzK2QUqWQ0TY8Yko9654Vt6VsPqAAZtAgrBjG35O9/bJ7OEeTDk1orUrxPsLDc0ccDqbrw29ao7BGQEkxAxSAME93SmJhQagPX2RsbxueG9R6cj3sMHNC2bACYY3mAQWCwfixyWxDLMQLIHLW4e4xhbT3HQKUtrm3IySixcRIMNJ5VukCoLB8yZRBSNnAONzhRa6EFUoungECBlVE/vz56xbhzOMH+/OQZEpBpEy3CQkgbkIHbmvvgtqEo48eEQjpFsnFXokpEANeQPmoaMkAwogEpWKslBev71WlfdWmDU2kdUQPgCyryzUv5h/jX7o0YsLmJcc/8BzEZataSsE/goKXnp1yBxlt29DUgQHyqee3trS/v39MzB5aMtplZQdO7dI51Ha1PCiEPSPjE1a/u+ObmzIikHFiTH6f8c2n7q+DlD18+rvAzIYrzSMZgwurhcrIvrHzSzh3l2bemtoYM3KMz6HuW+pUA8jChTFYMVgwW+c2C2GsNQP2FpW7jLUecd11j0BG/tzAACs+Pqun5QtCCBV6GbQ2UMzFB0bPVnSryQBBtfABrZ4eVm1/0H5ExBTwLz2wT2eOl0Ds1r/ojBxTodHNJ74FxMgWFHJg68KgakHVqtFc/Gcl+AWLvMFRoBW2zEfHd4dAWoz0QZWtExQUVAchC3d/PIkIYSPib3DqjZqCDFSjIAqp5v951iWTUfRVFKZisHel1vLwMh4SFkQppXdvxiOMaCO0wUycPUwXHvJwOEL23YzlhGX565pbjtnbU2wrhOypAIy18SJeUtI7c2UbvCTu0AGfhzkXz/0QHSriytbJy+dOdZt3X7Bgc3290fHLZ5Rc3FW9uV6fy7HOXaOjVBiLa4SBqGw//aV15dOG9B890rj+uemfPpy5/gmQTTFoU4MwGoDxPzzL8pTUPDBnEMGgq5LonDJj1BGiEvvJjBwe/S2OM0ziH/1REoXjZrQGxucLbKWTOoYxBhK2DbYZJRGP0QKCT8MpzE6TfYTeQBiVEo0J0OkFCWhCpqLrz1kMZIMci02Q1qIjoAwZ3VP96ZVS+NMrlUcal8gtnZftj8iUckjChXL3kKsUiuTP4dJ6qeSZRBfpB0lhGlCNRficAAAAAElFTkSuQmCC"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">GLM-4.5</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4="></span></span></div><div class="custom-select-item  " value="deepl-pro"><img class="custom-select-item-img" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAMAAABHPGVmAAAA/FBMVEUAAADn5+fm5ubm5ubm5ubm5ubq6urf39/k5OTn5+fl5eXm5ubm5ubm5ubn5+fk5OTl5eXm5ubn5+fm5ubm5ubo6Oj///8EK0jm5ub8/Pzv7+/19fXx8fIoSWPp6enHz9bk6Ov5+frn5+f39/fs7Ozu8fMVOVQJL0v6+/sOM0/r6+twhpcjRV/o6Ojd4+dheow/XXPp7fDK0tmvvMWOoK2Jm6k8WnEZPVjZ3+O9yM+1wMmerbiaqraEl6Y0VGsqS2QgQ1zV2+DBy9K5xM1sgpRnf5BbdYhXcIREYXcvT2jn6+3Q2N2ntb+hsLuVprJ+kqFPan5LZ3w2VW1JZXqjhMOgAAAAFnRSTlMAIN/vcL8wEJBAn4+vz2Bgz6CfgFBvyuvMXgAABPdJREFUaN7Fmudy2kAQgFGjY5zYuVtJhAASzWDcwL3g3hK3vP+7RJKx1yS600qQ5BuPf2jG/thyhTulqGSW9UJxUdXAQ1MNo6DnMql5ouh5FUJQi+X0fAy5QiBouBXbqZsm8zDNumNX3EYgyudmNWSWSr7Ask0WQt22qr6nrMygSBc0z1CpMwn1wJNPqlEMAHDRIMSxkmoyBT8Ik5Ewk2m+aACooGnUcuxMuaggawwlVhhVh8XGroKmx6iGhWHEDKZAS9UiNGyWELsBqkJwqFA1WWLMKsGS1mAFHUksK6ClIx0WmxELLSJHhc1MRWpR0DGrRZHU3GJzwRJXX4UVNidWYDF83SyQevd+/47WyYXQuQQa0Y69E87504BgaYAeWvTIcT74yQPaF2b02A8rvhFZ9OZjl7/R/0EovvG7YyGyIFt+ppDnQXRZ9D+6V56s05/8d3pNucUBbbrDPsuT1exhppD+odziTneYAiBL1uEOD+f4XpowAIUayOY6F9OrSacXgxbIxgWXsvMgHSxpQiDOqMWj+HomCSUbHcjeMadwVROFgg22IAiktsaJdEcdUYMtvc++Tqijz+msCXbKUHp15KDKwnjiH2ldr63LLIIx04CcrOzNNv/AzYY/s0i64EZeehXqocODf2DsOTzOJT0mypfqO9KCbH3jHxhNHh6TJZgvBXtLLjmfPLyMLbGCubgIdrTk++ThUWyJDfmgJJ1ICXbofj+mxPSLkoFVFinBfLHO0Q5NgkXJeKPEpUh2hnfm4OnSnz8G17EkLiyndKhESpDug+Pn7CSGpOJVPgs2RYL/bM/P2bDbGm4dHFMktjccDXDoEpxza8HE2yNIHCh6kjpNgrSO3j/XtkyCc6QKJlmC/3Efxw1KxD2sJZDguDmnSLQUAEsgeWavDKMlDCCJpOv9DF5H5svfkqyfrXu/mliSeUpwq/2tzfl4tHWwzWmSmIXvBhvgXVwhSYUnt/DjaXPreH3XH8IXbY6QWrgEHYpk//1vDmLOwnUwvDXLYTHWk02sA1HigEGcIPcmD0fTmSJOkMSp/m27i0tJrKl+GRctyZboYPLwVig5ES9aOfHy25z6nK8tuMWFbMuWX3EPT+1Kr/3d3VlLLBkx2e7uk6jym1NFHl/1nttix4ktrHvRk+jCb0Cnt5zKZU38db4cfAVaFQ7W4Q5J8bLHhFQhjRvucDbW2pGK1pB5yErikZWepN1H5Kx91ZQffuQDSc7Ll4TOQUviuN1kUqowuV4pYb5ifstuHTI5jp+tgCVwmZxvL+GSXRaBC+WJJIMLl5DDfpgEG1d68IGlj6DWiyvBsgekYdVkkZxuCyTEExyDdh78MCZKMBDyURRiX3bJEgwEq+IyErvbZAkGgg3mMBrfx0SJ/ccxt06/NWn22hSJWYVy/CNbZPeGILHAEB0+U3PWR0n04TOi42AhcPeIkuhjdCQb7zJrcONJJAXJhl/9lWJebfzoCyUroM7rkqZuSy5p/s910/wvzv7FFeD/v8z869eyaFmd5YJ5ER0ysrNclWepr8zoGlQTBOPgpT8FxYgfjOni6wtEFtR4GrMCGAYZ5ROgJlrRwGok0DiEKcwFzFQyTdWqSw1+EFoWx18CzYIaeOxOaJZsyzPA4lJm5levPoW8etXBV6+yudRcSC8Uw18iy+tKap5kcnrWMN5ehysVs/oyOUm/AJAdz9mDSbxUAAAAAElFTkSuQmCC"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">DeepL Pro</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4="></span></span></div><div class="custom-select-item  " value="qwen-pro"><img class="custom-select-item-img" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAMAAABHPGVmAAAAjVBMVEUAAADn5+fm5ubm5ubl5eXn5+fm5ubm5ubq6urf39/m5ubn5+fm5ubn5+fk5OTm5ubm5ub///98Vuvm5ube1fr8/Pzw8PDv6v3OwPeMa+339/fp6emtlfP19fXs7Oz39f6dgPC9qvWMbO2EYe22oPStlvPWy/mli/GVdu/m3/zGtfa+q/WdgfCEYu3FtfY8OLe9AAAAEXRSTlMAIN/vkHC/nzAQz0CvYGCAUGOTB44AAATYSURBVGje1Vprc6JAEOSNgDFhhzcKikbNXZL///NOUYcizD4Aq1LXH+6qkqq0Pd07O+6upgrvzbaWvmHCBabhOJYdeNozoduuAQSM5WrxHIbAuhFUyaaI4zi8II6LYpNUNyI3mMvgvfpwQbKJQwLxJimvPCt9BsXCMq8MRShA0fK4U2l051okZBDwVFNpPOsqIg6VECeTaGwTKZRpjNXoSlVIoU7j6KNklEU4GpsSTFvdDazUeDGWWql8gE04ERsAQ1fgMKCMw8mISwWWhYmOT2SpwFxIOZJwJhJkmcoxn0VHjtksOt9z5JjLwnffgCp8Eirw6X3TGmR3VpItspcACDnqqEV2jJRYAGzKdMk6z9kDf5XWPmW+IzH9LzsjS6pmvvOT40ViSLrP6/2DZKtoiz1Ir7hYa5aF3yhFyZYCzH7CXEmxUna6/Lt9kJwVc2z1hEiSFZ5bHyKU8kcxYfoIIRlbt/+jlP36gfcWf6Tey4XkeXq3n3EQcaQs5EIwvt+4WDhoOFIsVSEpy7FsXOxoKRiwF6ik8W1R53ySr5oO2Ct230ISXyybAAd6rfg3jgBKSdNKH2wUxM0GIBDZnmY3HNgayybEp8h6ulpdWu/xDT+YBBFZL6MdHqCk3d5GN3yEd5JIiE+W0fXS22wllBAssiLSpknJerW9eEn23zN2dEW8s4yzebmtJTHRrJQ7OipvOF3yaooHJXevzdVJTqy1jjTF0wJquf9V7uio/J2/q7xpNiT8+O5rRZIGU0I6bxG+H7teoerIWTC2WJpDLMV6P+wVH3m+5/eRAzvyt/olSRLu2GAwGTaVde9jNTV3E/YxwTwpEfEz7DYddrihUBk2+ySD3Snvy+vw/cP6r5pHYmoA5K+2w8EEtyxyDUXcEAOQJDj9YIzxZ4hBE/lkkYhEIuVA/Iydurynj4/wOZokJWIcEfFNm5MkxgBovFKMD8P4HjCA9VdT08ZjhEfFOO+E4L6LMSYi7CPJiBjveksUJyYyxgU42hJXvHqM8x9drqkxxiQJNsgxMe7im6MyjDHRILHVU9jTMd4OK9rc8MUistW/4aZFbV1kjDvXc4W5u4KA3n7xT1Ax7sX3B4709ktnGINDxLgTMuB45wwSmjtwnvwTufBTYFEJ35eaxnX+xBD0UHEUC0HfV+1XoFKc3/O2xYkYm/ogR8gSFjhw80m2soaAyPgDt2ZBIvI9lWbvtGuR0QORK/oSlO6x31I4EE6Q1Qq0Fj4U3F6f84SQkaKr1eJ1sOixGXJnkLWakApWdxKPs3Ed+SP3cRAp0cEHWk/3+lPWRz2IL9otsv3+jS4WrhXEYbifSYTIj+3SqI8z+8D4qgpRP8FBadt+fNdyIR0sImB0qKJhfOVCMGC4ViRHkRhfmZDN4Jjblp4849hzJAZ7+qBzNfbIFlfoXtl1R/nwWbCL5CqHz9MKFmV3HGvJMfpvXQhonv/Mqw3jly5pnn/dJLs4+x+u564cv3+Z+bxrWTnLnAtmHzmEmHdV7ilf+k8SU+ClvxJ0Z7yYuMLnC6p4McY/xEAZ6mLccU9K0I2xNOqPY7BSE2lK2TMfADCthTYd+ovR8nAfLMEF/qunzUTgdk+visfTq7h7emUF2lOweFnSj8hcW9eeCS+wLcd5PIfzl5b9plykfyzdKISafIeqAAAAAElFTkSuQmCC"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">Qwen Plus</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4="></span></span></div></div><div><div class="custom-select-group-header">顶级模型</div><div class="custom-select-item  " value="openai-max"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">GPT-5</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,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"></span></span></div><div class="custom-select-item  " value="claude-max"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">Claude 4.5 Sonnet</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,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"></span></span></div><div class="custom-select-item  " value="gemini-max"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">Gemini 2.5 Pro</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,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"></span></span></div><div class="custom-select-item  " value="kimi-max"><img class="custom-select-item-img" src="data:image/png;base64,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"><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">Kimi K2</span><span class="custom-select-item-pro"><img src="data:image/svg+xml;base64,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"></span></span></div></div><div><div class="custom-select-group-header">其他/自定义</div><div class="custom-select-item  " value="more"><img class="custom-select-item-img" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAABQCAMAAAC5zwKfAAAAclBMVEUAAADm5ubn5+ff39/m5ubm5ubm5ubm5ubm5ubl5eXl5eXm5ubn5+fn5+fk5OTn5+fn5+f///8zMzPm5uZNTU35+fns7Oz19fXy8vJAQEDp6emAgIBmZmaZmZnMzMzZ2dmzs7NZWVmmpqZzc3O/v7+MjIwtOcgWAAAAEXRSTlMA3yAQ759Qz7+QgK9wYGBAfzNtP58AAAQESURBVFjDzVntlpowFAQJgmhrcfgIAirqvv8rNiHbZGOuV13bczo/ejj0MDvJ3I/kGj1AstykeRxDQWR5WmyTiAdPtooRIE6X3yPdrgUUGtm2dV1q1HUrG2iky5fF/RKarK3LAHWrSeOfi1fp9tJyhJx7Rfnrab4fsRJXlyzaRqt8im6Rs3ROplK5fmLdGwG05VNQCxePRCYrJa98FrUEVvxys1AeLxLIFgxfjD21e/xOxguGj3SDZ2wsI8VXfgO0Rp6Pxx2NGc/Ha8zCerHy/HjZmVWQboDie4Nxc7OBIoy/1+JR+Nu4dhv4XWNyb8HcBsqPqZoGjR73GYGvaR0zC0a1s+iOzKJj5/Qv7Mu76HdfMHCLLlxIcw5PSlg1o1OMjNMQid1BzpHK6uo1ISuR30HjwHnnEVYnTqLhW5I7OHa7bpTHaucRasrj2NG8e2xnwpQSOJqPjRW9eXetdg4HIr6wnqs+lXT46qz79jrYtxXRZY0tSzR0rAzmQ1/KSavs9D8jZcvyzopPmglQtP2tEPXygoNmBRHcuuhQQagVnDTxuQyhs+VD7yzhc6y2kPD4rAWWHGRH+gIk0RYNKfDofX8Yx/FwGwUDuYkFArsOt+s5d8afE/dHTeBsKE+O+uuRKg/uJQZqzS3SKKc88fSMO4dPk+Q4a5YhYR5lBKFOOCsAJrhxmHSsGI6T0UvaLEDVhXmV+n9MhHzMTxcr8ai5qZBShAgI7cfmabDUUj1drOqebgQhoaPx66F5nMzTW4QuyLs/3PJlQjlYEy/WnqulOZp9JQnJfnKYbYbLQ/xpf1cb+hXppiAJr197ppzJ+/HSuQw/3+mpNbIoJ6qXoZAucQxcycKF7qk1cir1pKurfumvnKZTp+VSqbdBWMu7m/KJfq7To/R7xER0lSLsAHT5xE00TGTqNdjaAsuWT7pHlGSBtTZT5RM9wo/OtkeQLSBaETabD6Tira632nSXH80OEp7ca6NzWzN12oq08WKAe200ESBz2cJRHuxbMpVrIDHHYeoQMMvrKhN/Xuk29Rz0ijW2vs+uaXQDyrFzhP3O1NXT5TJK8rD0OYoQzmdKqkf4IblDcWRQ8AdOjxDMgdMe2xNGoskJdyRmJhv6xsdLtFY4TNyFr3CDAe5aIZ++VvgXH8aWflCYqmrqj9xtz5tn5O9ezSTW//byGG1euC6TSffzr17AG2J8k7wxImiQ3R1i/A9jkSbge38Q9LdHVewwbf/mMC2MnleW3QCr5NG8VPgieXli88TIdA23k7wbyBfPD3Xbh3T+UJdHEUMtnBnl7AFRvDJwX/yI2cE4TcdjmeJzdO8m95+je7HefvPHhZT6cWG1fOsXi22R5pmYmeI83Twk+w2VbF9Avb3n0wAAAABJRU5ErkJggg=="><span class="flex items-center overflow-hidden"><span class="text-ellipsis overflow-hidden">更多翻译服务</span></span></div></div></div></div></div></div><div class="min-select-container"><label class="inline-block text-label mb-0 text-gray-6 flex flex-row items-center" style="min-width: 60px; flex-shrink: 0;">启用 AI 精翻<img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0ZGQzczNiIgZD0iTTMgN2gxN3YxMEgzeiIvPjxwYXRoIGZpbGw9InVybCgjYSkiIGQ9Ik02Ljg5NyA5LjI0MmMuNDE1IDAgLjcyLjExMS45MjguMzQ3LjIwNy4yMzUuMzE4LjUyNy4zMTguODczcy0uMTEuNjIzLS4zMTguODQ1Yy0uMjA4LjIyMi0uNTI3LjMzMy0uOTI4LjMzM2gtMS4zM1Y5LjI0MmgxLjMzWm05Ljg0NiAxLjc4OGMuMzg4IDAgLjY2NS4xNTIuODQ1LjQ1Ny4xNTIuMjY0LjIzNS41ODIuMjYzLjk4NHYuMzE5YzAgLjQ5OS0uMDgzLjg4Ny0uMjYzIDEuMTkyLS4xOC4zMDQtLjQ1Ny40NTctLjgzLjQ1Ny0uMzg5IDAtLjY2Ni0uMTUzLS44NDYtLjQ0NC0uMTUyLS4yNjMtLjIzNS0uNTk1LS4yNjMtMS4wMTF2LS4yOTFjMC0uNDg1LjA4My0uODczLjI2My0xLjE3OC4xOC0uMzA1LjQ0My0uNDg1LjgzMS0uNDg1Wm0tMy40MDctMS4xMzZhMS4xNyAxLjE3IDAgMCAwLS43MDYuMjM1IDEuNDgyIDEuNDgyIDAgMCAwLS40MTUuNWwtLjA4My4xNjUtLjA3LS44MDNoLTEuMzU3djUuNDMyaDEuNDU0di0zLjY1OWEuODguODggMCAwIDEgLjMxOS0uMzg4Yy4xMS0uMDY5LjI1LS4xMS40MTUtLjEyNGguMTI1bC41NC4wMTQuMTY2LTEuMzE3Yy0uMDctLjAxNC0uMTI0LS4wMjgtLjE5NC0uMDQxLS4wNTUtLjAxNC0uMTI0LS4wMTQtLjE5NC0uMDE0Wk02Ljg5NiA4LjEySDQuMTE0djcuMzE3aDEuNDY4VjEyLjc5aDEuMzNjLjg0NCAwIDEuNDk1LS4yMDggMS45OC0uNjM4LjQ4NS0uNDMuNzItLjk4My43Mi0xLjY5cy0uMjM1LTEuMjYxLS43Mi0xLjY5Yy0uNDQzLS4zODktMS4wMzktLjYxLTEuNzczLS42MzhsLS4yMjEtLjAxNFptOS44NDcgMS43NzRjLS44MDMgMC0xLjQyNi4yNjMtMS44ODMuNzc2LS40MTYuNDctLjYzNyAxLjA2Ny0uNjc5IDEuNzczdi4zMzNjMCAuODE4LjIyMiAxLjQ4My42NzkgMS45OTUuNDU3LjUxMyAxLjA4Ljc3NiAxLjg4My43NzYuODA0IDAgMS40MjctLjI2MyAxLjg4NC0uNzc2LjQxNS0uNDcuNjM3LTEuMDUzLjY3OC0xLjc3M3YtLjMzM2MwLS44MTctLjIyMS0xLjQ4Mi0uNjc4LTEuOTk1LS40NTctLjUxMy0xLjA4LS43NzYtMS44ODQtLjc3NlpNMTguMDAzIDZhNiA2IDAgMCAxIDAgMTJIMFY5LjQyM0EzLjQyIDMuNDIgMCAwIDEgMy40MiA2aDE0LjU4M1oiLz48ZGVmcz48bGluZWFyR3JhZGllbnQgaWQ9ImEiIHgxPSI3LjUiIHgyPSIyMiIgeTE9IjE5IiB5Mj0iNiIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIHN0b3AtY29sb3I9IiMyMjIiLz48c3RvcCBvZmZzZXQ9IjEiIHN0b3AtY29sb3I9IiM2OTY5NjkiLz48L2xpbmVhckdyYWRpZW50PjwvZGVmcz48L3N2Zz4=" class="ml-2"><div class=" " style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin-left: 4px; cursor: pointer;"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4763 8C14.4763 4.42323 11.5769 1.5238 8.00012 1.5238C4.42335 1.5238 1.52393 4.42323 1.52393 8C1.52393 11.5768 4.42335 14.4762 8.00012 14.4762C11.5769 14.4762 14.4763 11.5768 14.4763 8ZM2.66678 8C2.66678 5.05447 5.05459 2.66666 8.00012 2.66666C10.9456 2.66666 13.3335 5.05447 13.3335 8C13.3335 10.9455 10.9456 13.3333 8.00012 13.3333C5.05459 13.3333 2.66678 10.9455 2.66678 8ZM8.64493 4.62911C9.33636 4.76854 10.1588 5.42797 10.1588 6.38721C10.1588 7.25184 9.52267 7.63216 9.19136 7.83023L9.19135 7.83023L9.1913 7.83026C9.15492 7.85201 9.12223 7.87155 9.09445 7.8893C8.81331 8.06911 8.70817 8.27635 8.70817 8.49654V9.52359H7.63731V8.10683C7.63731 7.77083 7.74512 7.5354 8.04493 7.3274L8.11236 7.28283L8.71388 6.88283C9.0975 6.62454 9.09217 6.10607 8.85483 5.87711C8.72757 5.76556 8.57584 5.68553 8.4119 5.64351C8.24797 5.60148 8.07645 5.59864 7.91121 5.63521C7.24379 5.76626 7.16683 6.23711 7.16226 6.69426V6.95292H6.09521C6.09521 6.06302 6.19731 5.65959 6.67198 5.14988C7.20379 4.58035 7.95312 4.48892 8.64493 4.62911ZM8.70817 10.2855V11.4284H7.63769L7.63731 10.2855H8.70817Z" fill="#CCCCCC"></path></svg></div></div></label><input id="toggle-ai-context" class="shrink-0" role="switch" type="checkbox"></div></div><div class="flex flex-row mt-3 items-center"><div class=" " style="position: relative; pointer-events: all; display: inline-block; opacity: 1;"><div><div class="translate-mode mr-2 "><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 24 24" fill="#222222"><path d="M22.9331 7.46673V21.3334C22.9331 22.2667 22.1331 23.0667 21.1997 23.0667H10.1331V22.0001V20.9334H20.9331V7.60006H15.3331L11.0664 18.0001C10.7997 18.6667 10.1331 19.0667 9.46641 19.0667H2.79974C1.86641 19.0667 1.06641 18.2667 1.06641 17.3334V3.46673C1.06641 2.5334 1.86641 1.7334 2.79974 1.7334L12.9331 1.7334V2.80007V3.86673H2.93307V17.3334H9.33307L13.5997 6.9334C13.8664 6.26673 14.5331 5.86673 15.1997 5.86673H21.3331C22.2664 5.60006 22.9331 6.40007 22.9331 7.46673Z"></path><path d="M5.904 11.4063L5.472 13H4L6.056 6H7.96L10 13H8.496L8.072 11.4063H5.904ZM7.688 9.95389L7.048 7.54323H6.952L6.296 9.95389H7.688Z" fill="#EA4C89"></path><path d="M19.4337 18.9805C18.403 18.6732 17.5907 18.3117 16.9968 17.8961C16.6999 18.1039 16.3542 18.2965 15.9597 18.474C15.5652 18.6558 15.1071 18.8312 14.5854 19L14 17.8831C14.9035 17.6494 15.6076 17.3918 16.1124 17.1104C15.8579 16.816 15.6394 16.4848 15.4571 16.1169C15.2789 15.7489 15.1262 15.3312 14.9989 14.8636H14.1718V13.8182H16.456C16.4178 13.5844 16.3669 13.3312 16.3033 13.0584L17.5504 13L17.6522 13.8182H19.8091V14.8636H18.9374C18.8059 15.3485 18.6532 15.7749 18.4793 16.1429C18.3054 16.5108 18.0976 16.8377 17.8558 17.1234C18.4327 17.4524 19.1474 17.6926 20 17.8442L19.4337 18.9805ZM16.1633 14.8636C16.3118 15.487 16.5854 16.013 16.9841 16.4416C17.1707 16.2424 17.3256 16.0152 17.4486 15.7597C17.5758 15.5 17.684 15.2013 17.7731 14.8636H16.1633Z" fill="#EA4C89"></path></svg></div></div></div><button type="button" id="translate-button" class="mb-0 main-button" aria-busy="false">显示原文 (⌥A)</button></div><div class="text-sm text-gray-9 mt-4 ml-1 display-none"></div><div class="text-sm text-gray-9 mt-4 ml-1 display-none" style="color: rgb(208, 147, 29);"></div><div class="text-sm mt-2" style="max-width: 218px;"></div><div class="text-sm px-1 text-gray-2"><div class="flex justify-between mt-5"><select autocomplete="off" class="transform-padding-left min-select always-translate-this-site-select" style="max-width: 230px; width: unset; flex: unset;"><option value="matches">总是翻译该网站</option><option value="excludeMatches">不自动翻译该网站</option></select><input id="always-translate-this-site-input" type="checkbox" role="switch" class="shrink-0"></div><div class="flex mt-3 items-center justify-between"><div class="flex items-center"><label class="mb-0 mr-2 shrink-0">鼠标悬停:</label><select autocomplete="off" class="transform-padding-left min-select mouse-hover-translate-select" style="max-width: 100%; width: 100%;"><option value="Ctrl">+ Ctrl 翻译/还原该段</option><option value="Shift">+ Shift 翻译/还原该段</option><option value="Alt">+ ⌥ 翻译/还原该段</option><option value="MouseHoldKeyPressHold">+ 长按鼠标左键</option><option value="Auto">直接翻译该段</option><option value="Other">自定义快捷键(打开设置)</option></select></div><input id="mouse-hover-translate-input" type="checkbox" role="switch" class="shrink-0"></div><div class="flex mt-3 items-center justify-between"><div class="flex items-center"><label class="mb-0 mr-2 shrink-0">划词翻译:</label><select autocomplete="off" class="transform-padding-left min-select mouse-hover-translate-select" style="max-width: 100%; width: 100%;"><option value="direct">直接触发</option><option value="icon">显示图标</option><option value="mini">显示小圆点</option><option value="Ctrl">按 Ctrl 触发</option><option value="Alt">按 ⌥ 触发</option><option value="Shift">按 Shift 触发</option></select></div><input id="mouse-hover-translate-input" type="checkbox" role="switch" class="shrink-0"></div><span></span></div><div class="widgets-container mt-5 "><div class=" " style="position: relative; pointer-events: all; display: inline-block; flex: 1 1 0%; opacity: 1;"><div><div class="widget-item" title="文档翻译"><svg width="24" height="24" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="currentColor" style="margin-right: 0px;"><path fill-rule="evenodd" clip-rule="evenodd" d="M19.4284 6.59193L15.1187 2.28564H6.28557C5.83092 2.28564 5.39488 2.46626 5.07339 2.78775C4.7519 3.10924 4.57129 3.54527 4.57129 3.99993V9.71422V18.8571V19.9999C4.57129 20.4546 4.7519 20.8906 5.07339 21.2121C5.39488 21.5336 5.83092 21.7142 6.28557 21.7142H17.7141C18.1688 21.7142 18.6048 21.5336 18.9263 21.2121C19.2478 20.8906 19.4284 20.4546 19.4284 19.9999V18.8571V9.71422V6.59193ZM15.341 6.82964V4.93136L17.2404 6.82964H15.341ZM6.28551 18.8571V19.9999H17.7141V18.8571V8.54335H13.6272L13.6267 3.99992H6.28551V18.8571Z"></path><rect x="7.55957" y="10.2002" width="8.88" height="1.8" fill="#EA4C89"></rect><rect x="7.55957" y="13.2002" width="8.88" height="1.68" fill="#EA4C89"></rect><rect x="7.55957" y="16.0801" width="4.92" height="1.8" fill="#EA4C89"></rect></svg><span class="widget-icon-text">文档翻译</span></div></div></div><div class="widget-item" title="文本翻译"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="20" viewBox="0 0 16 20" fill="currentColor" style="margin-right: 4px;"><path d="M14.2857 0.286133C14.7404 0.286133 15.1764 0.466744 15.4979 0.788235C15.8194 1.10973 16 1.54576 16 2.00042V18.0004C16 18.2255 15.9557 18.4485 15.8695 18.6564C15.7834 18.8644 15.6571 19.0534 15.4979 19.2126C15.3387 19.3718 15.1497 19.4981 14.9417 19.5842C14.7338 19.6704 14.5108 19.7147 14.2857 19.7147H1.71429C1.48916 19.7147 1.26624 19.6704 1.05826 19.5842C0.85027 19.4981 0.661288 19.3718 0.502102 19.2126C0.342916 19.0534 0.216643 18.8644 0.130492 18.6564C0.0443411 18.4485 0 18.2255 0 18.0004V2.00042C0 1.54576 0.180611 1.10973 0.502102 0.788235C0.823593 0.466744 1.25963 0.286133 1.71429 0.286133H14.2857ZM14.2857 2.00042H1.71429V18.0004H14.2857V2.00042Z" fill="currentColor"></path><text x="4.5" y="14.5" textAnchor="middle" dominantBaseline="middle" fill="#EA4C89" fontFamily="Alibaba PuHuiTi 3.0" fontSize="11" fontWeight="700" fontStyle="normal">T</text></svg><span class="widget-icon-text">文本翻译</span></div><div class="widget-item" title="奖励中心"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" style="margin-right: 0px;"><path d="M4.73641 19.9325C4.73641 20.3776 4.85796 20.4998 5.23835 20.4998H11.2616V11.995H4.73641V19.9325ZM12.7364 20.4998H18.7597C19.1408 20.4998 19.2616 20.3784 19.2616 19.9325V11.995H12.7357V20.4998H12.7364ZM19.2718 7.36327H15.6354C16.5133 7.15085 17.4404 6.46316 17.5546 5.65636C17.6885 4.7352 16.6588 3.33896 15.4127 3.5159C13.9227 3.73458 12.8303 5.13177 12.0594 6.21528C11.2943 5.1532 10.2972 3.91153 8.86885 3.55061C7.48548 3.20297 6.538 4.72648 6.56335 5.66945C6.58816 6.47074 7.46013 7.15161 8.36263 7.36327H4.72623C4.27677 7.36327 3.99902 7.6322 3.99902 8.13611V11.2254L11.2718 11.2269V7.36327H12.7262V11.2269L19.999 11.2254V8.13611C19.999 7.6322 19.7206 7.36327 19.2718 7.36327ZM7.56116 5.95393C7.30948 5.65636 7.47977 5.2522 7.63756 4.94705C7.9278 4.40918 8.3321 4.08241 9.02076 4.3868C9.98091 4.81258 10.6878 5.71288 11.2638 6.52024C10.0441 6.66324 8.22447 6.71881 7.56116 5.95393ZM12.8674 6.5064C13.4608 5.69809 14.1496 4.87744 15.103 4.37296C16.1026 3.84818 17.0295 5.26624 16.5554 5.9471C16.1904 6.46392 15.0335 6.51266 14.4088 6.54187C13.8948 6.56912 13.3798 6.55726 12.8674 6.5064Z" fill="#ED6D8F"></path><path d="M11.2614 11.9952H7.21768C6.52575 13.2879 6.15297 14.7457 6.13406 16.2328C6.11514 17.7198 6.45071 19.1878 7.10951 20.4999H11.2614V11.9952ZM12.726 7.73418V11.2271L19.9988 11.2256V9.8496C19.0298 8.91196 17.8656 8.23144 16.6015 7.86376C15.3374 7.49607 14.0094 7.45167 12.726 7.73418ZM19.2614 19.9327V11.9952H12.7355V20.4999H18.7595C19.1406 20.4999 19.2614 20.3785 19.2614 19.9327ZM11.2716 11.2271V8.2068C9.83264 8.83641 8.58896 9.88261 7.68213 11.2263L11.2716 11.2271Z" fill="#E55884"></path><path d="M12.7372 20.4998H18.7612C19.1423 20.4998 19.2632 20.3784 19.2632 19.9325V11.995H12.7372V20.4998ZM9.37501 18.3432C9.37449 19.073 9.47179 19.7991 9.664 20.4998H11.2632V13.1671C10.0463 14.5806 9.3725 16.4275 9.37501 18.3432ZM16.6044 10.6621C15.67 10.6608 14.7443 10.8526 13.8787 11.2267L19.3273 11.2256C18.4625 10.8522 17.5378 10.6608 16.6044 10.6621Z" fill="#DB3E77"></path><path d="M18.9676 14.0576C16.3136 14.0576 13.9937 15.5771 12.7363 17.842V20.5H18.7603C19.1414 20.5 19.2623 20.3787 19.2623 19.9328V14.0639C19.1645 14.0597 19.0662 14.0576 18.9676 14.0576Z" fill="#D63070"></path><path d="M8.20238 8.06029C8.33786 8.2763 7.62511 8.54334 6.87327 9.07551C6.12143 9.60769 5.6152 10.204 5.47954 9.98795C5.34388 9.77193 5.75979 9.03132 6.51163 8.49896C7.26347 7.9666 8.0669 7.84408 8.20238 8.06029Z" fill="white"></path></svg><span class="widget-icon-text">奖励中心</span></div></div></div><footer><div class="px-3 py-2-5 text-sm flex  items-center justify-between popup-footer"><div class="setting flex flex-row items-center justify-center secondary clickable"><svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 16px; height: 16px;"><path d="M10.3873 2.29199C10.6319 2.29227 10.8664 2.38963 11.0392 2.56268C11.2121 2.73573 11.3092 2.97032 11.3092 3.21491V4.07845L12.1175 4.38366C12.7273 4.61311 13.2952 4.94108 13.7988 5.35449L14.4675 5.90241L15.2165 5.47012L15.2394 5.45658C15.3787 5.37513 15.5373 5.33233 15.6988 5.33262C15.861 5.33283 16.0203 5.37555 16.1608 5.45652C16.3014 5.53748 16.4182 5.65387 16.4998 5.79408L16.8925 6.47428C17.0145 6.68626 17.0475 6.93798 16.9843 7.17425C16.921 7.41052 16.7666 7.61207 16.555 7.7347L16.5321 7.74824L15.7842 8.17949L15.9227 9.03053C16.031 9.67987 16.031 10.3427 15.9227 10.992L15.781 11.8462L16.531 12.2785L16.5467 12.2878C16.758 12.4105 16.9122 12.6118 16.9754 12.8478C17.0387 13.0839 17.0059 13.3353 16.8842 13.5472L16.5154 14.1847C16.3932 14.3964 16.1919 14.551 15.9558 14.6145C15.7196 14.678 15.468 14.6451 15.256 14.5232L15.2415 14.5139L14.4904 14.0805L13.8206 14.6326C13.3125 15.0522 12.7384 15.3849 12.1217 15.617L11.3133 15.9222V16.7868C11.3132 16.9082 11.2891 17.0283 11.2425 17.1404C11.1958 17.2524 11.1276 17.3542 11.0415 17.4398C10.9555 17.5254 10.8535 17.5933 10.7412 17.6394C10.6289 17.6855 10.5087 17.7091 10.3873 17.7087H9.61229C9.3677 17.7084 9.13322 17.611 8.96037 17.438C8.78751 17.2649 8.69042 17.0303 8.69042 16.7857V15.9222L7.88209 15.617C7.27233 15.3875 6.70437 15.0596 6.20084 14.6462L5.53209 14.0982L4.78313 14.5305L4.76021 14.5441C4.62084 14.6255 4.46226 14.6683 4.30084 14.668C4.13864 14.6678 3.97932 14.6251 3.83877 14.5441C3.69823 14.4632 3.58135 14.3468 3.49979 14.2066L3.10709 13.5264C2.98505 13.3144 2.95205 13.0627 3.01532 12.8264C3.07858 12.5901 3.23296 12.3886 3.44459 12.266L3.4675 12.2524L4.21542 11.8212L4.07688 10.9701C3.96856 10.3208 3.96856 9.65799 4.07688 9.00866L4.21854 8.15553L3.46959 7.7222L3.45709 7.70866C3.24914 7.58523 3.09787 7.3852 3.03575 7.1515C2.97362 6.9178 3.00559 6.66905 3.12479 6.45866L3.49354 5.82116C3.57469 5.68082 3.69133 5.5643 3.83175 5.4833C3.97217 5.40231 4.13144 5.35968 4.29354 5.3597C4.45497 5.35942 4.61355 5.40221 4.75292 5.48366L4.7675 5.49199L5.51854 5.92533L6.18834 5.37324C6.69646 4.95362 7.27054 4.62101 7.88729 4.38887L8.69563 4.08366V3.21908C8.69452 2.97466 8.79041 2.73979 8.96226 2.56598C9.13411 2.39218 9.36788 2.29364 9.61229 2.29199H10.3873ZM10.3873 1.04199H9.61229C9.03636 1.04227 8.4841 1.27118 8.07685 1.67842C7.66961 2.08567 7.4407 2.63794 7.44042 3.21387C6.69518 3.49457 6.00146 3.89651 5.38729 4.40345L5.37271 4.39512C4.87362 4.10719 4.2806 4.02927 3.72407 4.17852C3.16753 4.32776 2.69307 4.69193 2.405 5.19095L2.03729 5.83366C1.74928 6.33263 1.67121 6.92555 1.82025 7.48207C1.96929 8.03858 2.33324 8.51313 2.83209 8.80137L2.84771 8.8097C2.78023 9.20478 2.74539 9.60474 2.74354 10.0055C2.74367 10.3974 2.77572 10.7886 2.83938 11.1753L2.81646 11.1889C2.56927 11.3314 2.35259 11.5213 2.1788 11.7476C2.00501 11.9739 1.87752 12.2322 1.80361 12.5078C1.7297 12.7834 1.71083 13.0709 1.74807 13.3538C1.7853 13.6367 1.87792 13.9095 2.02063 14.1566L2.41334 14.8368C2.55638 15.084 2.74681 15.3006 2.97371 15.4741C3.20061 15.6476 3.45953 15.7746 3.73561 15.8479C4.01169 15.9211 4.29952 15.9392 4.58259 15.901C4.86566 15.8628 5.13841 15.7691 5.38521 15.6253L5.40813 15.6118C6.01714 16.1109 6.70362 16.507 7.44042 16.7847C7.44028 17.0701 7.49635 17.3526 7.60542 17.6163C7.7145 17.88 7.87444 18.1196 8.07612 18.3215C8.27779 18.5234 8.51726 18.6835 8.78084 18.7929C9.04441 18.9022 9.32694 18.9585 9.61229 18.9587H10.3873C10.9632 18.9584 11.5155 18.7295 11.9227 18.3222C12.33 17.915 12.5589 17.3627 12.5592 16.7868C13.3043 16.5064 13.9981 16.1048 14.6123 15.5982L14.6269 15.6066C15.126 15.8945 15.719 15.9724 16.2755 15.8232C16.8321 15.6739 17.3065 15.3098 17.5946 14.8107L17.9623 14.1732C18.2503 13.6743 18.3284 13.0813 18.1793 12.5248C18.0303 11.9683 17.6663 11.4938 17.1675 11.2055L17.1519 11.1972C17.2194 10.8021 17.2542 10.4022 17.256 10.0014C17.2559 9.60948 17.2239 9.21826 17.1602 8.83158L17.1831 8.81803C17.4303 8.6755 17.647 8.48565 17.8208 8.25934C17.9946 8.03303 18.1221 7.77469 18.196 7.49908C18.2699 7.22348 18.2888 6.93601 18.2515 6.65311C18.2143 6.37021 18.1217 6.09742 17.979 5.85033L17.5863 5.17012C17.4437 4.92236 17.2537 4.70518 17.027 4.53106C16.8003 4.35693 16.5415 4.22928 16.2654 4.15544C15.9893 4.08159 15.7013 4.063 15.418 4.10074C15.1346 4.13847 14.8616 4.23179 14.6144 4.37533L14.5915 4.38887C13.9824 3.8898 13.296 3.4936 12.5592 3.21595C12.5593 2.9306 12.5032 2.64801 12.3942 2.38433C12.2851 2.12065 12.1252 1.88103 11.9235 1.67916C11.7218 1.47729 11.4823 1.31712 11.2188 1.20779C10.9552 1.09847 10.6726 1.04213 10.3873 1.04199Z" fill="#666666"></path><path d="M9.99984 7.91699C10.4119 7.91699 10.8147 8.03918 11.1573 8.2681C11.4999 8.49702 11.7669 8.82239 11.9246 9.20307C12.0823 9.58375 12.1235 10.0026 12.0431 10.4068C11.9628 10.8109 11.7643 11.1821 11.473 11.4735C11.1816 11.7648 10.8104 11.9632 10.4063 12.0436C10.0021 12.124 9.58326 12.0828 9.20258 11.9251C8.8219 11.7674 8.49653 11.5004 8.26761 11.1578C8.03869 10.8152 7.91651 10.4124 7.91651 10.0003C7.91651 9.44779 8.136 8.91789 8.5267 8.52719C8.9174 8.13649 9.4473 7.91699 9.99984 7.91699ZM9.99984 6.66699C9.34057 6.66699 8.6961 6.86249 8.14794 7.22876C7.59977 7.59503 7.17253 8.11563 6.92024 8.72471C6.66795 9.3338 6.60194 10.004 6.73055 10.6506C6.85917 11.2972 7.17664 11.8912 7.64282 12.3573C8.10899 12.8235 8.70293 13.141 9.34954 13.2696C9.99614 13.3982 10.6664 13.3322 11.2754 13.0799C11.8845 12.8276 12.4051 12.4004 12.7714 11.8522C13.1377 11.3041 13.3332 10.6596 13.3332 10.0003C13.3332 9.11627 12.982 8.26842 12.3569 7.6433C11.7317 7.01818 10.8839 6.66699 9.99984 6.66699Z" fill="#666666"></path></svg><span class="ml-1 text-gray-6">设置</span></div><div class="flex"><span class="immersive-translate-no-select text-sm text-gray-c2" style="cursor: pointer;">1.22.4</span></div><div class="more-container"><select id="more-select" autocomplete="off" class="min-select  text-gray-6 more" style="max-width: 48px;"><option value="DROP_DOWN_DEFAULT_VALUE">更多</option><option value="openInstruction">📙 使用说明</option><option value="changeToOnlyTranslationMode">🔤 临时切换默认译文模式为仅显示译文</option><option value="changeToTranslateTheWholePage">💀 切换为翻译所有区域</option><option value="switchNavEnableTranslate">💪 关闭侧边栏翻译</option><option value="translateToThePageEndImmediately">⚡ 立即翻译到页面底部</option><option value="openEbookViewer">📘 阅读本地电子书</option><option value="openEbookBuilder">📚 制作双语 EPUB 电子书</option><option value="babelDOC">📕 BabelDOC 保留排版 PDF 翻译</option><option value="translateLocalPdfFile">📁 翻译本地 PDF 文件</option><option value="pdfProFile">❇️ AI 驱动的 PDF Pro 翻译</option><option value="translateLocalHtmlFile">🌐 翻译 HTML/txt 文件</option><option value="translateLocalSubtitleFile">📺 翻译本地字幕文件</option><option value="disableFloatBall">⭕ 禁用悬浮球</option><option value="editTranslation">🖌️ 临时开启译文编辑</option><option value="goPro">👑 免费试用 Pro 会员</option><option value="cleanCache">🧹 清除缓存</option><option value="webReport">💬 反馈当前页面翻译问题</option><option value="storeReview">👍 去商店评价</option><option value="about">❤️ 关于 - 反馈</option></select></div></div></footer></div></div></div></div></div></template></div></html>
