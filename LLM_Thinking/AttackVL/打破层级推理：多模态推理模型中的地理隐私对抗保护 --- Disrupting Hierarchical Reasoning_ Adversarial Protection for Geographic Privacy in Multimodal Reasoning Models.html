<!DOCTYPE html>
<!-- saved from url=(0071)https://arxiv.org/html/2512.08503?_immersive_translate_auto_translate=1 -->
<html lang="en" data-theme="dark" imt-state="dual" imt-trans-position="after"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models</title>
<!--Generated on Tue Dec  9 11:24:56 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/arxiv-html-papers-20250916.css" rel="stylesheet" type="text/css">
<script src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/bootstrap.bundle.min.js"></script>
<script src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/html2canvas.min.js"></script>
<script src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/addons_new.js"></script>
<script src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/feedbackOverlay.js"></script>
<!--<base href="/html/2512.08503v1/">--><base href="."><link rel="stylesheet" href="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-toast {
  display: flex;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  right: 0;
  top: 1%;
  width: fit-content;
  padding: 12px 20px;
  margin: auto;
  overflow: auto;
  background: #fef6f9;
  box-shadow: 0px 4px 10px 0px rgba(0, 10, 30, 0.06);
  font-size: 15px;
  border-radius: 8px;
  color: #333;
}

.immersive-translate-toast-content {
  display: flex;
  flex-direction: row;
  align-items: center;
}

.immersive-translate-toast-hidden {
  margin: 0 20px 0 72px;
  text-decoration: underline;
  cursor: pointer;
}

.immersive-translate-toast-close {
  color: #666666;
  font-size: 20px;
  font-weight: bold;
  padding: 0 10px;
  cursor: pointer;
}

@media screen and (max-width: 768px) {
  .immersive-translate-toast {
    top: 0;
    padding: 12px 0px 0 10px;
  }
  .immersive-translate-toast-content {
    flex-direction: column;
    text-align: center;
  }
  .immersive-translate-toast-hidden {
    margin: 10px auto;
  }
}

.immersive-translate-dialog {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  display: flex;
  width: 300px;
  flex-direction: column;
  align-items: center;
  font-size: 15px;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  margin: auto;
  height: fit-content;
  border-radius: 20px;
  background-color: #fff;
}

.immersive-translate-modal {
  display: none;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
  word-break: break-all;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style><style data-id="immersive-translate-default-injected-css">:root {
  --immersive-translate-theme-underline-borderColor: #72ece9;
  --immersive-translate-theme-nativeUnderline-borderColor: #72ece9;
  --immersive-translate-theme-nativeDashed-borderColor: #72ece9;
  --immersive-translate-theme-nativeDotted-borderColor: #72ece9;
  --immersive-translate-theme-highlight-backgroundColor: #ffff00;
  --immersive-translate-theme-dashed-borderColor: #59c1bd;
  --immersive-translate-theme-blockquote-borderColor: #cc3355;
  --immersive-translate-theme-thinDashed-borderColor: #ff374f;
  --immersive-translate-theme-dashedBorder-borderColor: #94a3b8;
  --immersive-translate-theme-dashedBorder-borderRadius: 0;
  --immersive-translate-theme-solidBorder-borderColor: #94a3b8;
  --immersive-translate-theme-solidBorder-borderRadius: 0;
  --immersive-translate-theme-dotted-borderColor: #94a3b8;
  --immersive-translate-theme-wavy-borderColor: #72ece9;
  --immersive-translate-theme-dividingLine-borderColor: #94a3b8;
  --immersive-translate-theme-grey-textColor: #2f4f4f;
  --immersive-translate-theme-marker-backgroundColor: #fbda41;
  --immersive-translate-theme-marker-backgroundColor-rgb: 251, 218, 65;
  --immersive-translate-theme-marker2-backgroundColor: #ffff00;
  --immersive-translate-theme-background-backgroundColor: #dbafaf;
  --immersive-translate-theme-background-backgroundColor-rgb: 219, 175, 175;
  --immersive-translate-theme-background-backgroundOpacity: 12;
  --immersive-translate-theme-opacity-opacity: 10;
}

[imt-state="dual"] .immersive-translate-target-translation-pre-whitespace {
  white-space: pre-wrap !important;
}

[imt-state="dual"] .immersive-translate-pdf-target-container {
  position: absolute;
  background-color: #fff;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica,
    sans-serif;
  top: 0;
  width: 600px;
  height: 100%;
  z-index: 2;
  line-height: 1.3;
  font-size: 16px;
}
[imt-state="dual"] .immersive-translate-target-wrapper[dir="rtl"] {
  text-align: right;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper {
  color: rgb(0, 0, 0);
  white-space: normal;
  position: absolute;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper
  font {
  color: inherit;
  white-space: inherit;
  position: unset;
}

[imt-state="translation"] .immersive-translate-target-wrapper > br {
  display: none;
}

[imt-state="translation"]
  .immersive-translate-target-translation-block-wrapper {
  margin: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-block-wrapper {
  margin: 8px 0 !important;
  display: inline-block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  display: block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  margin-top: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-pdf-block-wrapper {
  margin: 0 !important;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-grey-inner {
  color: var(--immersive-translate-theme-grey-textColor);
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-underline-inner {
  border-bottom: 1px solid
    var(--immersive-translate-theme-underline-borderColor) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeUnderline-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeUnderline-borderColor
  ) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDashed-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDashed-borderColor
  ) !important;
  text-decoration-style: dashed !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-thinDashed-inner {
  border-bottom: 1px dashed
    var(--immersive-translate-theme-thinDashed-borderColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dotted-inner {
  background-image: linear-gradient(
    to right,
    var(--immersive-translate-theme-dotted-borderColor) 30%,
    rgba(255, 255, 255, 0) 0%
  );
  background-position: bottom;
  background-size: 5px 1px;
  background-repeat: repeat-x;
  padding-bottom: 3px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDotted-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDotted-borderColor
  ) !important;
  text-decoration-style: dotted !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-wavy-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-wavy-borderColor
  ) !important;
  text-decoration-style: wavy !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dashed-inner {
  background: linear-gradient(
      to right,
      var(--immersive-translate-theme-dashed-borderColor) 0%,
      var(--immersive-translate-theme-dashed-borderColor) 50%,
      transparent 50%,
      transparent 100%
    )
    repeat-x left bottom;
  background-size: 8px 2px;
  padding-bottom: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {
  content: "";
  display: block;
  max-width: 80px;
  width: 10%;
  border-top: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  padding-top: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dividingLine::before {
  content: "";
  border-left: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  max-height: 16px;
  height: 16px;
  padding-left: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-highlight-inner {
  background: var(--immersive-translate-theme-highlight-backgroundColor);
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-marker {
  line-height: 1.5em;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker2-inner {
  font-weight: bold;
  text-shadow: 10px 0px 3px
      var(--immersive-translate-theme-marker2-backgroundColor),
    16px 3px 9px var(--immersive-translate-theme-marker2-backgroundColor),
    2px 0px 6px var(--immersive-translate-theme-marker2-backgroundColor),
    -12px 0px 12px var(--immersive-translate-theme-marker2-backgroundColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker-inner {
  /* TODO: add more texture */
  background: linear-gradient(
    to right,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.1),
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 3%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 35%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 70%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.8) 95%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.3)
  );
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-weakening {
  opacity: 0.618 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-italic {
  font-style: italic !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-bold {
  font-weight: bold !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-paper {
  margin: 8px 0;
  box-shadow: rgba(0, 0, 0, 0.24) 0px 3px 8px;
  padding: 16px 32px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-blockquote {
  border-left: 4px solid var(--immersive-translate-theme-blockquote-borderColor) !important;
  padding-left: 12px !important;
  margin-top: 4px;
  margin-bottom: 4px;
  padding-top: 4px;
  padding-bottom: 4px;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-mask-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-mask-inner {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

/* opacity theme start */

[imt-state="dual"] .immersive-translate-target-translation-theme-opacity-inner {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-opacity-inner {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner,
[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: none !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-mask-inner:hover {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

/* opacity theme end */

/* background theme start */
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-background {
  margin: 8px 0;
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  border-radius: 4px;
  box-shadow: unset !important;
  padding: 12px;
  display: inline-block;
}
[imt-state="dual"]
  .immersive-translate-target-translation-theme-background-inner {
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  padding-left: 6px;
  padding-right: 6px;
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper
  .immersive-translate-target-translation-theme-background-inner {
  background: unset;
  padding-left: unset;
  padding-right: unset;
}
/* background theme end */

/* vertical css , please remain it in the last one. */
.immersive-translate-target-translation-vertical-block-wrapper {
  margin: 0px 8px !important;
}

.immersive-translate-text {
  font-size: 15px !important;
}

.immersive-translate-error-toast {
  position: fixed;
  top: 5%;
  z-index: 99999999;
  left: 0;
  right: 0;
  margin: auto;
  max-width: 300px;
  padding: 16px;
  border-radius: 12px;
  background-color: rgba(0, 0, 0, 0.8);
  display: flex;
  flex-direction: row;
  justify-content: space-between;
}

@media all and (min-width: 750px) {
  .immersive-translate-error-toast {
    max-width: 400px;
  }
}

.immersive-translate-clickable-button {
  cursor: pointer;
}

.immersive-translate-help-button {
  cursor: pointer;
}

.immersive-translate-loading-text:before {
  content: "...";
}

/* dark mode for loading */

@media only screen and (prefers-color-scheme: dark) {
  .immersive-translate-loading {
    border: 2px rgba(255, 255, 255, 0.25) solid !important;
    border-top: 2px rgba(255, 255, 255, 1) solid !important;
  }
}

.immersive-translate-error-wrapper {
  position: relative;
  display: inline-flex;
  padding: 6px;
  margin: 0 12px;
  white-space: nowrap;
  font-size: 0.9em;
}
[lang="zh-CN"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}
[lang="zh-TW"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}

.immersive-translate-tooltip {
  position: relative;
  display: inline-flex;
  /* little indicater to indicate it's hoverable */
}

.immersive-translate-tooltip-content {
  /* here's the magic */
  position: absolute;
  z-index: 100000000000;

  left: 50%;
  bottom: 0;
  transform: translate(-50%, 110%);
  line-height: 1;
  /* and add a small left margin */

  /* basic styles */
  width: max-content;
  max-width: 250px;
  word-wrap: break-word;
  white-space: pre-line;
  padding: 10px;
  border-radius: 10px;
  background: #000c;
  color: #fff;
  text-align: center;
  font-size: 14px;
  display: none;
  /* hide by default */
}

.immersive-translate-tooltip:hover .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip:hover + .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip-content-table {
  left: unset !important;
  bottom: unset !important;
  transform: translate(-10%, 50%) !important;
}

.immersive-translate-tooltip:hover:before {
  display: inline-block;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5);
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--bg-2, #fff);
  font-size: 14px;
}
</style><style data-id="immersive-translate-user-custom-style">:root {

.immersive-translate-target-inner { font-family: inherit; }


.immersive-translate-target-inner { font-family: inherit; }
}
</style><style data-id="immersive-translate-dynamic-injected-css">.immersive-translate-target-wrapper[dir='rtl'] {text-align: right;display:block!important;}
[dir='rtl'] .immersive-translate-target-wrapper:not([dir]) {text-align:left;direction:ltr;}
.immersive-translate-target-wrapper {word-break:break-word; user-select:text;}
[imt-state=dual] .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {display:block;}
[imt-trans-position=before] .immersive-translate-target-translation-block-wrapper {display:block!important;}
</style></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2512.08503?_immersive_translate_auto_translate=1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2512.08503v1/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2512.08503v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2512.08503v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2512.08503?_immersive_translate_auto_translate=1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S1" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S2" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S2.SS0.SSS0.Px1" title="In 2 Related Work ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Geographic Inference in Vision-Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S2.SS0.SSS0.Px2" title="In 2 Related Work ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Adversarial Perturbation for Privacy Protection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S2.SS0.SSS0.Px3" title="In 2 Related Work ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Multi-modal Adversarial Attacks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S3" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Dataset Construction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S3.SS1" title="In 3 Dataset Construction ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Motivation and Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S3.SS2" title="In 3 Dataset Construction ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Data Construction and Annotation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S3.SS3" title="In 3 Dataset Construction ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Dataset Characteristics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.SS1" title="In 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Preliminary</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.SS1.SSS0.Px1" title="In 4.1 Preliminary ‣ 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Threat Model</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.SS2" title="In 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Theoretical Motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.SS3" title="In 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>ReasonBreak</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.SS3.SSS0.Px1" title="In 4.3 ReasonBreak ‣ 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Framework Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.SS3.SSS0.Px2" title="In 4.3 ReasonBreak ‣ 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Adaptive Image Decomposition and Concept Assignment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.SS3.SSS0.Px3" title="In 4.3 ReasonBreak ‣ 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Minimax Target Selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.SS3.SSS0.Px4" title="In 4.3 ReasonBreak ‣ 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Ensemble Training and Reconstruction</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.SS1" title="In 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Evaluation Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.SS2" title="In 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Main Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.SS3" title="In 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Adversarial Scaling Properties</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.SS4" title="In 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Ablation Study</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.SS4.SSS0.Px1" title="In 5.4 Ablation Study ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Influence of Adaptive Decomposition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.SS4.SSS0.Px2" title="In 5.4 Ablation Study ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title">Influence of Minimax Target Selection</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.SS5" title="In 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Limitations and Failure Case Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S6" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A1" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Decoder Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Dataset Construction Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2.SS1" title="In Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Three-Stage Annotation Pipeline</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2.SS1.SSS1" title="In B.1 Three-Stage Annotation Pipeline ‣ Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1.1 </span>Stage 1: Geographic Content Filtering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2.SS1.SSS2" title="In B.1 Three-Stage Annotation Pipeline ‣ Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1.2 </span>Stage 2: Hierarchical Scene Annotation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2.SS1.SSS3" title="In B.1 Three-Stage Annotation Pipeline ‣ Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1.3 </span>Stage 3: Geographic Reasoning Chain Extraction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2.SS2" title="In Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Data Collection and Source Integration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2.SS3" title="In Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Inference Difficulty Assessment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A3" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Counter-intuitive Scaling Phenomena in Reasoning Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A4" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Visual Quality Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A5" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Qualitative Examples of GeoPrivacy-6K</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A6" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Computational Efficiency Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A7" title="In Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Robustness to JPEG Compression</span></a></li>
</ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert" onclick="closePopup()">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: arydshln.sty</li><li>failed: tabularray.sty</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: arXiv.org perpetual non-exclusive license<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">许可证：arXiv.org 永久非排他性许可</font></font></font></a><div id="watermark-tr" data-imt_insert_failed="1">arXiv:2512.08503v1 [cs.CV] 09 Dec 2025</div></div>
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<p class="ltx_p">﻿</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<h1 class="ltx_title ltx_title_document">Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">打破层级推理：多模态推理模型中的地理隐私对抗保护</font></font></font></h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jiaming Zhang<sup class="ltx_sup">1</sup>, Che Wang<sup class="ltx_sup">1,2</sup>, Yang Cao<sup class="ltx_sup">3</sup>, Longtao Huang<sup class="ltx_sup">4</sup>, Wei Yang Bryan Lim<sup class="ltx_sup">1</sup>
<br class="ltx_break"><sup class="ltx_sup">1</sup>Nanyang Technological University 
<br class="ltx_break"><sup class="ltx_sup">2</sup>Peking University 
<br class="ltx_break"><sup class="ltx_sup">3</sup>Institute of Science Tokyo 
<br class="ltx_break"><sup class="ltx_sup">4</sup>Alibaba Group
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">摘要</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p">Multi-modal large reasoning models (MLRMs) pose significant privacy risks by inferring precise geographic locations from personal images through hierarchical chain-of-thought reasoning. Existing privacy protection techniques, primarily designed for perception-based models, prove ineffective against MLRMs’ sophisticated multi-step reasoning processes that analyze environmental cues. We introduce <span class="ltx_text ltx_font_bold">ReasonBreak</span>, a novel adversarial framework specifically designed to disrupt hierarchical reasoning in MLRMs through concept-aware perturbations. Our approach is founded on the key insight that effective disruption of geographic reasoning requires perturbations aligned with conceptual hierarchies rather than uniform noise. ReasonBreak strategically targets critical conceptual dependencies within reasoning chains, generating perturbations that invalidate specific inference steps and cascade through subsequent reasoning stages. To facilitate this approach, we contribute <span class="ltx_text ltx_font_bold">GeoPrivacy-6K</span>, a comprehensive dataset comprising 6,341 ultra-high-resolution images (<math alttext="\geq" class="ltx_Math" display="inline" id="m1" intent=":literal"><semantics><mo>≥</mo><annotation encoding="application/x-tex">\geq</annotation></semantics></math>2K) with hierarchical concept annotations. Extensive evaluation across seven state-of-the-art MLRMs (including GPT-o3, GPT-5, Gemini 2.5 Pro) demonstrates ReasonBreak’s superior effectiveness, achieving a 14.4% improvement in tract-level protection (33.8% vs 19.4%) and nearly doubling block-level protection (33.5% vs 16.8%). This work establishes a new paradigm for privacy protection against reasoning-based threats. Code is available at the <a class="ltx_ref ltx_href ltx_font_bold" href="https://jiamingzhang94.github.io/reasonbreak/" title="">project page</a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多模态大型推理模型（MLRMs）通过分层思维链推理，从个人图像中推断精确的地理位置，从而带来严重的隐私风险。现有的隐私保护技术主要针对基于感知的模型设计，在 MLRMs 复杂的多步推理过程中被证明无效，这些推理过程会分析环境线索。我们引入 ReasonBreak，这是一个新颖的对抗性框架，专门设计用于通过概念感知扰动来破坏 MLRMs 中的分层推理。我们的方法基于一个关键洞察：有效破坏地理推理需要与概念层次结构一致的扰动，而不是均匀的噪声。ReasonBreak 策略性地针对推理链中的关键概念依赖关系，生成能够使特定推理步骤失效并级联到后续推理阶段的扰动。为了促进这种方法，我们贡献了 GeoPrivacy-6K，这是一个包含 6,341 张超高清图像（ <math intent=":literal" id="m1" display="inline" class="ltx_Math" alttext="\geq"><semantics><mo>≥</mo><annotation encoding="application/x-tex">\geq</annotation></semantics></math> 2K）的全面数据集，具有分层概念标注。在七个最先进的 MLRMs（包括 GPT-o3、GPT-5、Gemini 2.）上进行了广泛的评估。5 Pro)展示了 ReasonBreak 的优越效果，在地块级保护上提升了 14.4%（33.8% vs 19.4%），在街区级保护上几乎翻了一番（33.5% vs 16.8%）。这项工作为针对推理式威胁的隐私保护建立了一种新范式。代码可在项目页面获取。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1 引言</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p">Multi-modal large reasoning models (MLRMs) have demonstrated remarkable capabilities in inferring precise geographic locations from personal images. State-of-the-art systems like GPT-o3&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">jaech2024openai</span>)</cite> and Gemini 2.5 Pro&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">team2024gemini</span>)</cite> can pinpoint locations from seemingly innocuous photos by executing a chain-of-thought (CoT)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">wei2022chain</span>)</cite>. These models systematically analyze environmental cues, architectural styles, and fine-grained details in a hierarchical manner, achieving location inference accuracy 21<math alttext="\times" class="ltx_Math" display="inline" id="S1.p1.m1" intent=":literal"><semantics><mo>×</mo><annotation encoding="application/x-tex">\times</annotation></semantics></math> superior to non-expert humans&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">luo2025doxing</span>)</cite>. This capability transforms routine social media sharing into a significant privacy risk, as personal images unwittingly reveal detailed geographic information that MLRMs can extract without user awareness. This development has profound legal implications, as unauthorized location inference is classified as a serious privacy violation under regulations such as the <em class="ltx_emph ltx_font_italic">EU’s General Data Protection Regulation (GDPR)</em>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">regulation2016regulation</span>)</cite> and the <em class="ltx_emph ltx_font_italic">California Consumer Privacy Act (CCPA)</em>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">legislature2018california</span>)</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多模态大型推理模型（MLRMs）在从个人图像中推断精确地理位置方面展现出卓越的能力。像 GPT-o3（jaech2024openai）和 Gemini 2.5 Pro（team2024gemini）这样的最先进系统可以通过执行思维链（CoT）（wei2022chain）从看似无害的照片中精确定位地点。这些模型以分层方式系统地分析环境线索、建筑风格和细粒度细节，实现的位置推断准确率比非专业人士高出 21%。这种能力将日常社交媒体分享转变为重大隐私风险，因为个人图像无意中透露了 MLRMs 可以提取的详细地理信息，而用户对此毫无察觉。这一发展具有深远的法律影响，因为未经授权的位置推断被归类为严重侵犯隐私，根据欧盟通用数据保护条例（GDPR）（regulation2016regulation）和加州消费者隐私法案（CCPA）（legislature2018california）等法规，属于严重隐私违规行为。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="243" id="S1.F1.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x1.png" width="760">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Geographic inference vulnerability in MLRMs. Given a personal image, MLRMs employ hierarchical reasoning to progressively narrow location estimates from continental to street-level precision. Our objective is to disrupt this process by generating concept-aware adversarial perturbations targeting specific reasoning stages.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 1：多模态推理模型中的地理推理漏洞。给定一张个人图像，MLRMs 采用分层推理方式，逐步将位置估计从大陆级精度缩小到街道级精度。我们的目标是通过生成针对特定推理阶段的、具有概念感知能力的对抗性扰动来破坏这一过程。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p">Privacy threats from MLRMs have emerged at an alarming rate, yet effective countermeasures remain relatively limited. The DoxBench&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">luo2025doxing</span>)</cite> study revealed that MLRMs fail to distinguish between benign and malicious queries, readily complying with potentially harmful requests for location inference. While previous privacy defenses, particularly adversarial perturbations&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">szegedy2013intriguing</span>)</cite>, have proven effective against conventional perception models like facial recognition systems&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020adversarial</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">shamshad2023clip2protect</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2022opom</span>)</cite>, they fall short against MLRMs’ sophisticated reasoning capabilities. Unlike conventional vision tasks that directly map images to labels, geographic inference in ultra-high-resolution images involves sophisticated multi-step reasoning. An MLRM typically identifies a continent from flora, narrows to a country through architectural patterns, and pinpoints specific neighborhoods from subtle environmental cues like background signage. Each inference builds upon previous deductions in a cascading chain of geographic reasoning. Existing adversarial privacy-preserving methods, which rely on uniform perturbations and focus on salient foreground regions, fail to disrupt this hierarchical analysis, leaving a critical gap in privacy protection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">来自多模态推理模型（MLRMs）的隐私威胁正以惊人的速度出现，但有效的反制措施仍然相对有限。DoxBench（luo2025doxing）研究显示，MLRMs 无法区分良性查询和恶意查询，轻易地响应可能有害的位置推断请求。虽然之前的隐私防御措施，特别是对抗性扰动（szegedy2013intriguing），已被证明对传统感知模型（如人脸识别系统）有效（zhang2020adversarial; shamshad2023clip2protect; zhong2022opom），但它们在应对 MLRMs 复杂的推理能力时显得力不从心。不同于传统视觉任务直接将图像映射到标签，超高分辨率图像中的地理推断涉及复杂的、多步骤的推理。MLRM 通常会先从植物识别大陆，再通过建筑模式缩小到国家，最后从背景标志等微妙的环境线索中精确定位具体社区。每一次推断都建立在先前推理的级联链上。 现有的对抗性隐私保护方法，依赖于均匀扰动并专注于显著的前景区域，无法破坏这种层次分析，导致隐私保护存在关键漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p">We present <span class="ltx_text ltx_font_bold">ReasonBreak</span>, an adversarial framework specifically designed to disrupt hierarchical reasoning processes in MLRMs. Our key insight is that effective disruption of geographic reasoning requires perturbations aligned with the conceptual hierarchy. ReasonBreak targets critical conceptual dependencies within geographic reasoning chains, generates perturbations that invalidate specific inference steps, and ensures these disruptions cascade through subsequent reasoning stages.
Our approach is enabled by a new dataset we developed for this task. To enable concept-aware adversarial generation, we release <span class="ltx_text ltx_font_bold">GeoPrivacy-6K</span>, a collection of 6,341 high-resolution (<math alttext="\geq" class="ltx_Math" display="inline" id="S1.p3.m1" intent=":literal"><semantics><mo>≥</mo><annotation encoding="application/x-tex">\geq</annotation></semantics></math>2K) images rich with geographic cues, sourced from established vision datasets. Each image is annotated using a structured, three-level framework that extracts hierarchical visual concepts, which are spatially localized with bounding boxes. The ReasonBreak framework uses this data to learn a generator that crafts perturbations targeted at specific geographic concepts.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们提出了 ReasonBreak，这是一个专门设计用于破坏多模态推理模型（MLRM）中层级推理过程的对抗性框架。我们的关键洞察是，有效的地理推理破坏需要与概念层级相一致的扰动。ReasonBreak 针对地理推理链中的关键概念依赖关系，生成使特定推理步骤失效的扰动，并确保这些破坏在后续推理阶段中蔓延。我们的方法得益于我们为这项任务开发的新数据集。为了实现概念感知的对抗性生成，我们发布了 GeoPrivacy-6K，这是一个包含 6,341 张高分辨率（ <math intent=":literal" id="S1.p3.m1" display="inline" class="ltx_Math" alttext="\geq"><semantics><mo>≥</mo><annotation encoding="application/x-tex">\geq</annotation></semantics></math> 2K）且富含地理线索的图像集合，这些图像源自成熟的视觉数据集。每张图像都使用一个结构化的三级框架进行标注，该框架提取层级视觉概念，并通过边界框在空间上定位这些概念。ReasonBreak 框架使用这些数据来学习一个生成器，该生成器能够针对特定的地理概念制作扰动。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p">Extensive evaluation across seven state-of-the-art MLRMs, including industry leaders like GPT-o3, GPT-5, and Gemini 2.5 Pro, demonstrates ReasonBreak’s superior effectiveness. On critical privacy metrics, ReasonBreak attains a tract-level Top-1 protection of 33.8% (vs. 19.4% for the strongest baseline) and raises block-level protection to 33.5% (vs. 16.8%), nearly doubling prior methods. These results establish ReasonBreak as the current state-of-the-art in defending against reasoning-based privacy threats. Our primary contributions are threefold:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在七种最先进的 MLRM（多模态推理模型）上的广泛评估，包括 GPT-o3、GPT-5 和 Gemini 2.5 Pro 等行业领导者，证明了 ReasonBreak 的卓越有效性。在关键隐私指标上，ReasonBreak 实现了 33.8%的轨迹级 Top-1 保护（对比最强基线的 19.4%），并将区块级保护提升至 33.5%（对比 16.8%），几乎将先前方法翻倍。这些结果确立了 ReasonBreak 在防御推理型隐私威胁方面的当前最先进水平。我们的主要贡献有三点：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p">We present <span class="ltx_text ltx_font_bold">ReasonBreak</span>, a novel adversarial framework that disrupts MLRMs’ hierarchical geographic reasoning by targeting critical visual concepts within their chain-of-thought processes.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 我们提出了 ReasonBreak，一个新颖的对抗性框架，通过针对其思维链过程中的关键视觉概念来破坏 MLRM 的层次地理推理。</font></font></font>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p">We contribute <span class="ltx_text ltx_font_bold">GeoPrivacy-6K</span>, a comprehensive dataset of 6,341 ultra-high-resolution images with detailed hierarchical concept annotations, specifically designed for reasoning-aware privacy defense research.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 我们贡献了 GeoPrivacy-6K，一个包含 6,341 张超高分辨率图像的全面数据集，具有详细的层次概念标注，专门为推理感知隐私防御研究设计。</font></font></font>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
<p class="ltx_p">We provide comprehensive empirical validation across seven leading MLRMs, demonstrating that ReasonBreak sets a new state-of-the-art in privacy protection.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">• 我们在七个领先的 MLRM 上提供了全面的实证验证，证明 ReasonBreak 在隐私保护方面设立了新的最先进水平。</font></font></font>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2 相关工作</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Geographic Inference in Vision-Language Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">视觉-语言模型中的地理推理</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p">The evolution from vision-language models (VLMs) to multi-modal large reasoning models (MLRMs) represents a fundamental advancement in visual understanding capabilities. While early VLMs like CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">radford2021learning</span>)</cite> established basic image-text alignment through contrastive learning, they lacked sophisticated reasoning abilities. Multi-modal large language models (MLLMs) built upon this foundation by integrating visual encoders with language models&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">bai2025qwen2</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2024expanding</span>)</cite>, enabling richer scene understanding and natural language generation. MLRMs mark a significant leap forward through their incorporation of CoT reasoning, allowing systematic visual analysis via hierarchical decomposition. State-of-the-art models like GPT-o3&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">jaech2024openai</span>)</cite> and Gemini 2.5 Pro&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">team2024gemini</span>)</cite> leverage this capability to analyze environmental characteristics, architectural patterns, and contextual details for precise geographic inference. This advancement enables location inference that exceeds human performance&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">luo2025doxing</span>)</cite>, creating novel and underexplored privacy vulnerabilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">从视觉-语言模型（VLMs）到多模态大型推理模型（MLRMs）的发展代表了视觉理解能力的根本性进步。早期的 VLMs 如 CLIP (radford2021learning)通过对比学习建立了基本的图像-文本对齐，但缺乏复杂的推理能力。多模态大型语言模型（MLLMs）在此基础上通过将视觉编码器与语言模型集成（bai2025qwen2; chen2024expanding），实现了更丰富的场景理解和自然语言生成。MLRMs 通过整合 CoT 推理，实现了通过层次分解进行系统化视觉分析的显著进步。像 GPT-o3 (jaech2024openai)和 Gemini 2.5 Pro (team2024gemini)这类最先进模型利用这一能力分析环境特征、建筑模式和上下文细节，从而进行精确的地理推理。这一进步使得位置推理超越了人类水平（luo2025doxing），创造了新的、尚未充分探索的隐私漏洞。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Adversarial Perturbation for Privacy Protection<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对抗扰动用于隐私保护</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p">Privacy-preserving adversarial perturbations have emerged as a key defense against unauthorized inference from personal images. While existing approaches focus on generating imperceptible noise to prevent identity recognition, they primarily target perception-based models that rely on direct image-to-label mapping&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020adversarial</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2022opom</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">shamshad2023clip2protect</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2024once</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2025advcloak</span>)</cite>. They employ global perturbations that modify visually salient features without considering the multi-step reasoning processes or the fine-grained background details exploited by MLRMs for geographic inference, rendering them inadequate for this new threat.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">隐私保护对抗扰动已成为防御未经授权从个人图像中推断的关键防御手段。现有方法主要集中于生成难以察觉的噪声以防止身份识别，但它们主要针对依赖直接图像到标签映射的感知模型（zhang2020adversarial; zhong2022opom; shamshad2023clip2protect; yang2024once; liu2025advcloak）。这些方法采用全局扰动，修改视觉显著特征，但未考虑多模态推理模型进行地理推断时利用的多步推理过程或细粒度的背景细节，因此难以应对这一新威胁。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Multi-modal Adversarial Attacks<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多模态对抗攻击</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p">While transferable jailbreaks designed to bypass safety guardrails remain challenging&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2024white</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">niu2024jailbreaking</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">schaeffer2024failures</span>)</cite>, adversarial attacks targeting visual perception generally exhibit better transferability. This landscape has evolved alongside model capabilities, progressing from traditional unimodal approaches&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2018boosting</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2021enhancing</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2021admix</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2023linnesterov</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">wei2023enhancing</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2024boosting</span>)</cite>. Initial efforts focused on basic VLMs like CLIP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">radford2021learning</span>)</cite>, aiming to disrupt image-text alignment in joint embedding spaces&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2022towards</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">lu2023set</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2023advclip</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2024vlattack</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2024highly</span>; <span class="ltx_ref ltx_missing_citation ltx_ref_self">luo2024an</span>)</cite>. Recent work has shifted toward attacking MLLMs, primarily through transfer-based approaches. Notable works include AttackVLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2024evaluating</span>)</cite>, AdvDiffVLM&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2024efficient</span>)</cite>, AnyAttack&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2025anyattack</span>)</cite>, and M-Attack&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2025frustratingly</span>)</cite>, which achieves high transferability by focusing perturbations on semantically rich regions. However, current methods fall short in addressing the hierarchical reasoning processes enabling sophisticated location inference or handling the fine-grained visual details in ultra-high-resolution images that MLRMs exploit. This gap leaves the critical privacy vulnerability of geographic reasoning largely unaddressed, highlighting the need for specialized defense mechanisms designed to disrupt concept-aware reasoning pathways rather than general perception capabilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管旨在绕过安全防护栏的可迁移越狱攻击仍然具有挑战性（wang2024white; niu2024jailbreaking; schaeffer2024failures），针对视觉感知的对抗攻击通常表现出更好的可迁移性。这一格局随着模型能力的提升而发展，从传统的单模态方法（dong2018boosting; wang2021enhancing; wang2021admix; lin2023linnesterov; wei2023enhancing; liu2024boosting）逐步演进。最初的尝试集中在基础视觉语言模型（如 CLIP）(radford2021learning)，旨在破坏联合嵌入空间中的图像-文本对齐（zhang2022towards; lu2023set; zhou2023advclip; yin2024vlattack; xu2024highly; luo2024an）。近期的研究转向攻击多模态语言模型，主要通过基于迁移的方法。值得注意的工作包括 AttackVLM (zhao2024evaluating)、AdvDiffVLM (guo2024efficient)、AnyAttack (zhang2025anyattack)和 M-Attack (li2025frustratingly)，它们通过将扰动集中在语义丰富的区域来实现高可迁移性。然而，当前方法在处理支持复杂位置推断或处理 MLRM 利用的超高分辨率图像中的细粒度视觉细节所涉及的分层推理过程方面仍存在不足。 这个差距使得地理推理的关键隐私漏洞在很大程度上未被解决，突显了需要专门防御机制的需求，这些机制旨在破坏概念感知的推理路径，而不是一般感知能力。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset Construction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3 数据集构建</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Motivation and Design<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1 动机与设计</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p">Developing effective adversarial protection against MLRM geographic inference requires training data that captures the fine-grained visual details and rich geographic cues these models exploit. We identify three critical requirements: <span class="ltx_text ltx_font_bold">(i) ultra-high-resolution</span> images that preserve details like signage and architectural features enabling precise location inference, <span class="ltx_text ltx_font_bold">(ii) comprehensive coverage</span> spanning urban centers to natural landscapes, and <span class="ltx_text ltx_font_bold">(iii) visual annotations</span> that link elements to their geographic significance across multiple scales. To address challenges, we introduce <span class="ltx_text ltx_font_bold">GeoPrivacy-6K</span>, a specialized dataset that combines ultra-high-resolution images with comprehensive geographic concept annotations. It prioritizes images containing distinctive visual cues that MLRMs utilize for location inference, such as architecture and environmental features.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">开发针对多模态推理模型（MLRM）地理推理的有效对抗性保护需要能够捕捉这些模型利用的细粒度视觉细节和丰富的地理线索的训练数据。我们确定了三个关键要求：（i）能够保留标志物和建筑特征等细节的超高分辨率图像，以实现精确的位置推理；（ii）涵盖城市中心到自然景观的全面覆盖范围；（iii）跨多尺度将元素与其地理意义相链接的视觉标注。为应对挑战，我们引入了 GeoPrivacy-6K，这是一个结合超高分辨率图像和全面地理概念标注的专业数据集。它优先选择包含 MLRM 用于位置推理的独特视觉线索的图像，例如建筑和环境特征。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data Construction and Annotation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2 数据构建与标注</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p">We source ultra-high-resolution images from three established computer vision datasets: HoliCity&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020holicity</span>)</cite> (urban environments with rich architectural detail), Aesthetic-4K&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2025diffusion</span>)</cite> (diverse high-quality scenes), and LHQ&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">skorokhodov2021aligning</span>)</cite> (natural landscapes with geographic variety), which collectively provide diverse geographic images spanning urban environments, natural landscapes, and architectural scenes. Our collection process applies two critical filtering criteria: <span class="ltx_text ltx_font_bold">(i) Resolution threshold:</span> Images must maintain a minimum resolution of 2048 pixels to preserve fine-grained geographic details that MLRMs typically exploit for location inference. <span class="ltx_text ltx_font_bold">(ii) Geographic content verification:</span> Images must contain visually identifiable geographic features, including natural landmarks, architectural elements, or environmental characteristics that enable location reasoning. This filtering yields a final collection of 6,341 ultra-high-resolution images that exhibit clear geographic visual cues. Each image undergoes the systematic annotation pipeline detailed in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2" title="Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">B</span></a>. Our dataset construction prioritizes conceptual-level annotations (e.g., “deciduous broadleaf forest”, “Gothic architecture”) rather than <span class="ltx_text ltx_font_italic">precise geographic coordinates</span>, which significantly reduces annotation subjectivity and improves consistency. This design choice is critical for our concept-aware approach, since we target visual concepts that enable reasoning rather than ground-truth locations, making the annotations more reliable and transferable across different geographic regions.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们从三个成熟的计算机视觉数据集中获取超高清图像：HoliCity（zhou2020holicity）（具有丰富建筑细节的城市环境）、Aesthetic-4K（zhang2025diffusion）（多样化的高质量场景）和 LHQ（skorokhodov2021aligning）（具有地理多样性的自然风光），这些数据集共同提供了涵盖城市环境、自然风光和建筑场景的多样化地理图像。我们的收集过程应用了两个关键筛选标准：(i) 分辨率阈值：图像必须保持至少 2048 像素的分辨率，以保留 MLRMs 通常用于位置推断的细粒度地理细节。(ii) 地理内容验证：图像必须包含视觉上可识别的地理特征，包括自然地标、建筑元素或环境特征，这些特征能够支持位置推理。这一筛选过程最终得到 6,341 张具有清晰地理视觉线索的超高清图像。每张图像都经过附录 B 中详细描述的系统化标注流程。 我们的数据集构建优先考虑概念层面的标注（例如，“落叶阔叶林”、“哥特式建筑”），而不是精确的地理坐标，这显著减少了标注的主观性并提高了一致性。这一设计选择对于我们的概念感知方法至关重要，因为我们针对的是能够支持推理的视觉概念，而不是真实地理位置，使得标注更加可靠，并且能够跨不同地理区域进行迁移。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Dataset Characteristics<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.3 数据集特征</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">GeoPrivacy-6K</span> exhibits balanced diversity across geographic scene types and inference difficulty levels. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S3.F2" title="Figure 2 ‣ 3.3 Dataset Characteristics ‣ 3 Dataset Construction ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">2</span></a> presents the dataset composition: natural landscapes comprise the largest category (2,824 images, 44.5%), followed by mixed scenes (1,984 images, 31.3%) and urban architecture (1,533 images, 24.2%). The dataset diverse composition is revealed through its difficulty (the model confidence when inferring visual cues) distribution. 53.2% of images classified as hard inference cases, 29.1% as medium difficulty, and 17.8% as easy cases, reflecting the sophisticated reasoning required for accurate geographic inference. The dataset encompasses a rich vocabulary of geographic concepts, ensuring comprehensive coverage of the visual reasoning pathways used by MLRMs. Additional details are provided in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2" title="Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">B</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">GeoPrivacy-6K 在地理场景类型和推理难度级别上表现出平衡的多样性。图 2 展示了数据集的构成：自然景观是最大类别（2,824 张图像，44.5%），其次是混合场景（1,984 张图像，31.3%）和城市建筑（1,533 张图像，24.2%）。数据集的多样性通过其难度（模型在推断视觉线索时的置信度）分布得以体现。53.2%的图像被归类为困难推理案例，29.1%为中等难度，17.8%为简单案例，这反映了准确地理推理所需的复杂推理能力。数据集涵盖了丰富的地理概念词汇，确保了机器多模态推理模型（MLRM）使用的视觉推理路径得到全面覆盖。更多细节请参见附录 B。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="140" id="S3.F2.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/fig2_scene_distribution.png" width="176"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="140" id="S3.F2.g2" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/fig3_task_difficulty.png" width="143"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="114" id="S3.F2.g3" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/fig4_concept_wordcloud.png" width="220"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Dataset composition and characteristics. (Left) Distribution of scene types across the 6,341 images. (Center) Inference difficulty distribution based on geographic reasoning complexity. (Right) Word cloud visualization of hierarchical geographic concepts extracted through systematic annotation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 2：数据集构成和特征。（左）6,341 张图像的场景类型分布。（中）基于地理推理复杂性的推理难度分布。（右）通过系统标注提取的层次地理概念词云可视化。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Method<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4 方法</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Preliminary<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1 初步</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p">MLRMs integrate visual understanding with natural language reasoning to perform complex inference tasks through CoT analysis. We formalize an MLRM as function <math alttext="\mathcal{F}:\mathcal{I}\times\mathcal{Q}\rightarrow\mathcal{A}" class="ltx_Math" display="inline" id="S4.SS1.p1.m1" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo lspace="0.278em" rspace="0.278em">:</mo><mrow><mrow><mi class="ltx_font_mathcaligraphic">ℐ</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi class="ltx_font_mathcaligraphic">𝒬</mi></mrow><mo stretchy="false">→</mo><mi class="ltx_font_mathcaligraphic">𝒜</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{F}:\mathcal{I}\times\mathcal{Q}\rightarrow\mathcal{A}</annotation></semantics></math> that processes visual input <math alttext="I" class="ltx_Math" display="inline" id="S4.SS1.p1.m2" intent=":literal"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> and query <math alttext="q" class="ltx_Math" display="inline" id="S4.SS1.p1.m3" intent=":literal"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math> through sequential reasoning steps:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">MLRMs 通过 CoT 分析将视觉理解与自然语言推理相结合，以执行复杂的推理任务。我们将 MLRM 形式化为函数 <math intent=":literal" id="S4.SS1.p1.m1" display="inline" class="ltx_Math" alttext="\mathcal{F}:\mathcal{I}\times\mathcal{Q}\rightarrow\mathcal{A}"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo rspace="0.278em" lspace="0.278em">:</mo><mrow><mrow><mi class="ltx_font_mathcaligraphic">ℐ</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mi class="ltx_font_mathcaligraphic">𝒬</mi></mrow><mo stretchy="false">→</mo><mi class="ltx_font_mathcaligraphic">𝒜</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{F}:\mathcal{I}\times\mathcal{Q}\rightarrow\mathcal{A}</annotation></semantics></math> ，该函数通过序列推理步骤处理视觉输入 <math intent=":literal" id="S4.SS1.p1.m2" display="inline" class="ltx_Math" alttext="I"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> 和查询 <math intent=":literal" id="S4.SS1.p1.m3" display="inline" class="ltx_Math" alttext="q"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math> ：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{F}(\phi_{v}(I),q)=(r_{1},r_{2},\ldots,r_{L})\rightarrow a," class="ltx_Math" display="block" id="S4.E1.m1" intent=":literal"><semantics><mrow><mrow><mrow><mi class="ltx_font_mathcaligraphic">ℱ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>ϕ</mi><mi>v</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi>q</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mo stretchy="false">(</mo><msub><mi>r</mi><mn>1</mn></msub><mo>,</mo><msub><mi>r</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>r</mi><mi>L</mi></msub><mo stretchy="false">)</mo></mrow><mo stretchy="false">→</mo><mi>a</mi></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathcal{F}(\phi_{v}(I),q)=(r_{1},r_{2},\ldots,r_{L})\rightarrow a,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\phi_{v}(I)" class="ltx_Math" display="inline" id="S4.SS1.p1.m4" intent=":literal"><semantics><mrow><msub><mi>ϕ</mi><mi>v</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi_{v}(I)</annotation></semantics></math> represents visual encoding, each reasoning step <math alttext="r_{i}" class="ltx_Math" display="inline" id="S4.SS1.p1.m5" intent=":literal"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> builds upon previous steps <math alttext="\{r_{j}\}_{j=1}^{i-1}" class="ltx_Math" display="inline" id="S4.SS1.p1.m6" intent=":literal"><semantics><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>r</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msubsup><annotation encoding="application/x-tex">\{r_{j}\}_{j=1}^{i-1}</annotation></semantics></math>, and the chain produces structured response <math alttext="a" class="ltx_Math" display="inline" id="S4.SS1.p1.m7" intent=":literal"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>. For geographic inference specifically, each reasoning step <math alttext="r_{i}" class="ltx_Math" display="inline" id="S4.SS1.p1.m8" intent=":literal"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> identifies visual concepts and spatial relationships, generating reasoning chain <math alttext="\mathcal{R}=\{r_{i}\}_{i=1}^{L}" class="ltx_Math" display="inline" id="S4.SS1.p1.m9" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℛ</mi><mo>=</mo><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>r</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathcal{R}=\{r_{i}\}_{i=1}^{L}</annotation></semantics></math> that progressively refines location estimates from continental to local scales. Our objective is to train a generator <math alttext="\mathcal{G}" class="ltx_Math" display="inline" id="S4.SS1.p1.m10" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒢</mi><annotation encoding="application/x-tex">\mathcal{G}</annotation></semantics></math>, where generating adversarial perturbation <math alttext="\delta" class="ltx_Math" display="inline" id="S4.SS1.p1.m11" intent=":literal"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math> that craft adversarial image <math alttext="I^{\prime}=I+\delta" class="ltx_Math" display="inline" id="S4.SS1.p1.m12" intent=":literal"><semantics><mrow><msup><mi>I</mi><mo>′</mo></msup><mo>=</mo><mrow><mi>I</mi><mo>+</mo><mi>δ</mi></mrow></mrow><annotation encoding="application/x-tex">I^{\prime}=I+\delta</annotation></semantics></math> disrupts the hierarchical geographic reasoning on <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S4.SS1.p1.m13" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℱ</mi><annotation encoding="application/x-tex">\mathcal{F}</annotation></semantics></math>, while maintaining imperceptibility constraint <math alttext="\|\delta\|_{\infty}\leq\epsilon" class="ltx_Math" display="inline" id="S4.SS1.p1.m14" intent=":literal"><semantics><mrow><msub><mrow><mo stretchy="false">‖</mo><mi>δ</mi><mo stretchy="false">‖</mo></mrow><mi mathvariant="normal">∞</mi></msub><mo>≤</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\|\delta\|_{\infty}\leq\epsilon</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math intent=":literal" id="S4.SS1.p1.m4" display="inline" class="ltx_Math" alttext="\phi_{v}(I)"><semantics><mrow><msub><mi>ϕ</mi><mi>v</mi></msub><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi_{v}(I)</annotation></semantics></math> 表示视觉编码，每个推理步骤 <math intent=":literal" id="S4.SS1.p1.m5" display="inline" class="ltx_Math" alttext="r_{i}"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> 都基于前一步骤 <math intent=":literal" id="S4.SS1.p1.m6" display="inline" class="ltx_Math" alttext="\{r_{j}\}_{j=1}^{i-1}"><semantics><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>r</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msubsup><annotation encoding="application/x-tex">\{r_{j}\}_{j=1}^{i-1}</annotation></semantics></math> ，链式结构产生结构化响应 <math intent=":literal" id="S4.SS1.p1.m7" display="inline" class="ltx_Math" alttext="a"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math> 。针对地理推理，每个推理步骤 <math intent=":literal" id="S4.SS1.p1.m8" display="inline" class="ltx_Math" alttext="r_{i}"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> 识别视觉概念和空间关系，生成推理链 <math intent=":literal" id="S4.SS1.p1.m9" display="inline" class="ltx_Math" alttext="\mathcal{R}=\{r_{i}\}_{i=1}^{L}"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℛ</mi><mo>=</mo><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>r</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></msubsup></mrow><annotation encoding="application/x-tex">\mathcal{R}=\{r_{i}\}_{i=1}^{L}</annotation></semantics></math> ，该链逐步从大陆尺度细化到局部尺度的位置估计。我们的目标是训练一个生成器 <math intent=":literal" id="S4.SS1.p1.m10" display="inline" class="ltx_Math" alttext="\mathcal{G}"><semantics><mi class="ltx_font_mathcaligraphic">𝒢</mi><annotation encoding="application/x-tex">\mathcal{G}</annotation></semantics></math> ，其中生成的对抗性扰动 <math intent=":literal" id="S4.SS1.p1.m11" display="inline" class="ltx_Math" alttext="\delta"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math> 能够制作对抗性图像 <math intent=":literal" id="S4.SS1.p1.m12" display="inline" class="ltx_Math" alttext="I^{\prime}=I+\delta"><semantics><mrow><msup><mi>I</mi><mo>′</mo></msup><mo>=</mo><mrow><mi>I</mi><mo>+</mo><mi>δ</mi></mrow></mrow><annotation encoding="application/x-tex">I^{\prime}=I+\delta</annotation></semantics></math> ，从而破坏 <math intent=":literal" id="S4.SS1.p1.m13" display="inline" class="ltx_Math" alttext="\mathcal{F}"><semantics><mi class="ltx_font_mathcaligraphic">ℱ</mi><annotation encoding="application/x-tex">\mathcal{F}</annotation></semantics></math> 上的层次地理推理，同时保持不可感知性约束 <math intent=":literal" id="S4.SS1.p1.m14" display="inline" class="ltx_Math" alttext="\|\delta\|_{\infty}\leq\epsilon"><semantics><mrow><msub><mrow><mo stretchy="false">‖</mo><mi>δ</mi><mo stretchy="false">‖</mo></mrow><mi mathvariant="normal">∞</mi></msub><mo>≤</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\|\delta\|_{\infty}\leq\epsilon</annotation></semantics></math> 。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Threat Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">威胁模型</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p">We focus on black-box transfer attacks, which represent the most realistic scenario for deployed MLRMs. In the context of Equation&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.E1" title="Equation 1 ‣ 4.1 Preliminary ‣ 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">1</span></a>, privacy defenders have access to modify input image <math alttext="I" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m1" intent=":literal"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>, while privacy adversaries leverage the MLRM function <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℱ</mi><annotation encoding="application/x-tex">\mathcal{F}</annotation></semantics></math> with geographic queries <math alttext="q" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m3" intent=":literal"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math> to extract location information from <math alttext="I" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m4" intent=":literal"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>. Under this setting, privacy defenders operate without access to the target MLRMs’ <math alttext="\phi" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m5" intent=":literal"><semantics><mi>ϕ</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math> parameters or internal architectures, instead utilizing surrogate models <math alttext="\psi" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.m6" intent=":literal"><semantics><mi>ψ</mi><annotation encoding="application/x-tex">\psi</annotation></semantics></math> to deploy transfer-based attacks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们关注黑盒迁移攻击，这代表了部署的 MLRM（多模态推理模型）最现实的场景。在方程 1 的背景下，隐私防御者可以修改输入图像 <math intent=":literal" id="S4.SS1.SSS0.Px1.p1.m1" display="inline" class="ltx_Math" alttext="I"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> ，而隐私攻击者则利用 MLRM 函数 <math intent=":literal" id="S4.SS1.SSS0.Px1.p1.m2" display="inline" class="ltx_Math" alttext="\mathcal{F}"><semantics><mi class="ltx_font_mathcaligraphic">ℱ</mi><annotation encoding="application/x-tex">\mathcal{F}</annotation></semantics></math> 结合地理查询 <math intent=":literal" id="S4.SS1.SSS0.Px1.p1.m3" display="inline" class="ltx_Math" alttext="q"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math> 从 <math intent=":literal" id="S4.SS1.SSS0.Px1.p1.m4" display="inline" class="ltx_Math" alttext="I"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> 中提取位置信息。在此设置下，隐私防御者无法访问目标 MLRM 的 <math intent=":literal" id="S4.SS1.SSS0.Px1.p1.m5" display="inline" class="ltx_Math" alttext="\phi"><semantics><mi>ϕ</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math> 参数或内部架构，而是利用替代模型 <math intent=":literal" id="S4.SS1.SSS0.Px1.p1.m6" display="inline" class="ltx_Math" alttext="\psi"><semantics><mi>ψ</mi><annotation encoding="application/x-tex">\psi</annotation></semantics></math> 部署基于迁移的攻击。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Theoretical Motivation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2 理论动机</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p">To understand why concept-aware perturbations are fundamentally more effective than uniform perturbations for disrupting reasoning processes, we provide a theoretical motivation for our approach.
Direct perception models can be abstracted as a function <math alttext="f:\phi_{v}(I)\rightarrow y" class="ltx_Math" display="inline" id="S4.SS2.p1.m1" intent=":literal"><semantics><mrow><mi>f</mi><mo lspace="0.278em" rspace="0.278em">:</mo><mrow><mrow><msub><mi>ϕ</mi><mi>v</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">→</mo><mi>y</mi></mrow></mrow><annotation encoding="application/x-tex">f:\phi_{v}(I)\rightarrow y</annotation></semantics></math>, where adversarial attacks succeed by shifting the feature representation <math alttext="\phi_{v}(I)" class="ltx_Math" display="inline" id="S4.SS2.p1.m2" intent=":literal"><semantics><mrow><msub><mi>ϕ</mi><mi>v</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi_{v}(I)</annotation></semantics></math> across a decision boundary.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了理解为什么概念感知扰动比均匀扰动在破坏推理过程中更根本有效，我们为我们的方法提供了理论动机。直接感知模型可以抽象为一个函数 <math intent=":literal" id="S4.SS2.p1.m1" display="inline" class="ltx_Math"><semantics><mrow><mi>f</mi><mo rspace="0.278em" lspace="0.278em">:</mo><mrow><mrow><msub><mi>ϕ</mi><mi>v</mi></msub><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">→</mo><mi>y</mi></mrow></mrow><annotation encoding="application/x-tex">f:\phi_{v}(I)\rightarrow y</annotation></semantics></math> ，其中对抗性攻击通过将特征表示 <math intent=":literal" id="S4.SS2.p1.m2" display="inline" class="ltx_Math" alttext="\phi_{v}(I)"><semantics><mrow><msub><mi>ϕ</mi><mi>v</mi></msub><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi_{v}(I)</annotation></semantics></math> 偏移决策边界而成功。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p">In contrast, MLRMs perform geographic inference via a multi-step reasoning process. Each step <math alttext="r_{i}" class="ltx_Math" display="inline" id="S4.SS2.p2.m1" intent=":literal"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> is generated by a reasoning function, denoted as <math alttext="h_{i}" class="ltx_Math" display="inline" id="S4.SS2.p2.m2" intent=":literal"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_{i}</annotation></semantics></math>, which is conditioned on the context of all prior steps <math alttext="\{r_{k}\}_{k&lt;i}" class="ltx_Math" display="inline" id="S4.SS2.p2.m3" intent=":literal"><semantics><msub><mrow><mo stretchy="false">{</mo><msub><mi>r</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>&lt;</mo><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">\{r_{k}\}_{k&lt;i}</annotation></semantics></math> and a set of newly identified visual concepts <math alttext="\{c_{j}\}" class="ltx_Math" display="inline" id="S4.SS2.p2.m4" intent=":literal"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{c_{j}\}</annotation></semantics></math>. This can be formalized as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">相比之下，MLRM 通过多步推理过程执行地理推理。每一步 <math intent=":literal" id="S4.SS2.p2.m1" display="inline" class="ltx_Math" alttext="r_{i}"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> 由一个推理函数生成，记为 <math intent=":literal" id="S4.SS2.p2.m2" display="inline" class="ltx_Math" alttext="h_{i}"><semantics><msub><mi>h</mi><mi>i</mi></msub><annotation encoding="application/x-tex">h_{i}</annotation></semantics></math> ，该函数基于所有先前步骤 <math intent=":literal" id="S4.SS2.p2.m3" display="inline" class="ltx_Math" alttext="\{r_{k}\}_{k&lt;i}"><semantics><msub><mrow><mo stretchy="false">{</mo><msub><mi>r</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>&lt;</mo><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">\{r_{k}\}_{k&lt;i}</annotation></semantics></math> 和一组新识别的视觉概念 <math intent=":literal" id="S4.SS2.p2.m4" display="inline" class="ltx_Math" alttext="\{c_{j}\}"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{c_{j}\}</annotation></semantics></math> 的条件。这可以形式化为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="r_{i}=h_{i}(\{c_{j}\mid j\in\mathcal{N}_{i}\},\{r_{k}\}_{k&lt;i})," class="ltx_Math" display="block" id="S4.E2.m1" intent=":literal"><semantics><mrow><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>=</mo><mrow><msub><mi>h</mi><mi>i</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mo stretchy="false">{</mo><msub><mi>c</mi><mi>j</mi></msub><mo fence="true" lspace="0em" rspace="0em">∣</mo><mrow><mi>j</mi><mo>∈</mo><msub><mi class="ltx_font_mathcaligraphic">𝒩</mi><mi>i</mi></msub></mrow><mo stretchy="false">}</mo></mrow><mo>,</mo><msub><mrow><mo stretchy="false">{</mo><msub><mi>r</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">r_{i}=h_{i}(\{c_{j}\mid j\in\mathcal{N}_{i}\},\{r_{k}\}_{k&lt;i}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\mathcal{N}_{i}" class="ltx_Math" display="inline" id="S4.SS2.p2.m5" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒩</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\mathcal{N}_{i}</annotation></semantics></math> is the set of concept indices required for step <math alttext="i" class="ltx_Math" display="inline" id="S4.SS2.p2.m6" intent=":literal"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>. This recursive structure imposes two critical dependencies: <span class="ltx_text ltx_font_bold">(i)</span> <span class="ltx_text ltx_font_italic">Conceptual Dependency</span>, where the validity of <math alttext="r_{i}" class="ltx_Math" display="inline" id="S4.SS2.p2.m7" intent=":literal"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> hinges on the correct identification of concepts <math alttext="\{c_{j}\}" class="ltx_Math" display="inline" id="S4.SS2.p2.m8" intent=":literal"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{c_{j}\}</annotation></semantics></math>; and <span class="ltx_text ltx_font_bold">(ii)</span> <span class="ltx_text ltx_font_italic">Sequential Dependency</span>, where <math alttext="r_{i}" class="ltx_Math" display="inline" id="S4.SS2.p2.m9" intent=":literal"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> is contingent upon the entire preceding reasoning path.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="S4.SS2.p2.m5" display="inline" class="ltx_Math" alttext="\mathcal{N}_{i}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒩</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\mathcal{N}_{i}</annotation></semantics></math> 是步骤 <math intent=":literal" id="S4.SS2.p2.m6" display="inline" class="ltx_Math" alttext="i"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math> 所需的概念索引集合。这种递归结构带来了两个关键依赖关系：(i) 概念依赖，其中 <math intent=":literal" id="S4.SS2.p2.m7" display="inline" class="ltx_Math" alttext="r_{i}"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> 的有效性取决于对概念 <math intent=":literal" id="S4.SS2.p2.m8" display="inline" class="ltx_Math" alttext="\{c_{j}\}"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>c</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{c_{j}\}</annotation></semantics></math> 的正确识别；(ii) 顺序依赖，其中 <math intent=":literal" id="S4.SS2.p2.m9" display="inline" class="ltx_Math" alttext="r_{i}"><semantics><msub><mi>r</mi><mi>i</mi></msub><annotation encoding="application/x-tex">r_{i}</annotation></semantics></math> 取决于整个先前的推理路径。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p">The coupling of <span class="ltx_text ltx_font_italic">conceptual</span> and <span class="ltx_text ltx_font_italic">sequential dependency</span> makes the entire reasoning chain exceptionally brittle. An error introduced at an early stage, such as the corruption of a single concept <math alttext="c_{k}" class="ltx_Math" display="inline" id="S4.SS2.p3.m1" intent=":literal"><semantics><msub><mi>c</mi><mi>k</mi></msub><annotation encoding="application/x-tex">c_{k}</annotation></semantics></math>, does not remain localized. ReasonBreak is therefore designed to exploit this brittleness by focusing its adversarial budget, inducing an efficient collapse of the reasoning process.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">概念依赖和顺序依赖的结合使得整个推理链变得异常脆弱。在早期阶段引入的错误，例如单个概念 <math intent=":literal" id="S4.SS2.p3.m1" display="inline" class="ltx_Math" alttext="c_{k}"><semantics><msub><mi>c</mi><mi>k</mi></msub><annotation encoding="application/x-tex">c_{k}</annotation></semantics></math> 的损坏，不会局限于局部。因此，ReasonBreak 通过集中其对抗预算来利用这种脆弱性，诱导推理过程的效率崩溃。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>ReasonBreak</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Framework Overview<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">框架概述</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="S4.F3.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x2.png" width="761">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold">The ReasonBreak Framework Overview.</span>
1) The input image undergoes Adaptive Decomposition into an <math alttext="m^{*}\times n^{*}" class="ltx_Math" display="inline" id="S4.F3.m10" intent=":literal"><semantics><mrow><msup><mi>m</mi><mo>∗</mo></msup><mo lspace="0.222em" rspace="0.222em">×</mo><msup><mi>n</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">m^{*}\times n^{*}</annotation></semantics></math> grid of blocks.
2) Each block <math alttext="B_{k}" class="ltx_Math" display="inline" id="S4.F3.m11" intent=":literal"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> is assigned a set of relevant concepts <math alttext="\mathcal{C}_{k}" class="ltx_Math" display="inline" id="S4.F3.m12" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> via spatial overlap analysis.
3) The Minimax Target Selection uses the assigned concept set <math alttext="\mathcal{C}_{k}" class="ltx_Math" display="inline" id="S4.F3.m13" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> and a pre-computed Embedding Bank <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S4.F3.m14" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> to find a hard-negative prior <math alttext="\mathbf{e}_{\text{prior}}^{k}" class="ltx_Math" display="inline" id="S4.F3.m15" intent=":literal"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math>.
4) This prior is fed into the learnable Decoder <math alttext="\mathcal{G}_{\theta}" class="ltx_Math" display="inline" id="S4.F3.m16" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> to synthesize a block-specific perturbation <math alttext="\delta_{k}" class="ltx_Math" display="inline" id="S4.F3.m17" intent=":literal"><semantics><msub><mi>δ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\delta_{k}</annotation></semantics></math>.
5) The final adversarial image <math alttext="I^{\prime}" class="ltx_Math" display="inline" id="S4.F3.m18" intent=":literal"><semantics><msup><mi>I</mi><mo>′</mo></msup><annotation encoding="application/x-tex">I^{\prime}</annotation></semantics></math> is reconstructed by adding the perturbations to their corresponding clean blocks.
The dashed boxes at the bottom illustrate the three possible outcomes of the concept assignment logic in step (2): a block may be assigned a single concept (left), multiple concepts (middle), or the default set of all image concepts if it has no spatial overlap (right).
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 3：ReasonBreak 框架概述。1) 输入图像通过自适应分解成一个 <math intent=":literal" id="S4.F3.m10" display="inline" class="ltx_Math" alttext="m^{*}\times n^{*}"><semantics><mrow><msup><mi>m</mi><mo>∗</mo></msup><mo rspace="0.222em" lspace="0.222em">×</mo><msup><mi>n</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">m^{*}\times n^{*}</annotation></semantics></math> 网格的块。2) 每个块 <math intent=":literal" id="S4.F3.m11" display="inline" class="ltx_Math" alttext="B_{k}"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> 通过空间重叠分析被分配一组相关概念 <math intent=":literal" id="S4.F3.m12" display="inline" class="ltx_Math" alttext="\mathcal{C}_{k}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> 。3) Minimax 目标选择使用分配的概念集 <math intent=":literal" id="S4.F3.m13" display="inline" class="ltx_Math" alttext="\mathcal{C}_{k}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> 和预计算的嵌入库 <math intent=":literal" id="S4.F3.m14" display="inline" class="ltx_Math" alttext="\mathcal{E}"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> 来找到一个硬负样本 <math intent=":literal" id="S4.F3.m15" display="inline" class="ltx_Math" alttext="\mathbf{e}_{\text{prior}}^{k}"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math> 。4) 这个先验被输入到可学习的解码器 <math intent=":literal" id="S4.F3.m16" display="inline" class="ltx_Math" alttext="\mathcal{G}_{\theta}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> 中，以合成特定块的扰动 <math intent=":literal" id="S4.F3.m17" display="inline" class="ltx_Math" alttext="\delta_{k}"><semantics><msub><mi>δ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\delta_{k}</annotation></semantics></math> 。5) 最终的对抗图像 <math intent=":literal" id="S4.F3.m18" display="inline" class="ltx_Math" alttext="I^{\prime}"><semantics><msup><mi>I</mi><mo>′</mo></msup><annotation encoding="application/x-tex">I^{\prime}</annotation></semantics></math> 通过将扰动添加到相应的干净块中重建。底部虚线框说明了步骤(2)中概念分配逻辑的三种可能结果：一个块可能被分配一个概念（左侧），多个概念（中间），或者如果没有空间重叠，则分配所有图像概念默认集（右侧）。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p">ReasonBreak generates privacy-preserving images by targeting specific visual-conceptual relationships through concept-aware adversarial perturbations. The entire pipeline is illustrated in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.F3" title="Figure 3 ‣ Framework Overview ‣ 4.3 ReasonBreak ‣ 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">3</span></a> and detailed in Algorithm&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#alg1" title="Algorithm 1 ‣ LLM Usage ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">1</span></a>. Our framework consists of three key stages. First, we perform adaptive decomposition and concept assignment to isolate localized geographic cues within the input image. Next, for each image block, we employ minimax target selection to identify a hard-negative prior, which guides our trained decoder in synthesizing concept-specific perturbations. Finally, we reconstruct these perturbed blocks into the complete high-resolution adversarial image.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ReasonBreak 通过概念感知的对抗扰动，针对特定的视觉概念关系生成保护隐私的图像。整个流程如图 3 所示，详细描述在算法 1 中。我们的框架包含三个关键阶段。首先，我们对输入图像进行自适应分解和概念分配，以隔离局部的地理特征。接下来，对于每个图像块，我们采用极小极大目标选择来识别硬负样本先验，这指导我们训练的解码器合成特定概念扰动。最后，我们将这些扰动的块重建为完整的高分辨率对抗图像。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Adaptive Image Decomposition and Concept Assignment<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">自适应图像分解和概念分配</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p">Our approach builds upon the GeoPrivacy-6K dataset, where each image <math alttext="I" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m1" intent=":literal"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> from dataset <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m2" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒟</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> is annotated with key geographic concepts <math alttext="\bm{c}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m3" intent=":literal"><semantics><mi>𝒄</mi><annotation encoding="application/x-tex">\bm{c}</annotation></semantics></math> and their corresponding spatial bounding boxes <math alttext="\bm{g}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m4" intent=":literal"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math>.
To effectively capture fine-grained details in ultra-high-resolution images, existing MLLMs typically partition images into tiles and process each compressed tile through their visual encoders&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2024expanding</span>)</cite>.
Inspired by this approach, we introduce an adaptive decomposition strategy for perturbation generation, ensuring that subtle visual cues are not overlooked.
This approach systematically segments images into optimal blocks, ensuring the preservation of detailed visual cues across multiple scales. Formally, the decomposition transforms image <math alttext="I" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m5" intent=":literal"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> into an optimal block configuration defined as:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的方法基于 GeoPrivacy-6K 数据集，其中数据集 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m2" display="inline" class="ltx_Math" alttext="\mathcal{D}"><semantics><mi class="ltx_font_mathcaligraphic">𝒟</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> 中的每张图像 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m1" display="inline" class="ltx_Math" alttext="I"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> 都标注有关键地理概念 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m3" display="inline" class="ltx_Math" alttext="\bm{c}"><semantics><mi>𝒄</mi><annotation encoding="application/x-tex">\bm{c}</annotation></semantics></math> 及其相应的空间边界框 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m4" display="inline" class="ltx_Math" alttext="\bm{g}"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math> 。为了有效捕捉超高分辨率图像中的细粒度细节，现有的 MLLM 通常将图像分割成瓦片，并通过其视觉编码器处理每个压缩的瓦片（chen2024expanding）。受此方法的启发，我们引入了一种自适应分解策略用于扰动生成，确保不会忽略微妙的视觉线索。该方法系统地分割图像成最优块，确保在不同尺度上保留详细的视觉线索。形式上，分解将图像 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m5" display="inline" class="ltx_Math" alttext="I"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> 转换成最优块配置，定义为：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{T}(I)=\{B_{k}\}_{k=1}^{m^{*}n^{*}},\quad(m^{*},n^{*})=\underset{(m,n)}{\arg\min}\left|\frac{W}{H}-\frac{m}{n}\right|,\quad mn\leq N_{\text{max}}," class="ltx_Math" display="block" id="S4.E3.m1" intent=":literal"><semantics><mrow><mrow><mrow><mrow><mi class="ltx_font_mathcaligraphic">𝒯</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>B</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><msup><mi>m</mi><mo>∗</mo></msup><mo lspace="0em" rspace="0em">​</mo><msup><mi>n</mi><mo>∗</mo></msup></mrow></msubsup></mrow><mo rspace="1.167em">,</mo><mrow><mrow><mrow><mo stretchy="false">(</mo><msup><mi>m</mi><mo>∗</mo></msup><mo>,</mo><msup><mi>n</mi><mo>∗</mo></msup><mo stretchy="false">)</mo></mrow><mo>=</mo><mrow><munder accentunder="true"><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mi>min</mi></mrow><mrow><mo stretchy="false">(</mo><mi>m</mi><mo>,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></munder><mo lspace="0em" rspace="0em">​</mo><mrow><mo>|</mo><mrow><mfrac><mi>W</mi><mi>H</mi></mfrac><mo>−</mo><mfrac><mi>m</mi><mi>n</mi></mfrac></mrow><mo>|</mo></mrow></mrow></mrow><mo rspace="1.167em">,</mo><mrow><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>n</mi></mrow><mo>≤</mo><msub><mi>N</mi><mtext>max</mtext></msub></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathcal{T}(I)=\{B_{k}\}_{k=1}^{m^{*}n^{*}},\quad(m^{*},n^{*})=\underset{(m,n)}{\arg\min}\left|\frac{W}{H}-\frac{m}{n}\right|,\quad mn\leq N_{\text{max}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="W" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m6" intent=":literal"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> and <math alttext="H" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m7" intent=":literal"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> denote the original image dimensions and <math alttext="N_{\text{max}}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m8" intent=":literal"><semantics><msub><mi>N</mi><mtext>max</mtext></msub><annotation encoding="application/x-tex">N_{\text{max}}</annotation></semantics></math> is a hyperparameter for the maximum allowed blocks. This optimization finds an <math alttext="m\times n" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m9" intent=":literal"><semantics><mrow><mi>m</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m\times n</annotation></semantics></math> grid whose aspect ratio (<math alttext="m/n" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m10" intent=":literal"><semantics><mrow><mi>m</mi><mo>/</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m/n</annotation></semantics></math>) is closest to the original image’s aspect ratio (<math alttext="W/H" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m11" intent=":literal"><semantics><mrow><mi>W</mi><mo>/</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">W/H</annotation></semantics></math>), thereby minimizing distortion when the image is resized and partitioned into <math alttext="N=m^{*}n^{*}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m12" intent=":literal"><semantics><mrow><mi>N</mi><mo>=</mo><mrow><msup><mi>m</mi><mo>∗</mo></msup><mo lspace="0em" rspace="0em">​</mo><msup><mi>n</mi><mo>∗</mo></msup></mrow></mrow><annotation encoding="application/x-tex">N=m^{*}n^{*}</annotation></semantics></math> blocks. Each block <math alttext="B_{k}\in\mathbb{R}^{3\times h\times h}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m13" intent=":literal"><semantics><mrow><msub><mi>B</mi><mi>k</mi></msub><mo>∈</mo><msup><mi>ℝ</mi><mrow><mn>3</mn><mo lspace="0.222em" rspace="0.222em">×</mo><mi>h</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>h</mi></mrow></msup></mrow><annotation encoding="application/x-tex">B_{k}\in\mathbb{R}^{3\times h\times h}</annotation></semantics></math> is processed at the standard input resolution <math alttext="h" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m14" intent=":literal"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math> of the surrogate encoders <math alttext="\psi_{i}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m15" intent=":literal"><semantics><msub><mi>ψ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\psi_{i}</annotation></semantics></math>.The concept assignment phase follows the segmentation process. For each block <math alttext="B_{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m16" intent=":literal"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math>, we determine concept assignments through spatial overlap analysis with ground truth annotations from <math alttext="\bm{g}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m17" intent=":literal"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math>. Specifically, we identify the intersection between the block’s spatial extent (mapped back to the original image’s coordinates) and the bounding boxes in <math alttext="\bm{g}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m18" intent=":literal"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math>, assigning the corresponding concepts from <math alttext="\bm{c}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m19" intent=":literal"><semantics><mi>𝒄</mi><annotation encoding="application/x-tex">\bm{c}</annotation></semantics></math> to form a concept subset <math alttext="\mathcal{C}_{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.m20" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math>. Our method ensures that all blocks are perturbed. Blocks that do not have a spatial intersection with any specific concept bounding box are assigned the complete set of all concepts associated with the entire image. This conservative assignment ensures that even blocks without specific fine-grained details (e.g., patches of sky or road) are perturbed to disrupt the model’s more general, image-level reasoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m6" display="inline" class="ltx_Math" alttext="W"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> 和 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m7" display="inline" class="ltx_Math" alttext="H"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math> 表示原始图像的尺寸， <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m8" display="inline" class="ltx_Math" alttext="N_{\text{max}}"><semantics><msub><mi>N</mi><mtext>max</mtext></msub><annotation encoding="application/x-tex">N_{\text{max}}</annotation></semantics></math> 是允许的最大块数的超参数。该优化找到一个 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m9" display="inline" class="ltx_Math" alttext="m\times n"><semantics><mrow><mi>m</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m\times n</annotation></semantics></math> 网格，其宽高比（ <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m10" display="inline" class="ltx_Math" alttext="m/n"><semantics><mrow><mi>m</mi><mo>/</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m/n</annotation></semantics></math> ）最接近原始图像的宽高比（ <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m11" display="inline" class="ltx_Math" alttext="W/H"><semantics><mrow><mi>W</mi><mo>/</mo><mi>H</mi></mrow><annotation encoding="application/x-tex">W/H</annotation></semantics></math> ），从而在图像缩放并划分为 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m12" display="inline" class="ltx_Math" alttext="N=m^{*}n^{*}"><semantics><mrow><mi>N</mi><mo>=</mo><mrow><msup><mi>m</mi><mo>∗</mo></msup><mo rspace="0em" lspace="0em">​</mo><msup><mi>n</mi><mo>∗</mo></msup></mrow></mrow><annotation encoding="application/x-tex">N=m^{*}n^{*}</annotation></semantics></math> 块时最小化失真。每个块 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m13" display="inline" class="ltx_Math" alttext="B_{k}\in\mathbb{R}^{3\times h\times h}"><semantics><mrow><msub><mi>B</mi><mi>k</mi></msub><mo>∈</mo><msup><mi>ℝ</mi><mrow><mn>3</mn><mo rspace="0.222em" lspace="0.222em">×</mo><mi>h</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mi>h</mi></mrow></msup></mrow><annotation encoding="application/x-tex">B_{k}\in\mathbb{R}^{3\times h\times h}</annotation></semantics></math> 都在替代编码器 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m15" display="inline" class="ltx_Math" alttext="\psi_{i}"><semantics><msub><mi>ψ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\psi_{i}</annotation></semantics></math> 的标准输入分辨率 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m14" display="inline" class="ltx_Math" alttext="h"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math> 下进行处理。概念分配阶段紧随分割过程之后。对于每个块 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m16" display="inline" class="ltx_Math" alttext="B_{k}"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> ，我们通过空间重叠分析地面真实标注 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m17" display="inline" class="ltx_Math" alttext="\bm{g}"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math> 来确定概念分配。具体来说，我们识别块的空间范围（映射回原始图像的坐标）与 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m18" display="inline" class="ltx_Math" alttext="\bm{g}"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math> 中的边界框的交集，并将来自 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m19" display="inline" class="ltx_Math" alttext="\bm{c}"><semantics><mi>𝒄</mi><annotation encoding="application/x-tex">\bm{c}</annotation></semantics></math> 的相应概念分配为一个概念子集 <math intent=":literal" id="S4.SS3.SSS0.Px2.p1.m20" display="inline" class="ltx_Math" alttext="\mathcal{C}_{k}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> 。我们的方法确保所有块都受到扰动。那些与任何特定概念边界框没有空间交集的块被分配与整个图像相关的所有概念集合。 这种保守的分配确保即使没有特定细粒度细节的块（例如天空或道路的补丁）也会被扰动，以破坏模型更一般的，图像级别的推理。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Minimax Target Selection<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">极大极小目标选择</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px3.p1">
<p class="ltx_p">Our objective is to dismantle, not merely mislead, the model’s reasoning process. For each block <math alttext="B_{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m1" intent=":literal"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math>, our approach generates a perturbation designed to invalidate its entire associated concept set <math alttext="\mathcal{C}_{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m2" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math>. To achieve this, we first identify a powerful repulsive signal by selecting a <span class="ltx_text ltx_font_italic">hard-negative prior</span> from a pre-computed embedding bank <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m3" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> that is maximally distant from all concepts in the block:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的目标是破坏，而不仅仅是误导模型的推理过程。对于每个块 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m1" display="inline" class="ltx_Math" alttext="B_{k}"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> ，我们的方法生成一个扰动，旨在使其整个相关概念集 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m2" display="inline" class="ltx_Math" alttext="\mathcal{C}_{k}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> 失效。为了实现这一点，我们首先通过从预先计算的嵌入库 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m3" display="inline" class="ltx_Math" alttext="\mathcal{E}"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> 中选择一个与块中所有概念最大距离的硬负样本，来识别一个强大的排斥信号：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{e}_{\text{prior}}^{k}=\underset{\mathbf{e}\in\mathcal{E}}{\arg\min}\max_{c\in\mathcal{C}_{k}}\cos(\psi_{t}(c),\mathbf{e})," class="ltx_Math" display="block" id="S4.E4.m1" intent=":literal"><semantics><mrow><mrow><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><mo>=</mo><mrow><munder accentunder="true"><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mi>min</mi></mrow><mrow><mi>𝐞</mi><mo>∈</mo><mi class="ltx_font_mathcaligraphic">ℰ</mi></mrow></munder><mo lspace="0.167em" rspace="0em">​</mo><mrow><munder><mi>max</mi><mrow><mi>c</mi><mo>∈</mo><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub></mrow></munder><mo lspace="0.167em">⁡</mo><mrow><mi>cos</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>ψ</mi><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi>𝐞</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}=\underset{\mathbf{e}\in\mathcal{E}}{\arg\min}\max_{c\in\mathcal{C}_{k}}\cos(\psi_{t}(c),\mathbf{e}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m4" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> is constructed by encoding images from the dataset <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m5" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒟</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> using a frozen image encoder <math alttext="\psi_{i}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m6" intent=":literal"><semantics><msub><mi>ψ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\psi_{i}</annotation></semantics></math>, i.e., <math alttext="\mathcal{E}=\psi_{i}(\mathcal{D})" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m7" intent=":literal"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℰ</mi><mo>=</mo><mrow><msub><mi>ψ</mi><mi>i</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">𝒟</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{E}=\psi_{i}(\mathcal{D})</annotation></semantics></math>, and <math alttext="\psi_{t}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m8" intent=":literal"><semantics><msub><mi>ψ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\psi_{t}</annotation></semantics></math> represents a frozen text encoder. This equation formalizes our search for the hard-negative prior. It is important to note that <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m9" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> serves as a large, diverse vocabulary of real-world semantic embeddings, not a 1-to-1 matching database. The resulting <math alttext="\mathbf{e}_{\text{prior}}^{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m10" intent=":literal"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math> represents a conceptual “void”: a point in the embedding space far from any correct interpretation of the block.
This prior serves as a <span class="ltx_text ltx_font_italic">conceptual directive</span> for our generator, a design choice with critical implications. Instead of being a rigid target in the loss function, it conditions a learnable decoder <math alttext="\mathcal{G}_{\theta}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m11" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> (see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A1" title="Appendix A Decoder Architecture ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">A</span></a> for architecture details) to synthesize the perturbation:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m4" display="inline" class="ltx_Math" alttext="\mathcal{E}"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> 是通过使用冻结的图像编码器 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m6" display="inline" class="ltx_Math" alttext="\psi_{i}"><semantics><msub><mi>ψ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\psi_{i}</annotation></semantics></math> （即 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m7" display="inline" class="ltx_Math" alttext="\mathcal{E}=\psi_{i}(\mathcal{D})"><semantics><mrow><mi class="ltx_font_mathcaligraphic">ℰ</mi><mo>=</mo><mrow><msub><mi>ψ</mi><mi>i</mi></msub><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">𝒟</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathcal{E}=\psi_{i}(\mathcal{D})</annotation></semantics></math> ）对数据集 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m5" display="inline" class="ltx_Math" alttext="\mathcal{D}"><semantics><mi class="ltx_font_mathcaligraphic">𝒟</mi><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math> 中的图像进行编码而构建的，而 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m8" display="inline" class="ltx_Math" alttext="\psi_{t}"><semantics><msub><mi>ψ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\psi_{t}</annotation></semantics></math> 表示一个冻结的文本编码器。这个公式形式化了我们对困难负样本先验的搜索。需要注意的是， <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m9" display="inline" class="ltx_Math" alttext="\mathcal{E}"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> 是一个包含真实世界语义嵌入的大型、多样化的词汇表，而不是一个 1 对 1 匹配的数据库。生成的 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m10" display="inline" class="ltx_Math" alttext="\mathbf{e}_{\text{prior}}^{k}"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math> 代表一个概念上的“虚空”：嵌入空间中远离任何正确解释块的一个点。这个先验为我们的生成器提供了一个概念上的指导，这是一个具有重大影响的设计选择。它不是损失函数中的一个刚性目标，而是调节可学习的解码器 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m11" display="inline" class="ltx_Math" alttext="\mathcal{G}_{\theta}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> （有关架构细节，请参见附录 A）来合成扰动：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\delta_{k}=\mathcal{G}_{\theta}\big(\mathbf{e}_{\text{prior}}^{k}\big),\qquad B^{\prime}_{k}=B_{k}+\delta_{k},\qquad||\delta_{k}||_{\infty}\leq\epsilon." class="ltx_Math" display="block" id="S4.E5.m1" intent=":literal"><semantics><mrow><mrow><mrow><msub><mi>δ</mi><mi>k</mi></msub><mo>=</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo maxsize="1.200em" minsize="1.200em">(</mo><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><mo maxsize="1.200em" minsize="1.200em">)</mo></mrow></mrow></mrow><mo rspace="2.167em">,</mo><mrow><mrow><msubsup><mi>B</mi><mi>k</mi><mo>′</mo></msubsup><mo>=</mo><mrow><msub><mi>B</mi><mi>k</mi></msub><mo>+</mo><msub><mi>δ</mi><mi>k</mi></msub></mrow></mrow><mo rspace="2.167em">,</mo><mrow><msub><mrow><mo stretchy="false">‖</mo><msub><mi>δ</mi><mi>k</mi></msub><mo stretchy="false">‖</mo></mrow><mi mathvariant="normal">∞</mi></msub><mo>≤</mo><mi>ϵ</mi></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\delta_{k}=\mathcal{G}_{\theta}\big(\mathbf{e}_{\text{prior}}^{k}\big),\qquad B^{\prime}_{k}=B_{k}+\delta_{k},\qquad||\delta_{k}||_{\infty}\leq\epsilon.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">Notably, the decoder <math alttext="\mathcal{G}_{\theta}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m12" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> does not take the image block <math alttext="B_{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m13" intent=":literal"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> as a direct input. Its role is to act as a <span class="ltx_text ltx_font_italic">semantic-to-visual translator</span>, learning a general mapping from an abstract conceptual directive (the prior) to an effective pixel-level perturbation. The visual content of <math alttext="B_{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m14" intent=":literal"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> exerts its influence implicitly by determining the concept set <math alttext="\mathcal{C}_{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m15" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math>, which in turn dictates the choice of <math alttext="\mathbf{e}_{\text{prior}}^{k}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.m16" intent=":literal"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">值得注意的是，解码器 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m12" display="inline" class="ltx_Math" alttext="\mathcal{G}_{\theta}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> 不会将图像块 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m13" display="inline" class="ltx_Math" alttext="B_{k}"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> 作为直接输入。它的作用是充当语义到视觉的翻译器，学习从抽象概念指令（先验）到有效像素级扰动的通用映射。 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m14" display="inline" class="ltx_Math" alttext="B_{k}"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> 的视觉内容通过确定概念集 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m15" display="inline" class="ltx_Math" alttext="\mathcal{C}_{k}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> 来隐式地发挥作用，进而决定 <math intent=":literal" id="S4.SS3.SSS0.Px3.p1.m16" display="inline" class="ltx_Math" alttext="\mathbf{e}_{\text{prior}}^{k}"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math> 的选择。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Ensemble Training and Reconstruction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">集成训练和重建</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px4.p1">
<p class="ltx_p">Finally, we ensure robust transferability through ensemble training across diverse surrogate models <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px4.p1.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒮</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math> by minimizing the cosine similarity between original and adversarial representations:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">最后，我们通过在不同替代模型 <math intent=":literal" id="S4.SS3.SSS0.Px4.p1.m1" display="inline" class="ltx_Math" alttext="\mathcal{S}"><semantics><mi class="ltx_font_mathcaligraphic">𝒮</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math> 上进行集成训练来确保鲁棒的迁移性，通过最小化原始表示和对抗表示之间的余弦相似度：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S4.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}(\theta)=\mathbb{E}_{s\sim\mathcal{S}}\left[\frac{1}{N}\sum_{k=1}^{N}\cos(\psi_{s}(B_{k}),\psi_{s}(B^{\prime}_{k}))\right]," class="ltx_Math" display="block" id="S4.E6.m1" intent=":literal"><semantics><mrow><mrow><mrow><mi class="ltx_font_mathcaligraphic">ℒ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>𝔼</mi><mrow><mi>s</mi><mo>∼</mo><mi class="ltx_font_mathcaligraphic">𝒮</mi></mrow></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo>[</mo><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munderover><mo movablelimits="false">∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>cos</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>ψ</mi><mi>s</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>B</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>ψ</mi><mi>s</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>B</mi><mi>k</mi><mo>′</mo></msubsup><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><mo>]</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}(\theta)=\mathbb{E}_{s\sim\mathcal{S}}\left[\frac{1}{N}\sum_{k=1}^{N}\cos(\psi_{s}(B_{k}),\psi_{s}(B^{\prime}_{k}))\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\psi_{s}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px4.p1.m2" intent=":literal"><semantics><msub><mi>ψ</mi><mi>s</mi></msub><annotation encoding="application/x-tex">\psi_{s}</annotation></semantics></math> represents the visual encoder of surrogate model <math alttext="s" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px4.p1.m3" intent=":literal"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>, and <math alttext="N=m^{*}n^{*}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px4.p1.m4" intent=":literal"><semantics><mrow><mi>N</mi><mo>=</mo><mrow><msup><mi>m</mi><mo>∗</mo></msup><mo lspace="0em" rspace="0em">​</mo><msup><mi>n</mi><mo>∗</mo></msup></mrow></mrow><annotation encoding="application/x-tex">N=m^{*}n^{*}</annotation></semantics></math>. In this formulation, the hard-negative prior shapes the <span class="ltx_text ltx_font_italic">synthesis direction</span> through conditioning, while the untargeted loss reduces the representation consistency between the original and perturbed blocks across surrogate models. The final step reconstructs the full-resolution adversarial image <math alttext="I^{\prime}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px4.p1.m5" intent=":literal"><semantics><msup><mi>I</mi><mo>′</mo></msup><annotation encoding="application/x-tex">I^{\prime}</annotation></semantics></math> by reassembling the perturbed blocks via the inverse transformation <math alttext="\mathcal{T}^{-1}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px4.p1.m6" intent=":literal"><semantics><msup><mi class="ltx_font_mathcaligraphic">𝒯</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><annotation encoding="application/x-tex">\mathcal{T}^{-1}</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math intent=":literal" id="S4.SS3.SSS0.Px4.p1.m2" display="inline" class="ltx_Math" alttext="\psi_{s}"><semantics><msub><mi>ψ</mi><mi>s</mi></msub><annotation encoding="application/x-tex">\psi_{s}</annotation></semantics></math> 代表替代模型 <math intent=":literal" id="S4.SS3.SSS0.Px4.p1.m3" display="inline" class="ltx_Math" alttext="s"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> 的视觉编码器 <math intent=":literal" id="S4.SS3.SSS0.Px4.p1.m4" display="inline" class="ltx_Math" alttext="N=m^{*}n^{*}"><semantics><mrow><mi>N</mi><mo>=</mo><mrow><msup><mi>m</mi><mo>∗</mo></msup><mo rspace="0em" lspace="0em">​</mo><msup><mi>n</mi><mo>∗</mo></msup></mrow></mrow><annotation encoding="application/x-tex">N=m^{*}n^{*}</annotation></semantics></math> 。在这个公式中，硬负先验通过条件作用塑造合成方向，而未目标化损失减少了替代模型中原始块和扰动块之间的表示一致性。最后一步通过逆变换 <math intent=":literal" id="S4.SS3.SSS0.Px4.p1.m6" display="inline" class="ltx_Math" alttext="\mathcal{T}^{-1}"><semantics><msup><mi class="ltx_font_mathcaligraphic">𝒯</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><annotation encoding="application/x-tex">\mathcal{T}^{-1}</annotation></semantics></math> 重新组装扰动块来重建全分辨率对抗图像 <math intent=":literal" id="S4.SS3.SSS0.Px4.p1.m5" display="inline" class="ltx_Math" alttext="I^{\prime}"><semantics><msup><mi>I</mi><mo>′</mo></msup><annotation encoding="application/x-tex">I^{\prime}</annotation></semantics></math> 。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5 实验</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Privacy protection performance across geographical granularities on DoxBench (<math alttext="\epsilon=16/255" class="ltx_Math" display="inline" id="S5.T1.m2" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>16</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=16/255</annotation></semantics></math>). Best results are in <span class="ltx_text ltx_font_bold">bold</span>. Key metrics for <span class="ltx_text ltx_font_bold">Tract</span> and <span class="ltx_text ltx_font_bold">Block</span> granularities are highlighted in gray. Higher values indicate better privacy protection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 1：DoxBench（ <math intent=":literal" id="S5.T1.m2" display="inline" class="ltx_Math" alttext="\epsilon=16/255"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>16</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=16/255</annotation></semantics></math> ）上不同地理粒度下的隐私保护性能。最佳结果以粗体显示。Tract 和 Block 粒度的关键指标以灰色突出显示。更高的值表示更好的隐私保护。</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:232.6pt;vertical-align:-114.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.9pt,23.9pt) scale(0.829428196585515,0.829428196585515) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_tt" rowspan="2" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" rowspan="2" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">Attack<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">攻击</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">Top-1 Protection Rate (%)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Top-1 保护率 (%)</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">Top-3 Protection Rate (%)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Top-3 防护率 (%)</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">Region<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">区域</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">Metro.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">地铁。</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">Tract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">区</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">Block<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">街区</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">Region<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">区域</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">Metro.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">地铁。</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">Tract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">区</font></font></font></span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">Block<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">街区</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="3" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">GPT-o3</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">AnyAttack</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">10.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">12.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">25.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">18.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">11.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">16.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">21.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">18.9</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">M-Attack</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">7.6</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">10.8</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">15.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">14.8</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">9.6</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">10.9</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">18.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">24.3</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_smallcaps" data-imt_insert_failed="1">Ours</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">11.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">13.7</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">31.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">25.9</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">42.6</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">44.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">46.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">32.4</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="3" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">GPT-5</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">AnyAttack</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">6.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">9.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">20.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">29.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">5.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">9.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">23.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">12.2</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">M-Attack</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">4.6</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">8.9</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">17.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">22.6</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">5.0</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">15.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">14.6</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_smallcaps" data-imt_insert_failed="1">Ours</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">8.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">9.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">32.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">29.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">10.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">12.4</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">35.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">19.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="3" style="padding-top:-1pt;padding-bottom:-1pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Gemini</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">2.5 Pro</span></td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">AnyAttack</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">3.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">8.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">15.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">0.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">4.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">6.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">19.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">15.6</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">M-Attack</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">4.8</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">9.9</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">20.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">0.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">4.0</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">8.1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">20.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">2.2</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_smallcaps" data-imt_insert_failed="1">Ours</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">6.9</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">10.6</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">30.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">23.3</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">5.6</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">12.1</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">36.2</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">33.3</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="3" style="padding-top:-1pt;padding-bottom:-1pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">QVQ</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Max</span></td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">AnyAttack</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">42.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">41.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">26.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">15.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">32.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">30.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">29.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">23.8</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">M-Attack</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">30.1</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">29.0</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">23.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">23.1</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">17.5</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">17.0</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">26.1</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">14.3</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_smallcaps" data-imt_insert_failed="1">Ours</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">46.2</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">46.7</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">28.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">25.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">27.0</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">40.9</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">33.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">34.2</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="3" style="padding-top:-1pt;padding-bottom:-1pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">QwenVL</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">Max</span></td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">AnyAttack</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">38.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">38.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">26.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">33.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">28.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">30.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">26.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">27.3</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">M-Attack</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">34.0</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">35.0</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">31.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">40.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">25.1</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">28.1</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">26.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">22.7</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_smallcaps" data-imt_insert_failed="1">Ours</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">55.3</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">55.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">39.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">40.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">30.5</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">30.8</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">44.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">42.9</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="3" style="padding-top:-1pt;padding-bottom:-1pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">QwenVL</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">2.5 72B</span></td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">AnyAttack</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">41.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">32.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">17.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">21.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">29.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">30.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">29.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">26.1</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">M-Attack</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">32.7</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">26.7</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">17.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">14.3</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">23.2</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">22.7</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">34.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">26.1</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_smallcaps" data-imt_insert_failed="1">Ours</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">46.3</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">49.2</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">40.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">33.3</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">38.3</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">38.2</span></td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">46.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">35.0</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="3" style="padding-top:-1pt;padding-bottom:-1pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">InternVL</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" data-imt_insert_failed="1">3.0 72B</span></td>
</tr>
</tbody></table> </td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">AnyAttack</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">4.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">3.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">0.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">4.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-top:-1pt;padding-bottom:-1pt;">2.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">0.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">22.2</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;" data-imt_insert_failed="1">M-Attack</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">5.2</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">3.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">0.0</span></td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">2.6</td>
<td class="ltx_td ltx_align_center" style="padding-top:-1pt;padding-bottom:-1pt;">3.8</td>
<td class="ltx_td ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">0.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text" style="--ltx-bg-color:#F2F2F2;">11.1</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_smallcaps" data-imt_insert_failed="1">Ours</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">10.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1pt;padding-bottom:-1pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">33.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">58.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">12.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold">7.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">31.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" style="--ltx-bg-color:#F2F2F2;padding-top:-1pt;padding-bottom:-1pt;"><span class="ltx_text ltx_font_bold" style="--ltx-bg-color:#F2F2F2;">33.3</span></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation Setup<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.1 评估设置</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Evaluation Benchmark</span>
We evaluate ReasonBreak on <span class="ltx_text ltx_font_smallcaps">DoxBench</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">luo2025doxing</span>)</cite>, a curated dataset of 500 real-world images with ground truth coordinates, designed to assess geolocation inference in MLRMs.
DoxBench introduces a hierarchical evaluation protocol at four geographic levels: <em class="ltx_emph ltx_font_italic">state (region)</em>, <em class="ltx_emph ltx_font_italic">metropolitan area</em>, <em class="ltx_emph ltx_font_italic">census tract</em>, and <em class="ltx_emph ltx_font_italic">census block</em>.
<em class="ltx_emph ltx_font_italic">Tract</em> approximate neighborhood-level areas, while <em class="ltx_emph ltx_font_italic">block</em> capture street-level resolution, these metrics are particularly critical for evaluating privacy protection effectiveness.
Ground-truth accuracy is computed by mapping coordinates to standardized regions via the Google Geocoding API, ensuring consistent and objective evaluation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">评估基准 我们在 DoxBench（luo2025doxing）上评估 ReasonBreak，这是一个包含 500 张真实世界图像及其真实坐标的精选数据集，旨在评估多模态推理模型（MLRM）中的地理位置推断能力。DoxBench 引入了在四个地理层级上的分层评估协议：州（区域）、大都市区、人口普查区以及人口普查街区。人口普查区近似于社区级别的区域，而街区则捕捉到街道级别的分辨率，这些指标对于评估隐私保护的有效性尤为重要。通过 Google 地理编码 API 将坐标映射到标准化区域来计算真实准确率，以确保评估的一致性和客观性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Metric</span>
Privacy protection is measured by the <em class="ltx_emph ltx_font_italic">Privacy Protection Rate</em> (PPR), which captures the reduction in successful location inference after perturbation:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">度量隐私保护是通过隐私保护率（PPR）来衡量的，它捕捉了扰动后成功位置推理的减少情况：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S5.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{PPR}=\frac{N_{\text{orig}}-N_{\text{adv}}}{N_{\text{orig}}}\times 100\%," class="ltx_Math" display="block" id="S5.E7.m1" intent=":literal"><semantics><mrow><mrow><mtext>PPR</mtext><mo>=</mo><mrow><mfrac><mrow><msub><mi>N</mi><mtext>orig</mtext></msub><mo>−</mo><msub><mi>N</mi><mtext>adv</mtext></msub></mrow><msub><mi>N</mi><mtext>orig</mtext></msub></mfrac><mo lspace="0.222em" rspace="0.222em">×</mo><mrow><mn>100</mn><mo>%</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">\text{PPR}=\frac{N_{\text{orig}}-N_{\text{adv}}}{N_{\text{orig}}}\times 100\%,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="N_{\text{orig}}" class="ltx_Math" display="inline" id="S5.SS1.p2.m1" intent=":literal"><semantics><msub><mi>N</mi><mtext>orig</mtext></msub><annotation encoding="application/x-tex">N_{\text{orig}}</annotation></semantics></math> represents the number of correct predictions on original images and <math alttext="N_{\text{adv}}" class="ltx_Math" display="inline" id="S5.SS1.p2.m2" intent=":literal"><semantics><msub><mi>N</mi><mtext>adv</mtext></msub><annotation encoding="application/x-tex">N_{\text{adv}}</annotation></semantics></math> denotes correct predictions on adversarial examples.
It’s worth noting that while some existing works use attack success rate (1 - adversarial accuracy) as their evaluation metric, this approach can conflate model inherent errors with successful attacks. Our metric specifically measures the reduction in correct predictions, eliminating this confounding factor. While this results in numerically lower reported values, it provides a more precise measure of true privacy protection effectiveness.
The PPR is normalized from <math alttext="0\%" class="ltx_Math" display="inline" id="S5.SS1.p2.m3" intent=":literal"><semantics><mrow><mn>0</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">0\%</annotation></semantics></math> to <math alttext="100\%" class="ltx_Math" display="inline" id="S5.SS1.p2.m4" intent=":literal"><semantics><mrow><mn>100</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">100\%</annotation></semantics></math>, with higher values indicating better protection performance.
We report both Top-1 accuracy (exact match) and Top-3 accuracy (correct answer within top three predictions) at each geographic granularity.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math intent=":literal" id="S5.SS1.p2.m1" display="inline" class="ltx_Math" alttext="N_{\text{orig}}"><semantics><msub><mi>N</mi><mtext>orig</mtext></msub><annotation encoding="application/x-tex">N_{\text{orig}}</annotation></semantics></math> 表示在原始图像上的正确预测数量， <math intent=":literal" id="S5.SS1.p2.m2" display="inline" class="ltx_Math" alttext="N_{\text{adv}}"><semantics><msub><mi>N</mi><mtext>adv</mtext></msub><annotation encoding="application/x-tex">N_{\text{adv}}</annotation></semantics></math> 表示在对抗样本上的正确预测。值得注意的是，虽然一些现有工作使用攻击成功率（1 - 对抗准确率）作为其评估指标，但这种方法可能会将模型的固有错误与成功的攻击混淆。我们的指标专门测量正确预测的减少量，消除了这种混杂因素。虽然这会导致报告的数值较低，但它提供了更精确的真正隐私保护有效性的度量。PPR 从 <math intent=":literal" id="S5.SS1.p2.m3" display="inline" class="ltx_Math" alttext="0\%"><semantics><mrow><mn>0</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">0\%</annotation></semantics></math> 归一化到 <math intent=":literal" id="S5.SS1.p2.m4" display="inline" class="ltx_Math" alttext="100\%"><semantics><mrow><mn>100</mn><mo>%</mo></mrow><annotation encoding="application/x-tex">100\%</annotation></semantics></math> ，数值越高表示保护性能越好。我们在每个地理粒度下都报告了 Top-1 准确率（精确匹配）和 Top-3 准确率（正确答案在预测的前三中）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Target Models</span>
Following the performance analysis in <span class="ltx_text ltx_font_smallcaps">DoxBench</span>, we evaluate on state-of-the-art MLRMs, including GPT-o3, Gemini 2.5 Pro, and QVQ-Max, and additionally supplement our evaluation with GPT-5, QwenVL Max, QwenVL-2.5-72B, and InternVL-3.0-72B.
All models are tested with their latest public versions under default parameter settings (e.g., temperatures).
For geographic queries, we use the standardized prompt from <span class="ltx_text ltx_font_smallcaps">DoxBench</span>: <span class="ltx_text ltx_font_italic">“Where is it?”</span> followed by output format instructions. Direct questioning yields better performance for GPT-o3, GPT-5, and Gemini 2.5 Pro, while CoT prompts prove more effective for other models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在 DoxBench 的性能分析之后，我们评估了最先进的 MLRM 模型，包括 GPT-o3、Gemini 2.5 Pro 和 QVQ-Max，并额外补充了 GPT-5、QwenVL Max、QwenVL-2.5-72B 和 InternVL-3.0-72B 的评估。所有模型均在默认参数设置（例如温度）下的最新公开版本上进行了测试。对于地理查询，我们使用了 DoxBench 的标准提示：“它在哪里？”随后是输出格式说明。直接提问对 GPT-o3、GPT-5 和 Gemini 2.5 Pro 的性能更好，而 CoT 提示对其他模型更有效。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Baselines</span>
We compare ReasonBreak against strong adversarial methods: AnyAttack&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2025anyattack</span>)</cite> and M-Attack&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2025frustratingly</span>)</cite>.
For AnyAttack, we utilize the officially released generator. For M-Attack, we employ CLIP ViT-B/32, ViT-L/14, and RN50 as ensemble surrogate models, with steps=50.
All baselines and our method are evaluated under <math alttext="L_{\infty}" class="ltx_Math" display="inline" id="S5.SS1.p4.m1" intent=":literal"><semantics><msub><mi>L</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">L_{\infty}</annotation></semantics></math> constraints with <math alttext="\epsilon\in{8/255,16/255}" class="ltx_Math" display="inline" id="S5.SS1.p4.m2" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>∈</mo><mrow><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow><mo>,</mo><mrow><mn>16</mn><mo>/</mo><mn>255</mn></mrow></mrow></mrow><annotation encoding="application/x-tex">\epsilon\in{8/255,16/255}</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基线 我们将 ReasonBreak 与强大的对抗方法进行比较：AnyAttack (zhang2025anyattack) 和 M-Attack (li2025frustratingly)。对于 AnyAttack，我们使用官方发布的生成器。对于 M-Attack，我们采用 CLIP ViT-B/32、ViT-L/14 和 RN50 作为集成替代模型，步数=50。所有基线和我们的方法均在 <math intent=":literal" id="S5.SS1.p4.m1" display="inline" class="ltx_Math" alttext="L_{\infty}"><semantics><msub><mi>L</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">L_{\infty}</annotation></semantics></math> 约束下使用 <math intent=":literal" id="S5.SS1.p4.m2" display="inline" class="ltx_Math" alttext="\epsilon\in{8/255,16/255}"><semantics><mrow><mi>ϵ</mi><mo>∈</mo><mrow><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow><mo>,</mo><mrow><mn>16</mn><mo>/</mo><mn>255</mn></mrow></mrow></mrow><annotation encoding="application/x-tex">\epsilon\in{8/255,16/255}</annotation></semantics></math> 进行评估。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Implementation Details</span>
For surrogate set <math alttext="\mathcal{S}" class="ltx_Math" display="inline" id="S5.SS1.p5.m1" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒮</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>, we use CLIP ViT-B/32, ViT-B/16, ViT-H/14, and ViT-L/14.
We freeze CLIP ViT-B/32 as the image encoder <math alttext="\psi_{i}" class="ltx_Math" display="inline" id="S5.SS1.p5.m2" intent=":literal"><semantics><msub><mi>ψ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\psi_{i}</annotation></semantics></math> and text encoder <math alttext="\psi_{t}" class="ltx_Math" display="inline" id="S5.SS1.p5.m3" intent=":literal"><semantics><msub><mi>ψ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\psi_{t}</annotation></semantics></math>.
The learnable decoder <math alttext="\mathcal{G}_{\theta}" class="ltx_Math" display="inline" id="S5.SS1.p5.m4" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> adopts the architecture from AnyAttack with pre-trained weight initialization.
It is trained on GeoPrivacy-6K for 2 epochs with <math alttext="N_{\text{max}}=64" class="ltx_Math" display="inline" id="S5.SS1.p5.m5" intent=":literal"><semantics><mrow><msub><mi>N</mi><mtext>max</mtext></msub><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">N_{\text{max}}=64</annotation></semantics></math> using AdamW with learning rate <math alttext="1\times 10^{-5}" class="ltx_Math" display="inline" id="S5.SS1.p5.m6" intent=":literal"><semantics><mrow><mn>1</mn><mo lspace="0.222em" rspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">1\times 10^{-5}</annotation></semantics></math>.
For images in <span class="ltx_text ltx_font_smallcaps">DoxBench</span> that are not part of our training dataset, we utilize Gemini Pro 2.5 with the same three-stage annotation protocol described in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S3" title="3 Dataset Construction ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">3</span></a> to automatically extract geographic concepts <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S5.SS1.p5.m7" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">𝒞</mi><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math> and their corresponding spatial bounding boxes <math alttext="\bm{g}" class="ltx_Math" display="inline" id="S5.SS1.p5.m8" intent=":literal"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math>. This ensures consistent concept-region mapping between training and testing phases.
The training process is conducted on a single NVIDIA A800 80GB GPU.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">实现细节对于替代集 <math intent=":literal" id="S5.SS1.p5.m1" display="inline" class="ltx_Math" alttext="\mathcal{S}"><semantics><mi class="ltx_font_mathcaligraphic">𝒮</mi><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math> ，我们使用 CLIP ViT-B/32、ViT-B/16、ViT-H/14 和 ViT-L/14。我们将 CLIP ViT-B/32 作为图像编码器 <math intent=":literal" id="S5.SS1.p5.m2" display="inline" class="ltx_Math" alttext="\psi_{i}"><semantics><msub><mi>ψ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\psi_{i}</annotation></semantics></math> 和文本编码器 <math intent=":literal" id="S5.SS1.p5.m3" display="inline" class="ltx_Math" alttext="\psi_{t}"><semantics><msub><mi>ψ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\psi_{t}</annotation></semantics></math> 进行冻结。可学习的解码器 <math intent=":literal" id="S5.SS1.p5.m4" display="inline" class="ltx_Math" alttext="\mathcal{G}_{\theta}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> 采用了 AnyAttack 的架构，并使用预训练权重初始化。它在 GeoPrivacy-6K 上使用 <math intent=":literal" id="S5.SS1.p5.m5" display="inline" class="ltx_Math" alttext="N_{\text{max}}=64"><semantics><mrow><msub><mi>N</mi><mtext>max</mtext></msub><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">N_{\text{max}}=64</annotation></semantics></math> 通过 AdamW 算法以学习率 <math intent=":literal" id="S5.SS1.p5.m6" display="inline" class="ltx_Math" alttext="1\times 10^{-5}"><semantics><mrow><mn>1</mn><mo rspace="0.222em" lspace="0.222em">×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">1\times 10^{-5}</annotation></semantics></math> 进行了 2 个 epoch 的训练。对于 DoxBench 中不属于我们训练数据集的图像，我们使用 Gemini Pro 2.5 并采用第 3 节中描述的三阶段标注协议，自动提取地理概念 <math intent=":literal" id="S5.SS1.p5.m7" display="inline" class="ltx_Math" alttext="\mathcal{C}"><semantics><mi class="ltx_font_mathcaligraphic">𝒞</mi><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math> 及其对应的空间边界框 <math intent=":literal" id="S5.SS1.p5.m8" display="inline" class="ltx_Math" alttext="\bm{g}"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math> 。这确保了训练和测试阶段之间概念-区域的映射一致性。训练过程在单个 NVIDIA A800 80GB GPU 上进行。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Main Results<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.2 主要结果</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.T1" title="Table 1 ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">1</span></a> evaluates ReasonBreak across seven state-of-the-art MLRMs using Top-1 and Top-3 accuracy metrics at four geographical granularities, demonstrating consistent superiority over existing adversarial methods (<math alttext="\epsilon=16" class="ltx_Math" display="inline" id="S5.SS2.p1.m1" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">\epsilon=16</annotation></semantics></math>). At the <em class="ltx_emph ltx_font_italic">Tract</em> and <em class="ltx_emph ltx_font_italic">Block</em> levels, where privacy threats are the most severe, ReasonBreak shows remarkable effectiveness. Our method achieves an average Top-1 PPR of 33.8% at the tract level, surpassing the strongest baseline (19.4%) by 14.4%. At the <em class="ltx_emph ltx_font_italic">Block</em> level, ReasonBreak nearly doubles the protection rate of baselines (33.5% vs. 16.8%). Notably, our method’s strong performance against commercial APIs demonstrates its particular effectiveness against powerful, closed-source models. For instance, on GPT-o3, our method boosts the Top-1 Tract-level PPR to 31.7%, compared to 25.6% from AnyAttack and 15.9% from M-Attack, and on Gemini 2.5 Pro, it achieves 30.8% where baselines only reach around 20%. Remarkably, while baseline methods fail to provide any protection at the Top-1 Block-level against Gemini 2.5 Pro, our method achieves a 23.3% PPR. These results validate our core hypothesis that targeting hierarchical reasoning processes through concept-aware perturbations provides fundamentally stronger defense than methods based on disrupting general perceptual features.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 1 评估了 ReasonBreak 在七个最先进的 MLRMs 上的表现，使用四个地理粒度下的 Top-1 和 Top-3 准确率指标，展示了其相较于现有对抗方法的持续优越性（ <math intent=":literal" id="S5.SS2.p1.m1" display="inline" class="ltx_Math" alttext="\epsilon=16"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">\epsilon=16</annotation></semantics></math> ）。在隐私威胁最严重的 Tract 和 Block 级别，ReasonBreak 显示出显著的有效性。我们的方法在 Tract 级别实现了平均 Top-1 PPR 为 33.8%，比最强的基线（19.4%）高出 14.4%。在 Block 级别，ReasonBreak 将基线的保护率几乎翻倍（33.5% vs. 16.8%）。值得注意的是，我们的方法在商业 API 上的优异表现证明了其对强大、闭源模型的特别有效性。例如，在 GPT-o3 上，我们的方法将 Top-1 Tract 级别的 PPR 提升至 31.7%，而 AnyAttack 为 25.6%，M-Attack 为 15.9%；在 Gemini 2.5 Pro 上，它达到了 30.8%，而基线仅达到约 20%。值得注意的是，基线方法在 Gemini 2 的 Top-1 Block 级别无法提供任何保护。5 我们的模型达到了 23.3%的 PPR。这些结果验证了我们的核心假设：通过概念感知扰动来针对分层推理过程，能够提供比基于破坏一般感知特征的方法更根本的防御。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S5.F4.sf1.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x3.png" width="761">
<figcaption class="ltx_caption ltx_centering" data-imt_insert_failed="1"><span class="ltx_tag ltx_tag_figure">(a) </span>GPT-o3</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S5.F4.sf2.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x4.png" width="761">
<figcaption class="ltx_caption ltx_centering" data-imt_insert_failed="1"><span class="ltx_tag ltx_tag_figure">(b) </span>GPT-5</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S5.F4.sf3.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x5.png" width="761">
<figcaption class="ltx_caption ltx_centering" data-imt_insert_failed="1"><span class="ltx_tag ltx_tag_figure">(c) </span>Gemini 2.5 Pro</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S5.F4.sf4.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x6.png" width="761">
<figcaption class="ltx_caption ltx_centering" data-imt_insert_failed="1"><span class="ltx_tag ltx_tag_figure">(d) </span>QVQ-Max</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S5.F4.sf5.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x7.png" width="761">
<figcaption class="ltx_caption ltx_centering" data-imt_insert_failed="1"><span class="ltx_tag ltx_tag_figure">(e) </span>QwenVL Max</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S5.F4.sf6.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x8.png" width="761">
<figcaption class="ltx_caption ltx_centering" data-imt_insert_failed="1"><span class="ltx_tag ltx_tag_figure">(f) </span>QwenVL 2.5 72B</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S5.F4.sf7.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x9.png" width="761">
<figcaption class="ltx_caption ltx_centering" data-imt_insert_failed="1"><span class="ltx_tag ltx_tag_figure">(g) </span>InternVL 3.0 72B</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.fig1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="573" id="S5.F4.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x10.png" width="761">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Privacy protection rates across different geographic granularity levels under different noise levels (<math alttext="\epsilon=16" class="ltx_Math" display="inline" id="S5.F4.m3" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">\epsilon=16</annotation></semantics></math> and <math alttext="\epsilon=8" class="ltx_Math" display="inline" id="S5.F4.m4" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">\epsilon=8</annotation></semantics></math>). Higher values indicate better privacy protection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 4：在不同噪声水平（ <math intent=":literal" id="S5.F4.m3" display="inline" class="ltx_Math" alttext="\epsilon=16"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">\epsilon=16</annotation></semantics></math> 和 <math intent=":literal" id="S5.F4.m4" display="inline" class="ltx_Math" alttext="\epsilon=8"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">\epsilon=8</annotation></semantics></math> ）下，不同地理粒度级别的隐私保护率。数值越高表示隐私保护效果越好。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Adversarial Scaling Properties<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.3 对抗性缩放特性</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p">To assess the robustness and imperceptibility trade-off, we evaluate performance under a stricter perturbation budget (<math alttext="\epsilon=8/255" class="ltx_Math" display="inline" id="S5.SS3.p1.m1" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=8/255</annotation></semantics></math>). The results, visualized in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.F4" title="Figure 4 ‣ 5.2 Main Results ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">4</span></a>, reveal two key insights. First, ReasonBreak demonstrates superior perturbation efficiency. While all methods show a predictable performance drop from <math alttext="\epsilon=16" class="ltx_Math" display="inline" id="S5.SS3.p1.m2" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">\epsilon=16</annotation></semantics></math> (solid bars) to <math alttext="\epsilon=8" class="ltx_Math" display="inline" id="S5.SS3.p1.m3" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">\epsilon=8</annotation></semantics></math> (hatched bars), the advantage of ReasonBreak over the baselines becomes even more pronounced.
For instance, on challenging models like Gemini 2.5 Pro, while the protection offered by baselines nearly vanishes at <math alttext="\epsilon=8" class="ltx_Math" display="inline" id="S5.SS3.p1.m4" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">\epsilon=8</annotation></semantics></math>, ReasonBreak maintains a consistently superior PPR. This indicates that our concept-aware approach can induce reasoning failures with more subtle, less perceptible noise, offering a better trade-off between privacy and visual quality.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了评估鲁棒性和不可察觉性之间的权衡，我们在更严格的扰动预算（ <math intent=":literal" id="S5.SS3.p1.m1" display="inline" class="ltx_Math" alttext="\epsilon=8/255"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=8/255</annotation></semantics></math> ）下评估性能。结果如图 4 所示，揭示了两个关键见解。首先，ReasonBreak 展示了更优越的扰动效率。虽然所有方法从 <math intent=":literal" id="S5.SS3.p1.m2" display="inline" class="ltx_Math" alttext="\epsilon=16"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">\epsilon=16</annotation></semantics></math> （实心条形图）到 <math intent=":literal" id="S5.SS3.p1.m3" display="inline" class="ltx_Math" alttext="\epsilon=8"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">\epsilon=8</annotation></semantics></math> （条纹条形图）都显示出可预测的性能下降，但 ReasonBreak 相对于基线的优势变得更加明显。例如，在像 Gemini 2.5 Pro 这样具有挑战性的模型上，当基线提供的保护在 <math intent=":literal" id="S5.SS3.p1.m4" display="inline" class="ltx_Math" alttext="\epsilon=8"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">\epsilon=8</annotation></semantics></math> 时几乎消失时，ReasonBreak 始终保持着更优越的 PPR。这表明我们的概念感知方法可以通过更微妙、更不易察觉的噪声诱导推理失败，从而在隐私和视觉质量之间提供了更好的权衡。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p">Second, we uncover a counter-intuitive scaling phenomenon unique to reasoning models. For InternVL (Fig.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.F4" title="Figure 4 ‣ 5.2 Main Results ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">4</span></a>g), ReasonBreak’s protection at the <em class="ltx_emph ltx_font_italic">Tract</em> and <em class="ltx_emph ltx_font_italic">Block</em> levels is substantially higher with the smaller perturbation (<math alttext="\epsilon=8" class="ltx_Math" display="inline" id="S5.SS3.p2.m1" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">\epsilon=8</annotation></semantics></math>) than with the larger one (<math alttext="\epsilon=16" class="ltx_Math" display="inline" id="S5.SS3.p2.m2" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">\epsilon=16</annotation></semantics></math>). This anomalous result, which is not observed for perception-focused baselines, suggests a distinct adversarial mechanism. We provide detailed analysis of this phenomenon in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A3" title="Appendix C Counter-intuitive Scaling Phenomena in Reasoning Models ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">C</span></a>. This finding underscores the fundamental difference between attacking perception and attacking reasoning, opening a compelling direction for future research.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其次，我们揭示了一种独特的、仅存在于推理模型中的反直觉的缩放现象。对于 InternVL（图 4g），ReasonBreak 在轨迹层和区块层上的保护效果，使用较小的扰动（ <math intent=":literal" id="S5.SS3.p2.m1" display="inline" class="ltx_Math" alttext="\epsilon=8"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">\epsilon=8</annotation></semantics></math> ）时显著高于使用较大的扰动（ <math intent=":literal" id="S5.SS3.p2.m2" display="inline" class="ltx_Math" alttext="\epsilon=16"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">\epsilon=16</annotation></semantics></math> ）。这一反常结果在以感知为重点的基线模型中并未观察到，这表明存在一种独特的对抗机制。我们在附录 C 中对这一现象进行了详细分析。这一发现强调了攻击感知与攻击推理之间的根本差异，为未来的研究开辟了一个引人入胜的方向。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Ablation Study<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.4 消融研究</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS4.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Influence of Adaptive Decomposition<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">自适应分解的影响</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS4.SSS0.Px1.p1">
<p class="ltx_p">A key component of our framework is the adaptive decomposition mechanism, controlled by the hyperparameter <math alttext="N_{max}" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px1.p1.m1" intent=":literal"><semantics><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">N_{max}</annotation></semantics></math>. To validate its importance, we conduct an ablation study analyzing how partitioning granularity affects protection performance against InternVL 3.0 72B. The results, shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.F5" title="Figure 5 ‣ Influence of Adaptive Decomposition ‣ 5.4 Ablation Study ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">5</span></a>, reveal a distinct unimodal performance curve for fine-grained geographic levels, confirming a critical trade-off governed by <math alttext="N_{max}" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px1.p1.m2" intent=":literal"><semantics><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">N_{max}</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们框架的一个关键组成部分是自适应分解机制，由超参数 <math intent=":literal" id="S5.SS4.SSS0.Px1.p1.m1" display="inline" class="ltx_Math" alttext="N_{max}"><semantics><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">N_{max}</annotation></semantics></math> 控制。为了验证其重要性，我们进行了一项消融研究，分析划分粒度如何影响对 InternVL 3.0 72B 的保护性能。结果如图 5 所示，揭示了细粒度地理层级上的独特单模态性能曲线，确认了由 <math intent=":literal" id="S5.SS4.SSS0.Px1.p1.m2" display="inline" class="ltx_Math" alttext="N_{max}"><semantics><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">N_{max}</annotation></semantics></math> 控制的一个关键权衡。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="288" id="S5.F5.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x11.png" width="403">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Ablation study on adaptive decomposition mechanism. Top-1 PPR across different values of <math alttext="N_{max}" class="ltx_Math" display="inline" id="S5.F5.m2" intent=":literal"><semantics><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">N_{max}</annotation></semantics></math>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 5：自适应分解机制的消融研究。不同 <math intent=":literal" id="S5.F5.m2" display="inline" class="ltx_Math" alttext="N_{max}"><semantics><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><annotation encoding="application/x-tex">N_{max}</annotation></semantics></math> 值下的 Top-1 PPR。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS4.SSS0.Px1.p2">
<p class="ltx_p">When partitioning is too coarse (<math alttext="N_{max}\leq 4" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px1.p2.m1" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">N_{max}\leq 4</annotation></semantics></math>), we observe suboptimal protection at the <em class="ltx_emph ltx_font_italic">Block</em> and <em class="ltx_emph ltx_font_italic">Tract</em> levels (<math alttext="N_{max}=1" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px1.p2.m2" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">N_{max}=1</annotation></semantics></math> represents complete removal of the adaptive decomposition mechanism). This leads to concept entanglement where distinct visual cues (e.g., a storefront sign and a unique architectural style) are merged into a single block. Conversely, overly fine-grained partitioning (<math alttext="N_{max}&gt;64" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px1.p2.m3" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><mo>&gt;</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">N_{max}&gt;64</annotation></semantics></math>) causes sharp performance degradation.
This concept fragmentation breaks semantically coherent objects into meaningless patches, preventing our method from targeting the complete visual concepts that form the basis of the MLRM’s reasoning steps. For example, a landmark building is no longer recognized as a whole, but as a collection of disconnected textures and edges.
Notably, performance on macroscopic metrics like Region and Metro. remains comparatively strong at coarse granularities (<math alttext="N_{max}\leq 4" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px1.p2.m4" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">N_{max}\leq 4</annotation></semantics></math>), as they do not depend on such fine-grained features. Performance peaks in the optimal range of <math alttext="16\leq N_{max}\leq 64" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px1.p2.m5" intent=":literal"><semantics><mrow><mn>16</mn><mo>≤</mo><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><mo>≤</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">16\leq N_{max}\leq 64</annotation></semantics></math>. This analysis validates our choice of <math alttext="N_{max}=64" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px1.p2.m6" intent=":literal"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo lspace="0em" rspace="0em">​</mo><mi>a</mi><mo lspace="0em" rspace="0em">​</mo><mi>x</mi></mrow></msub><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">N_{max}=64</annotation></semantics></math>, which strikes the optimal balance between isolating concepts and preserving their meaning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">当划分过于粗略（ <math intent=":literal" id="S5.SS4.SSS0.Px1.p2.m1" display="inline" class="ltx_Math" alttext="N_{max}\leq 4"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">N_{max}\leq 4</annotation></semantics></math> ）时，我们在街区（Block）和地块（Tract）级别观察到保护效果不佳（ <math intent=":literal" id="S5.SS4.SSS0.Px1.p2.m2" display="inline" class="ltx_Math" alttext="N_{max}=1"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">N_{max}=1</annotation></semantics></math> 表示完全移除自适应分解机制）。这会导致概念纠缠，其中不同的视觉线索（例如，一家商店的招牌和独特的建筑风格）被合并成一个街区。相反，过于细粒度的划分（ <math intent=":literal" id="S5.SS4.SSS0.Px1.p2.m3" display="inline" class="ltx_Math" alttext="N_{max}&gt;64"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><mo>&gt;</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">N_{max}&gt;64</annotation></semantics></math> ）会导致性能急剧下降。这种概念碎片化将语义连贯的对象分解成无意义的碎片，阻止我们的方法针对构成 MLRM 推理步骤基础的完整视觉概念。例如，一座地标建筑不再被视为一个整体，而是被看作是互不连接的纹理和边缘的集合。值得注意的是，在粗粒度（ <math intent=":literal" id="S5.SS4.SSS0.Px1.p2.m4" display="inline" class="ltx_Math" alttext="N_{max}\leq 4"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">N_{max}\leq 4</annotation></semantics></math> ）下，宏观指标（如区域和都市）的性能仍然相对较强，因为它们不依赖于如此细粒度的特征。性能在 <math intent=":literal" id="S5.SS4.SSS0.Px1.p2.m5" display="inline" class="ltx_Math" alttext="16\leq N_{max}\leq 64"><semantics><mrow><mn>16</mn><mo>≤</mo><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><mo>≤</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">16\leq N_{max}\leq 64</annotation></semantics></math> 的最佳范围内达到峰值。这项分析验证了我们选择 <math intent=":literal" id="S5.SS4.SSS0.Px1.p2.m6" display="inline" class="ltx_Math" alttext="N_{max}=64"><semantics><mrow><msub><mi>N</mi><mrow><mi>m</mi><mo rspace="0em" lspace="0em">​</mo><mi>a</mi><mo rspace="0em" lspace="0em">​</mo><mi>x</mi></mrow></msub><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">N_{max}=64</annotation></semantics></math> 的合理性，它在隔离概念和保留其意义之间取得了最佳平衡。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS4.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Influence of Minimax Target Selection<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">极小极大目标选择的影响</font></font></font></h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table ltx_align_floatright" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Ablation study on minimax target selection. Top-1 PPR w/ and w/o minimax target selection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 2：极小极大目标选择消融研究。Top-1 PPR 带和不带极小极大目标选择。</font></font></font></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_border_tt"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span class="ltx_text ltx_font_bold">Privacy Protection Rate (%)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">隐私保护率（%）</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">Method<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">方法</font></font></font></span></td>
<td class="ltx_td ltx_align_left ltx_border_t">Region<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">区域</font></font></font></td>
<td class="ltx_td ltx_align_left ltx_border_t">Metro.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">地铁。</font></font></font></td>
<td class="ltx_td ltx_align_left ltx_border_t">Tract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">地块。</font></font></font></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Block<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">街区。</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">w/ Minimax<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">带极小极大算法</font></font></font></td>
<td class="ltx_td ltx_align_left ltx_border_t"><math alttext="10.8" class="ltx_Math" display="inline" id="S5.T2.m1" intent=":literal"><semantics><mn>10.8</mn><annotation encoding="application/x-tex">10.8</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_t"><math alttext="0.0" class="ltx_Math" display="inline" id="S5.T2.m2" intent=":literal"><semantics><mn>0.0</mn><annotation encoding="application/x-tex">0.0</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_border_t"><math alttext="33.3" class="ltx_Math" display="inline" id="S5.T2.m3" intent=":literal"><semantics><mn>33.3</mn><annotation encoding="application/x-tex">33.3</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"><math alttext="58.3" class="ltx_Math" display="inline" id="S5.T2.m4" intent=":literal"><semantics><mn>58.3</mn><annotation encoding="application/x-tex">58.3</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">w/o Minimax<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">不带极小极大算法</font></font></font></td>
<td class="ltx_td ltx_align_left"><math alttext="9.3" class="ltx_Math" display="inline" id="S5.T2.m5" intent=":literal"><semantics><mn>9.3</mn><annotation encoding="application/x-tex">9.3</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left"><math alttext="0.0" class="ltx_Math" display="inline" id="S5.T2.m6" intent=":literal"><semantics><mn>0.0</mn><annotation encoding="application/x-tex">0.0</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left"><math alttext="26.7" class="ltx_Math" display="inline" id="S5.T2.m7" intent=":literal"><semantics><mn>26.7</mn><annotation encoding="application/x-tex">26.7</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_r ltx_align_left"><math alttext="33.3" class="ltx_Math" display="inline" id="S5.T2.m8" intent=":literal"><semantics><mn>33.3</mn><annotation encoding="application/x-tex">33.3</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_italic">Improvement <math alttext="\Delta" class="ltx_Math" display="inline" id="S5.T2.m9" intent=":literal"><semantics><mi mathvariant="normal">Δ</mi><annotation encoding="application/x-tex">\Delta</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在 0#处的改进</font></font></font></span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">+1.5</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" data-imt_insert_failed="1">—</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">+6.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t"><span class="ltx_text ltx_font_bold">+25.0</span></td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS4.SSS0.Px2.p1">
<p class="ltx_p">Another critical component of our framework is the minimax target selection. To validate its effectiveness, we conduct an ablation study analyzing its impact on privacy protection performance. Specifically, we compare our approach using <math alttext="\mathbf{e}_{\text{prior}}^{k}" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px2.p1.m1" intent=":literal"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math> from <a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S4.E4" title="In Minimax Target Selection ‣ 4.3 ReasonBreak ‣ 4 Method ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a> against a baseline where <math alttext="\mathbf{e}_{\text{prior}}^{k}" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px2.p1.m2" intent=":literal"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math> is replaced with <math alttext="\psi_{i}(B_{k})" class="ltx_Math" display="inline" id="S5.SS4.SSS0.Px2.p1.m3" intent=":literal"><semantics><mrow><msub><mi>ψ</mi><mi>i</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>B</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\psi_{i}(B_{k})</annotation></semantics></math>, effectively reducing it to a general untargeted adversarial attack. Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.T2" title="Table 2 ‣ Influence of Minimax Target Selection ‣ 5.4 Ablation Study ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">2</span></a> presents the Top-1 PPR results on InternVL 3.0 72B. The results demonstrate that our minimax target selection strategy significantly improves protection effectiveness, particularly at finer geographic granularities. The improvement is most pronounced at the Block level (+25.0%) and remains substantial at the Tract level (+6.6%), while maintaining comparable performance at coarser scales. These findings confirm that our concept-aware targeting approach more effectively disrupts the model’s hierarchical reasoning process compared to traditional untargeted perturbations.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们框架的另一个关键组件是极小极大目标选择。为了验证其有效性，我们进行了一项消融研究，分析其对隐私保护性能的影响。具体而言，我们使用方程 4 中的 <math intent=":literal" id="S5.SS4.SSS0.Px2.p1.m1" display="inline" class="ltx_Math" alttext="\mathbf{e}_{\text{prior}}^{k}"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math> 与将 <math intent=":literal" id="S5.SS4.SSS0.Px2.p1.m2" display="inline" class="ltx_Math" alttext="\mathbf{e}_{\text{prior}}^{k}"><semantics><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}</annotation></semantics></math> 替换为 <math intent=":literal" id="S5.SS4.SSS0.Px2.p1.m3" display="inline" class="ltx_Math" alttext="\psi_{i}(B_{k})"><semantics><mrow><msub><mi>ψ</mi><mi>i</mi></msub><mo rspace="0em" lspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msub><mi>B</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\psi_{i}(B_{k})</annotation></semantics></math> 的基线方法进行比较，后者有效地将其简化为一般的非目标对抗攻击。表 2 展示了在 InternVL 3.0 72B 上的 Top-1 PPR 结果。结果表明，我们的极小极大目标选择策略显著提高了保护效果，尤其是在更精细的地理粒度上。改进在街区级别最为明显（+25.0%），在区级别仍然显著（+6.6%），同时在较粗的尺度上保持相当的性能。这些发现证实，我们的概念感知目标方法比传统的非目标扰动更有效地破坏了模型的层次推理过程。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Limitations and Failure Case Analysis<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.5 局限性及失败案例分析</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS5.p1">
<p class="ltx_p">To rigorously define the boundary conditions of our method, we conducted a failure case analysis on images where protection failed across all seven target MLRMs. This analysis revealed only two such instances in the DoxBench dataset, shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.F6" title="Figure 6 ‣ 5.5 Limitations and Failure Case Analysis ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">6</span></a>. A qualitative inspection reveals a common property: both images contain dominant, high-saliency, machine-readable text (e.g., “1565, B46, Google”,) that explicitly names the location. This highlights a fundamental dichotomy in the MLRM’s inference modality.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了严格定义我们方法的有效边界条件，我们对所有七个目标 MLRM 均失效的图像进行了失效案例分析。该分析显示，在 DoxBench 数据集中只有两个这样的案例，如图 6 所示。定性检查揭示了一个共同特征：两张图像都包含显著、高显著性、机器可读的文本（例如，“1565, B46, Google”），这些文本明确指出了位置。这突显了 MLRM 推理模式中的一个基本二分法。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S5.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.fig1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="411" id="S5.F6.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/460.jpg" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.fig2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="411" id="S5.F6.g2" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/391.jpg" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The two failure cases from DoxBench where all seven MLRMs correctly inferred the location. Both images contain machine-readable text that explicitly names the location.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 6：DoxBench 中的两个失败案例，其中所有七个 MLRM 都正确推断出了位置。两张图片都包含机器可读的文本，明确标明了位置。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS5.p2">
<p class="ltx_p">ReasonBreak is designed to disrupt hierarchical geographic reasoning by targeting the fragile visual-conceptual links (e.g., <span class="ltx_text ltx_font_italic">architectural style</span> <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S5.SS5.p2.m1" intent=":literal"><semantics><mo stretchy="false">→</mo><annotation encoding="application/x-tex">\rightarrow</annotation></semantics></math> <span class="ltx_text ltx_font_italic">region</span>). In these cases, the MLRMs shift their inference modality. They bypass the conceptual reasoning chain and instead leverage their optical character recognition (OCR) capabilities to extract the location directly from the text.
Our framework was not designed to target this OCR modality. Defeating a robust OCR module under a strict imperceptibility constraint is an orthogonal challenge, likely requiring perceptible, text-targeted modifications. This analysis thus defines a clear boundary for our approach: ReasonBreak does not counter direct text-based identification, which we identify as a distinct problem for future work.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ReasonBreak 旨在通过攻击脆弱的视觉概念链接（例如，建筑风格 <math intent=":literal" id="S5.SS5.p2.m1" display="inline" class="ltx_Math" alttext="\rightarrow"><semantics><mo stretchy="false">→</mo><annotation encoding="application/x-tex">\rightarrow</annotation></semantics></math> 地区）来破坏层次地理推理。在这种情况下，多模态推理模型（MLRMs）会转换其推理模式。它们绕过概念推理链，转而利用其光学字符识别（OCR）功能直接从文本中提取位置。我们的框架并非设计用来针对这种 OCR 模式。在严格的不可感知性约束下击败一个强大的 OCR 模块是一项正交挑战，很可能需要可感知的、针对文本的修改。因此，这项分析为我们的方法定义了一个明确的边界：ReasonBreak 不针对直接基于文本的识别，我们将此识别为未来工作的一个独立问题。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6 结论</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p">In this work, we identified and addressed a critical privacy vulnerability in modern MLRMs: their ability to infer precise geographic locations by reasoning over visual concepts. We argued that existing privacy defenses, which target perception, are insufficient for this new threat. We proposed ReasonBreak, a novel adversarial framework that, for the first time, disrupts the model’s hierarchical reasoning process directly. By targeting specific visual concepts in the model’s chain-of-thought, ReasonBreak provides significantly better protection than state-of-the-art baselines. To facilitate this, we also constructed and released GeoPrivacy-6K, an ultra-high-resolution dataset with rich conceptual annotations. Our extensive experiments on seven leading MLRMs demonstrate the effectiveness and robustness of our approach. This work opens a new direction for privacy research, shifting the focus from perceptual disruption to reasoning-level intervention.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在这项工作中，我们识别并解决了一个现代多模态推理模型（MLRM）中的关键隐私漏洞：它们通过推理视觉概念来推断精确的地理位置。我们指出，现有的针对感知的隐私防御措施对于这种新威胁是不够的。我们提出了 ReasonBreak，一个首次直接干扰模型层次推理过程的新型对抗性框架。通过针对模型思维链中的特定视觉概念，ReasonBreak 比最先进的基线提供了显著更好的保护。为了实现这一目标，我们还构建并发布了 GeoPrivacy-6K，这是一个具有丰富概念标注的超高分辨率数据集。我们在七个领先的多模态推理模型上的大量实验证明了我们方法的有效性和鲁棒性。这项工作为隐私研究开辟了新的方向，将重点从感知干扰转向推理级别的干预。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Reproducibility Statement<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">可复现性声明</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p">To ensure reproducibility and practical deployment, we provide comprehensive computational requirements and resource specifications:
<span class="ltx_text ltx_font_bold">(i) Training Efficiency</span>: The complete training of ReasonBreak on GeoPrivacy-6K requires approximately 6-8 hours on a single A800 80GB GPU. The lightweight decoder architecture and efficient ensemble training make the method accessible to researchers with standard GPU resources.
<span class="ltx_text ltx_font_bold">(ii) Inference Requirements</span>: For practical deployment, we will release pre-trained generator weights that enable direct adversarial image generation. The inference process requires only 24GB of GPU memory and generates adversarial examples in under <math alttext="\leq" class="ltx_Math" display="inline" id="Sx1.p1.m1" intent=":literal"><semantics><mo>≤</mo><annotation encoding="application/x-tex">\leq</annotation></semantics></math> 1 seconds per image, making it suitable for real-time privacy protection applications.
<span class="ltx_text ltx_font_bold">(iii)Evaluation Costs</span>: The primary computational expense lies in evaluation across multiple MLRMs. Commercial API calls, particularly GPT-o3, GPT-5, and Gemini 2.5 Pro, incur non-trivial costs, generally on the order of one to several thousand dollars. Deploying open-source models like InternVL 3.0 72B requires approximately 144GB of GPU memory (typically two A800 80GB GPUs with tensor parallelism). We will release the code, pre-trained model weights, and the GeoPrivacy-6K dataset.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为确保可复现性和实际部署，我们提供了全面的计算需求和资源规格：(i) 训练效率：在单个 A800 80GB GPU 上，ReasonBreak 在 GeoPrivacy-6K 上的完整训练需要大约 6-8 小时。轻量级解码器架构和高效的集成训练使得该方法适用于拥有标准 GPU 资源的科研人员。(ii) 推理需求：为实际部署，我们将发布预训练的生成器权重，以实现直接对抗性图像生成。推理过程仅需 24GB 的 GPU 内存，每张图像生成对抗样本的时间不到 1 秒，适合实时隐私保护应用。(iii) 评估成本：主要的计算开销在于跨多个 MLRM 的评估。商业 API 调用，特别是 GPT-o3、GPT-5 和 Gemini 2.5 Pro，会产生不小的成本，通常在 1 到数千美元之间。部署 InternVL 3.0 72B 等开源模型需要大约 144GB 的 GPU 内存（通常需要两块 A800 80GB GPU 进行张量并行）。 我们将发布代码、预训练模型权重以及 GeoPrivacy-6K 数据集。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Ethical Considerations<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">伦理考量</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="Sx2.p1">
<p class="ltx_p">While ReasonBreak provides crucial privacy protection against unauthorized geographic inference, we acknowledge the dual-use potential of adversarial techniques. Our method could potentially be misused to evade legitimate content moderation.
We establish concrete guidelines for responsible use: <span class="ltx_text ltx_font_bold">(i)</span> ReasonBreak should only be used to protect legitimate privacy rights of individuals sharing personal content; <span class="ltx_text ltx_font_bold">(ii)</span> The technology should not be employed to circumvent legal investigations or regulatory compliance; <span class="ltx_text ltx_font_bold">(iii)</span> Platform providers should consider implementing detection mechanisms for adversarially modified content when legally required.
This work contributes to the broader goal of privacy-preserving AI by demonstrating that reasoning-based privacy threats can be effectively countered, encouraging the development of privacy-aware MLRM architectures.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">虽然 ReasonBreak 提供了关键的隐私保护，防止未经授权的地理推理，但我们承认对抗性技术的双重用途潜力。我们的方法可能被误用以规避合法的内容审核。我们制定了具体的责任使用指南：(i) ReasonBreak 只能用于保护个人分享个人内容时的合法隐私权；(ii) 该技术不应被用于规避法律调查或合规要求；(iii) 平台提供者应在法律要求时考虑实施对抗性修改内容的检测机制。这项工作通过证明基于推理的隐私威胁可以被有效对抗，为隐私保护型 AI 的更广泛目标做出了贡献，并鼓励了隐私感知型 MLRM 架构的开发。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">LLM Usage<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLM 使用</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="Ax1.p1">
<p class="ltx_p">We employed LLMs as a general-purpose assistive tool of this work.
Specifically, LLMs were used to (i) suggest alternative phrasings and improve the clarity of exposition, and (ii) assist in coding.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们使用 LLMs 作为这项工作的通用辅助工具。具体来说，LLMs 用于（i）提出替代短语并提高论述的清晰度，以及（ii）协助编码。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold">Algorithm 1</span> </span> ReasonBreak Adversarial Image Generation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">算法 1 ReasonBreak 对抗图像生成</font></font></font></figcaption>
<div class="ltx_listing ltx_listing">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline">1:</span><span class="ltx_text ltx_font_bold">Input:</span> Image <math alttext="I" class="ltx_Math" display="inline" id="alg1.l1.m1" intent=":literal"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>, geographic concepts <math alttext="\bm{c}" class="ltx_Math" display="inline" id="alg1.l1.m2" intent=":literal"><semantics><mi>𝒄</mi><annotation encoding="application/x-tex">\bm{c}</annotation></semantics></math> and bounding boxes <math alttext="\bm{g}" class="ltx_Math" display="inline" id="alg1.l1.m3" intent=":literal"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math> for <math alttext="I" class="ltx_Math" display="inline" id="alg1.l1.m4" intent=":literal"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math>, trained decoder <math alttext="\mathcal{G}_{\theta}" class="ltx_Math" display="inline" id="alg1.l1.m5" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math>, pre-computed embedding bank <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="alg1.l1.m6" intent=":literal"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math>, pre-trained text encoder <math alttext="\psi_{t}" class="ltx_Math" display="inline" id="alg1.l1.m7" intent=":literal"><semantics><msub><mi>ψ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\psi_{t}</annotation></semantics></math>, perturbation budget <math alttext="\epsilon" class="ltx_Math" display="inline" id="alg1.l1.m8" intent=":literal"><semantics><mi>ϵ</mi><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math>, max blocks <math alttext="N_{\text{max}}" class="ltx_Math" display="inline" id="alg1.l1.m9" intent=":literal"><semantics><msub><mi>N</mi><mtext>max</mtext></msub><annotation encoding="application/x-tex">N_{\text{max}}</annotation></semantics></math>.

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1:输入：图像 <math intent=":literal" id="alg1.l1.m1" display="inline" class="ltx_Math" alttext="I"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> ，地理概念 <math intent=":literal" id="alg1.l1.m2" display="inline" class="ltx_Math" alttext="\bm{c}"><semantics><mi>𝒄</mi><annotation encoding="application/x-tex">\bm{c}</annotation></semantics></math> 和边界框 <math intent=":literal" id="alg1.l1.m3" display="inline" class="ltx_Math" alttext="\bm{g}"><semantics><mi>𝒈</mi><annotation encoding="application/x-tex">\bm{g}</annotation></semantics></math> 对于 <math intent=":literal" id="alg1.l1.m4" display="inline" class="ltx_Math" alttext="I"><semantics><mi>I</mi><annotation encoding="application/x-tex">I</annotation></semantics></math> ，训练好的解码器 <math intent=":literal" id="alg1.l1.m5" display="inline" class="ltx_Math" alttext="\mathcal{G}_{\theta}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> ，预计算的嵌入库 <math intent=":literal" id="alg1.l1.m6" display="inline" class="ltx_Math" alttext="\mathcal{E}"><semantics><mi class="ltx_font_mathcaligraphic">ℰ</mi><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math> ，预训练的文本编码器 <math intent=":literal" id="alg1.l1.m7" display="inline" class="ltx_Math" alttext="\psi_{t}"><semantics><msub><mi>ψ</mi><mi>t</mi></msub><annotation encoding="application/x-tex">\psi_{t}</annotation></semantics></math> ，扰动预算 <math intent=":literal" id="alg1.l1.m8" display="inline" class="ltx_Math" alttext="\epsilon"><semantics><mi>ϵ</mi><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math> ，最大块数 <math intent=":literal" id="alg1.l1.m9" display="inline" class="ltx_Math" alttext="N_{\text{max}}"><semantics><msub><mi>N</mi><mtext>max</mtext></msub><annotation encoding="application/x-tex">N_{\text{max}}</annotation></semantics></math> 。</font></font></font></div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline">2:</span><span class="ltx_text ltx_font_bold">Output:</span> Adversarial image <math alttext="I^{\prime}" class="ltx_Math" display="inline" id="alg1.l2.m1" intent=":literal"><semantics><msup><mi>I</mi><mo>′</mo></msup><annotation encoding="application/x-tex">I^{\prime}</annotation></semantics></math>.

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2:输出：对抗图像 <math intent=":literal" id="alg1.l2.m1" display="inline" class="ltx_Math" alttext="I^{\prime}"><semantics><msup><mi>I</mi><mo>′</mo></msup><annotation encoding="application/x-tex">I^{\prime}</annotation></semantics></math> 。</font></font></font></div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span><span class="ltx_text ltx_font_bold">procedure</span> <span class="ltx_text ltx_font_smallcaps">ReasonBreak-Generate</span>(<math alttext="I,\bm{c},\bm{g},\mathcal{G}_{\theta},\mathcal{E},\psi_{t},\epsilon,N_{\text{max}}" class="ltx_Math" display="inline" id="alg1.l3.m1" intent=":literal"><semantics><mrow><mi>I</mi><mo>,</mo><mi>𝒄</mi><mo>,</mo><mi>𝒈</mi><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><mo>,</mo><mi class="ltx_font_mathcaligraphic">ℰ</mi><mo>,</mo><msub><mi>ψ</mi><mi>t</mi></msub><mo>,</mo><mi>ϵ</mi><mo>,</mo><msub><mi>N</mi><mtext>max</mtext></msub></mrow><annotation encoding="application/x-tex">I,\bm{c},\bm{g},\mathcal{G}_{\theta},\mathcal{E},\psi_{t},\epsilon,N_{\text{max}}</annotation></semantics></math>)

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3:过程 ReasonBreak-Generate( <math intent=":literal" id="alg1.l3.m1" display="inline" class="ltx_Math" alttext="I,\bm{c},\bm{g},\mathcal{G}_{\theta},\mathcal{E},\psi_{t},\epsilon,N_{\text{max}}"><semantics><mrow><mi>I</mi><mo>,</mo><mi>𝒄</mi><mo>,</mo><mi>𝒈</mi><mo>,</mo><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><mo>,</mo><mi class="ltx_font_mathcaligraphic">ℰ</mi><mo>,</mo><msub><mi>ψ</mi><mi>t</mi></msub><mo>,</mo><mi>ϵ</mi><mo>,</mo><msub><mi>N</mi><mtext>max</mtext></msub></mrow><annotation encoding="application/x-tex">I,\bm{c},\bm{g},\mathcal{G}_{\theta},\mathcal{E},\psi_{t},\epsilon,N_{\text{max}}</annotation></semantics></math> ) </font></font></font></div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span>  <math alttext="\{B_{k}\}_{k=1}^{N}\leftarrow\text{AdaptiveDecomposition}(I,N_{\text{max}})" class="ltx_Math" display="inline" id="alg1.l4.m1" intent=":literal"><semantics><mrow><msubsup><mrow><mo stretchy="false">{</mo><msub><mi>B</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo stretchy="false">←</mo><mrow><mtext>AdaptiveDecomposition</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>I</mi><mo>,</mo><msub><mi>N</mi><mtext>max</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\{B_{k}\}_{k=1}^{N}\leftarrow\text{AdaptiveDecomposition}(I,N_{\text{max}})</annotation></semantics></math> <span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l4.m2" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> Equation 3
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="alg1.l4.m2" display="inline" class="ltx_Math" alttext="\triangleright"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> 公式 3 </font></font></font></span>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span>  <math alttext="\{\mathcal{C}_{k}\}_{k=1}^{N}\leftarrow\text{AssignConcepts}(\{B_{k}\},\bm{c},\bm{g})" class="ltx_Math" display="inline" id="alg1.l5.m1" intent=":literal"><semantics><mrow><msubsup><mrow><mo stretchy="false">{</mo><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo stretchy="false">←</mo><mrow><mtext>AssignConcepts</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mo stretchy="false">{</mo><msub><mi>B</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mo>,</mo><mi>𝒄</mi><mo>,</mo><mi>𝒈</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\{\mathcal{C}_{k}\}_{k=1}^{N}\leftarrow\text{AssignConcepts}(\{B_{k}\},\bm{c},\bm{g})</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline">6:</span>  <math alttext="\{\hat{B}_{k}\}_{k=1}^{N}\leftarrow\text{empty list}" class="ltx_Math" display="inline" id="alg1.l6.m1" intent=":literal"><semantics><mrow><msubsup><mrow><mo stretchy="false">{</mo><msub><mover accent="true"><mi>B</mi><mo>^</mo></mover><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo stretchy="false">←</mo><mtext>empty list</mtext></mrow><annotation encoding="application/x-tex">\{\hat{B}_{k}\}_{k=1}^{N}\leftarrow\text{empty list}</annotation></semantics></math> <span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l6.m2" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> To store perturbed blocks
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="alg1.l6.m2" display="inline" class="ltx_Math" alttext="\triangleright"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> 用于存储扰动块 </font></font></font></span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span>  <span class="ltx_text ltx_font_bold">for</span> each block <math alttext="B_{k}" class="ltx_Math" display="inline" id="alg1.l7.m1" intent=":literal"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> and concept set <math alttext="\mathcal{C}_{k}" class="ltx_Math" display="inline" id="alg1.l7.m2" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> <span class="ltx_text ltx_font_bold">do</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7: 对每个块 <math intent=":literal" id="alg1.l7.m1" display="inline" class="ltx_Math" alttext="B_{k}"><semantics><msub><mi>B</mi><mi>k</mi></msub><annotation encoding="application/x-tex">B_{k}</annotation></semantics></math> 和概念集 <math intent=":literal" id="alg1.l7.m2" display="inline" class="ltx_Math" alttext="\mathcal{C}_{k}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\mathcal{C}_{k}</annotation></semantics></math> 进行循环</font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline">8:</span>   <math alttext="\mathbf{e}_{\text{prior}}^{k}\leftarrow\underset{\mathbf{e}\in\mathcal{E}}{\arg\min}\max_{c\in\mathcal{C}_{k}}\cos(\psi_{t}(c),\mathbf{e})" class="ltx_Math" display="inline" id="alg1.l8.m1" intent=":literal"><semantics><mrow><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><mo stretchy="false">←</mo><mrow><munder accentunder="true"><mrow><mi>arg</mi><mo lspace="0.167em">⁡</mo><mi>min</mi></mrow><mrow><mi>𝐞</mi><mo>∈</mo><mi class="ltx_font_mathcaligraphic">ℰ</mi></mrow></munder><mo lspace="0.167em" rspace="0em">​</mo><mrow><msub><mi>max</mi><mrow><mi>c</mi><mo>∈</mo><msub><mi class="ltx_font_mathcaligraphic">𝒞</mi><mi>k</mi></msub></mrow></msub><mo lspace="0.167em">⁡</mo><mrow><mi>cos</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mi>ψ</mi><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo><mi>𝐞</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding="application/x-tex">\mathbf{e}_{\text{prior}}^{k}\leftarrow\underset{\mathbf{e}\in\mathcal{E}}{\arg\min}\max_{c\in\mathcal{C}_{k}}\cos(\psi_{t}(c),\mathbf{e})</annotation></semantics></math> <span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l8.m2" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> Equation 4
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="alg1.l8.m2" display="inline" class="ltx_Math" alttext="\triangleright"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> 方程 4 </font></font></font></span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline">9:</span>   <math alttext="\delta_{k}\leftarrow\mathcal{G}_{\theta}(\mathbf{e}_{\text{prior}}^{k})" class="ltx_Math" display="inline" id="alg1.l9.m1" intent=":literal"><semantics><mrow><msub><mi>δ</mi><mi>k</mi></msub><mo stretchy="false">←</mo><mrow><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>𝐞</mi><mtext>prior</mtext><mi>k</mi></msubsup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\delta_{k}\leftarrow\mathcal{G}_{\theta}(\mathbf{e}_{\text{prior}}^{k})</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline">10:</span>   <math alttext="B^{\prime}_{k}\leftarrow B_{k}+\delta_{k}" class="ltx_Math" display="inline" id="alg1.l10.m1" intent=":literal"><semantics><mrow><msubsup><mi>B</mi><mi>k</mi><mo>′</mo></msubsup><mo stretchy="false">←</mo><mrow><msub><mi>B</mi><mi>k</mi></msub><mo>+</mo><msub><mi>δ</mi><mi>k</mi></msub></mrow></mrow><annotation encoding="application/x-tex">B^{\prime}_{k}\leftarrow B_{k}+\delta_{k}</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline">11:</span>   <math alttext="\hat{B}_{k}\leftarrow\text{clip}(B^{\prime}_{k},B_{k}-\epsilon,B_{k}+\epsilon)" class="ltx_Math" display="inline" id="alg1.l11.m1" intent=":literal"><semantics><mrow><msub><mover accent="true"><mi>B</mi><mo>^</mo></mover><mi>k</mi></msub><mo stretchy="false">←</mo><mrow><mtext>clip</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><msubsup><mi>B</mi><mi>k</mi><mo>′</mo></msubsup><mo>,</mo><mrow><msub><mi>B</mi><mi>k</mi></msub><mo>−</mo><mi>ϵ</mi></mrow><mo>,</mo><mrow><msub><mi>B</mi><mi>k</mi></msub><mo>+</mo><mi>ϵ</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\hat{B}_{k}\leftarrow\text{clip}(B^{\prime}_{k},B_{k}-\epsilon,B_{k}+\epsilon)</annotation></semantics></math> <span class="ltx_text" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l11.m2" intent=":literal"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> Enforce <math alttext="L_{\infty}" class="ltx_Math" display="inline" id="alg1.l11.m3" intent=":literal"><semantics><msub><mi>L</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">L_{\infty}</annotation></semantics></math> constraint
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="alg1.l11.m2" display="inline" class="ltx_Math" alttext="\triangleright"><semantics><mo>⊳</mo><annotation encoding="application/x-tex">\triangleright</annotation></semantics></math> 强制 <math intent=":literal" id="alg1.l11.m3" display="inline" class="ltx_Math" alttext="L_{\infty}"><semantics><msub><mi>L</mi><mi mathvariant="normal">∞</mi></msub><annotation encoding="application/x-tex">L_{\infty}</annotation></semantics></math> 约束</font></font></font></span>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline">12:</span>   Append <math alttext="\hat{B}_{k}" class="ltx_Math" display="inline" id="alg1.l12.m1" intent=":literal"><semantics><msub><mover accent="true"><mi>B</mi><mo>^</mo></mover><mi>k</mi></msub><annotation encoding="application/x-tex">\hat{B}_{k}</annotation></semantics></math> to <math alttext="\{\hat{B}_{k}\}" class="ltx_Math" display="inline" id="alg1.l12.m2" intent=":literal"><semantics><mrow><mo stretchy="false">{</mo><msub><mover accent="true"><mi>B</mi><mo>^</mo></mover><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\hat{B}_{k}\}</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">12: 将 <math intent=":literal" id="alg1.l12.m1" display="inline" class="ltx_Math" alttext="\hat{B}_{k}"><semantics><msub><mover accent="true"><mi>B</mi><mo>^</mo></mover><mi>k</mi></msub><annotation encoding="application/x-tex">\hat{B}_{k}</annotation></semantics></math> 添加到 <math intent=":literal" id="alg1.l12.m2" display="inline" class="ltx_Math" alttext="\{\hat{B}_{k}\}"><semantics><mrow><mo stretchy="false">{</mo><msub><mover accent="true"><mi>B</mi><mo>^</mo></mover><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\hat{B}_{k}\}</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l13">
<span class="ltx_tag ltx_tag_listingline">13:</span>  <span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">for</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">13: 结束循环</font></font></font>
</div>
<div class="ltx_listingline" id="alg1.l14">
<span class="ltx_tag ltx_tag_listingline">14:</span>  <math alttext="I^{\prime}\leftarrow\text{ReconstructImage}(\{\hat{B}_{k}\})" class="ltx_Math" display="inline" id="alg1.l14.m1" intent=":literal"><semantics><mrow><msup><mi>I</mi><mo>′</mo></msup><mo stretchy="false">←</mo><mrow><mtext>ReconstructImage</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mo stretchy="false">{</mo><msub><mover accent="true"><mi>B</mi><mo>^</mo></mover><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">I^{\prime}\leftarrow\text{ReconstructImage}(\{\hat{B}_{k}\})</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l15" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">15:</span>  <span class="ltx_text ltx_font_bold">return</span> <math alttext="I^{\prime}" class="ltx_Math" display="inline" id="alg1.l15.m1" intent=":literal"><semantics><msup><mi>I</mi><mo>′</mo></msup><annotation encoding="application/x-tex">I^{\prime}</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l16">
<span class="ltx_tag ltx_tag_listingline">16:</span><span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">procedure</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">16:end 程序</font></font></font>
</div>
</div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Decoder Architecture<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 ADecoder 架构</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.p1">
<p class="ltx_p">The architecture of our learnable decoder <math alttext="\mathcal{G}_{\theta}" class="ltx_Math" display="inline" id="A1.p1.m1" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math>, which translates a conceptual prior embedding into an adversarial perturbation, is detailed in Algorithm&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#alg2" title="Algorithm 2 ‣ Appendix A Decoder Architecture ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">2</span></a>. The decoder is primarily composed of a series of residual blocks (<span class="ltx_text ltx_font_typewriter">ResBlock</span>) and upsampling blocks (<span class="ltx_text ltx_font_typewriter">UpBlock</span>), as specified in Algorithms&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#alg3" title="Algorithm 3 ‣ Appendix A Decoder Architecture ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#alg4" title="Algorithm 4 ‣ Appendix A Decoder Architecture ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">4</span></a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的可学习解码器 <math intent=":literal" id="A1.p1.m1" display="inline" class="ltx_Math" alttext="\mathcal{G}_{\theta}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> 的架构，即将概念先验嵌入转换为对抗性扰动，在算法 2 中详细说明。解码器主要由一系列残差块（ResBlock）和上采样块（UpBlock）组成，如算法 3 和 4 所示。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold">Algorithm 2</span> </span> Decoder Architecture (<math alttext="\mathcal{G}_{\theta}" class="ltx_Math" display="inline" id="alg2.m2" intent=":literal"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math>)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">算法 2 解码器架构 ( <math intent=":literal" id="alg2.m2" display="inline" class="ltx_Math" alttext="\mathcal{G}_{\theta}"><semantics><msub><mi class="ltx_font_mathcaligraphic">𝒢</mi><mi>θ</mi></msub><annotation encoding="application/x-tex">\mathcal{G}_{\theta}</annotation></semantics></math> )</font></font></font></figcaption>
<div class="ltx_listing ltx_listing">
<div class="ltx_listingline" id="alg2.l1">
<span class="ltx_tag ltx_tag_listingline">1:</span>Input embedding <math alttext="\mathbf{e}\in\mathbb{R}^{B\times D}" class="ltx_Math" display="inline" id="alg2.l1.m1" intent=":literal"><semantics><mrow><mi>𝐞</mi><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>B</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>D</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{e}\in\mathbb{R}^{B\times D}</annotation></semantics></math>, where <math alttext="B" class="ltx_Math" display="inline" id="alg2.l1.m2" intent=":literal"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> is batch size and where <math alttext="D" class="ltx_Math" display="inline" id="alg2.l1.m3" intent=":literal"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math> is embedding size

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1:输入嵌入 <math intent=":literal" id="alg2.l1.m1" display="inline" class="ltx_Math" alttext="\mathbf{e}\in\mathbb{R}^{B\times D}"><semantics><mrow><mi>𝐞</mi><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>B</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mi>D</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathbf{e}\in\mathbb{R}^{B\times D}</annotation></semantics></math> ，其中 <math intent=":literal" id="alg2.l1.m2" display="inline" class="ltx_Math" alttext="B"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> 是批次大小， <math intent=":literal" id="alg2.l1.m3" display="inline" class="ltx_Math" alttext="D"><semantics><mi>D</mi><annotation encoding="application/x-tex">D</annotation></semantics></math> 是嵌入大小</font></font></font></div>
<div class="ltx_listingline" id="alg2.l2">
<span class="ltx_tag ltx_tag_listingline">2:</span>Target image size <math alttext="H,W" class="ltx_Math" display="inline" id="alg2.l2.m1" intent=":literal"><semantics><mrow><mi>H</mi><mo>,</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">H,W</annotation></semantics></math>, and target channels <math alttext="C" class="ltx_Math" display="inline" id="alg2.l2.m2" intent=":literal"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2:目标图像大小 <math intent=":literal" id="alg2.l2.m1" display="inline" class="ltx_Math" alttext="H,W"><semantics><mrow><mi>H</mi><mo>,</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">H,W</annotation></semantics></math> ，以及目标通道 <math intent=":literal" id="alg2.l2.m2" display="inline" class="ltx_Math" alttext="C"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg2.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span>Adversarial perturbation <math alttext="\delta\in\mathbb{R}^{B\times C\times H\times W}" class="ltx_Math" display="inline" id="alg2.l3.m1" intent=":literal"><semantics><mrow><mi>δ</mi><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>B</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>C</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>H</mi><mo lspace="0.222em" rspace="0.222em">×</mo><mi>W</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\delta\in\mathbb{R}^{B\times C\times H\times W}</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3:对抗扰动 <math intent=":literal" id="alg2.l3.m1" display="inline" class="ltx_Math" alttext="\delta\in\mathbb{R}^{B\times C\times H\times W}"><semantics><mrow><mi>δ</mi><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>B</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mi>C</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mi>H</mi><mo rspace="0.222em" lspace="0.222em">×</mo><mi>W</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\delta\in\mathbb{R}^{B\times C\times H\times W}</annotation></semantics></math> </font></font></font>
</div>
<div class="ltx_listingline" id="alg2.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span><math alttext="h_{\text{init}}\leftarrow H/16" class="ltx_Math" display="inline" id="alg2.l4.m1" intent=":literal"><semantics><mrow><msub><mi>h</mi><mtext>init</mtext></msub><mo stretchy="false">←</mo><mrow><mi>H</mi><mo>/</mo><mn>16</mn></mrow></mrow><annotation encoding="application/x-tex">h_{\text{init}}\leftarrow H/16</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span><math alttext="x\leftarrow\text{Linear}(\mathbf{e})" class="ltx_Math" display="inline" id="alg2.l5.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mrow><mtext>Linear</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>𝐞</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{Linear}(\mathbf{e})</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l6">
<span class="ltx_tag ltx_tag_listingline">6:</span><math alttext="x\leftarrow\text{Reshape}(x,(B,256,h_{\text{init}},h_{\text{init}}))" class="ltx_Math" display="inline" id="alg2.l6.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mrow><mtext>Reshape</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mrow><mo stretchy="false">(</mo><mi>B</mi><mo>,</mo><mn>256</mn><mo>,</mo><msub><mi>h</mi><mtext>init</mtext></msub><mo>,</mo><msub><mi>h</mi><mtext>init</mtext></msub><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{Reshape}(x,(B,256,h_{\text{init}},h_{\text{init}}))</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span><math alttext="x\leftarrow\text{ResBlock}(x,\text{in\_ch}=256,\text{out\_ch}=256)" class="ltx_math_unparsed" display="inline" id="alg2.l7.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>ResBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>256</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>256</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{ResBlock}(x,\text{in\_ch}=256,\text{out\_ch}=256)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l8">
<span class="ltx_tag ltx_tag_listingline">8:</span><math alttext="x\leftarrow\text{UpBlock}(x,\text{in\_ch}=256,\text{out\_ch}=128)" class="ltx_math_unparsed" display="inline" id="alg2.l8.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>UpBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>256</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>128</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{UpBlock}(x,\text{in\_ch}=256,\text{out\_ch}=128)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l9">
<span class="ltx_tag ltx_tag_listingline">9:</span><math alttext="x\leftarrow\text{ResBlock}(x,\text{in\_ch}=128,\text{out\_ch}=128)" class="ltx_math_unparsed" display="inline" id="alg2.l9.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>ResBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>128</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>128</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{ResBlock}(x,\text{in\_ch}=128,\text{out\_ch}=128)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l10">
<span class="ltx_tag ltx_tag_listingline">10:</span><math alttext="x\leftarrow\text{UpBlock}(x,\text{in\_ch}=128,\text{out\_ch}=64)" class="ltx_math_unparsed" display="inline" id="alg2.l10.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>UpBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>128</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>64</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{UpBlock}(x,\text{in\_ch}=128,\text{out\_ch}=64)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l11">
<span class="ltx_tag ltx_tag_listingline">11:</span><math alttext="x\leftarrow\text{ResBlock}(x,\text{in\_ch}=64,\text{out\_ch}=64)" class="ltx_math_unparsed" display="inline" id="alg2.l11.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>ResBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>64</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>64</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{ResBlock}(x,\text{in\_ch}=64,\text{out\_ch}=64)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l12">
<span class="ltx_tag ltx_tag_listingline">12:</span><math alttext="x\leftarrow\text{UpBlock}(x,\text{in\_ch}=64,\text{out\_ch}=32)" class="ltx_math_unparsed" display="inline" id="alg2.l12.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>UpBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>64</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>32</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{UpBlock}(x,\text{in\_ch}=64,\text{out\_ch}=32)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l13">
<span class="ltx_tag ltx_tag_listingline">13:</span><math alttext="x\leftarrow\text{ResBlock}(x,\text{in\_ch}=32,\text{out\_ch}=32)" class="ltx_math_unparsed" display="inline" id="alg2.l13.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>ResBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>32</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>32</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{ResBlock}(x,\text{in\_ch}=32,\text{out\_ch}=32)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l14">
<span class="ltx_tag ltx_tag_listingline">14:</span><math alttext="x\leftarrow\text{UpBlock}(x,\text{in\_ch}=32,\text{out\_ch}=16)" class="ltx_math_unparsed" display="inline" id="alg2.l14.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>UpBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>32</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>16</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{UpBlock}(x,\text{in\_ch}=32,\text{out\_ch}=16)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l15">
<span class="ltx_tag ltx_tag_listingline">15:</span><math alttext="x\leftarrow\text{ResBlock}(x,\text{in\_ch}=16,\text{out\_ch}=16)" class="ltx_math_unparsed" display="inline" id="alg2.l15.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>ResBlock</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>16</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mn>16</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{ResBlock}(x,\text{in\_ch}=16,\text{out\_ch}=16)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l16">
<span class="ltx_tag ltx_tag_listingline">16:</span><math alttext="x\leftarrow\text{Conv2d}(x,\text{in\_ch}=16,\text{out\_ch}=C,\text{kernel}=3,\text{padding}=1)" class="ltx_math_unparsed" display="inline" id="alg2.l16.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo stretchy="false">←</mo><mtext>Conv2d</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>=</mo><mn>16</mn><mo>,</mo><mtext>out_ch</mtext><mo>=</mo><mi>C</mi><mo>,</mo><mtext>kernel</mtext><mo>=</mo><mn>3</mn><mo>,</mo><mtext>padding</mtext><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">x\leftarrow\text{Conv2d}(x,\text{in\_ch}=16,\text{out\_ch}=C,\text{kernel}=3,\text{padding}=1)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l17">
<span class="ltx_tag ltx_tag_listingline">17:</span><math alttext="\delta\leftarrow\text{Tanh}(x)" class="ltx_Math" display="inline" id="alg2.l17.m1" intent=":literal"><semantics><mrow><mi>δ</mi><mo stretchy="false">←</mo><mrow><mtext>Tanh</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">\delta\leftarrow\text{Tanh}(x)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg2.l18">
<span class="ltx_tag ltx_tag_listingline">18:</span><span class="ltx_text ltx_font_bold">return</span> <math alttext="\delta" class="ltx_Math" display="inline" id="alg2.l18.m1" intent=":literal"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">18：返回 <math intent=":literal" id="alg2.l18.m1" display="inline" class="ltx_Math" alttext="\delta"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math> </font></font></font>
</div>
</div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold">Algorithm 3</span> </span> ResBlock Module<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">算法 3 ResBlock 模块</font></font></font></figcaption>
<div class="ltx_listing ltx_listing">
<div class="ltx_listingline" id="alg3.l1">
<span class="ltx_tag ltx_tag_listingline">1:</span><span class="ltx_text ltx_font_bold">procedure</span> <span class="ltx_text ltx_font_smallcaps">ResBlock</span>(<math alttext="x,\text{in\_ch},\text{out\_ch}" class="ltx_Math" display="inline" id="alg3.l1.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>,</mo><mtext>out_ch</mtext></mrow><annotation encoding="application/x-tex">x,\text{in\_ch},\text{out\_ch}</annotation></semantics></math>)

<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1:过程 ResBlock( <math intent=":literal" id="alg3.l1.m1" display="inline" class="ltx_Math" alttext="x,\text{in\_ch},\text{out\_ch}"><semantics><mrow><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>,</mo><mtext>out_ch</mtext></mrow><annotation encoding="application/x-tex">x,\text{in\_ch},\text{out\_ch}</annotation></semantics></math> )</font></font></font></div>
<div class="ltx_listingline" id="alg3.l2">
<span class="ltx_tag ltx_tag_listingline">2:</span>  <math alttext="r\leftarrow\text{Conv2d}(x,\text{in\_ch},\text{out\_ch},\text{kernel}=1)" class="ltx_Math" display="inline" id="alg3.l2.m1" intent=":literal"><semantics><mrow><mi>r</mi><mo stretchy="false">←</mo><mrow><mtext>Conv2d</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>,</mo><mtext>out_ch</mtext><mo>,</mo><mtext>kernel</mtext></mrow><mo>=</mo><mn>1</mn></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">r\leftarrow\text{Conv2d}(x,\text{in\_ch},\text{out\_ch},\text{kernel}=1)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span>  <math alttext="h\leftarrow\text{Conv2d}(x,\text{in\_ch},\text{out\_ch},\text{kernel}=3,\text{padding}=1)" class="ltx_math_unparsed" display="inline" id="alg3.l3.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mtext>Conv2d</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>,</mo><mtext>out_ch</mtext><mo>,</mo><mtext>kernel</mtext><mo>=</mo><mn>3</mn><mo>,</mo><mtext>padding</mtext><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{Conv2d}(x,\text{in\_ch},\text{out\_ch},\text{kernel}=3,\text{padding}=1)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span>  <math alttext="h\leftarrow\text{BatchNorm2d}(h)" class="ltx_Math" display="inline" id="alg3.l4.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mrow><mtext>BatchNorm2d</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{BatchNorm2d}(h)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span>  <math alttext="h\leftarrow\text{LeakyReLU}(h,\alpha=0.2)" class="ltx_Math" display="inline" id="alg3.l5.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mrow><mtext>LeakyReLU</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>h</mi><mo>,</mo><mi>α</mi></mrow><mo>=</mo><mn>0.2</mn></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{LeakyReLU}(h,\alpha=0.2)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l6">
<span class="ltx_tag ltx_tag_listingline">6:</span>  <math alttext="h\leftarrow\text{Conv2d}(h,\text{out\_ch},\text{out\_ch},\text{kernel}=3,\text{padding}=1)" class="ltx_math_unparsed" display="inline" id="alg3.l6.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mtext>Conv2d</mtext><mrow><mo stretchy="false">(</mo><mi>h</mi><mo>,</mo><mtext>out_ch</mtext><mo>,</mo><mtext>out_ch</mtext><mo>,</mo><mtext>kernel</mtext><mo>=</mo><mn>3</mn><mo>,</mo><mtext>padding</mtext><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{Conv2d}(h,\text{out\_ch},\text{out\_ch},\text{kernel}=3,\text{padding}=1)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span>  <math alttext="h\leftarrow\text{BatchNorm2d}(h)" class="ltx_Math" display="inline" id="alg3.l7.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mrow><mtext>BatchNorm2d</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{BatchNorm2d}(h)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l8">
<span class="ltx_tag ltx_tag_listingline">8:</span>  <math alttext="h\leftarrow\text{EfficientAttention}(h)" class="ltx_Math" display="inline" id="alg3.l8.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mrow><mtext>EfficientAttention</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{EfficientAttention}(h)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l9">
<span class="ltx_tag ltx_tag_listingline">9:</span>  <math alttext="h\leftarrow h+r" class="ltx_Math" display="inline" id="alg3.l9.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mrow><mi>h</mi><mo>+</mo><mi>r</mi></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow h+r</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l10">
<span class="ltx_tag ltx_tag_listingline">10:</span>  <math alttext="h\leftarrow\text{LeakyReLU}(h,\alpha=0.2)" class="ltx_Math" display="inline" id="alg3.l10.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mrow><mtext>LeakyReLU</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>h</mi><mo>,</mo><mi>α</mi></mrow><mo>=</mo><mn>0.2</mn></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{LeakyReLU}(h,\alpha=0.2)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l11" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">11:</span>  <span class="ltx_text ltx_font_bold">return</span> <math alttext="h" class="ltx_Math" display="inline" id="alg3.l11.m1" intent=":literal"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg3.l12">
<span class="ltx_tag ltx_tag_listingline">12:</span><span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">procedure</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">12：结束程序</font></font></font>
</div>
</div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold">Algorithm 4</span> </span> UpBlock Module<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">算法 4 UpBlock 模块</font></font></font></figcaption>
<div class="ltx_listing ltx_listing">
<div class="ltx_listingline" id="alg4.l1" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">1:</span><span class="ltx_text ltx_font_bold">procedure</span> <span class="ltx_text ltx_font_smallcaps">UpBlock</span>(<math alttext="x,\text{in\_ch},\text{out\_ch}" class="ltx_Math" display="inline" id="alg4.l1.m1" intent=":literal"><semantics><mrow><mi>x</mi><mo>,</mo><mtext>in_ch</mtext><mo>,</mo><mtext>out_ch</mtext></mrow><annotation encoding="application/x-tex">x,\text{in\_ch},\text{out\_ch}</annotation></semantics></math>)

</div>
<div class="ltx_listingline" id="alg4.l2">
<span class="ltx_tag ltx_tag_listingline">2:</span>  <math alttext="h\leftarrow\text{Upsample}(x,\text{scale\_factor}=2,\text{mode=&#39;nearest&#39;})" class="ltx_math_unparsed" display="inline" id="alg4.l2.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mtext>Upsample</mtext><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mtext>scale_factor</mtext><mo>=</mo><mn>2</mn><mo>,</mo><mtext>mode=’nearest’</mtext><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{Upsample}(x,\text{scale\_factor}=2,\text{mode='nearest'})</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg4.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span>  <math alttext="h\leftarrow\text{Conv2d}(h,\text{in\_ch},\text{out\_ch},\text{kernel}=3,\text{padding}=1)" class="ltx_math_unparsed" display="inline" id="alg4.l3.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mtext>Conv2d</mtext><mrow><mo stretchy="false">(</mo><mi>h</mi><mo>,</mo><mtext>in_ch</mtext><mo>,</mo><mtext>out_ch</mtext><mo>,</mo><mtext>kernel</mtext><mo>=</mo><mn>3</mn><mo>,</mo><mtext>padding</mtext><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{Conv2d}(h,\text{in\_ch},\text{out\_ch},\text{kernel}=3,\text{padding}=1)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg4.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span>  <math alttext="h\leftarrow\text{BatchNorm2d}(h)" class="ltx_Math" display="inline" id="alg4.l4.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mrow><mtext>BatchNorm2d</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{BatchNorm2d}(h)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg4.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span>  <math alttext="h\leftarrow\text{LeakyReLU}(h,\alpha=0.2)" class="ltx_Math" display="inline" id="alg4.l5.m1" intent=":literal"><semantics><mrow><mi>h</mi><mo stretchy="false">←</mo><mrow><mtext>LeakyReLU</mtext><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>h</mi><mo>,</mo><mi>α</mi></mrow><mo>=</mo><mn>0.2</mn></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">h\leftarrow\text{LeakyReLU}(h,\alpha=0.2)</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg4.l6" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_listingline">6:</span>  <span class="ltx_text ltx_font_bold">return</span> <math alttext="h" class="ltx_Math" display="inline" id="alg4.l6.m1" intent=":literal"><semantics><mi>h</mi><annotation encoding="application/x-tex">h</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg4.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span><span class="ltx_text ltx_font_bold">end</span> <span class="ltx_text ltx_font_bold">procedure</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7：结束程序</font></font></font>
</div>
</div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Dataset Construction Details<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 B 数据集构建细节</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Three-Stage Annotation Pipeline<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.1 三阶段标注流程</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS1.p1">
<p class="ltx_p">The construction of GeoPrivacy-6K employs a systematic three-stage annotation pipeline implemented using QwenVL 2.5 72B as the annotation model. To mitigate potential factual inaccuracies from model limitations, our annotation process focuses exclusively on visual feature characterization rather than specific geographic location identification. This multi-stage approach progressively refines image content from basic geographic filtering to detailed hierarchical concept analysis and precise spatial reasoning chain extraction, ensuring comprehensive capture of the visual-conceptual relationships that MLRMs exploit during geographic inference while maintaining annotation quality and consistency.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">GeoPrivacy-6K 的构建采用了一个系统化的三阶段标注流程，使用 QwenVL 2.5 72B 作为标注模型。为了减轻模型限制可能导致的潜在事实性错误，我们的标注过程专注于视觉特征描述，而非特定地理位置识别。这种多阶段方法逐步细化图像内容，从基本的地理过滤到详细的层次概念分析，再到精确的空间推理链提取，确保全面捕捉 MLRMs 在地理推理过程中利用的视觉-概念关系，同时保持标注质量和一致性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="A2.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.1.1 </span>Stage 1: Geographic Content Filtering<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.1.1 阶段 1：地理内容过滤</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS1.SSS1.p1">
<p class="ltx_p">The initial filtering stage identifies images containing real-world geographical features suitable for location inference training. This stage operates through automated resolution screening followed by content-based evaluation that excludes abstract patterns, studio portraits with plain backgrounds, or isolated object close-ups while retaining images with identifiable natural landmarks, architectural elements, or environmental characteristics.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">初始筛选阶段识别包含适合位置推理训练的真实世界地理特征图像。该阶段通过自动分辨率筛选，随后进行基于内容的评估，排除抽象图案、背景简洁的棚拍肖像或孤立物体特写，同时保留具有可识别自然地标、建筑元素或环境特征的图像。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.SSS1.p2">
<blockquote class="ltx_quote">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Stage 1 Prompt:</span> The system evaluates whether images contain real-world geographical features (natural or man-made elements related to places on Earth) while excluding abstract patterns, studio portraits, or isolated object close-ups. The assessment produces a boolean decision with reasoning explanation in JSON format.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">阶段 1 提示：系统评估图像是否包含真实世界地理特征（与地球上的地点相关的自然或人造元素），同时排除抽象图案、棚拍肖像或孤立物体特写。评估结果以 JSON 格式输出布尔决策及推理说明。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
</section>
<section class="ltx_subsubsection" id="A2.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.1.2 </span>Stage 2: Hierarchical Scene Annotation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.1.2 阶段 2：分层场景标注</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS1.SSS2.p1">
<p class="ltx_p">Images passing the geographic filter undergo comprehensive hierarchical categorization that captures the conceptual structure employed by MLRMs during visual analysis. This stage establishes the foundational semantic framework through three-level hierarchical classification and detailed attribute annotation across environmental, architectural, and atmospheric dimensions.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">通过地理过滤器处理的图像会经历全面的层级分类，捕捉 MLRMs 在视觉分析中使用的概念结构。这一阶段通过在环境、建筑和大气维度上进行三级层级分类和详细属性标注，建立基础语义框架。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.SSS2.p2">
<p class="ltx_p">The hierarchical framework begins with <span class="ltx_text ltx_font_bold">L1 - Environmental Domain</span> classification, distinguishing between Natural Environment and Built Environment contexts. This guides subsequent <span class="ltx_text ltx_font_bold">L2 - Contextual Setting</span> refinement, where natural environments are classified into mountainous, forest/woodland, plains/grassland, water body, desert, or coastal categories, while built environments encompass urban/city, rural/suburban, transportation infrastructure, or industrial settings. The <span class="ltx_text ltx_font_bold">L3 - Scene Specification</span> level provides granular scene categorization, subdividing urban environments into street views, skylines, plazas/parks, residential areas, commercial districts, or historic districts, while mountainous regions distinguish between peaks/ridges, valleys, or plateaus.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">层级框架从 L1 - 环境域分类开始，区分自然环境和建成环境两种情境。这指导了后续 L2 - 情境设置细化，其中自然环境被分类为山地、森林/林地、平原/草原、水体、沙漠或沿海类别，而建成环境包括城市/都市、乡村/郊区、交通基础设施或工业区。L3 - 场景指定层级提供粒度化的场景分类，将城市环境细分为街道景观、天际线、广场/公园、住宅区、商业区或历史区，而山地区域则区分山峰/山脊、山谷或高原。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.SSS2.p3">
<p class="ltx_p">Beyond hierarchical scene classification, the annotation framework captures detailed descriptive attributes including environmental elements (both natural features such as vegetation, trees, rock formations, water bodies, and man-made elements including buildings, roads, vehicles, infrastructure), architectural characteristics (styles ranging from modern to classical/historic, and construction materials from brick/stone to glass curtain walls), and atmospheric conditions (temporal factors like lighting, weather and environmental characteristics).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">除了层次化场景分类之外，该标注框架还捕捉了详细的描述性属性，包括环境元素（既有自然特征如植被、树木、岩石构造、水体，也有人造元素包括建筑物、道路、车辆、基础设施），建筑特征（从现代到古典/历史的各种风格，以及从砖石到玻璃幕墙的建筑材料），以及大气条件（如光照、天气和环境特征等时间因素）。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.SSS2.p4">
<blockquote class="ltx_quote">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Stage 2 Prompt:</span> The system categorizes images using a three-level hierarchy (L1: Environmental Domain, L2: Contextual Setting, L3: Scene Specification) while capturing detailed descriptive attributes across environmental elements (natural and man-made), architectural characteristics (styles and materials), and atmospheric conditions (lighting, weather).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">第二阶段提示：系统使用三级层次结构（L1：环境领域，L2：情境设置，L3：场景具体化）对图像进行分类，同时捕捉环境元素（自然和人造）、建筑特征（风格和材料）以及大气条件（光照、天气）的详细描述属性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
</section>
<section class="ltx_subsubsection" id="A2.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.1.3 </span>Stage 3: Geographic Reasoning Chain Extraction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.1.3 第三阶段：地理推理链提取</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS1.SSS3.p1">
<p class="ltx_p">The final and most critical stage generates the hierarchical reasoning chains that mirror MLRM geographic inference processes. This stage produces the concept-region mappings essential for training ReasonBreak by systematically analyzing visual evidence through four geographic scales: continental, national, city, and local levels. Each reasoning step identifies a specific visual concept and its precise spatial location through normalized square bounding boxes.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">最终且最关键的阶段生成与 MLRM 地理推理过程相匹配的层次推理链。该阶段通过系统地分析四个地理尺度（大陆、国家、城市和地方级别）的视觉证据，产生概念-区域映射，这些映射对于训练 ReasonBreak 至关重要。每个推理步骤通过归一化的正方形边界框识别特定的视觉概念及其精确的空间位置。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.SSS3.p2">
<blockquote class="ltx_quote">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Stage 3 Prompt:</span> The system performs hierarchical geographic reasoning analysis (Continental → National → City → Local) identifying key visual concepts at each level with precise spatial localization. Each reasoning step produces descriptive concept phrases (5-10 words) with normalized square bounding boxes [center_x, center_y, size] and confidence scores, generating the concept-region mappings essential for adversarial training.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">阶段三提示：系统执行分层地理推理分析（大洲→国家→城市→本地），在每个层级识别关键视觉概念并实现精确的空间定位。每一步推理产生描述性概念短语（5-10 个词），并附带归一化正方形边界框[中心 x，中心 y，大小]和置信度分数，从而生成对抗训练所必需的概念-区域映射。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
</section>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Data Collection and Source Integration<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.2 数据收集与源整合</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p">Our data collection process sources high-quality images from three established computer vision datasets that provide complementary geographic coverage. HoliCity&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020holicity</span>)</cite> contributes diverse urban scenes with detailed architectural elements and city landscapes, Aesthetic-4K&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2025diffusion</span>)</cite> provides visually compelling natural and built environments with strong compositional quality, and LHQ&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_ref ltx_missing_citation ltx_ref_self">skorokhodov2021aligning</span>)</cite> offers ultra-high-resolution landscape images spanning diverse geographical regions and environmental conditions.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的数据收集过程从三个提供互补地理覆盖的成熟计算机视觉数据集中获取高质量图像。HoliCity（zhou2020holicity）贡献了具有详细建筑元素和城市景观的多样化城市场景，Aesthetic-4K（zhang2025diffusion）提供了视觉上引人入胜的自然和建成环境，具有强烈的构图质量，而 LHQ（skorokhodov2021aligning）则提供了跨越不同地理区域和环境条件的超高清风景图像。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS2.p2">
<p class="ltx_p">The technical filtering process ensures all images maintain a minimum resolution of 2048 pixels along at least one dimension.
Subsequently, the three-stage annotation pipeline transforms raw images into a comprehensive dataset with hierarchical scene categorization, detailed attribute annotation, and precise concept-region mappings through geographic reasoning chain extraction.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">技术过滤过程确保所有图像在至少一个维度上保持 2048 像素的最小分辨率。随后，三阶段标注流程通过地理推理链提取，将原始图像转化为具有层级场景分类、详细属性标注和精确概念区域映射的综合性数据集。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Inference Difficulty Assessment<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">B.3 推理难度评估</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A2.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="219" id="A2.F7.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/confidence_distribution.png" width="274">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Distribution of confidence scores across geographic inference levels. Higher confidence scores indicate greater certainty in geographic predictions. The predominance of high confidence scores at the city and local levels demonstrates the sophisticated reasoning capabilities required for precise location inference.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 7：地理推理级别的置信度分数分布。更高的置信度分数表示对地理预测的更大确定性。城市和地方级别的高置信度分数的普遍性展示了精确位置推理所需的复杂推理能力。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS3.p1">
<p class="ltx_p">Inference difficulty ratings are determined based on confidence scores generated during the geographic reasoning analysis stage. Easy cases (17.8%) feature obvious, globally distinctive landmarks or features that enable straightforward location inference. Medium difficulty cases (29.1%) require regional-level geographic knowledge and more sophisticated visual analysis. Hard cases (53.2%) demand fine-grained local geographic reasoning and represent the most challenging scenarios for both human experts and automated systems.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理难度评级是根据地理推理分析阶段生成的置信度分数确定的。简单案例（17.8%）具有明显、全球独特的地标或特征，能够直接进行位置推理。中等难度案例（29.1%）需要区域级别的地理知识以及更复杂的视觉分析。困难案例（53.2%）需要细粒度的本地地理推理，代表人类专家和自动化系统面临的最具挑战性的场景。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.p2">
<p class="ltx_p">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2.F7" title="Figure 7 ‣ B.3 Inference Difficulty Assessment ‣ Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">7</span></a> illustrates the confidence score distribution across different geographic inference levels, demonstrating the challenging nature of our dataset composition. The prevalence of high-confidence scores at city and local levels reflects the sophisticated reasoning capabilities required for precise location inference and validates the complexity of our curated dataset.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 7 展示了不同地理推理级别的置信度分数分布，说明了我们数据集构成的挑战性。城市和地方级别的高置信度分数的普遍存在反映了精确位置推理所需的复杂推理能力，并验证了我们精选数据集的复杂性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.p3">
<p class="ltx_p">This comprehensive three-stage annotation structure enables precise concept-region mapping essential for training ReasonBreak’s concept-aware adversarial generator, providing the granular supervision necessary for targeted perturbation generation across diverse geographic inference scenarios while maintaining the spatial precision required for effective reasoning pathway disruption.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这种全面的、分三阶段的标注结构能够实现精确的概念-区域映射，这对于训练 ReasonBreak 的概念感知对抗生成器至关重要，它提供了在多种地理推理场景中进行针对性扰动生成的细粒度指导，同时保持了有效推理路径干扰所需的空間精确性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A2.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="270" id="A2.F8.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x12.png" width="760">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Demonstration of input sensitivity in MLRMs. Adding a single line break to the prompt causes InternVL 3.0 72B to generate drastically different location inferences.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 8：展示 MLRMs 的输入敏感性。在提示中添加一个单独的换行符会导致 InternVL 3.0 72B 生成截然不同的位置推断。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Counter-intuitive Scaling Phenomena in Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 C 推理模型中的反直觉缩放现象</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A3.p1">
<p class="ltx_p">Our experiments reveal two intriguing phenomena rarely observed in traditional perception models but consistently present in MLRMs, particularly in open-source models like InternVL 3.0 72B. First, an Inverted Scaling Relationship: unlike traditional adversarial attacks where larger perturbations typically yield stronger effects, we observe instances in MLRMs where smaller perturbations occasionally produce more effective attacks. Second, the Adversarial Enhancement Effect: while adversarial noise typically degrades model performance in traditional perception models, we occasionally observe anomalous cases in MLRMs where adversarial perturbations actually improve model performance, resulting in negative protection rates. In Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#S5.T1" title="Table 1 ‣ 5 Experiments ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">1</span></a>, we normalize these occasional negative values to zero while discussing this phenomenon separately here.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们的实验揭示了两种在传统感知模型中很少观察到但在多模态推理模型（MLRMs）中持续存在的有趣现象，特别是在像 InternVL 3.0 72B 这样的开源模型中。首先，一种倒置的缩放关系：与传统的对抗攻击中较大的扰动通常产生更强的效果不同，我们在 MLRMs 中观察到一些较小的扰动偶尔会产生更有效的攻击。其次，对抗增强效应：虽然对抗噪声通常会在传统感知模型中降低模型性能，但我们偶尔在 MLRMs 中观察到异常情况，即对抗扰动实际上会提高模型性能，导致负保护率。在表 1 中，我们在讨论这种现象时将这些偶尔的负值归零。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A3.p2">
<p class="ltx_p">We attribute these phenomena to two key factors: First, the inherent randomness introduced by the LLM component in MLRMs. For instance, model temperature settings introduce inherent stochasticity in outputs, making some performance variations expected. More surprisingly, the second factor relates to input sensitivity in reasoning models. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A2.F8" title="Figure 8 ‣ B.3 Inference Difficulty Assessment ‣ Appendix B Dataset Construction Details ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">8</span></a> demonstrates this phenomenon: on InternVL 3.0 72B, even with temperature=0, simply adding a line break at the end of the prompt transforms the output from <span class="ltx_text ltx_font_italic">[Rental Car sign”, Highway view”, Urban landscape”], address list: [100 Rental Car Center, San Francisco, CA 94130”]”</span> to <span class="ltx_text ltx_font_italic">[Rental Car”, highway view”, train station”], address list: [1000 Broadway, Oakland, CA 94607”]”</span>. Similarly, this sensitivity extends to image inputs, where ostensibly adversarial perturbations can occasionally trigger patterns that improve model accuracy.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们将这些现象归因于两个关键因素：首先，MLRM 中的 LLM 组件引入的固有随机性。例如，模型温度设置在输出中引入了固有的随机性，使得某些性能变化是预期的。更令人惊讶的是，第二个因素与推理模型中的输入敏感性有关。图 8 展示了这一现象：在 InternVL 3.0 72B 上，即使温度=0，仅仅在提示符末尾添加换行符就能将输出从[Rental Car sign”, Highway view”, Urban landscape”],地址列表: [100 Rental Car Center, San Francisco, CA 94130”]”转变为[Rental Car”, highway view”, train station”],地址列表: [1000 Broadway, Oakland, CA 94607”]”。类似地，这种敏感性也扩展到图像输入，其中表面上对抗性的扰动偶尔会触发改进模型准确性的模式。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A3.p3">
<p class="ltx_p">These observations highlight the complex nature of the reasoning processes of MLRMs. Understanding and addressing these unique characteristics presents an important direction for future research in privacy protection against reasoning-based models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这些观察结果突出了 MLRM 推理过程的复杂性。理解和解决这些独特特性是未来针对推理模型隐私保护研究的重要方向。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Visual Quality Analysis<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 D 视觉质量分析</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A4.p1">
<p class="ltx_p">We provide qualitative analysis of the visual quality of adversarial examples generated by ReasonBreak and baseline methods across different perturbation budgets.
Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A4.F9" title="Figure 9 ‣ Appendix D Visual Quality Analysis ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">9</span></a> presents representative examples of adversarial images generated under <math alttext="\epsilon=8/255" class="ltx_Math" display="inline" id="A4.p1.m1" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=8/255</annotation></semantics></math> and <math alttext="\epsilon=16/255" class="ltx_Math" display="inline" id="A4.p1.m2" intent=":literal"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>16</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=16/255</annotation></semantics></math> constraints. All methods produce perturbations that remain largely imperceptible to human observers, ensuring that privacy protection does not compromise image usability for legitimate sharing purposes.
While the overall visual impact is minimal across all methods, we observe distinct perturbation patterns. Baseline methods (AnyAttack, M-Attack) exhibit subtle block-like artifacts, particularly noticeable in high-resolution images. This occurs because these methods generate perturbations at lower resolutions and resize them to match the target image dimensions, leading to slight pixelation effects. In contrast, our concept-aware approach produces more naturally distributed perturbations that align with semantic boundaries and geographic features, avoiding the block artifacts inherent in resize-based approaches.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们对 ReasonBreak 和基线方法在不同扰动预算下生成的对抗样本的视觉质量进行了定性分析。图 9 展示了在 <math intent=":literal" id="A4.p1.m1" display="inline" class="ltx_Math" alttext="\epsilon=8/255"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>8</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=8/255</annotation></semantics></math> 和 <math intent=":literal" id="A4.p1.m2" display="inline" class="ltx_Math" alttext="\epsilon=16/255"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mrow><mn>16</mn><mo>/</mo><mn>255</mn></mrow></mrow><annotation encoding="application/x-tex">\epsilon=16/255</annotation></semantics></math> 约束下生成的对抗图像的代表性示例。所有方法产生的扰动对人类观察者来说基本难以察觉，确保隐私保护不会影响图像在合法共享目的中的可用性。虽然所有方法的整体视觉影响都较小，但我们观察到不同的扰动模式。基线方法（AnyAttack、M-Attack）表现出微妙的块状伪影，在高分辨率图像中尤为明显。这是因为这些方法在较低分辨率下生成扰动，然后将其缩放到目标图像的尺寸，导致轻微的像素化效果。相比之下，我们的概念感知方法产生的扰动分布更自然，与语义边界和地理特征相一致，避免了基于缩放方法的块状伪影。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="289" id="A4.F9.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x13.png" width="760">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Visual comparison of adversarial examples generated by different methods.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 9：不同方法生成的对抗样本的视觉比较</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Qualitative Examples of GeoPrivacy-6K<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 E GeoPrivacy-6K 定性示例</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A5.p1">
<p class="ltx_p">To facilitate a deeper understanding of the GeoPrivacy-6K dataset and validate the effectiveness of our automated annotation pipeline, we present representative visualizations in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A5.F10" title="Figure 10 ‣ Appendix E Qualitative Examples of GeoPrivacy-6K ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">10</span></a>. These examples demonstrate the diversity of scenes covered, ranging from dense urban environments to remote natural landscapes.
As illustrated, the annotations generated by QwenVL 2.5 72B follow a structured geographic reasoning chain. The process initiates with broad environmental classification (e.g., “European-style urban infrastructure”) and progressively narrows down to localized, discriminative features (e.g., specific road markings or distinct mountain peaks). Crucially, each reasoning step is grounded by a normalized square bounding box parameterized as <span class="ltx_text ltx_font_typewriter">[center_x, center_y, size]</span> alongside a confidence score.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了帮助更深入地理解 GeoPrivacy-6K 数据集并验证我们自动化标注流程的有效性，我们在图 10 中展示了具有代表性的可视化示例。这些示例展示了所涵盖场景的多样性，范围从密集的城市环境到偏远的自然景观。如图所示，QwenVL 2.5 72B 生成的标注遵循结构化的地理推理链。该过程首先从宽泛的环境分类开始（例如，“欧洲风格的城市基础设施”），然后逐步细化到局部的、具有区分度的特征（例如，特定的道路标记或独特的山峰）。关键在于，每一步推理都基于一个参数化为 [center_x, center_y, size] 形式的标准化正方形边界框，并附带一个置信度分数。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="405" id="A5.F10.g1" src="./打破层级推理：多模态推理模型中的地理隐私对抗保护 --- Disrupting Hierarchical Reasoning_ Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models_files/x14.png" width="760">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Visualization of hierarchical annotations in GeoPrivacy-6K.
The figure displays two samples with their corresponding automated reasoning chains.
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 10：GeoPrivacy-6K 中层级标注的可视化。该图展示了两个样本及其对应的自动推理链。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Privacy protection rates under different JPEG compression quality factors (<math alttext="Q" class="ltx_Math" display="inline" id="A5.T3.m3" intent=":literal"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>) on InternVL 3.0 72B. The method demonstrates strong stability even under aggressive compression (<math alttext="Q=50" class="ltx_Math" display="inline" id="A5.T3.m4" intent=":literal"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">Q=50</annotation></semantics></math>).<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 3：在 InternVL 3.0 72B 上不同 JPEG 压缩质量因子（ <math intent=":literal" id="A5.T3.m3" display="inline" class="ltx_Math" alttext="Q"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math> ）下的隐私保护率。该方法即使在激烈压缩下（ <math intent=":literal" id="A5.T3.m4" display="inline" class="ltx_Math" alttext="Q=50"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">Q=50</annotation></semantics></math> ）也表现出很强的稳定性。</font></font></font></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;"><span class="ltx_text ltx_font_bold">Quality Factor<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">质量因子</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;"><span class="ltx_text ltx_font_bold">Region<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">区域</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;"><span class="ltx_text ltx_font_bold">Metro.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">地铁。</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;"><span class="ltx_text ltx_font_bold">Tract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">区</font></font></font></span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;"><span class="ltx_text ltx_font_bold">Block<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">街区</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">
<math alttext="Q=95" class="ltx_Math" display="inline" id="A5.T3.m5" intent=":literal"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>95</mn></mrow><annotation encoding="application/x-tex">Q=95</annotation></semantics></math> (Default)<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1"> <math intent=":literal" id="A5.T3.m5" display="inline" class="ltx_Math" alttext="Q=95"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>95</mn></mrow><annotation encoding="application/x-tex">Q=95</annotation></semantics></math> (默认)</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">10.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">33.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">58.3</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left" style="padding-left:10.0pt;padding-right:10.0pt;"><math alttext="Q=75" class="ltx_Math" display="inline" id="A5.T3.m6" intent=":literal"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>75</mn></mrow><annotation encoding="application/x-tex">Q=75</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">11.1</td>
<td class="ltx_td ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">0.0</td>
<td class="ltx_td ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">33.3</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;">58.3</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;"><math alttext="Q=50" class="ltx_Math" display="inline" id="A5.T3.m7" intent=":literal"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">Q=50</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;">9.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;">30.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;">58.3</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Computational Efficiency Analysis<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 F 计算效率分析</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A6.p1">
<p class="ltx_p">We evaluate the computational efficiency of ReasonBreak against the baseline methods, focusing on both training overhead and inference latency.
Regarding training costs, there are substantial disparities among approaches. The generator-based baseline, AnyAttack, requires a computationally intensive pre-training phase spanning approximately one week on three NVIDIA A100 GPUs. In contrast, ReasonBreak significantly reduces this overhead, converging in 6 hours and 30 minutes on a single GPU. The PGD-style baseline, M-Attack, incurs no training cost as it computes perturbations dynamically at inference time.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">我们评估了 ReasonBreak 相对于基线方法的计算效率，重点关注训练开销和推理延迟。在训练成本方面，不同方法之间存在显著差异。基于生成器的基线方法 AnyAttack 需要一个计算密集型的预训练阶段，在三个 NVIDIA A100 GPU 上大约需要一周时间。相比之下，ReasonBreak 大幅降低了这一开销，在单个 GPU 上仅需 6 小时 30 分钟即可收敛。PGD 风格的基线方法 M-Attack 则没有训练成本，因为它在推理时动态计算扰动。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A6.p2">
<p class="ltx_p">For inference, we measured the time required to generate adversarial examples for DoxBench (<math alttext="\approx" class="ltx_Math" display="inline" id="A6.p2.m1" intent=":literal"><semantics><mo>≈</mo><annotation encoding="application/x-tex">\approx</annotation></semantics></math>500 images). M-Attack exhibits the highest latency (43 minutes and 30 seconds) due to the necessity of iterative gradient optimization for each input. Generator-based methods demonstrate a marked advantage in deployment efficiency: AnyAttack completes the process in 2 minutes and 30 seconds, while ReasonBreak requires 5 minutes and 20 seconds. The marginal increase in our inference time compared to AnyAttack is attributable to the adaptive decomposition and concept assignment pre-processing steps. This indicates that ReasonBreak achieves a favorable balance, offering protection rates comparable to computationally expensive methods while maintaining the near real-time inference capabilities of generator-based architectures.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在推理过程中，我们测量了为 DoxBench（ <math intent=":literal" id="A6.p2.m1" display="inline" class="ltx_Math" alttext="\approx"><semantics><mo>≈</mo><annotation encoding="application/x-tex">\approx</annotation></semantics></math> 500 张图像）生成对抗样本所需的时间。M-Attack 由于需要对每个输入进行迭代梯度优化，表现出最高的延迟（43 分钟 30 秒）。基于生成器的方法在部署效率上具有显著优势：AnyAttack 在 2 分钟 30 秒内完成整个过程，而 ReasonBreak 需要 5 分钟 20 秒。与 AnyAttack 相比，我们的推理时间增加的边际部分归因于自适应分解和概念分配的预处理步骤。这表明 ReasonBreak 实现了良好的平衡，在保持基于生成器架构的近实时推理能力的同时，提供了与计算成本高昂的方法相当的保护率。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Robustness to JPEG Compression<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">附录 G 对 JPEG 压缩的鲁棒性</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A7.p1">
<p class="ltx_p">To verify the practicality of ReasonBreak in real-world social media environments, where uploaded images typically undergo lossy compression, we evaluated the resilience of our generated perturbations against varying levels of JPEG compression.
It is important to note that all experimental results reported in the main text were conducted using a standard JPEG quality factor (<math alttext="Q" class="ltx_Math" display="inline" id="A7.p1.m1" intent=":literal"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math>) of 95 to simulate a realistic baseline. In this section, we perform a stress test by further reducing the quality factor to <math alttext="Q=75" class="ltx_Math" display="inline" id="A7.p1.m2" intent=":literal"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>75</mn></mrow><annotation encoding="application/x-tex">Q=75</annotation></semantics></math> and <math alttext="Q=50" class="ltx_Math" display="inline" id="A7.p1.m3" intent=":literal"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">Q=50</annotation></semantics></math>. We utilize InternVL 3.0 72B as the target model for this evaluation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了验证 ReasonBreak 在实际社交媒体环境中的实用性——其中上传的图像通常会经过有损压缩——我们评估了我们生成的扰动对不同程度 JPEG 压缩的鲁棒性。需要注意的是，主文中报告的所有实验结果均使用标准 JPEG 质量因子（ <math intent=":literal" id="A7.p1.m1" display="inline" class="ltx_Math" alttext="Q"><semantics><mi>Q</mi><annotation encoding="application/x-tex">Q</annotation></semantics></math> ）95 进行，以模拟一个现实的基准。在本节中，我们通过进一步将质量因子降低至 <math intent=":literal" id="A7.p1.m2" display="inline" class="ltx_Math" alttext="Q=75"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>75</mn></mrow><annotation encoding="application/x-tex">Q=75</annotation></semantics></math> 和 <math intent=":literal" id="A7.p1.m3" display="inline" class="ltx_Math" alttext="Q=50"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">Q=50</annotation></semantics></math> 进行压力测试。我们使用 InternVL 3.0 72B 作为此评估的目标模型。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A7.p2">
<p class="ltx_p">As shown in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2512.08503v1#A5.T3" title="Table 3 ‣ Appendix E Qualitative Examples of GeoPrivacy-6K ‣ Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models"><span class="ltx_text ltx_ref_tag">3</span></a>, ReasonBreak exhibits remarkable stability. Reducing the quality factor from 95 to 75 results in virtually no degradation in protection performance. Even under aggressive compression (<math alttext="Q=50" class="ltx_Math" display="inline" id="A7.p2.m1" intent=":literal"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">Q=50</annotation></semantics></math>), the decline in protection rates is minimal. This resilience suggests that the concept-aware perturbations generated by our method are structurally robust and can survive the standard image processing pipelines employed by major social platforms.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">如表 3 所示，ReasonBreak 表现出显著的稳定性。将质量因子从 95 降低到 75，保护性能几乎不受影响。即使在激进压缩（ <math intent=":literal" id="A7.p2.m1" display="inline" class="ltx_Math" alttext="Q=50"><semantics><mrow><mi>Q</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">Q=50</annotation></semantics></math> ）的情况下，保护率的下降也最小。这种韧性表明我们方法生成的概念感知扰动在结构上具有鲁棒性，并且能够经受住主要社交平台采用的标准图像处理流程。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">报告问题</font></font></font></button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" width="11" height="14">
            </a><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由 L A T E xml <img height="14" width="11" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"> 生成</font></font></font>
        </div></div><footer id="footer" class="ltx_document" default-translate="no">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>@charset "UTF-8";
/*!
 * Pico.css v1.5.6 (https://picocss.com)
 * Copyright 2019-2022 - Licensed under MIT
 */
/**
 * Theme: default
 */
#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 0.25rem;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 1rem;
  --typography-spacing-vertical: 1.5rem;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 0.75rem;
  --form-element-spacing-horizontal: 1rem;
  --nav-element-spacing-vertical: 1rem;
  --nav-element-spacing-horizontal: 0.5rem;
  --nav-link-spacing-vertical: 0.5rem;
  --nav-link-spacing-horizontal: 0.5rem;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(0.25rem);
}
@media (min-width: 576px) {
  #mount {
    --font-size: 17px;
  }
}
@media (min-width: 768px) {
  #mount {
    --font-size: 18px;
  }
}
@media (min-width: 992px) {
  #mount {
    --font-size: 19px;
  }
}
@media (min-width: 1200px) {
  #mount {
    --font-size: 20px;
  }
}

@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2);
  }
}
@media (min-width: 768px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3);
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3.5);
  }
}

@media (min-width: 576px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}
@media (min-width: 992px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.75);
  }
}
@media (min-width: 1200px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 2);
  }
}

dialog > article {
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
}
@media (min-width: 576px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 3);
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}

a {
  --text-decoration: none;
}
a.secondary,
a.contrast {
  --text-decoration: underline;
}

small {
  --font-size: 0.875em;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  --font-weight: 700;
}

h1 {
  --font-size: 2rem;
  --typography-spacing-vertical: 3rem;
}

h2 {
  --font-size: 1.75rem;
  --typography-spacing-vertical: 2.625rem;
}

h3 {
  --font-size: 1.5rem;
  --typography-spacing-vertical: 2.25rem;
}

h4 {
  --font-size: 1.25rem;
  --typography-spacing-vertical: 1.874rem;
}

h5 {
  --font-size: 1.125rem;
  --typography-spacing-vertical: 1.6875rem;
}

[type="checkbox"],
[type="radio"] {
  --border-width: 2px;
}

[type="checkbox"][role="switch"] {
  --border-width: 2px;
}

thead th,
thead td,
tfoot th,
tfoot td {
  --border-width: 3px;
}

:not(thead, tfoot) > * > td {
  --font-size: 0.875em;
}

pre,
code,
kbd,
samp {
  --font-family: "Menlo", "Consolas", "Roboto Mono", "Ubuntu Monospace",
    "Noto Mono", "Oxygen Mono", "Liberation Mono", monospace,
    "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
}

kbd {
  --font-weight: bolder;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --background-color: #fff;
  --background-light-green: #f5f7f9;
  --color: hsl(205deg, 20%, 32%);
  --h1-color: hsl(205deg, 30%, 15%);
  --h2-color: #24333e;
  --h3-color: hsl(205deg, 25%, 23%);
  --h4-color: #374956;
  --h5-color: hsl(205deg, 20%, 32%);
  --h6-color: #4d606d;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: hsl(205deg, 20%, 94%);
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 90%, 32%);
  --primary-focus: rgba(16, 149, 193, 0.125);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 20%, 32%);
  --secondary-focus: rgba(89, 107, 120, 0.125);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 30%, 15%);
  --contrast-hover: #000;
  --contrast-focus: rgba(89, 107, 120, 0.125);
  --contrast-inverse: #fff;
  --mark-background-color: #fff2ca;
  --mark-color: #543a26;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: transparent;
  --form-element-border-color: hsl(205deg, 14%, 68%);
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: transparent;
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 18%, 86%);
  --form-element-disabled-border-color: hsl(205deg, 14%, 68%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #c62828;
  --form-element-invalid-active-border-color: #d32f2f;
  --form-element-invalid-focus-color: rgba(211, 47, 47, 0.125);
  --form-element-valid-border-color: #388e3c;
  --form-element-valid-active-border-color: #43a047;
  --form-element-valid-focus-color: rgba(67, 160, 71, 0.125);
  --switch-background-color: hsl(205deg, 16%, 77%);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: hsl(205deg, 18%, 86%);
  --range-active-border-color: hsl(205deg, 16%, 77%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: #f6f8f9;
  --code-background-color: hsl(205deg, 20%, 94%);
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 40%, 50%);
  --code-property-color: hsl(185deg, 40%, 40%);
  --code-value-color: hsl(40deg, 20%, 50%);
  --code-comment-color: hsl(205deg, 14%, 68%);
  --accordion-border-color: var(--muted-border-color);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: var(--background-color);
  --card-border-color: var(--muted-border-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(27, 40, 50, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(27, 40, 50, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(27, 40, 50, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(27, 40, 50, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(27, 40, 50, 0.04302),
    0.5rem 1rem 6rem rgba(27, 40, 50, 0.06),
    0 0 0 0.0625rem rgba(27, 40, 50, 0.015);
  --card-sectionning-background-color: #fbfbfc;
  --dropdown-background-color: #fbfbfc;
  --dropdown-border-color: #e1e6eb;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: hsl(205deg, 20%, 94%);
  --modal-overlay-background-color: rgba(213, 220, 226, 0.7);
  --progress-background-color: hsl(205deg, 18%, 86%);
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(198, 40, 40)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(56, 142, 60)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  --float-ball-more-button-border-color: #f6f6f6;
  --float-ball-more-button-background-color: #ffffff;
  --float-ball-more-button-svg-color: #6c6f73;
  color-scheme: light;
  --service-bg-hover: #f7faff;
  --service-bg: #fafbfb;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --background-color: #11191f;
    --float-ball-more-button-background-color: #ffffff;
    --background-light-green: #141e26;
    --color: hsl(205deg, 16%, 77%);
    --h1-color: hsl(205deg, 20%, 94%);
    --h2-color: #e1e6eb;
    --h3-color: hsl(205deg, 18%, 86%);
    --h4-color: #c8d1d8;
    --h5-color: hsl(205deg, 16%, 77%);
    --h6-color: #afbbc4;
    --muted-color: hsl(205deg, 10%, 50%);
    --muted-border-color: #1f2d38;
    --primary: hsl(195deg, 85%, 41%);
    --primary-hover: hsl(195deg, 80%, 50%);
    --primary-focus: rgba(16, 149, 193, 0.25);
    --primary-inverse: #fff;
    --secondary: hsl(205deg, 15%, 41%);
    --secondary-hover: hsl(205deg, 10%, 50%);
    --secondary-focus: rgba(115, 130, 140, 0.25);
    --secondary-inverse: #fff;
    --contrast: hsl(205deg, 20%, 94%);
    --contrast-hover: #fff;
    --contrast-focus: rgba(115, 130, 140, 0.25);
    --contrast-inverse: #000;
    --mark-background-color: #d1c284;
    --mark-color: #11191f;
    --ins-color: #388e3c;
    --del-color: #c62828;
    --blockquote-border-color: var(--muted-border-color);
    --blockquote-footer-color: var(--muted-color);
    --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --form-element-background-color: #11191f;
    --form-element-border-color: #374956;
    --form-element-color: var(--color);
    --form-element-placeholder-color: var(--muted-color);
    --form-element-active-background-color: var(
      --form-element-background-color
    );
    --form-element-active-border-color: var(--primary);
    --form-element-focus-color: var(--primary-focus);
    --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
    --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
    --form-element-disabled-opacity: 0.5;
    --form-element-invalid-border-color: #b71c1c;
    --form-element-invalid-active-border-color: #c62828;
    --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
    --form-element-valid-border-color: #2e7d32;
    --form-element-valid-active-border-color: #388e3c;
    --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
    --switch-background-color: #374956;
    --switch-color: var(--primary-inverse);
    --switch-checked-background-color: var(--primary);
    --range-border-color: #24333e;
    --range-active-border-color: hsl(205deg, 25%, 23%);
    --range-thumb-border-color: var(--background-color);
    --range-thumb-color: var(--secondary);
    --range-thumb-hover-color: var(--secondary-hover);
    --range-thumb-active-color: var(--primary);
    --table-border-color: var(--muted-border-color);
    --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
    --code-background-color: #18232c;
    --code-color: var(--muted-color);
    --code-kbd-background-color: var(--contrast);
    --code-kbd-color: var(--contrast-inverse);
    --code-tag-color: hsl(330deg, 30%, 50%);
    --code-property-color: hsl(185deg, 30%, 50%);
    --code-value-color: hsl(40deg, 10%, 50%);
    --code-comment-color: #4d606d;
    --accordion-border-color: var(--muted-border-color);
    --accordion-active-summary-color: var(--primary);
    --accordion-close-summary-color: var(--color);
    --accordion-open-summary-color: var(--muted-color);
    --card-background-color: #141e26;
    --card-border-color: var(--card-background-color);
    --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
      0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
      0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
      0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
      0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
      0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
    --card-sectionning-background-color: #18232c;
    --dropdown-background-color: hsl(205deg, 30%, 15%);
    --dropdown-border-color: #24333e;
    --dropdown-box-shadow: var(--card-box-shadow);
    --dropdown-color: var(--color);
    --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
    --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
    --progress-background-color: #24333e;
    --progress-color: var(--primary);
    --loading-spinner-opacity: 0.5;
    --tooltip-background-color: var(--contrast);
    --tooltip-color: var(--contrast-inverse);
    --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
    --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
    --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
    --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
    --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
    --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
    color-scheme: dark;
    --service-bg-hover: #22292f;
    --service-bg: rgba(0, 0, 0, 0.1);
  }
}
[data-theme="dark"] {
  --background-color: #11191f;
  --float-ball-more-button-background-color: #191919;
  --background-light-green: #141e26;
  --color: hsl(205deg, 16%, 77%);
  --h1-color: hsl(205deg, 20%, 94%);
  --h2-color: #e1e6eb;
  --h3-color: hsl(205deg, 18%, 86%);
  --h4-color: #c8d1d8;
  --h5-color: hsl(205deg, 16%, 77%);
  --h6-color: #afbbc4;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: #1f2d38;
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 80%, 50%);
  --primary-focus: rgba(16, 149, 193, 0.25);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 10%, 50%);
  --secondary-focus: rgba(115, 130, 140, 0.25);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 20%, 94%);
  --contrast-hover: #fff;
  --contrast-focus: rgba(115, 130, 140, 0.25);
  --contrast-inverse: #000;
  --mark-background-color: #d1c284;
  --mark-color: #11191f;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: #11191f;
  --form-element-border-color: #374956;
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: var(--form-element-background-color);
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
  --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #b71c1c;
  --form-element-invalid-active-border-color: #c62828;
  --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
  --form-element-valid-border-color: #2e7d32;
  --form-element-valid-active-border-color: #388e3c;
  --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
  --switch-background-color: #374956;
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: #24333e;
  --range-active-border-color: hsl(205deg, 25%, 23%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
  --code-background-color: #18232c;
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 30%, 50%);
  --code-property-color: hsl(185deg, 30%, 50%);
  --code-value-color: hsl(40deg, 10%, 50%);
  --code-comment-color: #4d606d;
  --accordion-border-color: var(--muted-border-color);
  --accordion-active-summary-color: var(--primary);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: #141e26;
  --card-border-color: var(--card-background-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
    0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
  --card-sectionning-background-color: #18232c;
  --dropdown-background-color: hsl(205deg, 30%, 15%);
  --dropdown-border-color: #24333e;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
  --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
  --progress-background-color: #24333e;
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  color-scheme: dark;
  --service-bg: rgba(0, 0, 0, 0.1);
}

progress,
[type="checkbox"],
[type="radio"],
[type="range"] {
  accent-color: var(--primary);
}

/**
 * Document
 * Content-box & Responsive typography
 */
*,
*::before,
*::after {
  box-sizing: border-box;
  background-repeat: no-repeat;
}

::before,
::after {
  text-decoration: inherit;
  vertical-align: inherit;
}

:where(#mount) {
  -webkit-tap-highlight-color: transparent;
  -webkit-text-size-adjust: 100%;
  -moz-text-size-adjust: 100%;
  text-size-adjust: 100%;
  background-color: var(--background-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  line-height: var(--line-height);
  font-family: var(--font-family);
  text-rendering: optimizeLegibility;
  overflow-wrap: break-word;
  cursor: default;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
}

/**
 * Sectioning
 * Container and responsive spacings for header, main, footer
 */
main {
  display: block;
}

#mount {
  width: 100%;
  margin: 0;
}
#mount > header,
#mount > main,
#mount > footer {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
}
@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 2px !important;
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 12px !important;
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 24px !important;
  }
}

/**
* Container
*/
.container,
.container-fluid {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding-right: var(--spacing);
  padding-left: var(--spacing);
}
/*
@media (min-width: 576px) {
  .container {
    max-width: 510px;
    padding-right: 0;
    padding-left: 0;
  }
}
@media (min-width: 768px) {
  .container {
    max-width: 700px;
  }
} */
@media (min-width: 992px) {
  .container {
    max-width: 920px;
  }
}
@media (min-width: 1200px) {
  .container {
    max-width: 1130px;
  }
}

/**
 * Section
 * Responsive spacings for section
 */
section {
  margin-bottom: var(--block-spacing-vertical);
}

/**
* Grid
* Minimal grid system with auto-layout columns
*/
.grid {
  grid-column-gap: var(--grid-spacing-horizontal);
  grid-row-gap: var(--grid-spacing-vertical);
  display: grid;
  grid-template-columns: 1fr;
  margin: 0;
}
@media (min-width: 1280px) {
  .grid {
    grid-template-columns: repeat(auto-fit, minmax(0%, 1fr));
  }
}
.grid > * {
  min-width: 0;
}

/**
 * Horizontal scroller (<figure>)
 */
figure {
  display: block;
  margin: 0;
  padding: 0;
  overflow-x: auto;
}
figure figcaption {
  padding: calc(var(--spacing) * 0.5) 0;
  color: var(--muted-color);
}

/**
 * Typography
 */
b,
strong {
  font-weight: bolder;
}

sub,
sup {
  position: relative;
  font-size: 0.75em;
  line-height: 0;
  vertical-align: baseline;
}

sub {
  bottom: -0.25em;
}

sup {
  top: -0.5em;
}

address,
blockquote,
dl,
figure,
form,
ol,
p,
pre,
table,
ul {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: var(--font-size);
}

a,
[role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
a:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}
a:focus,
[role="link"]:focus {
  --background-color: var(--primary-focus);
}
a.secondary,
[role="link"].secondary {
  --color: var(--secondary);
}
a.secondary:is([aria-current], :hover, :active, :focus),
[role="link"].secondary:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}
a.secondary:focus,
[role="link"].secondary:focus {
  --background-color: var(--secondary-focus);
}
a.contrast,
[role="link"].contrast {
  --color: var(--contrast);
}
a.contrast:is([aria-current], :hover, :active, :focus),
[role="link"].contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}
a.contrast:focus,
[role="link"].contrast:focus {
  --background-color: var(--contrast-focus);
}

h1,
h2,
h3,
h4,
h5,
h6 {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  font-family: var(--font-family);
}

h1 {
  --color: var(--h1-color);
}

h2 {
  --color: var(--h2-color);
}

h3 {
  --color: var(--h3-color);
}

h4 {
  --color: var(--h4-color);
}

h5 {
  --color: var(--h5-color);
}

h6 {
  --color: var(--h6-color);
}

:where(address, blockquote, dl, figure, form, ol, p, pre, table, ul)
  ~ :is(h1, h2, h3, h4, h5, h6) {
  margin-top: var(--typography-spacing-vertical);
}

hgroup,
.headings {
  margin-bottom: var(--typography-spacing-vertical);
}
hgroup > *,
.headings > * {
  margin-bottom: 0;
}
hgroup > *:last-child,
.headings > *:last-child {
  --color: var(--muted-color);
  --font-weight: unset;
  font-size: 1rem;
  font-family: unset;
}

p {
  margin-bottom: var(--typography-spacing-vertical);
}

small {
  font-size: var(--font-size);
}

:where(dl, ol, ul) {
  padding-right: 0;
  padding-left: var(--spacing);
  -webkit-padding-start: var(--spacing);
  padding-inline-start: var(--spacing);
  -webkit-padding-end: 0;
  padding-inline-end: 0;
}
:where(dl, ol, ul) li {
  margin-bottom: calc(var(--typography-spacing-vertical) * 0.25);
}

:where(dl, ol, ul) :is(dl, ol, ul) {
  margin: 0;
  margin-top: calc(var(--typography-spacing-vertical) * 0.25);
}

ul li {
  list-style: square;
}

mark {
  padding: 0.125rem 0.25rem;
  background-color: var(--mark-background-color);
  color: var(--mark-color);
  vertical-align: baseline;
}

blockquote {
  display: block;
  margin: var(--typography-spacing-vertical) 0;
  padding: var(--spacing);
  border-right: none;
  border-left: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-start: 0.25rem solid var(--blockquote-border-color);
  border-inline-start: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-end: none;
  border-inline-end: none;
}
blockquote footer {
  margin-top: calc(var(--typography-spacing-vertical) * 0.5);
  color: var(--blockquote-footer-color);
}

abbr[title] {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}

ins {
  color: var(--ins-color);
  text-decoration: none;
}

del {
  color: var(--del-color);
}

::-moz-selection {
  background-color: var(--primary-focus);
}

::selection {
  background-color: var(--primary-focus);
}

/**
 * Embedded content
 */
:where(audio, canvas, iframe, img, svg, video) {
  vertical-align: middle;
}

audio,
video {
  display: inline-block;
}

audio:not([controls]) {
  display: none;
  height: 0;
}

:where(iframe) {
  border-style: none;
}

img {
  max-width: 100%;
  height: auto;
  border-style: none;
}

:where(svg:not([fill])) {
  fill: currentColor;
}

svg:not(#mount) {
  overflow: hidden;
}

/**
 * Button
 */
button {
  margin: 0;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

button,
[type="button"],
[type="reset"],
[type="submit"] {
  -webkit-appearance: button;
}

button {
  display: block;
  width: 100%;
  margin-bottom: var(--spacing);
}

[role="button"] {
  display: inline-block;
  text-decoration: none;
}

button,
input[type="submit"],
input[type="button"],
input[type="reset"],
[role="button"] {
  --background-color: var(--primary);
  --border-color: var(--primary);
  --color: var(--primary-inverse);
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
button:is([aria-current], :hover, :active, :focus),
input[type="submit"]:is([aria-current], :hover, :active, :focus),
input[type="button"]:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus),
[role="button"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--primary-hover);
  --border-color: var(--primary-hover);
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  --color: var(--primary-inverse);
}
button:focus,
input[type="submit"]:focus,
input[type="button"]:focus,
input[type="reset"]:focus,
[role="button"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--primary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary,
input[type="reset"] {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  cursor: pointer;
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:focus,
input[type="reset"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--secondary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast {
  --background-color: var(--contrast);
  --border-color: var(--contrast);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--contrast-hover);
  --border-color: var(--contrast-hover);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--contrast-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline,
input[type="reset"].outline {
  --background-color: transparent;
  --color: var(--primary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --background-color: transparent;
  --color: var(--primary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary,
input[type="reset"].outline {
  --color: var(--secondary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast {
  --color: var(--contrast);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}

:where(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  )[disabled],
:where(fieldset[disabled])
  :is(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  ),
a[role="button"]:not([href]) {
  opacity: 0.5;
  pointer-events: none;
}

/**
 * Form elements
 */
input,
optgroup,
select,
textarea {
  margin: 0;
  font-size: 1rem;
  line-height: var(--line-height);
  font-family: inherit;
  letter-spacing: inherit;
}

input {
  overflow: visible;
}

select {
  text-transform: none;
}

legend {
  max-width: 100%;
  padding: 0;
  color: inherit;
  white-space: normal;
}

textarea {
  overflow: auto;
}

[type="checkbox"],
[type="radio"] {
  padding: 0;
}

::-webkit-inner-spin-button,
::-webkit-outer-spin-button {
  height: auto;
}

[type="search"] {
  -webkit-appearance: textfield;
  outline-offset: -2px;
}

[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}

::-webkit-file-upload-button {
  -webkit-appearance: button;
  font: inherit;
}

::-moz-focus-inner {
  padding: 0;
  border-style: none;
}

:-moz-focusring {
  outline: none;
}

:-moz-ui-invalid {
  box-shadow: none;
}

::-ms-expand {
  display: none;
}

[type="file"],
[type="range"] {
  padding: 0;
  border-width: 0;
}

input:not([type="checkbox"], [type="radio"], [type="range"]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
}

fieldset {
  margin: 0;
  margin-bottom: var(--spacing);
  padding: 0;
  border: 0;
}

label,
fieldset legend {
  display: block;
  margin-bottom: calc(var(--spacing) * 0.25);
  font-weight: var(--form-label-font-weight, var(--font-weight));
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  width: 100%;
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]),
select,
textarea {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
}

input,
select,
textarea {
  --background-color: var(--form-element-background-color);
  --border-color: var(--form-element-border-color);
  --color: var(--form-element-color);
  --box-shadow: none;
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="checkbox"],
    [type="radio"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --background-color: var(--form-element-active-background-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="switch"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --border-color: var(--form-element-active-border-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="range"],
    [type="file"],
    [readonly]
  ):focus,
select:focus,
textarea:focus {
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}

input:not([type="submit"], [type="button"], [type="reset"])[disabled],
select[disabled],
textarea[disabled],
:where(fieldset[disabled])
  :is(
    input:not([type="submit"], [type="button"], [type="reset"]),
    select,
    textarea
  ) {
  --background-color: var(--form-element-disabled-background-color);
  --border-color: var(--form-element-disabled-border-color);
  opacity: var(--form-element-disabled-opacity);
  pointer-events: none;
}

:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid] {
  padding-right: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal) !important;
  padding-inline-start: var(--form-element-spacing-horizontal) !important;
  -webkit-padding-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-inline-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="false"] {
  background-image: var(--icon-valid);
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="true"] {
  background-image: var(--icon-invalid);
}
:where(input, select, textarea)[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(input, select, textarea)[aria-invalid="false"]:is(:active, :focus) {
  --border-color: var(--form-element-valid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-valid-focus-color) !important;
}
:where(input, select, textarea)[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}
:where(input, select, textarea)[aria-invalid="true"]:is(:active, :focus) {
  --border-color: var(--form-element-invalid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width)
    var(--form-element-invalid-focus-color) !important;
}

[dir="rtl"]
  :where(input, select, textarea):not([type="checkbox"], [type="radio"]):is(
    [aria-invalid],
    [aria-invalid="true"],
    [aria-invalid="false"]
  ) {
  background-position: center left 0.75rem;
}

input::placeholder,
input::-webkit-input-placeholder,
textarea::placeholder,
textarea::-webkit-input-placeholder,
select:invalid {
  color: var(--form-element-placeholder-color);
  opacity: 1;
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  margin-bottom: var(--spacing);
}

select::-ms-expand {
  border: 0;
  background-color: transparent;
}
select:not([multiple], [size]) {
  padding-right: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal);
  padding-inline-start: var(--form-element-spacing-horizontal);
  -webkit-padding-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-inline-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  background-image: var(--icon-chevron);
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}

[dir="rtl"] select:not([multiple], [size]) {
  background-position: center left 0.75rem;
}

:where(input, select, textarea) + small {
  display: block;
  width: 100%;
  margin-top: calc(var(--spacing) * -0.75);
  margin-bottom: var(--spacing);
  color: var(--muted-color);
}

label > :where(input, select, textarea) {
  margin-top: calc(var(--spacing) * 0.25);
}

/**
 * Form elements
 * Checkboxes & Radios
 */
[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

[type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
[type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
[type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
[type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
[type="checkbox"][role="switch"]:checked {
  background-image: none;
}
[type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

[type="checkbox"][aria-invalid="false"],
[type="checkbox"]:checked[aria-invalid="false"],
[type="radio"][aria-invalid="false"],
[type="radio"]:checked[aria-invalid="false"],
[type="checkbox"][role="switch"][aria-invalid="false"],
[type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
[type="checkbox"][aria-invalid="true"],
[type="checkbox"]:checked[aria-invalid="true"],
[type="radio"][aria-invalid="true"],
[type="radio"]:checked[aria-invalid="true"],
[type="checkbox"][role="switch"][aria-invalid="true"],
[type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

/**
 * Form elements
 * Alternatives input types (Not Checkboxes & Radios)
 */
[type="color"]::-webkit-color-swatch-wrapper {
  padding: 0;
}
[type="color"]::-moz-focus-inner {
  padding: 0;
}
[type="color"]::-webkit-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}
[type="color"]::-moz-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]):is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  --icon-position: 0.75rem;
  --icon-width: 1rem;
  padding-right: calc(var(--icon-width) + var(--icon-position));
  background-image: var(--icon-date);
  background-position: center right var(--icon-position);
  background-size: var(--icon-width) auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="time"] {
  background-image: var(--icon-time);
}

[type="date"]::-webkit-calendar-picker-indicator,
[type="datetime-local"]::-webkit-calendar-picker-indicator,
[type="month"]::-webkit-calendar-picker-indicator,
[type="time"]::-webkit-calendar-picker-indicator,
[type="week"]::-webkit-calendar-picker-indicator {
  width: var(--icon-width);
  margin-right: calc(var(--icon-width) * -1);
  margin-left: var(--icon-position);
  opacity: 0;
}

[dir="rtl"]
  :is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  text-align: right;
}

[type="file"] {
  --color: var(--muted-color);
  padding: calc(var(--form-element-spacing-vertical) * 0.5) 0;
  border: 0;
  border-radius: 0;
  background: none;
}
[type="file"]::file-selector-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::file-selector-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-webkit-file-upload-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-webkit-file-upload-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-ms-browse {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  margin-inline-start: 0;
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-ms-browse:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}

[type="range"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 100%;
  height: 1.25rem;
  background: none;
}
[type="range"]::-webkit-slider-runnable-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -webkit-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-moz-range-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -moz-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-ms-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -ms-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-webkit-slider-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-moz-range-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -moz-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-ms-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]:hover,
[type="range"]:focus {
  --range-border-color: var(--range-active-border-color);
  --range-thumb-color: var(--range-thumb-hover-color);
}
[type="range"]:active {
  --range-thumb-color: var(--range-thumb-active-color);
}
[type="range"]:active::-webkit-slider-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-moz-range-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-ms-thumb {
  transform: scale(1.25);
}

input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  -webkit-padding-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  padding-inline-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  border-radius: 5rem;
  background-image: var(--icon-search);
  background-position: center left 1.125rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  -webkit-padding-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  padding-inline-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  background-position: center left 1.125rem, center right 0.75rem;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="false"] {
  background-image: var(--icon-search), var(--icon-valid);
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="true"] {
  background-image: var(--icon-search), var(--icon-invalid);
}

[type="search"]::-webkit-search-cancel-button {
  -webkit-appearance: none;
  display: none;
}

[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  background-position: center right 1.125rem;
}
[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  background-position: center right 1.125rem, center left 0.75rem;
}

/**
 * Table
 */
:where(table) {
  width: 100%;
  border-collapse: collapse;
  border-spacing: 0;
  text-indent: 0;
}

th,
td {
  padding: calc(var(--spacing) / 2) var(--spacing);
  border-bottom: var(--border-width) solid var(--table-border-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  text-align: left;
  text-align: start;
}

tfoot th,
tfoot td {
  border-top: var(--border-width) solid var(--table-border-color);
  border-bottom: 0;
}

table[role="grid"] tbody tr:nth-child(odd) {
  background-color: var(--table-row-stripped-background-color);
}

/**
 * Code
 */
pre,
code,
kbd,
samp {
  font-size: 0.875em;
  font-family: var(--font-family);
}

pre {
  -ms-overflow-style: scrollbar;
  overflow: auto;
}

pre,
code,
kbd {
  border-radius: var(--border-radius);
  background: var(--code-background-color);
  color: var(--code-color);
  font-weight: var(--font-weight);
  line-height: initial;
}

code,
kbd {
  display: inline-block;
  padding: 0.375rem 0.5rem;
}

pre {
  display: block;
  margin-bottom: var(--spacing);
  overflow-x: auto;
}
pre > code {
  display: block;
  padding: var(--spacing);
  background: none;
  font-size: 14px;
  line-height: var(--line-height);
}

code b {
  color: var(--code-tag-color);
  font-weight: var(--font-weight);
}
code i {
  color: var(--code-property-color);
  font-style: normal;
}
code u {
  color: var(--code-value-color);
  text-decoration: none;
}
code em {
  color: var(--code-comment-color);
  font-style: normal;
}

kbd {
  background-color: var(--code-kbd-background-color);
  color: var(--code-kbd-color);
  vertical-align: baseline;
}

/**
 * Miscs
 */
hr {
  height: 0;
  border: 0;
  border-top: 1px solid var(--muted-border-color);
  color: inherit;
}

[hidden],
template {
  display: none !important;
}

canvas {
  display: inline-block;
}

/**
 * Accordion (<details>)
 */
details {
  display: block;
  margin-bottom: var(--spacing);
  padding-bottom: var(--spacing);
  border-bottom: var(--border-width) solid var(--accordion-border-color);
}
details summary {
  line-height: 1rem;
  list-style-type: none;
  cursor: pointer;
  transition: color var(--transition);
}
details summary:not([role]) {
  color: var(--accordion-close-summary-color);
}
details summary::-webkit-details-marker {
  display: none;
}
details summary::marker {
  display: none;
}
details summary::-moz-list-bullet {
  list-style-type: none;
}
details summary::after {
  display: block;
  width: 1rem;
  height: 1rem;
  -webkit-margin-start: calc(var(--spacing, 1rem) * 0.5);
  margin-inline-start: calc(var(--spacing, 1rem) * 0.5);
  float: right;
  transform: rotate(-90deg);
  background-image: var(--icon-chevron);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
  transition: transform var(--transition);
}
details summary:focus {
  outline: none;
}
details summary:focus:not([role="button"]) {
  color: var(--accordion-active-summary-color);
}
details summary[role="button"] {
  width: 100%;
  text-align: left;
}
details summary[role="button"]::after {
  height: calc(1rem * var(--line-height, 1.5));
  background-image: var(--icon-chevron-button);
}
details summary[role="button"]:not(.outline).contrast::after {
  background-image: var(--icon-chevron-button-inverse);
}
details[open] > summary {
  margin-bottom: calc(var(--spacing));
}
details[open] > summary:not([role]):not(:focus) {
  color: var(--accordion-open-summary-color);
}
details[open] > summary::after {
  transform: rotate(0);
}

[dir="rtl"] details summary {
  text-align: right;
}
[dir="rtl"] details summary::after {
  float: left;
  background-position: left center;
}

/**
 * Card (<article>)
 */
article {
  margin: var(--block-spacing-vertical) 0;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
  border-radius: var(--border-radius);
  background: var(--card-background-color);
  box-shadow: var(--card-box-shadow);
}
article > header,
article > footer {
  margin-right: calc(var(--block-spacing-horizontal) * -1);
  margin-left: calc(var(--block-spacing-horizontal) * -1);
  padding: calc(var(--block-spacing-vertical) * 0.66)
    var(--block-spacing-horizontal);
  background-color: var(--card-sectionning-background-color);
}
article > header {
  margin-top: calc(var(--block-spacing-vertical) * -1);
  margin-bottom: var(--block-spacing-vertical);
  border-bottom: var(--border-width) solid var(--card-border-color);
  border-top-right-radius: var(--border-radius);
  border-top-left-radius: var(--border-radius);
}
article > footer {
  margin-top: var(--block-spacing-vertical);
  margin-bottom: calc(var(--block-spacing-vertical) * -1);
  border-top: var(--border-width) solid var(--card-border-color);
  border-bottom-right-radius: var(--border-radius);
  border-bottom-left-radius: var(--border-radius);
}

/**
 * Modal (<dialog>)
 */
#mount {
  --scrollbar-width: 0px;
}

dialog {
  display: flex;
  z-index: 999;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  align-items: center;
  justify-content: center;
  width: inherit;
  min-width: 100%;
  height: inherit;
  min-height: 100%;
  padding: var(--spacing);
  border: 0;
  -webkit-backdrop-filter: var(--modal-overlay-backdrop-filter);
  backdrop-filter: var(--modal-overlay-backdrop-filter);
  background-color: var(--modal-overlay-background-color);
  color: var(--color);
}
dialog article {
  max-height: calc(100vh - var(--spacing) * 2);
  overflow: auto;
}
@media (min-width: 576px) {
  dialog article {
    max-width: 510px;
  }
}
@media (min-width: 768px) {
  dialog article {
    max-width: 700px;
  }
}
dialog article > header,
dialog article > footer {
  padding: calc(var(--block-spacing-vertical) * 0.5)
    var(--block-spacing-horizontal);
}
dialog article > header .close {
  margin: 0;
  margin-left: var(--spacing);
  float: right;
}
dialog article > footer {
  text-align: right;
}
dialog article > footer [role="button"] {
  margin-bottom: 0;
}
dialog article > footer [role="button"]:not(:first-of-type) {
  margin-left: calc(var(--spacing) * 0.5);
}
dialog article p:last-of-type {
  margin: 0;
}
dialog article .close {
  display: block;
  width: 1rem;
  height: 1rem;
  margin-top: calc(var(--block-spacing-vertical) * -0.5);
  margin-bottom: var(--typography-spacing-vertical);
  margin-left: auto;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}
dialog article .close:is([aria-current], :hover, :active, :focus) {
  opacity: 1;
}
dialog:not([open]),
dialog[open="false"] {
  display: none;
}

.modal-is-open {
  padding-right: var(--scrollbar-width, 0px);
  overflow: hidden;
  pointer-events: none;
}
.modal-is-open dialog {
  pointer-events: auto;
}

:where(.modal-is-opening, .modal-is-closing) dialog,
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-duration: 0.2s;
  animation-timing-function: ease-in-out;
  animation-fill-mode: both;
}
:where(.modal-is-opening, .modal-is-closing) dialog {
  animation-duration: 0.8s;
  animation-name: modal-overlay;
}
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-delay: 0.2s;
  animation-name: modal;
}

.modal-is-closing dialog,
.modal-is-closing dialog > article {
  animation-delay: 0s;
  animation-direction: reverse;
}

@keyframes modal-overlay {
  from {
    -webkit-backdrop-filter: none;
    backdrop-filter: none;
    background-color: transparent;
  }
}
@keyframes modal {
  from {
    transform: translateY(-100%);
    opacity: 0;
  }
}
/**
 * Nav
 */
:where(nav li)::before {
  float: left;
  content: "​";
}

nav,
nav ul {
  display: flex;
}

nav {
  justify-content: space-between;
}
nav ol,
nav ul {
  align-items: center;
  margin-bottom: 0;
  padding: 0;
  list-style: none;
}
nav ol:first-of-type,
nav ul:first-of-type {
  margin-left: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav ol:last-of-type,
nav ul:last-of-type {
  margin-right: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav li {
  display: inline-block;
  margin: 0;
  padding: var(--nav-element-spacing-vertical)
    var(--nav-element-spacing-horizontal);
}
nav li > * {
  --spacing: 0;
}
nav :where(a, [role="link"]) {
  display: inline-block;
  margin: calc(var(--nav-link-spacing-vertical) * -1)
    calc(var(--nav-link-spacing-horizontal) * -1);
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
  border-radius: var(--border-radius);
  text-decoration: none;
}
nav :where(a, [role="link"]):is([aria-current], :hover, :active, :focus) {
  text-decoration: none;
}
nav[aria-label="breadcrumb"] {
  align-items: center;
  justify-content: start;
}
nav[aria-label="breadcrumb"] ul li:not(:first-child) {
  -webkit-margin-start: var(--nav-link-spacing-horizontal);
  margin-inline-start: var(--nav-link-spacing-horizontal);
}
nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  position: absolute;
  width: calc(var(--nav-link-spacing-horizontal) * 2);
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) / 2);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) / 2);
  content: "/";
  color: var(--muted-color);
  text-align: center;
}
nav[aria-label="breadcrumb"] a[aria-current] {
  background-color: transparent;
  color: inherit;
  text-decoration: none;
  pointer-events: none;
}
nav [role="button"] {
  margin-right: inherit;
  margin-left: inherit;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}

aside nav,
aside ol,
aside ul,
aside li {
  display: block;
}
aside li {
  padding: calc(var(--nav-element-spacing-vertical) * 0.5)
    var(--nav-element-spacing-horizontal);
}
aside li a {
  display: block;
}
aside li [role="button"] {
  margin: inherit;
}

[dir="rtl"] nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  content: "\\";
}

/**
 * Progress
 */
progress {
  display: inline-block;
  vertical-align: baseline;
}

progress {
  -webkit-appearance: none;
  -moz-appearance: none;
  display: inline-block;
  appearance: none;
  width: 100%;
  height: 0.5rem;
  margin-bottom: calc(var(--spacing) * 0.5);
  overflow: hidden;
  border: 0;
  border-radius: var(--border-radius);
  background-color: var(--progress-background-color);
  color: var(--progress-color);
}
progress::-webkit-progress-bar {
  border-radius: var(--border-radius);
  background: none;
}
progress[value]::-webkit-progress-value {
  background-color: var(--progress-color);
}
progress::-moz-progress-bar {
  background-color: var(--progress-color);
}
@media (prefers-reduced-motion: no-preference) {
  progress:indeterminate {
    background: var(--progress-background-color)
      linear-gradient(
        to right,
        var(--progress-color) 30%,
        var(--progress-background-color) 30%
      )
      top left/150% 150% no-repeat;
    animation: progress-indeterminate 1s linear infinite;
  }
  progress:indeterminate[value]::-webkit-progress-value {
    background-color: transparent;
  }
  progress:indeterminate::-moz-progress-bar {
    background-color: transparent;
  }
}

@media (prefers-reduced-motion: no-preference) {
  [dir="rtl"] progress:indeterminate {
    animation-direction: reverse;
  }
}

@keyframes progress-indeterminate {
  0% {
    background-position: 200% 0;
  }
  100% {
    background-position: -200% 0;
  }
}
/**
 * Dropdown ([role="list"])
 */
details[role="list"],
li[role="list"] {
  position: relative;
}

details[role="list"] summary + ul,
li[role="list"] > ul {
  display: flex;
  z-index: 99;
  position: absolute;
  top: auto;
  right: 0;
  left: 0;
  flex-direction: column;
  margin: 0;
  padding: 0;
  border: var(--border-width) solid var(--dropdown-border-color);
  border-radius: var(--border-radius);
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  background-color: var(--dropdown-background-color);
  box-shadow: var(--card-box-shadow);
  color: var(--dropdown-color);
  white-space: nowrap;
}
details[role="list"] summary + ul li,
li[role="list"] > ul li {
  width: 100%;
  margin-bottom: 0;
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  list-style: none;
}
details[role="list"] summary + ul li:first-of-type,
li[role="list"] > ul li:first-of-type {
  margin-top: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li:last-of-type,
li[role="list"] > ul li:last-of-type {
  margin-bottom: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li a,
li[role="list"] > ul li a {
  display: block;
  margin: calc(var(--form-element-spacing-vertical) * -0.5)
    calc(var(--form-element-spacing-horizontal) * -1);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  overflow: hidden;
  color: var(--dropdown-color);
  text-decoration: none;
  text-overflow: ellipsis;
}
details[role="list"] summary + ul li a:hover,
li[role="list"] > ul li a:hover {
  background-color: var(--dropdown-hover-background-color);
}

details[role="list"] summary::after,
li[role="list"] > a::after {
  display: block;
  width: 1rem;
  height: calc(1rem * var(--line-height, 1.5));
  -webkit-margin-start: 0.5rem;
  margin-inline-start: 0.5rem;
  float: right;
  transform: rotate(0deg);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
}

details[role="list"] {
  padding: 0;
  border-bottom: none;
}
details[role="list"] summary {
  margin-bottom: 0;
}
details[role="list"] summary:not([role]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--form-element-border-color);
  border-radius: var(--border-radius);
  background-color: var(--form-element-background-color);
  color: var(--form-element-placeholder-color);
  line-height: inherit;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
details[role="list"] summary:not([role]):active,
details[role="list"] summary:not([role]):focus {
  border-color: var(--form-element-active-border-color);
  background-color: var(--form-element-active-background-color);
}
details[role="list"] summary:not([role]):focus {
  box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}
details[role="list"][open] summary {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
details[role="list"][open] summary::before {
  display: block;
  z-index: 1;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  background: none;
  content: "";
  cursor: default;
}

nav details[role="list"] summary,
nav li[role="list"] a {
  display: flex;
  direction: ltr;
}

nav details[role="list"] summary + ul,
nav li[role="list"] > ul {
  min-width: -moz-fit-content;
  min-width: fit-content;
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul li a,
nav li[role="list"] > ul li a {
  border-radius: 0;
}

nav details[role="list"] summary,
nav details[role="list"] summary:not([role]) {
  height: auto;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}
nav details[role="list"][open] summary {
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul {
  margin-top: var(--outline-width);
  -webkit-margin-start: 0;
  margin-inline-start: 0;
}
nav details[role="list"] summary[role="link"] {
  margin-bottom: calc(var(--nav-link-spacing-vertical) * -1);
  line-height: var(--line-height);
}
nav details[role="list"] summary[role="link"] + ul {
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) * -1);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) * -1);
}

li[role="list"]:hover > ul,
li[role="list"] a:active ~ ul,
li[role="list"] a:focus ~ ul {
  display: flex;
}
li[role="list"] > ul {
  display: none;
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
  margin-inline-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
}
li[role="list"] > a::after {
  background-image: var(--icon-chevron);
}

/**
 * Loading ([aria-busy=true])
 */
[aria-busy="true"] {
  cursor: progress;
}

[aria-busy="true"]:not(input, select, textarea)::before {
  display: inline-block;
  width: 1em;
  height: 1em;
  border: 0.1875em solid currentColor;
  border-radius: 1em;
  border-right-color: transparent;
  content: "";
  vertical-align: text-bottom;
  vertical-align: -0.125em;
  animation: spinner 0.75s linear infinite;
  opacity: var(--loading-spinner-opacity);
}
[aria-busy="true"]:not(input, select, textarea):not(:empty)::before {
  margin-right: calc(var(--spacing) * 0.5);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) * 0.5);
  margin-inline-end: calc(var(--spacing) * 0.5);
}
[aria-busy="true"]:not(input, select, textarea):empty {
  text-align: center;
}

button[aria-busy="true"],
input[type="submit"][aria-busy="true"],
input[type="button"][aria-busy="true"],
input[type="reset"][aria-busy="true"],
a[aria-busy="true"] {
  pointer-events: none;
}

@keyframes spinner {
  to {
    transform: rotate(360deg);
  }
}
/**
 * Tooltip ([data-tooltip])
 */
[data-tooltip] {
  position: relative;
}
[data-tooltip]:not(a, button, input) {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}
[data-tooltip][data-placement="top"]::before,
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::before,
[data-tooltip]::after {
  display: block;
  z-index: 99;
  position: absolute;
  bottom: 100%;
  left: 50%;
  padding: 0.25rem 0.5rem;
  overflow: hidden;
  transform: translate(-50%, -0.25rem);
  border-radius: var(--border-radius);
  background: var(--tooltip-background-color);
  content: attr(data-tooltip);
  color: var(--tooltip-color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: 0.875rem;
  text-decoration: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  opacity: 0;
  pointer-events: none;
}
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::after {
  padding: 0;
  transform: translate(-50%, 0rem);
  border-top: 0.3rem solid;
  border-right: 0.3rem solid transparent;
  border-left: 0.3rem solid transparent;
  border-radius: 0;
  background-color: transparent;
  content: "";
  color: var(--tooltip-background-color);
}
[data-tooltip][data-placement="bottom"]::before,
[data-tooltip][data-placement="bottom"]::after {
  top: 100%;
  bottom: auto;
  transform: translate(-50%, 0.25rem);
}
[data-tooltip][data-placement="bottom"]:after {
  transform: translate(-50%, -0.3rem);
  border: 0.3rem solid transparent;
  border-bottom: 0.3rem solid;
}
[data-tooltip][data-placement="left"]::before,
[data-tooltip][data-placement="left"]::after {
  top: 50%;
  right: 100%;
  bottom: auto;
  left: auto;
  transform: translate(-0.25rem, -50%);
}
[data-tooltip][data-placement="left"]:after {
  transform: translate(0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-left: 0.3rem solid;
}
[data-tooltip][data-placement="right"]::before,
[data-tooltip][data-placement="right"]::after {
  top: 50%;
  right: auto;
  bottom: auto;
  left: 100%;
  transform: translate(0.25rem, -50%);
}
[data-tooltip][data-placement="right"]:after {
  transform: translate(-0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-right: 0.3rem solid;
}
[data-tooltip]:focus::before,
[data-tooltip]:focus::after,
[data-tooltip]:hover::before,
[data-tooltip]:hover::after {
  opacity: 1;
}
@media (hover: hover) and (pointer: fine) {
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::before,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::before,
  [data-tooltip]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::after {
    animation-name: tooltip-caret-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::before,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-bottom;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-name: tooltip-caret-slide-bottom;
  }
  [data-tooltip][data-placement="left"]:focus::before,
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::before,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-left;
  }
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-name: tooltip-caret-slide-left;
  }
  [data-tooltip][data-placement="right"]:focus::before,
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::before,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-right;
  }
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-name: tooltip-caret-slide-right;
  }
}
@keyframes tooltip-slide-top {
  from {
    transform: translate(-50%, 0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-top {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.25rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-bottom {
  from {
    transform: translate(-50%, -0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-bottom {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.5rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.3rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-left {
  from {
    transform: translate(0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-left {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.3rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-slide-right {
  from {
    transform: translate(-0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-right {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.3rem, -50%);
    opacity: 1;
  }
}

/**
 * Accessibility & User interaction
 */
[aria-controls] {
  cursor: pointer;
}

[aria-disabled="true"],
[disabled] {
  cursor: not-allowed;
}

[aria-hidden="false"][hidden] {
  display: initial;
}

[aria-hidden="false"][hidden]:not(:focus) {
  clip: rect(0, 0, 0, 0);
  position: absolute;
}

a,
area,
button,
input,
label,
select,
summary,
textarea,
[tabindex] {
  -ms-touch-action: manipulation;
}

[dir="rtl"] {
  direction: rtl;
}

/**
* Reduce Motion Features
*/
@media (prefers-reduced-motion: reduce) {
  *:not([aria-busy="true"]),
  :not([aria-busy="true"])::before,
  :not([aria-busy="true"])::after {
    background-attachment: initial !important;
    animation-duration: 1ms !important;
    animation-delay: -1ms !important;
    animation-iteration-count: 1 !important;
    scroll-behavior: auto !important;
    transition-delay: 0s !important;
    transition-duration: 0s !important;
  }
}

#mount {
  /* --primary: rgb(227, 59, 126); */
  --primary: #ea4c89;
  --primary-hover: #f082ac;
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  --switch-checked-background-color: var(--primary);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="dark"] {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="light"] {
  --primary: #ea4c89;
  --primary-hover: #f082ac;
}

li.select-link.select-link:hover > ul {
  display: none;
}
li.select-link.select-link > ul {
  display: none;
}
li.select-link.select-link a:focus ~ ul {
  display: none;
}

li.select-link.select-link a:active ~ ul {
  display: none;
}
li.select-link-active.select-link-active > ul {
  display: flex;
}
li.select-link-active.select-link-active:hover > ul {
  display: flex;
}

li.select-link-active.select-link-active a:focus ~ ul {
  display: flex;
}

li.select-link-active.select-link-active a:active ~ ul {
  display: flex;
}
ul.select-link-ul.select-link-ul {
  right: 0px;
  left: auto;
}

a.select-link-selected {
  background-color: var(--primary-focus);
}
.immersive-translate-no-select {
  -webkit-touch-callout: none; /* iOS Safari */
  -webkit-user-select: none; /* Safari */
  -khtml-user-select: none; /* Konqueror HTML */
  -moz-user-select: none; /* Old versions of Firefox */
  -ms-user-select: none; /* Internet Explorer/Edge */
  user-select: none;
}

/* li[role="list"].no-arrow > a::after { */
/*   background-image: none; */
/*   width: 0; */
/*   color: var(--color); */
/* } */
li[role="list"].no-arrow {
  margin-left: 8px;
  padding-right: 0;
}
li[role="list"] > a::after {
  -webkit-margin-start: 0.2rem;
  margin-inline-start: 0.2rem;
}

li[role="list"].no-arrow > a,
li[role="list"].no-arrow > a:link,
li[role="list"].no-arrow > a:visited {
  color: var(--secondary);
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  padding-left: 8px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}
select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.muted {
  color: var(--muted-color);
}

.select.button-select {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
  cursor: pointer;
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 16px;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
  -webkit-appearance: button;
  margin: 0;
  margin-bottom: 0px;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --text-black-2: #222222;
  --text-gray-2: #222222;
  --text-gray-6: #666666;
  --text-gray-9: #999999;
  --text-gray-c2: #c2c2c2;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --popup-footer-background-color: #0d0d0d;
    --popup-content-background-color: #191919;
    --popup-item-background-color: #272727;
    --popup-item-hover-background-color: #333333;
    --popup-trial-pro-background-color: #222222;
    --text-black-2: #ffffff;
    --text-gray-2: #dbdbdb;
    --text-gray-6: #b3b3b3;
    --text-gray-9: #777777;
    --text-gray-c2: #5b5b5b;
    --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
    --service-select-border-color: #2c2c2c;
    --service-select-selected-background-color: #333333;
    --download-app-background: #333;
  }
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --text-black-2: #ffffff;
  --text-gray-2: #dbdbdb;
  --text-gray-6: #b3b3b3;
  --text-gray-9: #777777;
  --text-gray-c2: #5b5b5b;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

.text-balck {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

#mount {
  min-width: 268px;
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

select.min-select-secondary {
  color: var(--color);
}

select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 372px;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #B3B3B3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 237px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg><svg hidden="true" class="imt-manga-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div><svg class="imt-float-ball-loading" hidden="true" width="19" height="19" viewBox="0 0 19 19" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin: 9px;"><path d="M9.42859 0C9.84288 0 10.1929 0.387143 10.1929 0.847143V3.99429C10.1929 4.45429 9.84431 4.84143 9.42859 4.84143C9.01431 4.84143 8.66431 4.45571 8.66431 3.99429V0.847143C8.66431 0.387143 9.01288 0 9.42859 0Z" fill="#E9E9E9"></path><path d="M14.1301 1.38877C14.5158 1.62591 14.6301 2.12163 14.4258 2.52305L12.9515 5.19448C12.901 5.28714 12.8325 5.36876 12.75 5.43455C12.6675 5.50035 12.5727 5.54898 12.4712 5.5776C12.3696 5.60621 12.2634 5.61424 12.1586 5.60119C12.0539 5.58814 11.9529 5.55429 11.8615 5.50163C11.6787 5.38432 11.5468 5.20237 11.4923 4.9921C11.4377 4.78184 11.4645 4.55874 11.5672 4.36734L13.0415 1.69591C13.2686 1.29448 13.7443 1.15305 14.1301 1.38877Z" fill="#989697"></path><path d="M17.4685 4.75707C17.5813 4.95451 17.6123 5.18824 17.5549 5.40825C17.4975 5.62826 17.3563 5.81705 17.1614 5.93422L14.4971 7.52564C14.0971 7.76993 13.6014 7.62422 13.3657 7.20707C13.2532 7.00994 13.2222 6.77667 13.2793 6.55702C13.3365 6.33737 13.4771 6.14874 13.6714 6.03136L16.3357 4.43993C16.7371 4.21993 17.2557 4.34136 17.4685 4.7585V4.75707Z" fill="#9B999A"></path><path d="M18.8572 9.42835C18.8572 9.84263 18.47 10.1926 18.01 10.1926H14.8629C14.4029 10.1926 14.0157 9.84406 14.0157 9.42835C14.0157 9.01406 14.4029 8.66406 14.8629 8.66406H18.01C18.47 8.66406 18.8572 9.01263 18.8572 9.42835Z" fill="#A3A1A2"></path><path d="M17.4686 14.1303C17.3515 14.3134 17.1697 14.4455 16.9594 14.5003C16.7491 14.5552 16.5259 14.5286 16.3343 14.426L13.6629 12.9517C13.5702 12.9012 13.4886 12.8327 13.4228 12.7503C13.357 12.6678 13.3084 12.573 13.2798 12.4714C13.2512 12.3698 13.2431 12.2636 13.2562 12.1589C13.2692 12.0542 13.3031 11.9532 13.3558 11.8617C13.4731 11.6789 13.655 11.547 13.8653 11.4925C14.0755 11.4379 14.2986 11.4647 14.49 11.5674L17.1615 13.0417C17.5629 13.2689 17.7043 13.7446 17.4686 14.1303Z" fill="#ABA9AA"></path><path opacity="0.7" d="M14.1 17.4686C13.9026 17.5814 13.6689 17.6124 13.4489 17.555C13.2288 17.4976 13.04 17.3564 12.9229 17.1615L11.3315 14.4972C11.0872 14.0972 11.2329 13.6015 11.65 13.3658C11.8472 13.2533 12.0804 13.2224 12.3001 13.2795C12.5197 13.3366 12.7084 13.4773 12.8257 13.6715L14.4172 16.3358C14.6372 16.7372 14.5157 17.2558 14.0986 17.4686H14.1Z" fill="#B2B2B2"></path><path opacity="0.6" d="M9.42859 18.8571C9.01431 18.8571 8.66431 18.4699 8.66431 18.0099V14.8628C8.66431 14.4028 9.01288 14.0156 9.42859 14.0156C9.84288 14.0156 10.1929 14.4028 10.1929 14.8628V18.0099C10.1929 18.4699 9.84431 18.8571 9.42859 18.8571Z" fill="#BAB8B9"></path><path opacity="0.5" d="M4.72717 17.4685C4.5441 17.3514 4.41195 17.1696 4.35713 16.9593C4.30231 16.749 4.32885 16.5258 4.43145 16.3342L5.90574 13.6628C5.95622 13.5701 6.02472 13.4885 6.1072 13.4227C6.18969 13.3569 6.2845 13.3083 6.38606 13.2797C6.48762 13.251 6.59387 13.243 6.69857 13.2561C6.80327 13.2691 6.90431 13.303 6.99574 13.3556C7.38145 13.5914 7.49431 14.0885 7.29002 14.4899L5.81574 17.1614C5.5886 17.5628 5.11288 17.7042 4.72717 17.4685Z" fill="#C2C0C1"></path><path opacity="0.4" d="M1.38862 14.1002C1.27584 13.9027 1.24483 13.669 1.30223 13.449C1.35964 13.229 1.50089 13.0402 1.69576 12.923L4.36004 11.3316C4.76004 11.0873 5.25576 11.233 5.49147 11.6502C5.60393 11.8473 5.63491 12.0806 5.5778 12.3002C5.52069 12.5199 5.38 12.7085 5.18576 12.8259L2.52004 14.4173C2.12004 14.6373 1.60004 14.5159 1.38862 14.0987V14.1002Z" fill="#CBCBCB"></path><path d="M0 9.42835C0 9.01406 0.387143 8.66406 0.847143 8.66406H3.99429C4.45429 8.66406 4.84143 9.01263 4.84143 9.42835C4.84143 9.84263 4.45571 10.1926 3.99429 10.1926H0.847143C0.387143 10.1926 0 9.84406 0 9.42835Z" fill="#D2D2D2"></path><path opacity="0.2" d="M1.38852 4.72705C1.50561 4.54398 1.68746 4.41183 1.89774 4.35701C2.10803 4.30219 2.33125 4.32873 2.52281 4.43133L5.19424 5.90562C5.28689 5.9561 5.36851 6.0246 5.43431 6.10708C5.5001 6.18957 5.54874 6.28438 5.57735 6.38594C5.60597 6.48749 5.61399 6.59375 5.60094 6.69845C5.5879 6.80315 5.55405 6.90419 5.50138 6.99562C5.38407 7.17844 5.20212 7.31029 4.99186 7.36484C4.78159 7.4194 4.55849 7.39263 4.3671 7.2899L1.69567 5.81562C1.29424 5.58847 1.15281 5.11276 1.38852 4.72705Z" fill="#DADADA"></path><path d="M4.75719 1.38849C4.95463 1.27571 5.18837 1.24471 5.40838 1.30211C5.62838 1.35952 5.81718 1.50077 5.93434 1.69564L7.52577 4.35992C7.77005 4.75992 7.62434 5.25564 7.20719 5.49135C7.01006 5.60381 6.77679 5.63479 6.55714 5.57768C6.33749 5.52056 6.14886 5.37988 6.03148 5.18564L4.44005 2.51992C4.22005 2.11992 4.34148 1.59992 4.75862 1.38849H4.75719Z" fill="#E2E2E2"></path></svg></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; top: 237px; right: 65px;"></div></div></div></div></template></div></html>