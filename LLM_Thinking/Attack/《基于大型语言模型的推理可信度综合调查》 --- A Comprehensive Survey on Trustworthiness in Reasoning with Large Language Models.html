<!DOCTYPE html>
<!-- saved from url=(0354)https://whiffe.github.io/Paper_Translation/Attack/Survey/%E3%80%8A%E5%9F%BA%E4%BA%8E%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86%E5%8F%AF%E4%BF%A1%E5%BA%A6%E7%BB%BC%E5%90%88%E8%B0%83%E6%9F%A5%E3%80%8B%20-%2D-%20A%20Comprehensive%20Survey%20on%20Trustworthiness%20in%20Reasoning%20with%20Large%20Language%20Models.html -->
<html lang="en" data-theme="dark" imt-state="dual" imt-trans-position="after"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models</title>
<!--Generated on Thu Sep  4 04:14:11 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/ar5iv.0.8.2.min.css" rel="stylesheet" type="text/css">
<link href="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/ar5iv-fonts.0.8.2.min.css" rel="stylesheet" type="text/css">
<link href="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/latexml_styles.0.8.2.css" rel="stylesheet" type="text/css">
<script src="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/bootstrap.bundle.min.js"></script>
<script src="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/html2canvas.min.js"></script>
<script src="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/addons_new.js"></script>
<script src="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/feedbackOverlay.js"></script>
<!--<base href="/html/2509.03871v1/">--><!--<base href=".">--><base href="."><link rel="stylesheet" href="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/utz6mli.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-default-injected-css">:root {
  --immersive-translate-theme-underline-borderColor: #72ece9;
  --immersive-translate-theme-nativeUnderline-borderColor: #72ece9;
  --immersive-translate-theme-nativeDashed-borderColor: #72ece9;
  --immersive-translate-theme-nativeDotted-borderColor: #72ece9;
  --immersive-translate-theme-highlight-backgroundColor: #ffff00;
  --immersive-translate-theme-dashed-borderColor: #59c1bd;
  --immersive-translate-theme-blockquote-borderColor: #cc3355;
  --immersive-translate-theme-thinDashed-borderColor: #ff374f;
  --immersive-translate-theme-dashedBorder-borderColor: #94a3b8;
  --immersive-translate-theme-dashedBorder-borderRadius: 0;
  --immersive-translate-theme-solidBorder-borderColor: #94a3b8;
  --immersive-translate-theme-solidBorder-borderRadius: 0;
  --immersive-translate-theme-dotted-borderColor: #94a3b8;
  --immersive-translate-theme-wavy-borderColor: #72ece9;
  --immersive-translate-theme-dividingLine-borderColor: #94a3b8;
  --immersive-translate-theme-grey-textColor: #2f4f4f;
  --immersive-translate-theme-marker-backgroundColor: #fbda41;
  --immersive-translate-theme-marker-backgroundColor-rgb: 251, 218, 65;
  --immersive-translate-theme-marker2-backgroundColor: #ffff00;
  --immersive-translate-theme-background-backgroundColor: #dbafaf;
  --immersive-translate-theme-background-backgroundColor-rgb: 219, 175, 175;
  --immersive-translate-theme-background-backgroundOpacity: 12;
  --immersive-translate-theme-opacity-opacity: 10;
}

[imt-state="dual"] .immersive-translate-target-translation-pre-whitespace {
  white-space: pre-wrap !important;
}

[imt-state="dual"] .immersive-translate-pdf-target-container {
  position: absolute;
  background-color: #fff;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica,
    sans-serif;
  top: 0;
  width: 600px;
  height: 100%;
  z-index: 2;
  line-height: 1.3;
  font-size: 16px;
}
[imt-state="dual"] .immersive-translate-target-wrapper[dir="rtl"] {
  text-align: right;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper {
  color: rgb(0, 0, 0);
  white-space: normal;
  position: absolute;
}

[imt-state="dual"]
  .immersive-translate-pdf-target-container
  .immersive-translate-target-wrapper
  font {
  color: inherit;
  white-space: inherit;
  position: unset;
}

[imt-state="translation"] .immersive-translate-target-wrapper > br {
  display: none;
}

[imt-state="translation"]
  .immersive-translate-target-translation-block-wrapper {
  margin: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-block-wrapper {
  margin: 8px 0 !important;
  display: inline-block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  display: block;
}

[imt-trans-position="before"]
  .immersive-translate-target-translation-block-wrapper {
  margin-top: 0 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-pdf-block-wrapper {
  margin: 0 !important;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-grey-inner {
  color: var(--immersive-translate-theme-grey-textColor);
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-underline-inner {
  border-bottom: 1px solid
    var(--immersive-translate-theme-underline-borderColor) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeUnderline-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeUnderline-borderColor
  ) !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dashedBorder {
  border: 1px dashed var(--immersive-translate-theme-dashedBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-dashedBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 6px;
  margin-top: 2px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-solidBorder {
  border: 1px solid var(--immersive-translate-theme-solidBorder-borderColor) !important;
  border-radius: var(
    --immersive-translate-theme-solidBorder-borderRadius
  ) !important;
  padding: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDashed-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDashed-borderColor
  ) !important;
  text-decoration-style: dashed !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-thinDashed-inner {
  border-bottom: 1px dashed
    var(--immersive-translate-theme-thinDashed-borderColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dotted-inner {
  background-image: linear-gradient(
    to right,
    var(--immersive-translate-theme-dotted-borderColor) 30%,
    rgba(255, 255, 255, 0) 0%
  );
  background-position: bottom;
  background-size: 5px 1px;
  background-repeat: repeat-x;
  padding-bottom: 3px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-nativeDotted-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-nativeDotted-borderColor
  ) !important;
  text-decoration-style: dotted !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-wavy-inner {
  text-decoration: underline !important;
  text-decoration-color: var(
    --immersive-translate-theme-wavy-borderColor
  ) !important;
  text-decoration-style: wavy !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-dashed-inner {
  background: linear-gradient(
      to right,
      var(--immersive-translate-theme-dashed-borderColor) 0%,
      var(--immersive-translate-theme-dashed-borderColor) 50%,
      transparent 50%,
      transparent 100%
    )
    repeat-x left bottom;
  background-size: 8px 2px;
  padding-bottom: 2px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {
  content: "";
  display: block;
  max-width: 80px;
  width: 10%;
  border-top: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  padding-top: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-inline-wrapper-theme-dividingLine::before {
  content: "";
  border-left: 1px dashed
    var(--immersive-translate-theme-dividingLine-borderColor);
  max-height: 16px;
  height: 16px;
  padding-left: 8px;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-highlight-inner {
  background: var(--immersive-translate-theme-highlight-backgroundColor);
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-marker {
  line-height: 1.5em;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker2-inner {
  font-weight: bold;
  text-shadow: 10px 0px 3px
      var(--immersive-translate-theme-marker2-backgroundColor),
    16px 3px 9px var(--immersive-translate-theme-marker2-backgroundColor),
    2px 0px 6px var(--immersive-translate-theme-marker2-backgroundColor),
    -12px 0px 12px var(--immersive-translate-theme-marker2-backgroundColor) !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-marker-inner {
  /* TODO: add more texture */
  background: linear-gradient(
    to right,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.1),
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 3%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 35%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.9) 70%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.8) 95%,
    rgba(var(--immersive-translate-theme-marker-backgroundColor-rgb), 0.3)
  );
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-weakening {
  opacity: 0.618 !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-italic {
  font-style: italic !important;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-bold {
  font-weight: bold !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-paper {
  margin: 8px 0;
  box-shadow: rgba(0, 0, 0, 0.24) 0px 3px 8px;
  padding: 16px 32px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-blockquote {
  border-left: 4px solid var(--immersive-translate-theme-blockquote-borderColor) !important;
  padding-left: 12px !important;
  margin-top: 4px;
  margin-bottom: 4px;
  padding-top: 4px;
  padding-bottom: 4px;
  display: inline-block;
}

[imt-state="dual"] .immersive-translate-target-translation-theme-mask-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-mask-inner {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner {
  filter: blur(5px) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

/* opacity theme start */

[imt-state="dual"] .immersive-translate-target-translation-theme-opacity-inner {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[data-immersive-translate-root-translation-theme="none"]
  .immersive-translate-target-translation-theme-opacity-inner {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner,
[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: opacity(
    calc(var(--immersive-translate-theme-opacity-opacity) * 1%)
  ) !important;
  transition: filter 0.3s ease !important;
  border-radius: 10px;
  display: inline-block;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-opacity-inner:hover {
  filter: none !important;
}

[imt-state="dual"]
  .immersive-translate-target-translation-theme-mask-inner:hover {
  filter: none !important;
}
[data-immersive-translate-root-translation-theme="opacity"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

[data-immersive-translate-root-translation-theme="mask"]
  .immersive-translate-target-inner:hover {
  filter: none !important;
}

/* opacity theme end */

/* background theme start */
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper-theme-background {
  margin: 8px 0;
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  border-radius: 4px;
  box-shadow: unset !important;
  padding: 12px;
  display: inline-block;
}
[imt-state="dual"]
  .immersive-translate-target-translation-theme-background-inner {
  background: rgba(
    var(--immersive-translate-theme-background-backgroundColor-rgb),
    calc(var(--immersive-translate-theme-background-backgroundOpacity) * 1%)
  );
  padding-left: 6px;
  padding-right: 6px;
  box-decoration-break: clone;
  -webkit-box-decoration-break: clone;
}
[imt-state="dual"]
  .immersive-translate-target-translation-block-wrapper
  .immersive-translate-target-translation-theme-background-inner {
  background: unset;
  padding-left: unset;
  padding-right: unset;
}
/* background theme end */

/* vertical css , please remain it in the last one. */
.immersive-translate-target-translation-vertical-block-wrapper {
  margin: 0px 8px !important;
}

.immersive-translate-text {
  font-size: 15px !important;
}

.immersive-translate-error-toast {
  position: fixed;
  top: 5%;
  z-index: 99999999;
  left: 0;
  right: 0;
  margin: auto;
  max-width: 300px;
  padding: 16px;
  border-radius: 12px;
  background-color: rgba(0, 0, 0, 0.8);
  display: flex;
  flex-direction: row;
  justify-content: space-between;
}

@media all and (min-width: 750px) {
  .immersive-translate-error-toast {
    max-width: 400px;
  }
}

.immersive-translate-clickable-button {
  cursor: pointer;
}

.immersive-translate-help-button {
  cursor: pointer;
}

.immersive-translate-loading-text:before {
  content: "...";
}

/* dark mode for loading */

@media only screen and (prefers-color-scheme: dark) {
  .immersive-translate-loading {
    border: 2px rgba(255, 255, 255, 0.25) solid !important;
    border-top: 2px rgba(255, 255, 255, 1) solid !important;
  }
}

.immersive-translate-error-wrapper {
  position: relative;
  display: inline-flex;
  padding: 6px;
  margin: 0 12px;
  white-space: nowrap;
  font-size: 0.9em;
}
[lang="zh-CN"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}
[lang="zh-TW"] .immersive-translate-error-wrapper {
  font-size: 0.75em;
}

.immersive-translate-tooltip {
  position: relative;
  display: inline-flex;
  /* little indicater to indicate it's hoverable */
}

.immersive-translate-tooltip-content {
  /* here's the magic */
  position: absolute;
  z-index: 100000000000;

  left: 50%;
  bottom: 0;
  transform: translate(-50%, 110%);
  line-height: 1;
  /* and add a small left margin */

  /* basic styles */
  width: max-content;
  max-width: 250px;
  word-wrap: break-word;
  white-space: pre-line;
  padding: 10px;
  border-radius: 10px;
  background: #000c;
  color: #fff;
  text-align: center;
  font-size: 14px;
  display: none;
  /* hide by default */
}

.immersive-translate-tooltip:hover .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip:hover + .immersive-translate-tooltip-content {
  display: inline-block;
}

.immersive-translate-tooltip-content-table {
  left: unset !important;
  bottom: unset !important;
  transform: translate(-10%, 50%) !important;
}

.immersive-translate-tooltip:hover:before {
  display: inline-block;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5);
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: var(--bg-2, #fff);
  font-size: 14px;
}
</style><style data-id="immersive-translate-user-custom-style">:root {

.immersive-translate-target-inner { font-family: inherit; }


.immersive-translate-target-inner { font-family: inherit; }
}
</style><style data-id="immersive-translate-dynamic-injected-css">.immersive-translate-target-wrapper[dir='rtl'] {text-align: right;display:block!important;}
[dir='rtl'] .immersive-translate-target-wrapper:not([dir]) {text-align:left;direction:ltr;}
.immersive-translate-target-wrapper {word-break:break-word; user-select:text;}
[imt-state=dual] .immersive-translate-target-translation-block-wrapper-theme-dividingLine::before {display:block;}
[imt-trans-position=before] .immersive-translate-target-translation-block-wrapper {display:block!important;}
</style><link rel="stylesheet" href="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/utz6mli(1).css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"><style data-id="immersive-translate-input-injected-css">.immersive-translate-input {
  position: absolute;
  top: 0;
  right: 0;
  left: 0;
  bottom: 0;
  z-index: 2147483647;
  display: flex;
  justify-content: center;
  align-items: center;
}
.immersive-translate-attach-loading::after {
  content: " ";

  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;

  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-2000%, -50%);
  z-index: 100;
}

.immersive-translate-loading-spinner {
  vertical-align: middle !important;
  width: 10px !important;
  height: 10px !important;
  display: inline-block !important;
  margin: 0 4px !important;
  border: 2px rgba(221, 244, 255, 0.6) solid !important;
  border-top: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-left: 2px rgba(0, 0, 0, 0.375) solid !important;
  border-radius: 50% !important;
  padding: 0 !important;
  -webkit-animation: immersive-translate-loading-animation 0.6s infinite linear !important;
  animation: immersive-translate-loading-animation 0.6s infinite linear !important;
}

@-webkit-keyframes immersive-translate-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes immersive-translate-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.immersive-translate-input-loading {
  --loading-color: #f78fb6;
  width: 6px;
  height: 6px;
  border-radius: 50%;
  display: block;
  margin: 12px auto;
  position: relative;
  color: white;
  left: -100px;
  box-sizing: border-box;
  animation: immersiveTranslateShadowRolling 1.5s linear infinite;
}

@keyframes immersiveTranslateShadowRolling {
  0% {
    box-shadow: 0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  12% {
    box-shadow: 100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  25% {
    box-shadow: 110px 0 var(--loading-color), 100px 0 var(--loading-color),
      0px 0 rgba(255, 255, 255, 0), 0px 0 rgba(255, 255, 255, 0);
  }

  36% {
    box-shadow: 120px 0 var(--loading-color), 110px 0 var(--loading-color),
      100px 0 var(--loading-color), 0px 0 rgba(255, 255, 255, 0);
  }

  50% {
    box-shadow: 130px 0 var(--loading-color), 120px 0 var(--loading-color),
      110px 0 var(--loading-color), 100px 0 var(--loading-color);
  }

  62% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color),
      120px 0 var(--loading-color), 110px 0 var(--loading-color);
  }

  75% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      130px 0 var(--loading-color), 120px 0 var(--loading-color);
  }

  87% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 130px 0 var(--loading-color);
  }

  100% {
    box-shadow: 200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0),
      200px 0 rgba(255, 255, 255, 0), 200px 0 rgba(255, 255, 255, 0);
  }
}

.immersive-translate-toast {
  display: flex;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  right: 0;
  top: 1%;
  width: fit-content;
  padding: 12px 20px;
  margin: auto;
  overflow: auto;
  background: #fef6f9;
  box-shadow: 0px 4px 10px 0px rgba(0, 10, 30, 0.06);
  font-size: 15px;
  border-radius: 8px;
  color: #333;
}

.immersive-translate-toast-content {
  display: flex;
  flex-direction: row;
  align-items: center;
}

.immersive-translate-toast-hidden {
  margin: 0 20px 0 72px;
  text-decoration: underline;
  cursor: pointer;
}

.immersive-translate-toast-close {
  color: #666666;
  font-size: 20px;
  font-weight: bold;
  padding: 0 10px;
  cursor: pointer;
}

@media screen and (max-width: 768px) {
  .immersive-translate-toast {
    top: 0;
    padding: 12px 0px 0 10px;
  }
  .immersive-translate-toast-content {
    flex-direction: column;
    text-align: center;
  }
  .immersive-translate-toast-hidden {
    margin: 10px auto;
  }
}

.immersive-translate-dialog {
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  display: flex;
  width: 300px;
  flex-direction: column;
  align-items: center;
  font-size: 15px;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  margin: auto;
  height: fit-content;
  border-radius: 20px;
  background-color: #fff;
}

.immersive-translate-modal {
  display: none;
  position: fixed;
  z-index: 2147483647;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  overflow: auto;
  background-color: rgb(0, 0, 0);
  background-color: rgba(0, 0, 0, 0.4);
  font-size: 15px;
}

.immersive-translate-modal-content {
  background-color: #fefefe;
  margin: 10% auto;
  padding: 40px 24px 24px;
  border-radius: 12px;
  width: 350px;
  font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  position: relative;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-content {
    margin: 25% auto !important;
  }
}

@media screen and (max-width: 480px) {
  .immersive-translate-modal-content {
    width: 80vw !important;
    margin: 20vh auto !important;
    padding: 20px 12px 12px !important;
  }

  .immersive-translate-modal-title {
    font-size: 14px !important;
  }

  .immersive-translate-modal-body {
    font-size: 13px !important;
    max-height: 60vh !important;
  }

  .immersive-translate-btn {
    font-size: 13px !important;
    padding: 8px 16px !important;
    margin: 0 4px !important;
  }

  .immersive-translate-modal-footer {
    gap: 6px !important;
    margin-top: 16px !important;
  }
}

.immersive-translate-modal .immersive-translate-modal-content-in-input {
  max-width: 500px;
}
.immersive-translate-modal-content-in-input .immersive-translate-modal-body {
  text-align: left;
  max-height: unset;
}

.immersive-translate-modal-title {
  text-align: center;
  font-size: 16px;
  font-weight: 700;
  color: #333333;
}

.immersive-translate-modal-body {
  text-align: center;
  font-size: 14px;
  font-weight: 400;
  color: #333333;
  margin-top: 24px;
  word-break: break-all;
}

@media screen and (max-width: 768px) {
  .immersive-translate-modal-body {
    max-height: 250px;
    overflow-y: auto;
  }
}

.immersive-translate-close {
  color: #666666;
  position: absolute;
  right: 16px;
  top: 16px;
  font-size: 20px;
  font-weight: bold;
}

.immersive-translate-close:hover,
.immersive-translate-close:focus {
  text-decoration: none;
  cursor: pointer;
}

.immersive-translate-modal-footer {
  display: flex;
  justify-content: center;
  flex-wrap: wrap;
  margin-top: 24px;
}

.immersive-translate-btn {
  width: fit-content;
  color: #fff;
  background-color: #ea4c89;
  border: none;
  font-size: 14px;
  margin: 0 8px;
  padding: 9px 30px;
  border-radius: 5px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.immersive-translate-btn-container {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  gap: 8px;
}

.immersive-translate-btn:hover {
  background-color: #f082ac;
}
.immersive-translate-btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}
.immersive-translate-btn:disabled:hover {
  background-color: #ea4c89;
}

.immersive-translate-link-btn {
  background-color: transparent;
  color: #ea4c89;
  border: none;
  cursor: pointer;
  height: 30px;
  line-height: 30px;
}

.immersive-translate-cancel-btn {
  /* gray color */
  background-color: rgb(89, 107, 120);
}

.immersive-translate-cancel-btn:hover {
  background-color: hsl(205, 20%, 32%);
}

.immersive-translate-action-btn {
  background-color: transparent;
  color: #ea4c89;
  border: 1px solid #ea4c89;
}

.immersive-translate-btn svg {
  margin-right: 5px;
}

.immersive-translate-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-primary-link {
  cursor: pointer;
  user-select: none;
  -webkit-user-drag: none;
  text-decoration: none;
  color: #ea4c89;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0.1);
}

.immersive-translate-modal input[type="radio"] {
  margin: 0 6px;
  cursor: pointer;
}

.immersive-translate-modal label {
  cursor: pointer;
}

.immersive-translate-close-action {
  position: absolute;
  top: 2px;
  right: 0px;
  cursor: pointer;
}

.imt-image-status {
  background-color: rgba(0, 0, 0, 0.5) !important;
  display: flex !important;
  flex-direction: column !important;
  align-items: center !important;
  justify-content: center !important;
  border-radius: 16px !important;
}
.imt-image-status img,
.imt-image-status svg,
.imt-img-loading {
  width: 28px !important;
  height: 28px !important;
  margin: 0 0 8px 0 !important;
  min-height: 28px !important;
  min-width: 28px !important;
  position: relative !important;
}
.imt-img-loading {
  background-image: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAMAAACfWMssAAAAtFBMVEUAAAD////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////oK74hAAAAPHRSTlMABBMIDyQXHwyBfFdDMSw+OjXCb+5RG51IvV/k0rOqlGRM6KKMhdvNyZBz9MaupmxpWyj437iYd/yJVNZeuUC7AAACt0lEQVRIx53T2XKiUBCA4QYOiyCbiAsuuGBcYtxiYtT3f6/pbqoYHVFO5r+iivpo6DpAWYpqeoFfr9f90DsYAuRSWkFnPO50OgR9PwiCUFcl2GEcx+N/YBh6pvKaefHlUgZd1zVe0NbYcQjGBfzrPE8Xz8aF+71D8gG6DHFPpc4a7xFiCDuhaWgKgGIJQ3d5IMGDrpS4S5KgpIm+en9f6PlAhKby4JwEIxlYJV9h5k5nee9GoxHJ2IDSNB0dwdad1NAxDJ/uXDHYmebdk4PdbkS58CIVHdYSUHTYYRWOJblWSyu2lmy3KNFVJNBhxcuGW4YBVCbYGRZwIooipHsNqjM4FbgOQqQqSKQQU9V8xmi1QlgHqQQ6DDBvRUVCDirs+EzGDGOQTCATgtYTnbCVLgsVgRE0T1QE0qHCFAht2z6dLvJQs3Lo2FQoDxWNUiBhaP4eRgwNkI+dAjVOA/kUrIDwf3CG8NfNOE0eiFotSuo+rBiq8tD9oY4Qzc6YJw99hl1wzpQvD7ef2M8QgnOGJfJw+EltQc+oX2yn907QB22WZcvlUpd143dqQu+8pCJZuGE4xCuPXJqqcs5sNpsI93Rmzym1k4Npk+oD1SH3/a3LOK/JpUBpWfqNySxWzCfNCUITuDG5dtuphrUJ1myeIE9bIsPiKrfqTai5WZxbhtNphYx6GEIHihyGFTI69lje/rxajdh0s0msZ0zYxyPLhYCb1CyHm9Qsd2H37Y3lugVwL9kNh8Ot8cha6fUNQ8nuXi5z9/ExsAO4zQrb/ev1yrCB7lGyQzgYDGuxq1toDN/JGvN+HyWNHKB7zEoK+PX11e12G431erGYzwmytAWU56fkMHY5JJnDRR2eZji3AwtIcrEV8Cojat/BdQ7XOwGV1e1hDjGGjXbdArm8uJZtCH5MbcctVX8A1WpqumJHwckAAAAASUVORK5CYII=");
  background-size: 28px 28px;
  animation: image-loading-rotate 1s linear infinite !important;
}

.imt-image-status span {
  color: var(--bg-2, #fff) !important;
  font-size: 14px !important;
  line-height: 14px !important;
  font-weight: 500 !important;
  font-family: "PingFang SC", Arial, sans-serif !important;
}

.imt-primary-button {
  display: flex;
  padding: 12px 80px;
  justify-content: center;
  align-items: center;
  gap: 8px;
  border-radius: 8px;
  background: #ea4c89;
  color: #fff;
  font-size: 16px;
  font-style: normal;
  font-weight: 700;
  line-height: 24px;
  border: none;
  cursor: pointer;
}

.imt-retry-text {
  color: #999;
  text-align: center;
  font-size: 14px;
  font-style: normal;
  font-weight: 400;
  line-height: 21px;
  cursor: pointer;
}

.imt-action-container {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.imt-modal-content-text {
  text-align: left;
  color: #333;
  font-size: 16px;
  font-weight: 400;
  line-height: 24px;
}

@keyframes image-loading-rotate {
  from {
    transform: rotate(360deg);
  }
  to {
    transform: rotate(0deg);
  }
}

.imt-linear-gradient-text {
  background: linear-gradient(90deg, #00a6ff 0%, #c369ff 52.4%, #ff4590 100%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
}

.imt-flex-center {
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-linear-black-btn {
  border-radius: 50px;
  background: linear-gradient(66deg, #222 19%, #696969 94.25%);
  height: 48px;
  width: 100%;
  color: #fff;
  font-size: 16px;
  font-weight: 700;
  display: flex;
  align-items: center;
  cursor: pointer;
  justify-content: center;
}
</style></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2509.03871?_immersive_translate_auto_translate=1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main &gt;.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2509.03871v1/#myForm" onclick="event.preventDefault(); var modal = document.getElementById(&#39;myForm&#39;); modal.style.display = &#39;block&#39;; bugReportState.setInitiateWay(&#39;Header&#39;);">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2509.03871v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2509.03871v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://whiffe.github.io/Paper_Translation/Attack/Survey/%25E3%2580%258A%25E5%259F%25BA%25E4%25BA%258E%25E5%25A4%25A7%25E5%259E%258B%25E8%25AF%25AD%25E8%25A8%2580%25E6%25A8%25A1%25E5%259E%258B%25E7%259A%2584%25E6%258E%25A8%25E7%2590%2586%25E5%258F%25AF%25E4%25BF%25A1%25E5%25BA%25A6%25E7%25BB%25BC%25E5%2590%2588%25E8%25B0%2583%25E6%259F%25A5%25E3%2580%258B%2520---%2520A%2520Comprehensive%2520Survey%2520on%2520Trustworthiness%2520in%2520Reasoning%2520with%2520Large%2520Language%2520Models.html#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2509.03871?_immersive_translate_auto_translate=1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S1" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS1" title="In 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Large Language Model Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS2" title="In 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Chain-of-Thought Prompting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS3" title="In 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Large Reasoning Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS3.SSS1" title="In 2.3 Large Reasoning Models ‣ 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Model Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS3.SSS2" title="In 2.3 Large Reasoning Models ‣ 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>Multimodal LRM</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Truthfulness</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS1" title="In 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Hallucination</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS1.SSS1" title="In 3.1 Hallucination ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Hallucination with Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS1.SSS2" title="In 3.1 Hallucination ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Hallucination in Reasoning Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2" title="In 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Faithfulness of Reasoning Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2.SSS1" title="In 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Faithfulness Measuring</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2.SSS2" title="In 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Faithfulness Understanding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2.SSS3" title="In 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Faithfulness Improvement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2.SSS4" title="In 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.4 </span>Further Discussion of Faithfulness Definition</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Safety</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS1" title="In 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Vulnerability Assessment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2" title="In 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Jailbreak</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS1" title="In 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Jailbreaking with Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS2" title="In 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Jailbreaking Reasoning Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS3" title="In 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Jailbreak Defense with Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS4" title="In 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Jailbreak Defense for Reasoning Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3" title="In 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Alignment</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3.SSS1" title="In 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Aligning LLM Using Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3.SSS2" title="In 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Alignment of Large Reasoning Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3.SSS3" title="In 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>Safety Tax</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS4" title="In 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Backdoor</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Robustness</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS1" title="In 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Robustness Improvement with Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS2" title="In 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Robustness of Reasoning Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS3" title="In 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Overthinking and Underthinking</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S6" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Fairness</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Privacy</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7.SS1" title="In 7 Privacy ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Model-related Privacy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7.SS2" title="In 7 Privacy ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Prompt-related Privacy</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S8" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Future Research Directions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S9" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2509.03871?_immersive_translate_auto_translate=1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://whiffe.github.io/Paper_Translation/Attack/Survey/%25E3%2580%258A%25E5%259F%25BA%25E4%25BA%258E%25E5%25A4%25A7%25E5%259E%258B%25E8%25AF%25AD%25E8%25A8%2580%25E6%25A8%25A1%25E5%259E%258B%25E7%259A%2584%25E6%258E%25A8%25E7%2590%2586%25E5%258F%25AF%25E4%25BF%25A1%25E5%25BA%25A6%25E7%25BB%25BC%25E5%2590%2588%25E8%25B0%2583%25E6%259F%25A5%25E3%2580%258B%2520---%2520A%2520Comprehensive%2520Survey%2520on%2520Trustworthiness%2520in%2520Reasoning%2520with%2520Large%2520Language%2520Models.html#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert" onclick="closePopup()">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: tocloft.sty</li><li>failed: forest.sty</li><li>failed: fontawesome5.sty</li><li>failed: circledsteps.sty</li><li>failed: datetime.sty</li><li>failed: libertinus.sty</li><li>failed: manyfoot.sty</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">许可证：CC BY 4.0</font></font></font></a><div id="watermark-tr" data-imt_insert_failed="1">arXiv:2509.03871v1 [cs.CL] 04 Sep 2025</div></div>
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" data-imt_insert_failed="1">\cftsetindents</span>
<p class="ltx_p" data-imt_insert_failed="1">subsection2em3em

































































<span class="ltx_ERROR undefined">\DeclareNewFootnote</span>A[fnsymbol]

</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<h1 class="ltx_title ltx_title_document">A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">《基于大型语言模型的推理可信度综合调查》</font></font></font></h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yanbo Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">School of Artificial Intelligence, University of Chinese Academy of Sciences
</span>
<span class="ltx_contact ltx_role_affiliation">NLPR &amp; MAIS, Institute of Automation, Chinese Academy of Sciences
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yongcan Yu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">School of Artificial Intelligence, University of Chinese Academy of Sciences
</span>
<span class="ltx_contact ltx_role_affiliation">NLPR &amp; MAIS, Institute of Automation, Chinese Academy of Sciences
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jian Liang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">School of Artificial Intelligence, University of Chinese Academy of Sciences
</span>
<span class="ltx_contact ltx_role_affiliation">NLPR &amp; MAIS, Institute of Automation, Chinese Academy of Sciences
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ran He
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">School of Artificial Intelligence, University of Chinese Academy of Sciences
</span>
<span class="ltx_contact ltx_role_affiliation">NLPR &amp; MAIS, Institute of Automation, Chinese Academy of Sciences
</span></span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">摘要</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Abstract:</span> The development of Long-CoT reasoning has advanced LLM performance across various tasks, including language understanding, complex problem solving, and code generation. This paradigm enables models to generate intermediate reasoning steps, thereby improving both accuracy and interpretability. However, despite these advancements, a comprehensive understanding of how CoT-based reasoning affects the trustworthiness of language models remains underdeveloped. In this paper, we survey recent work on reasoning models and CoT techniques, focusing on five core dimensions of trustworthy reasoning: truthfulness, safety, robustness, fairness, and privacy. For each aspect, we provide a clear and structured overview of recent studies in chronological order, along with detailed analyses of their methodologies, findings, and limitations. Future research directions are also appended at the end for reference and discussion. Overall, while reasoning techniques hold promise for enhancing model trustworthiness through hallucination mitigation, harmful content detection, and robustness improvement, cutting-edge reasoning models themselves often suffer from comparable or even greater vulnerabilities in safety, robustness, and privacy. By synthesizing these insights, we hope this work serves as a valuable and timely resource for the AI safety community to stay informed on the latest progress in reasoning trustworthiness. A full list of related papers can be found at <a class="ltx_ref ltx_href" href="https://github.com/ybwang119/Awesome-reasoning-safety" title="">https://github.com/ybwang119/Awesome-reasoning-safety</a>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">摘要：长 CoT 推理的发展提升了 LLM 在语言理解、复杂问题解决和代码生成等任务上的表现。该范式使模型能够生成中间推理步骤，从而提高准确性和可解释性。然而，尽管取得了这些进展，对基于 CoT 的推理如何影响语言模型可信度的全面理解仍不充分。在本文中，我们调查了推理模型和 CoT 技术方面的近期研究，重点关注可信推理的五个核心维度：真实性、安全性、鲁棒性、公平性和隐私性。对于每个方面，我们按时间顺序提供了近期研究的清晰、结构化的概述，并对其方法、发现和局限性进行了详细分析。文末还附有未来研究方向供参考和讨论。 总体而言，虽然推理技术通过减少幻觉、检测有害内容和提高鲁棒性来提升模型可信度具有潜力，但最先进的推理模型本身在安全、鲁棒性和隐私方面往往存在相当甚至更大的漏洞。通过综合这些见解，我们希望这项工作能为 AI 安全社区提供一个宝贵且及时的资源，以了解推理可信度的最新进展。相关论文的完整列表可以在 https://github.上找到。com/ybwang119/Awesome-reasoning-safety.</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<span class="ltx_ERROR undefined" data-imt_insert_failed="1">\footnotetextA</span>
<p class="ltx_p">[3]Corresponding author: Jian Liang <span class="ltx_text ltx_font_italic">(liangjian92@gmail.com).</span>
<span class="ltx_ERROR undefined">\footnotetextA</span>[4]This survey considers papers published up to June 30, 2025. Work in progress.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">[3]通讯作者：梁健（liangjian92@gmail.com）。\footnotetextA[4]本综述考虑了截至 2025 年 6 月 30 日发表的论文。工作进行中。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">目录</font></font></font></h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S1" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS1" title="In 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Large Language Model Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS2" title="In 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Chain-of-Thought Prompting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS3" title="In 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Large Reasoning Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS3.SSS1" title="In 2.3 Large Reasoning Models ‣ 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.1 </span>Model Training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS3.SSS2" title="In 2.3 Large Reasoning Models ‣ 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3.2 </span>Multimodal LRM</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Truthfulness</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS1" title="In 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Hallucination</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS1.SSS1" title="In 3.1 Hallucination ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Hallucination with Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS1.SSS2" title="In 3.1 Hallucination ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Hallucination in Reasoning Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2" title="In 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Faithfulness of Reasoning Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2.SSS1" title="In 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Faithfulness Measuring</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2.SSS2" title="In 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Faithfulness Understanding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2.SSS3" title="In 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Faithfulness Improvement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2.SSS4" title="In 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.4 </span>Further Discussion of Faithfulness Definition</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Safety</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS1" title="In 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Vulnerability Assessment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2" title="In 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Jailbreak</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS1" title="In 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Jailbreaking with Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS2" title="In 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Jailbreaking Reasoning Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS3" title="In 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Jailbreak Defense with Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS4" title="In 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.4 </span>Jailbreak Defense for Reasoning Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3" title="In 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Alignment</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3.SSS1" title="In 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Aligning LLM Using Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3.SSS2" title="In 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Alignment of Large Reasoning Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3.SSS3" title="In 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>Safety Tax</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS4" title="In 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Backdoor</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Robustness</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS1" title="In 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Robustness Improvement with Reasoning Techniques</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS2" title="In 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Robustness of Reasoning Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS3" title="In 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Overthinking and Underthinking</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S6" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Fairness</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Privacy</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7.SS1" title="In 7 Privacy ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Model-related Privacy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7.SS2" title="In 7 Privacy ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Prompt-related Privacy</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S8" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Future Research Directions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S9" title="In A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Conclusion</span></a></li>
</ol></nav>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">1 引言</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p">With the advancement of large language models (LLMs), Chain-of-Thought (CoT) techniques have become an important way to improve model performance on various downstream tasks, especially in math and code generation. After the release of OpenAI’s o1 series models as well as the DeepSeek-R1, developing reasoning models with system-2 thinking also attracted significant interest from researchers around the world, followed by innovations in reinforcement learning algorithms, training data generation, and adaptation methods for other tasks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">随着大型语言模型（LLMs）的进步，思维链（CoT）技术已成为提高模型在各类下游任务上性能的重要途径，特别是在数学和代码生成领域。在 OpenAI 的 o1 系列模型以及 DeepSeek-R1 发布后，开发具有系统-2 思维的推理模型也吸引了全球研究人员的广泛关注，随后在强化学习算法、训练数据生成以及其他任务的适应方法上出现了创新。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p">Despite these improvements, the trustworthiness of CoT techniques as well as reasoning models remains underexplored. Intuitively, it may be reasonable that the thinking capability could be generalized to the trustworthiness domain, resulting in a safer and more reliable model. However, recent works&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>]</cite> did not support such an ideal hypothesis. Furthermore, prior surveys on LLM safety&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib6" title="">6</a>]</cite> provide little discussion of reasoning as a factor in model trustworthiness. This gap motivates the central question:
<span class="ltx_text ltx_font_bold">What does the reasoning capability bring to the language model trustworthiness?</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管取得了这些改进，但 CoT 技术以及推理模型的可靠性仍待深入探索。直观上，思维能力可能可以泛化到可靠性领域，从而产生更安全、更可靠的模型。然而，最近的研究工作[ 1, 2, 3]并未支持这种理想假设。此外，关于 LLM 安全的先验综述[ 4, 5, 6]对推理作为模型可靠性因素讨论甚少。这一空白促使了核心问题：推理能力为语言模型可靠性带来了什么？</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p">To answer this question, we propose the first comprehensive survey to thoroughly review recent advancements in trustworthy reasoning. We unfold our survey through five main components: truthfulness, safety, robustness, fairness, and privacy. In the truthfulness section, with a focus on model reliability, we include hallucination and reasoning faithfulness, encompassing hallucination detection and mitigation methods with CoT techniques, hallucination analysis in reasoning models, reasoning faithfulness measurement, faithfulness understanding, as well as methods to improve reasoning faithfulness. In the safety section, we aim to understand the harmlessness of the generation content, and mainly take vulnerability assessment, jailbreak, alignment, and backdoor into consideration. For better readability, we specifically distinguish between jailbreak attacks targeting reasoning models and the use of reasoning techniques in attack and defense, forming different paragraphs to structure the literature. In the robustness section, we mainly focus on adversarial input noises that elicit false answers at inference time. The overthinking and underthinking problems are highlighted as a special case when language models are equipped with reasoning capability. After that, in the fairness section, we mainly cover the latest evaluations and methods for bias detection. As for the privacy section, we split the related works into model-related privacy and prompt-related privacy, with topics containing model unlearning, IP protection, watermarking, and privacy inference.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了回答这个问题，我们提出了首个全面综述，旨在深入探讨可信推理的最新进展。我们的综述通过五个主要组成部分展开：真实性、安全性、鲁棒性、公平性和隐私性。在真实性部分，我们重点关注模型可靠性，包括幻觉和推理忠实性，涵盖使用思维链技术的幻觉检测与缓解方法、推理模型中的幻觉分析、推理忠实性度量、忠实性理解，以及提高推理忠实性的方法。在安全性部分，我们旨在理解生成内容的无害性，主要考虑漏洞评估、越狱攻击、对齐和后门。为了提高可读性，我们特别区分了针对推理模型的越狱攻击和攻击与防御中使用推理技术的情况，将文献分成不同段落进行结构化。在鲁棒性部分，我们主要关注在推理时导致错误答案的对抗性输入噪声。 当语言模型具备推理能力时，过度思考和思考不足问题被突出为一种特殊情况。随后，在公平性部分，我们主要涵盖了最新的偏见检测评估和方法。至于隐私部分，我们将相关研究工作分为模型相关隐私和提示相关隐私，主题包括模型去学习、知识产权保护、水印和隐私推理。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p">While existing surveys have explored reasoning techniques&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib7" title="">7</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib8" title="">8</a>]</cite> and reasoning efficiency&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib11" title="">11</a>]</cite>, relatively little attention has been paid to the trustworthiness of reasoning in large language models. A related survey&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib12" title="">12</a>]</cite> provided valuable discussions on safety-related aspects. In contrast, our work offers a more comprehensive perspective on trustworthiness.
In general, we provide a clear taxonomy for model trustworthiness in reasoning, which includes both early CoT techniques and end-to-end reasoning models. Through our review of existing work, we suggest that reasoning techniques not only facilitate the development of more interpretable and trustworthy models but also introduce new vulnerabilities. As models acquire more advanced reasoning capabilities, the attack surface correspondingly expands, enabling more complex and targeted adversarial strategies. We hope that both the surveyed literature and our proposed taxonomy will serve as a timely reference for the AI safety community, supporting ongoing efforts to understand and improve the trustworthiness of reasoning in language models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管现有综述已探讨了推理技术[7, 8]和推理效率[9, 10, 11]，但相对较少关注大型语言模型中推理的可信度。一项相关综述[12]对安全相关方面提供了有价值的讨论。相比之下，我们的工作提供了更全面的可信度视角。总体而言，我们为推理中的模型可信度提供了一个清晰的分类体系，包括早期的 CoT 技术和端到端推理模型。通过我们对现有工作的综述，我们提出推理技术不仅促进了更可解释和可信度更高的模型开发，还引入了新的漏洞。随着模型获得更高级的推理能力，攻击面相应扩大，使得更复杂和有针对性的对抗策略成为可能。我们希望所调查的文献和我们所提出的分类体系能为人工智能安全社区提供及时的参考，支持其持续努力理解和提升语言模型中推理的可信度。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S1.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>List of Abbreviations and Acronyms<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 1：缩写词和首字母缩略词列表</font></font></font></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:222pt;vertical-align:-222.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-67.7pt,0.0pt) scale(0.752684032231695,0.752684032231695) ;">
<table class="ltx_tabular ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Abbreviation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">缩写词</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Full Term<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">完整术语</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Abbreviation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">缩写词</font></font></font></span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Full Term<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">完整术语</font></font></font></span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">AOC</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Area Over Curve<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">曲线下面积 </font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_t">MCTS</td>
<td class="ltx_td ltx_align_center ltx_border_t">Monte-Carlo Tree Search<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">蒙特卡洛树搜索 </font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">ASR</td>
<td class="ltx_td ltx_align_center ltx_border_r">Attack Success Rate<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">攻击成功率</font></font></font></td>
<td class="ltx_td ltx_align_center">MLLM</td>
<td class="ltx_td ltx_align_center">Multimodal Large Language Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多模态大语言模型</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">CNN</td>
<td class="ltx_td ltx_align_center ltx_border_r">Convolutional Neural Network<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">卷积神经网络</font></font></font></td>
<td class="ltx_td ltx_align_center">MLRM</td>
<td class="ltx_td ltx_align_center">Multimodal Large Reasoning Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">多模态大推理模型</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" data-imt_insert_failed="1">CoT</td>
<td class="ltx_td ltx_align_center ltx_border_r">Chain-of-Thought<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">思维链</font></font></font></td>
<td class="ltx_td ltx_align_center">ORM</td>
<td class="ltx_td ltx_align_center">Outcome Reward Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">结果奖励模型</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">DFS</td>
<td class="ltx_td ltx_align_center ltx_border_r">Depth-First Search<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">深度优先搜索</font></font></font></td>
<td class="ltx_td ltx_align_center">PRM</td>
<td class="ltx_td ltx_align_center">Process Reward Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">过程奖励模型</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">DPO</td>
<td class="ltx_td ltx_align_center ltx_border_r">Direct Preference Optimization<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">直接偏好优化</font></font></font></td>
<td class="ltx_td ltx_align_center">QA</td>
<td class="ltx_td ltx_align_center">Question-Answering<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">问答</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">GRPO</td>
<td class="ltx_td ltx_align_center ltx_border_r">Group Relative Policy Optimization<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">组相对策略优化</font></font></font></td>
<td class="ltx_td ltx_align_center">RL</td>
<td class="ltx_td ltx_align_center">Reinforcement Learning<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">强化学习</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">ICL</td>
<td class="ltx_td ltx_align_center ltx_border_r">In-Context Learning<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">情境学习</font></font></font></td>
<td class="ltx_td ltx_align_center">RLHF</td>
<td class="ltx_td ltx_align_center">Reinforcement Learning from Human Feedback<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">人类反馈强化学习</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">KL</td>
<td class="ltx_td ltx_align_center ltx_border_r">Kullback-Leibler Divergence<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Kullback-Leibler 散度</font></font></font></td>
<td class="ltx_td ltx_align_center">RLVR</td>
<td class="ltx_td ltx_align_center">Reinforcement Learning with Verifiable Reward<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">可验证奖励强化学习</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">LAS</td>
<td class="ltx_td ltx_align_center ltx_border_r">Leakage-Adjusted Simulatability<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">泄漏调整模拟性</font></font></font></td>
<td class="ltx_td ltx_align_center">RAG</td>
<td class="ltx_td ltx_align_center">Retrieval-Augmented Generation<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">检索增强生成</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">LLM</td>
<td class="ltx_td ltx_align_center ltx_border_r">Large Language Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大型语言模型</font></font></font></td>
<td class="ltx_td ltx_align_center">SCM</td>
<td class="ltx_td ltx_align_center">Structural Causal Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">结构因果模型</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">LRM</td>
<td class="ltx_td ltx_align_center ltx_border_r">Large Reasoning Model<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大型推理模型</font></font></font></td>
<td class="ltx_td ltx_align_center" data-imt_insert_failed="1">SoTA</td>
<td class="ltx_td ltx_align_center">State-of-the-Art<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">最先进技术</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" data-imt_insert_failed="1">LoRA</td>
<td class="ltx_td ltx_align_center ltx_border_r">Low-Rank Adapter<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">低秩适配器</font></font></font></td>
<td class="ltx_td ltx_align_center">SFT</td>
<td class="ltx_td ltx_align_center">Supervised Fine-Tuning<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">监督微调</font></font></font></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b" data-imt_insert_failed="1">MoE</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Mixture-of-Experts<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">专家混合模型</font></font></font></td>
<td class="ltx_td ltx_align_center ltx_border_b">VR</td>
<td class="ltx_td ltx_align_center ltx_border_b">Verifiable Reward<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">可验证奖励</font></font></font></td>
</tr>
</tbody></table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2 背景</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p">In this section, we provide an overview of fundamental concepts related to reasoning in language models, including discussions of the general definition of reasoning, an introduction to CoT as a widely adopted technique, and key considerations in model training that influence the reasoning abilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本节中，我们概述了与语言模型推理相关的基本概念，包括对推理的一般定义的讨论、作为广泛采用技术的思维链（CoT）的介绍，以及影响推理能力的关键模型训练考虑因素。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Large Language Model Reasoning<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.1 大型语言模型推理</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p">LLM reasoning is a novel paradigm that leverages the knowledge embedded within models like GPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib13" title="">13</a>]</cite>, Claude&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib14" title="">14</a>]</cite>, and DeepSeek-R1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib15" title="">15</a>]</cite> to solve complex tasks—such as math, coding, and logical reasoning—by mimicking human cognitive processes.
Typically, LLM reasoning involves generating both the final answer and the intermediate steps, often referred to as “thoughts”, which guide the model from the question to the answer.
Formally, given a prompt <math alttext="x" class="ltx_Math" display="inline" id="S2.SS1.p1.m1"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> and context <math alttext="C" class="ltx_Math" display="inline" id="S2.SS1.p1.m2"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math>, the reasoning of an LLM <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.SS1.p1.m3"><semantics><mi class="ltx_font_mathcaligraphic">ℳ</mi><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math> can be represented as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLM 推理是一种新范式，它利用嵌入在 GPT-4[13]、Claude[14]和 DeepSeek-R1[15]等模型中的知识，通过模仿人类认知过程来解决复杂任务——如数学、编程和逻辑推理。通常，LLM 推理会生成最终答案和中间步骤，这些中间步骤通常被称为“思考”，它们引导模型从问题到答案。形式上，给定一个提示 <math id="S2.SS1.p1.m1" display="inline" class="ltx_Math" alttext="x"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> 和上下文 <math id="S2.SS1.p1.m2" display="inline" class="ltx_Math" alttext="C"><semantics><mi>C</mi><annotation encoding="application/x-tex">C</annotation></semantics></math> ，一个 LLM <math id="S2.SS1.p1.m3" display="inline" class="ltx_Math" alttext="\mathcal{M}"><semantics><mi class="ltx_font_mathcaligraphic">ℳ</mi><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math> 的推理可以表示如下：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="T,A=\mathcal{M}(x,C)," class="ltx_Math" display="block" id="S2.E1.m1"><semantics><mrow><mrow><mrow><mi>T</mi><mo>,</mo><mi>A</mi></mrow><mo>=</mo><mrow><mi class="ltx_font_mathcaligraphic">ℳ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>C</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">T,A=\mathcal{M}(x,C),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="T" class="ltx_Math" display="inline" id="S2.SS1.p1.m4"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> refers to the intermediate reasoning process and <math alttext="A" class="ltx_Math" display="inline" id="S2.SS1.p1.m5"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> is the answer.
By enabling the AI system to generate interpretable reasoning steps alongside the solution, LLM reasoning not only solves complex tasks but also improves human understanding of the problem-solving process, thereby enhancing its utility and reliability.
Currently, the two main paradigms for implementing large language model reasoning are CoT prompting and large reasoning model training.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S2.SS1.p1.m4" display="inline" class="ltx_Math" alttext="T"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> 指代中间推理过程， <math id="S2.SS1.p1.m5" display="inline" class="ltx_Math" alttext="A"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> 是答案。通过使 AI 系统能够在提供解决方案的同时生成可解释的推理步骤，LLM 推理不仅解决了复杂任务，还提高了人类对问题解决过程的理解，从而增强了其效用和可靠性。目前，实现大型语言模型推理的两种主要范式是 CoT 提示和大型推理模型训练。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Chain-of-Thought Prompting<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.2Chain-of-Thought 提示</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p">CoT prompting&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib17" title="">17</a>]</cite> is a prompt engineering technique designed to elicit a sequence of intermediate reasoning steps referred to as the thought, before providing the final answer.
There are various methods for implementing CoT, with two of the most common being few-shot-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib16" title="">16</a>]</cite> and zero-shot-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib17" title="">17</a>]</cite>.
As illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.F1" title="In 2.2 Chain-of-Thought Prompting ‣ 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">Figure</span>˜<span class="ltx_text ltx_ref_tag">1</span></a>, few-shot-CoT mirrors the approach of few-shot in-context learning (ICL)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib18" title="">18</a>]</cite>, utilizing a small number of examples to guide the model in answering questions.
Unlike traditional ICL, few-shot-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib19" title="">19</a>]</cite> not only shows the answer in the demonstrations, but also gives the specific reasoning steps before the answer. Therefore, the model will also give CoT before answering the question.
While few-shot-CoT demonstrates strong performance on complex tasks such as math and symbolic reasoning, it requires human-annotated, task-specific examples with intricate reasoning paths, limiting its applicability.
In contrast, zero-shot-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib16" title="">16</a>]</cite> offers a more flexible, task-agnostic method for eliciting CoT by simply adding the prefix “Let’s think step by step” before generating the answer.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">CoT 提示[16, 17]是一种提示工程技术，旨在提供最终答案之前，引导模型输出一系列中间推理步骤，这些步骤被称为思考过程。实现 CoT 的方法有多种，其中最常见的是少样本 CoT[16]和零样本 CoT[17]。如图 1 所示，少样本 CoT 模仿了少样本情境学习（ICL）[18]的方法，利用少量示例来引导模型回答问题。与传统的 ICL 不同，少样本 CoT[19]不仅会在示例中展示答案，还会在答案之前提供具体的推理步骤。因此，模型在回答问题时也会给出 CoT。虽然少样本 CoT 在数学和符号推理等复杂任务上表现出色，但它需要人工标注的、特定任务的示例，且推理路径复杂，限制了其适用性。相比之下，零样本 CoT[16]通过在生成答案前添加前缀“让我们一步步思考”，提供了一种更灵活、任务无关的方法来引导 CoT。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="287" id="S2.F1.g1" src="./《基于大型语言模型的推理可信度综合调查》 --- A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models_files/x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of typical CoT prompting. Few-shot-CoT uses several examples with the reasoning process to elicit CoT, and zero-shot-CoT uses a prefix prompt to induce the reasoning process.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 1：典型的思维链提示说明。Few-shot-CoT 使用带推理过程的几个例子来引出思维链，而 zero-shot-CoT 使用前缀提示来诱导推理过程。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Large Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.3 大型推理模型</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p">Large reasoning models (LRMs), represented by OpenAI o1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib20" title="">20</a>]</cite> and DeepSeek-R1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib15" title="">15</a>]</cite>, refer to a series of large language models that explicitly generate their thinking process before filling the final answers&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib8" title="">8</a>]</cite>. Instead of prompting models to “think step by step”, reasoning models could automatically create the thinking process that mimics how humans analyze a problem.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">大型推理模型（LRMs），以 OpenAI 的 o1 [ 20] 和 DeepSeek-R1 [ 15] 为代表，指的是一系列在填写最终答案之前明确生成其思考过程的大型语言模型 [ 8]。与提示模型“逐步思考”不同，推理模型可以自动创建模仿人类分析问题方式的思考过程。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S2.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Model Training<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.3.1 模型训练</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS1.p1">
<p class="ltx_p">There are a few open-source trials to replicate the o1 series&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib8" title="">8</a>]</cite>, including OpenR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib21" title="">21</a>]</cite>, o1-journey&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib24" title="">24</a>]</cite>, and LLaMA-Berry&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib25" title="">25</a>]</cite>. The key to the replication lies in distilling long CoT data, even if the source model has not been explicitly trained for reasoning. LLaMA-Berry&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib25" title="">25</a>]</cite> utilized Monte Carlo tree search (MCTS)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib26" title="">26</a>]</cite> with a pairwise preference reward model to scale test-time compute, achieving a higher performance on multiple Math datasets such as GSM8k&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib27" title="">27</a>]</cite>, MATH&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib28" title="">28</a>]</cite>, GaoKao2023En&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib29" title="">29</a>]</cite>, etc. O1-journey&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib22" title="">22</a>]</cite> utilized MCTS with a fine-grained reward model to construct long CoT data. After building the reasoning tree with each node annotated with a reward score indicating correctness, a traversal algorithm such as Depth-First Search (DFS) with constraints could be adopted to create a datapoint using an error-then-backtrack style. Supervised fine-tuning (SFT), followed by Direct Preference Optimization (DPO)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib30" title="">30</a>]</cite>, was then leveraged to train the reasoning model. OpenR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib21" title="">21</a>]</cite> introduced reinforcement learning with a process reward model to encourage reasoning capability. During training, the LLM policy was updated at each reasoning step using intermediate step-wise rewards from the reward model, optimized with either the proximal policy optimization (PPO)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib31" title="">31</a>]</cite> or the group relative policy optimization (GRPO)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib32" title="">32</a>]</cite>. Except for these tree searching methods, DeepSeek-R1 demonstrated the outstanding performance of pure reinforcement learning in boosting reasoning capability, utilizing distilled data from R1-Zero<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The model for long CoT data synthesis underwent preliminary supervised fine-tuning (cold start). Therefore, it is slightly different from the released R1-Zero model.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">用于长 CoT 数据的合成模型经历了初步的监督微调（冷启动）。因此，它与发布的 R1-Zero 模型略有不同。</font></font></font></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">有一些开源项目尝试复制 o1 系列[ 8]，包括 OpenR [ 21]、o1-journey [ 22, 23, 24]和 LLaMA-Berry [ 25]。复制的关键在于蒸馏长 CoT 数据，即使源模型没有经过明确的推理训练。LLaMA-Berry [ 25]利用蒙特卡洛树搜索（MCTS）[ 26]和成对偏好奖励模型来扩展测试时的计算量，在多个数学数据集（如 GSM8k [ 27]、MATH [ 28]、GaoKao2023En [ 29]等）上取得了更高的性能。O1-journey [ 22]利用 MCTS 和细粒度奖励模型来构建长 CoT 数据。在用奖励分数标注正确性的推理树节点构建完成后，可以采用带约束的深度优先搜索（DFS）等遍历算法，以错误回溯的方式创建数据点。随后利用监督微调（SFT）和直接偏好优化（DPO）[ 30]来训练推理模型。OpenR [ 21]引入了过程奖励模型的强化学习，以鼓励推理能力。 在训练过程中，LLM 策略在每个推理步骤中使用来自奖励模型的中间步骤奖励进行更新，优化方法采用近端策略优化（PPO）[31]或组相对策略优化（GRPO）[32]。 除了这些树搜索方法，DeepSeek-R1 展示了纯强化学习在提升推理能力方面的卓越性能，利用 R1-Zero <sup class="ltx_note_mark">1</sup> 的蒸馏数据</font></font></font> to train the base model.
One point worth noting is that, except for latent reasoning models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib34" title="">34</a>]</cite>, there is no obvious difference between previous chat models and current reasoning models in terms of model structure. In fact, all these models are developed based on well-trained chat models such as DeepSeek-V3&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib35" title="">35</a>]</cite>, Qwen2.5&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib36" title="">36</a>]</cite>, and Llama-3 series&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib37" title="">37</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">用于训练基础模型。有一点值得注意，除了潜推理模型[33, 34]之外，之前的聊天模型和当前的推理模型在模型结构上没有明显区别。事实上，所有这些模型都是基于 DeepSeek-V3[35]、Qwen2.5[36]和 Llama-3 系列[37]等训练良好的聊天模型开发的。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">PRM, ORM, and VR.</span> According to Uesato <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib38" title="">38</a>]</cite>, current reward models could be divided into two types: process reward model (PRM) and outcome reward model (ORM), in which the former provides stepwise reward on each reasoning process, and the latter simply gives one score for the whole generation sequence. Instead of ORM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib39" title="">39</a>]</cite>, Lightman <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib40" title="">40</a>]</cite> proposed PRM to verify the thinking process step by step, and demonstrated its superior performance to ORM in providing more reliable step-wise reward. For inference-time scaling, these reward models could not only facilitate the tree search at inference time for better performance, but also help filter reasoning trajectories with higher quality for post-training. Before the release of DeepSeek-R1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib15" title="">15</a>]</cite>, the training of reward models is crucial for reasoning model development. Verifiable reward (VR) was first proposed by Lambert <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib41" title="">41</a>]</cite>, which includes three types: correctness verification, verification via execution, and verifiable constraints&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib42" title="">42</a>]</cite>. Different from reward models, here we define verifiable reward as “<span class="ltx_text ltx_font_italic">the reward provided by a simple deterministic function instead of large models, which is objective, usually binary, and outcome-based</span>”. DeepSeek-R1 demonstrates the effectiveness of VR, which is then regarded as a prevailing post-training method when combined with GRPO.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">PRM、ORM 和 VR。根据 Uesato 等人[38]的研究，当前的奖励模型可以分为两种类型：过程奖励模型（PRM）和结果奖励模型（ORM），前者在推理过程中每一步都提供奖励，后者则对整个生成序列给出一个分数。与 ORM[39]不同，Lightman 等人[40]提出了 PRM 来逐步验证思考过程，并证明了它在提供更可靠的逐步奖励方面优于 ORM。在推理时扩展方面，这些奖励模型不仅可以促进推理时的树搜索以获得更好的性能，还可以帮助筛选出用于后训练的高质量推理轨迹。在 DeepSeek-R1[15]发布之前，奖励模型的训练对于推理模型开发至关重要。可验证奖励（VR）最早由 Lambert 等人[41]提出，包括三种类型：正确性验证、执行验证和可验证约束[42]。 与奖励模型不同，在这里我们将可验证奖励定义为“由简单的确定性函数提供的奖励，而不是大型模型，它是客观的、通常是二元的、基于结果的”。DeepSeek-R1 展示了 VR 的有效性，当与 GRPO 结合时，它被视为一种流行的后训练方法。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.2 </span>Multimodal LRM<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">2.3.2 多模态 LRM</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS2.p1">
<p class="ltx_p">Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib43" title="">43</a>]</cite> summarized the development of multimodal large reasoning models (MLRMs) into three stages: “perception driven modular reasoning”, “language-centric short reasoning”, and “language-centric long reasoning”. Like the development of unimodal large reasoning models, MLRMs also experienced the transformation from zero-shot or few-shot CoT prompting to long reasoning data post-training&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib44" title="">44</a>]</cite>. For example, Multimodal-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib45" title="">45</a>]</cite>, VoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib46" title="">46</a>]</cite>, and VIC&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib47" title="">47</a>]</cite> are some of the early works that focused on the prompting to elicit model thinking. In terms of training, LLaVA-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib48" title="">48</a>]</cite>, Llamav-o1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib49" title="">49</a>]</cite>, RedStar&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib50" title="">50</a>]</cite>, and Mulberry&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib51" title="">51</a>]</cite> propose to empower multimodal large language models (MLLMs) with reasoning capabilities by finetuning base models. As stated in <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S2.SS3.SSS1" title="2.3.1 Model Training ‣ 2.3 Large Reasoning Models ‣ 2 Background ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">Section</span>˜<span class="ltx_text ltx_ref_tag">2.3.1</span></a>, multimodal CoT data generation is also crucial for model training, and the construction of the reasoning path includes distillation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib49" title="">49</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib52" title="">52</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib53" title="">53</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib54" title="">54</a>]</cite> or MCTS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib51" title="">51</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib55" title="">55</a>]</cite>, which also resembles the way mentioned for text-domain CoT data generation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">李等人[43]将多模态大推理模型（MLRM）的发展总结为三个阶段：“感知驱动模块化推理”、“语言中心化短推理”和“语言中心化长推理”。与单模态大推理模型的发展类似，MLRM 也经历了从零样本或少样本 CoT 提示到训练后长推理数据的转变[44]。例如，Multimodal-CoT[45]、VoT[46]和 VIC[47]是一些早期专注于提示以引出模型思考的工作。在训练方面，LLaVA-CoT[48]、Llamav-o1[49]、RedStar[50]和 Mulberry[51]提出通过微调基础模型来赋予多模态大语言模型（MLLM）推理能力。如第 2.3.1 节所述，多模态 CoT 数据生成对于模型训练也至关重要，推理路径的构建包括蒸馏[48,49,52,53,54]或 MCTS[51,55]，这也类似于文本域 CoT 数据生成的方式。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.SSS2.p2">
<p class="ltx_p">As for model training, pure GRPO and SFT followed by GRPO become the prevailing method for reasoning model development&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib44" title="">44</a>]</cite>, which may be attributed to the outstanding performance of RL demonstrated by DeepSeek-R1.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">关于模型训练，纯 GROPO 和 SFT 随后再进行 GROPO 成为推理模型开发的主流方法[44]，这可以归因于 DeepSeek-R1 所展示的强化学习卓越性能。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
<figure class="ltx_figure" id="S2.F2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:416.3pt;height:1730.1pt;vertical-align:-1723.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-8.1pt,0.1pt) scale(0.962551718117989,0.962551718117989) ;"><span class="ltx_ERROR undefined" data-imt_insert_failed="1">{forest}</span>
<p class="ltx_p" data-imt_insert_failed="1">forked edges,
for tree=
grow=east,
reversed=true,
anchor=base west,
parent anchor=east,
child anchor=west,
base=center,
font=,
rectangle,
draw=hidden-draw,
rounded corners,
align=left,
minimum width=4em,
edge+=darkgray, line width=1pt,
s sep=3pt,
inner xsep=2pt,
inner ysep=3pt,
line width=0.8pt,
ver/.style=rotate=90, child anchor=north, parent anchor=south, anchor=center,
,
where level=1text
width=6em,align=center,font=,,
where level=2text width=8.2em,align=center,font=,,
where level=3text width=8.2em,align=center,font=,,
where level=4text width=8.2em, font=,,
[
Trustworthiness in language model reasoning, ver
[
Truthfulness 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">分叉边，对于树= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=center, font=, rectangle, draw=hidden-draw, rounded corners, align=left, minimum width=4em, edge+=darkgray, line width=1pt, s sep=3pt, inner xsep=2pt, inner ysep=3pt, line width=0.8pt, ver/.style=rotate=90, child anchor=north, parent anchor=south, anchor=center, , where level=1text width=6em,align=center,font=,, where level=2text width=8.2em,align=center,font=,, where level=3text width=8.2em,align=center,font=,, where level=4text width=8.2em, font=,, [ 语言模型推理中的可信度，ver [ 真实性 </font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3" title="3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>), my-box1
[
Hallucination
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§3), my-box1 [ 虚构</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS1" title="3.1 Hallucination ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">3.1</span></a>), my-box1
[
Hallucination with
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§3.1), 我的盒子 1 [幻觉与</font></font></font><br class="ltx_break">reasoning techniques, my-box2
[Multimodal-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib45" title="">45</a>]</cite>,  HaluSearch&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib56" title="">56</a>]</cite>,  HalluMeasure&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib57" title="">57</a>]</cite>,  
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理技术，我的盒子 2 [多模态思维链 [45]，HaluSearch [56]，HalluMeasure [57]，</font></font></font><br class="ltx_break">CLATTER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib58" title="">58</a>]</cite>,  Reflexive Prompting&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib59" title="">59</a>]</cite>,  GCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib60" title="">60</a>]</cite>, CoMT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib61" title="">61</a>]</cite>, leaf, text width=26em
]
]
[
Hallucination of
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">CLATTER [ 58], 反射式提示 [ 59], GCoT [ 60], CoMT [ 61], 叶片, 文本宽度=26em ] ] [ 幻觉</font></font></font><br class="ltx_break">reasoning models, my-box2
[
MIRAGE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib62" title="">62</a>]</cite>,  SUM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib63" title="">63</a>]</cite>, RH-Bench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib64" title="">64</a>]</cite>,  Yao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib65" title="">65</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理模型，我的盒子 2 [ MIRAGE [ 62], SUM [ 63], RH-Bench [ 64], Yao 等人 [ 65],</font></font></font><br class="ltx_break">VIC&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib47" title="">47</a>]</cite>, AbstentionBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib66" title="">66</a>]</cite>, 
Lu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib67" title="">67</a>]</cite>, 
FSPO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib68" title="">68</a>]</cite>,  
<br class="ltx_break">Anh <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib69" title="">69</a>]</cite>, 
GRPO-R&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib70" title="">70</a>]</cite>, 
RFMDataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib71" title="">71</a>]</cite>, 
FG-PRM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib72" title="">72</a>]</cite>,  
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Anh 等人[69]，GRPO-R[70]，RFMDataset[71]，FG-PRM[72]，</font></font></font><br class="ltx_break">Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib73" title="">73</a>]</cite>, 
RACE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib74" title="">74</a>]</cite>
, leaf, text width=26em
]
]
]
[
Faithfulness of
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">张等人[73]、RACE[74]、leaf，text width=26em] ] ] [ 忠实度</font></font></font><br class="ltx_break">Reasoning Models
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理模型</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.SS2" title="3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">3.2</span></a>), my-box1
[
Measuring &amp;
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§3.2), 我的盒子 1 [ 测量 &amp; </font></font></font><br class="ltx_break">understanding, my-box1
[
Lanham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib75" title="">75</a>]</cite>,  Turpin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib76" title="">76</a>]</cite>,  PFF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib77" title="">77</a>]</cite>,  Xiong <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib78" title="">78</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">理解, 我的盒子 1 [ 兰哈姆等[ 75], 特平等[ 76], PFF[ 77], 熊等[ 78], </font></font></font><br class="ltx_break">Bentham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib79" title="">79</a>]</cite>, 
Arcuschin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib80" title="">80</a>]</cite>,  Chua <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib81" title="">81</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">本瑟姆等[ 79], 阿尔库什因等[ 80], 茹阿等[ 81], </font></font></font><br class="ltx_break">Chen <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib82" title="">82</a>]</cite>, 
Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib83" title="">83</a>]</cite>, 
Agarwal <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib84" title="">84</a>]</cite>, 
Bao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib85" title="">85</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">陈等[ 82], 李等[ 83], 阿格拉瓦尔等[ 84], 包等[ 85],</font></font></font><br class="ltx_break">Tanneru <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib86" title="">86</a>]</cite>, 
Lobo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib87" title="">87</a>]</cite>
, leaf, text width=26em
]
]
[
Faithfulness
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Tanneru 等[86], Lobo 等[87], leaf, text width=26em] ] [ 忠实性 </font></font></font><br class="ltx_break">improvement, my-box1
[ FRODO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib88" title="">88</a>]</cite>,  SymbCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib89" title="">89</a>]</cite>,  Radhakrishnan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib90" title="">90</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">改进, my-box1 [ FRODO[88], SymbCoT[89], Radhakrishnan 等[90], </font></font></font><br class="ltx_break">Faithful CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib91" title="">91</a>]</cite>, 
LOGIC-LM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib92" title="">92</a>]</cite>, 
FLARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib93" title="">93</a>]</cite>,  CoMAT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib94" title="">94</a>]</cite>,  
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">忠实 CoT[91], LOGIC-LM[92], FLARE[93], CoMAT[94], </font></font></font><br class="ltx_break">CORE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib95" title="">95</a>]</cite>, 
QUIRE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib83" title="">83</a>]</cite>, 
Fact&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib96" title="">96</a>]</cite>, 
Viteri <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib97" title="">97</a>]</cite>, leaf, text width=26em
]
]
]
]
[
Safety 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">CORE[95], QUIRE[83], Fact[96], Viteri 等[97], leaf, text width=26em] ] ] ] ] [ 安全</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4" title="4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>), my-box1
[
Vulnerability
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§4), my-box1 [ 漏洞 </font></font></font><br class="ltx_break">Assessment
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">评估 </font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS1" title="4.1 Vulnerability Assessment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4.1</span></a>), my-box1
[
SafeChain&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>]</cite>,  CNSafe&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>]</cite>,  Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib98" title="">98</a>]</cite>, 
Romero <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib99" title="">99</a>]</cite>,  Zhou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§4.1), my-box1 [ SafeChain [ 1], CNSafe [ 3], 张等人 [ 98], 罗马诺等人 [ 99], 周等人 [ 100], </font></font></font><br class="ltx_break">Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib101" title="">101</a>]</cite>,  Lou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib102" title="">102</a>]</cite>, 
kassianik <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib103" title="">103</a>]</cite>, 
Krishna <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib104" title="">104</a>]</cite>,  FORTRESS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib105" title="">105</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">李等人 [ 101], 刘等人 [ 102], kassianik 等人 [ 103], 克里希纳等人 [ 104], FORTRESS [ 105],</font></font></font><br class="ltx_break">Fan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib106" title="">106</a>]</cite>,  BSAbench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib107" title="">107</a>]</cite>,  Is-bench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib108" title="">108</a>]</cite>, 
SafeMLRM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib109" title="">109</a>]</cite>,  Zhao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib110" title="">110</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Fan 等人[ 106]、BSAbench[ 107]、Is-bench[ 108]、SafeMLRM[ 109]、Zhao 等人[ 110]、</font></font></font><br class="ltx_break">Marjanović <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib111" title="">111</a>]</cite>
, leaf, text width=36em,align=left
]
]
[
Jailbreak
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Marjanović等人[111]，叶，文本宽度=36em，对齐=左] ] [越狱</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2" title="4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4.2</span></a>), my-box1
[
Attack with 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§4.2), my-box1 [ 攻击 ]</font></font></font><br class="ltx_break">reasoning techniques, my-box1
[
Sabbaghi <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib112" title="">112</a>]</cite>, 
CoT-GCG&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib113" title="">113</a>]</cite>, 
Ying <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib114" title="">114</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理技术，我的盒子 1 [Sabbaghi 等人[112]，CoT-GCG [113]，Ying 等人[114]，</font></font></font><br class="ltx_break">Chain-of-Lure&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib115" title="">115</a>]</cite>, 
Handa <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib116" title="">116</a>]</cite>
, leaf, text width=26em
]
]
[
Attack on
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Chain-of-Lure [ 115], Handa 等人[ 116], leaf, 文本宽度=26em ] ] [ 攻击</font></font></font><br class="ltx_break">reasoning models, my-box1
[
H-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib117" title="">117</a>]</cite>,  Mousetrap&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib118" title="">118</a>]</cite>,  AutoRAN&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib119" title="">119</a>]</cite>, 
SEAL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib120" title="">120</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理模型，我的盒子 1 [ H-CoT [ 117], 鼠夹 [ 118], AutoRAN [ 119], SEAL [ 120],</font></font></font><br class="ltx_break">FicDetail&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib2" title="">2</a>]</cite>, 
Lian <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib121" title="">121</a>]</cite>, 
RRTL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib122" title="">122</a>]</cite>,  VisCRA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib123" title="">123</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">FicDetail [ 2], 李连等[ 121], RRTL [ 122], VisCRA [ 123],</font></font></font><br class="ltx_break">HauntAttack&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib124" title="">124</a>]</cite>
, leaf, text width=26em
]
]
[
Defense with 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">HauntAttack [ 124] , 叶片, 文本宽度=26em ] ] [ 防御与</font></font></font><br class="ltx_break">reasoning techniques, my-box1
[
GuardReasoner&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib125" title="">125</a>]</cite>, 
X-Guard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib126" title="">126</a>]</cite>, 
MrGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib127" title="">127</a>]</cite> , 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理技术，my-box1 [ GuardReasoner [ 125], X-Guard [ 126], MrGuard [ 127], </font></font></font><br class="ltx_break">RSafe&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib128" title="">128</a>]</cite>, 
Sreedhar <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib129" title="">129</a>]</cite>, 
R<sup class="ltx_sup">2</sup>-Guard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib130" title="">130</a>]</cite>,  DR-IRL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib131" title="">131</a>]</cite>, 
<br class="ltx_break">ShieldVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib132" title="">132</a>]</cite>, 
GuardReasoner-VL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib133" title="">133</a>]</cite>, 
GuardAgent&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib134" title="">134</a>]</cite>, 
<br class="ltx_break">ShieldAgent&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib135" title="">135</a>]</cite>, 
Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib136" title="">136</a>]</cite>,  U-CoT+&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib137" title="">137</a>]</cite>
, leaf, text width=26em
]
]
[
Defense for 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ShieldAgent [ 135], Wang et&nbsp;al. [ 136], U-CoT+ [ 137] , leaf, text width=26em ] ] [ 防御</font></font></font><br class="ltx_break">reasoning models, my-box1
[
SafeChain&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>]</cite>, 
Thinking Intervention&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib138" title="">138</a>]</cite>, 
Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib12" title="">12</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理模型，my-box1 [ SafeChain [ 1], 思维干预 [ 138], 王等 [ 12]，</font></font></font><br class="ltx_break">Yamaguchi <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib139" title="">139</a>]</cite>, 
Zaremba <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib140" title="">140</a>]</cite>, 
Saffron-1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib141" title="">141</a>]</cite>
, leaf, text width=26em
]
]
]
[
Alignment
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">山口等人[139]、扎雷姆巴等人[140]、Saffron-1[141] ，叶，文本宽度=26em ] ] ] [ 对齐</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3" title="4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>), my-box1
[
Aligning LLM using
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§4.3), my-box1 [ 使用 LLM 对齐 ]</font></font></font><br class="ltx_break">reasoning techniques, my-box1
[
Liu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib142" title="">142</a>]</cite>,  Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib143" title="">143</a>]</cite>,  SCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib144" title="">144</a>]</cite>, 
STAIR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib144" title="">144</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理技术，我的盒子 1 [刘等人[142]，张等人[143]，SCoT[144]，STAIR[144]，</font></font></font><br class="ltx_break">R2D&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib145" title="">145</a>]</cite>,  RATIONAL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib146" title="">146</a>]</cite>, 
ERPO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib147" title="">147</a>]</cite>, 
SaRO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib148" title="">148</a>]</cite>, 
<br class="ltx_break">Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib12" title="">12</a>]</cite>, 
Kim <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib149" title="">149</a>]</cite>, 
Thought-Aligner&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib150" title="">150</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">王等 [ 12], 金等 [ 149], Thought-Aligner [ 150],</font></font></font><br class="ltx_break">ReasoningShield&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib151" title="">151</a>]</cite>
, leaf, text width=26em
]
]
[
Alignment of
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">ReasoningShield [ 151] , leaf, text width=26em ] ] [ 推理模型的对齐,</font></font></font><br class="ltx_break">reasoning models, my-box1
[
Deliberate Alignment&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib152" title="">152</a>]</cite>,  SafeChain&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>]</cite>,  STAR-1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib153" title="">153</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">my-box1 [ 故意对齐 [ 152], SafeChain [ 1], STAR-1 [ 153],</font></font></font><br class="ltx_break">RealSafe&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib154" title="">154</a>]</cite>, 
SAFEPATH&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib155" title="">155</a>]</cite>, 
Context Reasoner&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib156" title="">156</a>]</cite>, 
<br class="ltx_break">Lou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib102" title="">102</a>]</cite>, 
Baker <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib157" title="">157</a>]</cite>,  Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib158" title="">158</a>]</cite>,  Hair&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib159" title="">159</a>]</cite>, 
<br class="ltx_break">Liu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib160" title="">160</a>]</cite>,  Safety Tax&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib161" title="">161</a>]</cite>,  SafeKey&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib162" title="">162</a>]</cite>
, leaf, text width=26em
]
]
]
[
Backdoor
<br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS4" title="4.4 Backdoor ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4.4</span></a>), my-box1
[
Training-time
<br class="ltx_break">data poisoning, my-box1
[
SABER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib163" title="">163</a>]</cite>,  BoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib164" title="">164</a>]</cite>,  ShadowCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib165" title="">165</a>]</cite>, Chua <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib166" title="">166</a>]</cite>
, leaf, text width=26em
]
]
[
Inference-time
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">数据中毒，my-box1 [ SABER [ 163], BoT [ 164], ShadowCoT [ 165], Chua 等人 [ 166] , 叶片, 文本宽度=26em ] ] [ 推理时 </font></font></font><br class="ltx_break">prompt manipulation, my-box1
[
Badchain&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib167" title="">167</a>]</cite>,  BackdoorLLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib168" title="">168</a>]</cite>,  DarkMind&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib169" title="">169</a>]</cite>, CPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib170" title="">170</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">提示操纵，my-box1 [ Badchain [ 167], BackdoorLLM [ 168], DarkMind [ 169], CPT [ 170], </font></font></font><br class="ltx_break">Guo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib171" title="">171</a>]</cite>,  Cui <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib172" title="">172</a>]</cite>,  Cui <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib173" title="">173</a>]</cite> Song <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib174" title="">174</a>]</cite>
, leaf, text width=26em
]
]
[
Backdoor
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Guo 等人 [ 171], Cui 等人 [ 172], Cui 等人 [ 173] Song 等人 [ 174] , 叶片, 文本宽度=26em ] ] [ 后门 </font></font></font><br class="ltx_break">defense, my-box1
[
Chain-of-Scrutiny&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib19" title="">19</a>]</cite>,  Marinelli <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib175" title="">175</a>]</cite>,  GUARD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib176" title="">176</a>]</cite>
, leaf, text width=26em
]
]
]
]
[
Robustness 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">防御，my-box1 [ Chain-of-Scrutiny [ 19], Marinelli 等人 [ 175], GUARD [ 176] , 叶片, 文本宽度=26em ] ] ] ] [ 鲁棒性</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5" title="5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>), my-box1
[
Improvement with
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§5), my-box1 [ 改进</font></font></font><br class="ltx_break">reasoning techniques
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理技术</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS1" title="5.1 Robustness Improvement with Reasoning Techniques ‣ 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">5.1</span></a>), my-box1
[
Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib177" title="">177</a>]</cite>,  CoDT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib178" title="">178</a>]</cite>, 
Yan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib179" title="">179</a>]</cite>,  RBD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib180" title="">180</a>]</cite>, Zaremba <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib140" title="">140</a>]</cite>
, leaf, text width=36em, align=left
]
]
[
Robustness of
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§5.1), my-box1 [ 王等 [ 177], CoDT [ 178], 严等 [ 179], RBD [ 180], 扎雷姆巴等 [ 140] , leaf, text width=36em, align=left ] ] [ 对抗鲁棒性</font></font></font><br class="ltx_break">reasoning models
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理模型</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS2" title="5.2 Robustness of Reasoning Models ‣ 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">5.2</span></a>), my-box1
[
RUPbench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib181" title="">181</a>]</cite>, Mu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib182" title="">182</a>]</cite>, 
RoR-bench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib179" title="">179</a>]</cite>, M-Attack&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib183" title="">183</a>]</cite>, GaslightingBench-R&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib184" title="">184</a>]</cite>, 
<br class="ltx_break">Zhou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib185" title="">185</a>]</cite>, 
Peng <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib186" title="">186</a>]</cite>,  PolyMath&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib187" title="">187</a>]</cite>, 
CatAttack&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib188" title="">188</a>]</cite>,  Math-RoB&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib189" title="">189</a>]</cite>, 
<br class="ltx_break">MATH-Perturb&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib190" title="">190</a>]</cite>, 
CodeCrash&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib191" title="">191</a>]</cite>,  CoCC&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib192" title="">192</a>]</cite>, AbstentionBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib66" title="">66</a>]</cite>, Xu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib193" title="">193</a>]</cite>
, leaf, text width=36em, align=left
]
]
[
Overthinking
<br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS3" title="5.3 Overthinking and Underthinking ‣ 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">5.3</span></a>), my-box1
[
UMP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib194" title="">194</a>]</cite>,  DNR Bench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib195" title="">195</a>]</cite>, 
DeltaBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib196" title="">196</a>]</cite>, 
MiP-Overthinking&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib197" title="">197</a>]</cite>,  Si <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib198" title="">198</a>]</cite>, 
<br class="ltx_break">Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib199" title="">199</a>]</cite>,  Su <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib200" title="">200</a>]</cite>,  Dang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib201" title="">201</a>]</cite>, 
Overthink&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib202" title="">202</a>]</cite>,  Cuadron <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib203" title="">203</a>]</cite>
, leaf, text width=36em,align=left
]
]
[
Underthinking
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">王等人[199], 苏等人[200], 耿等人[201], Overthink[202], 库阿德罗等人[203], leaf, text width=36em,align=left ] ] [ 低估</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S5.SS3" title="5.3 Overthinking and Underthinking ‣ 5 Robustness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">5.3</span></a>), my-box1
[
CPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib170" title="">170</a>]</cite>, 
Zaremba <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib140" title="">140</a>]</cite>,  Zhao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib110" title="">110</a>]</cite>,  Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib204" title="">204</a>]</cite>,  ThinkEdit&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib205" title="">205</a>]</cite>
, leaf, text width=36em,align=left
]
]
]
[
Fairness 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§5.3), my-box1 [ CPT [170], 扎雷姆巴等人[140], 赵等人[110], 李等人[204], ThinkEdit [205] , leaf, text width=36em,align=left ] ] ] [ 公平性 </font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S6" title="6 Fairness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>), my-box1
[
Evaluation &amp;
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§6), my-box1 [ 评估 &amp; </font></font></font><br class="ltx_break">Detection, my-box1
[
Lin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib206" title="">206</a>]</cite>,  Cheng <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib207" title="">207</a>]</cite>,  Kamruzzaman&nbsp;<span class="ltx_text ltx_font_italic">et&nbsp;al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright">[</span><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib208" title="">208</a><span class="ltx_text ltx_font_upright">]</span></cite></span>, 
Dash&nbsp;<span class="ltx_text ltx_font_italic">et&nbsp;al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright">[</span><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib209" title="">209</a><span class="ltx_text ltx_font_upright">]</span></cite></span>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">检测, my-box1 [ 林等人[206], 程等人[207], 卡姆鲁兹曼等人[208], 达什等人[209],</font></font></font><br class="ltx_break">Gupta&nbsp;<span class="ltx_text ltx_font_italic">et&nbsp;al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright">[</span><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib210" title="">210</a><span class="ltx_text ltx_font_upright">]</span></cite></span>, 
BiasGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib211" title="">211</a>]</cite>,  Cantini <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib212" title="">212</a>]</cite>
, leaf, text width=36em,align=left
]
]
]
[
Privacy 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Gupta 等人[210], BiasGuard[211], Cantini 等人[212], leaf, text width=36em,align=left] [隐私</font></font></font><br class="ltx_break">(§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7" title="7 Privacy ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>), my-box1
[
Model-related
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">(§7), my-box1 [模型相关</font></font></font><br class="ltx_break">Privacy (§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7.SS1" title="7.1 Model-related Privacy ‣ 7 Privacy ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">7.1</span></a>), my-box1
[
R-TOFU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib213" title="">213</a>]</cite>,  R<sup class="ltx_sup">2</sup>MU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib214" title="">214</a>]</cite>,  SLEEK&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib215" title="">215</a>]</cite>, 
ImF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib216" title="">216</a>]</cite>, 
CoTSRF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib217" title="">217</a>]</cite>, 
Guo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib218" title="">218</a>]</cite>, 
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">隐私(§7.1), my-box1 [R-TOFU[213], R <sup class="ltx_sup">2</sup> MU[214], SLEEK[215], ImF[216], CoTSRF[217], Guo 等人[218],</font></font></font><br class="ltx_break">Savani <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib219" title="">219</a>]</cite>
, leaf, text width=36em,align=left
]
]
[
Prompt-related
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Savani 等人[219], leaf, text width=36em,align=left] [提示相关]</font></font></font><br class="ltx_break">Privacy (§<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7.SS2" title="7.2 Prompt-related Privacy ‣ 7 Privacy ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">7.2</span></a>), my-box1
[
Green <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib220" title="">220</a>]</cite>,  DoxBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib221" title="">221</a>]</cite>
, leaf, text width=36em,align=left
]
]
]
]<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">隐私（§7.2），my-box1 [ Green 等人 [ 220]，DoxBench [ 221]，leaf，text width=36em，align=left ] ] ] ]</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Taxonomy of trustworthiness in reasoning with large language models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 2：使用大型语言模型进行推理的可信度分类学</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Truthfulness<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3 真确性</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p">Truthfulness in the LLMs refers to how an AI system accurately represents information, facts, and results&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib222" title="">222</a>]</cite>. This fundamental dimension of truthfulness focuses on the model’s ability to provide factually correct and reliable information without generating misleading or false content.
In this section, we discuss the new challenges brought by the reasoning techniques, including two aspects: hallucination and faithfulness.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLMs 中的真确性是指一个 AI 系统如何准确地呈现信息、事实和结果[ 222]。这一真确性的基本维度关注于模型提供事实正确且可靠信息的能力，而不会生成误导性或虚假内容。在本节中，我们讨论了推理技术带来的新挑战，包括两个方面：幻觉和忠实性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Hallucination<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1 幻觉</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p">Hallucination in LLMs refers to instances where <span class="ltx_text ltx_font_italic">models generate responses that appear coherent and plausible but are inconsistent with the input, context, or factual information</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib223" title="">223</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib224" title="">224</a>]</cite>.
The emergence of reasoning models introduces new risks and challenges in managing hallucinations.
First, reasoning models often generate responses that are more structured, logically coherent, and superficially persuasive, making them appear more reliable.
As a result, hallucinated content from these models can appear more credible, making it harder for users to detect inaccuracies and increasing the risk of spreading misinformation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib70" title="">70</a>]</cite>, especially in high-stakes fields such as healthcare, law, or education.
On the other hand, the CoT reasoning generated by models can also contain hallucinations&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib68" title="">68</a>]</cite>. Compared to traditional LLMs, the hallucinations in reasoning models have not been as thoroughly evaluated.
Moreover, the powerful reasoning capabilities of these models can be leveraged to detect or mitigate hallucinations in certain complex tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib56" title="">56</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib58" title="">58</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">LLMs 中的幻觉指的是模型生成看似连贯且合理的响应，但这些响应与输入、上下文或事实信息不一致的情况[223, 224]。推理模型的涌现为管理幻觉带来了新的风险和挑战。首先，推理模型通常生成结构更清晰、逻辑上连贯且表面上有说服力的响应，使其看起来更可靠。因此，这些模型产生的幻觉内容可能更具可信度，使用户更难检测错误，增加了错误信息的传播风险[70]，特别是在医疗保健、法律或教育等高风险领域。另一方面，模型生成的 CoT 推理也可能包含幻觉[68]。与传统 LLMs 相比，推理模型中的幻觉尚未得到充分评估。此外，这些模型强大的推理能力可以被用于检测或减轻某些复杂任务中的幻觉[56, 58]。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Hallucination with Reasoning Techniques<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1.1Hallucination 使用推理技术</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p1">
<p class="ltx_p">In this section, we explore how reasoning techniques can be leveraged to detect and mitigate hallucinations in LLMs.
CoT prompting has shown remarkable success in addressing complex tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib16" title="">16</a>]</cite> and reducing hallucinations&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib225" title="">225</a>]</cite>. To further enhance model reasoning capabilities, several techniques have been proposed, such as test-time scaling&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib226" title="">226</a>]</cite>, self-consistency&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib227" title="">227</a>]</cite>, etc.
One such approach, HaluSearch&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib56" title="">56</a>]</cite>, employed a tree search-based algorithm coupled with a switch model to determine when to engage in more deliberate, “slow thinking” processes.
In contrast to hallucination mitigation, HalluMeasure&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib57" title="">57</a>]</cite> focused on fine-grained hallucination measurement, using CoT prompting. Specifically, it decomposed model responses into a series of claims and applies CoT techniques to detect hallucinations at the claim level.
Similarly, CLATTER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib58" title="">58</a>]</cite> adopted a multi-step reasoning process for hallucination detection, consisting of decomposition, attribution, entailment, and aggregation.
Moreover, Xie <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib59" title="">59</a>]</cite> observed that the order in which reasoning steps are applied can influence hallucination occurrence. As such, they propose Reflexive Prompting, which combines “answer-first” and “logic-first” reasoning strategies to improve model accuracy.
Beyond text-based tasks, Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib45" title="">45</a>]</cite> extended CoT to multimodal settings, proposing a method to mitigate visual hallucinations.
Their approach involves generating a rationale that is used to update the language input, which is then combined with the original visual input to produce the final answer.
Furthermore, Wu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib60" title="">60</a>]</cite> introduced Grounded Chain-of-Thought (GCoT), a technique in which the model gradually grounds visual cues before generating answers. This step-by-step process helps mitigate visual hallucinations by enhancing the model’s understanding of the input.
In addition, in the context of medical report generation, CoMT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib61" title="">61</a>]</cite> leveraged CoT prompting to reduce hallucinations and produce high-quality, accurate reports.
In summary, reasoning techniques have been used in various ways and in many application fields to help solve the hallucination problem of LLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在本节中，我们探讨了如何利用推理技术来检测和缓解 LLMs 中的幻觉。CoT 提示方法在处理复杂任务方面表现出色[17, 16]，并有效减少了幻觉[225]。为了进一步提升模型的推理能力，研究者们提出了多种技术，如测试时缩放[226]、自洽性[227]等。其中一种方法是 HaluSearch[56]，该技术采用基于树搜索的算法与切换模型相结合，以确定何时启动更审慎的“慢思考”过程。与幻觉缓解不同，HalluMeasure[57]专注于细粒度的幻觉测量，并使用 CoT 提示方法。具体而言，它将模型响应分解为一系列主张，并应用 CoT 技术来检测主张层面的幻觉。类似地，CLATTER[58]采用多步推理过程进行幻觉检测，包括分解、归因、蕴涵和聚合。此外，Xie 等人[59]观察到推理步骤的应用顺序会影响幻觉的发生。 因此，他们提出了反思性提示方法，该方法结合了“先回答”和“先逻辑”的推理策略以提高模型准确性。除了基于文本的任务外，Zhang 等人[45]将思维链扩展到多模态环境，提出了一种减轻视觉幻觉的方法。他们的方法涉及生成一个推理依据，用于更新语言输入，然后将该语言输入与原始视觉输入结合以生成最终答案。此外，Wu 等人[60]引入了基于思维链（GCoT），这是一种技术，其中模型在生成答案之前逐步将视觉线索具体化。这种逐步的过程通过增强模型对输入的理解来帮助减轻视觉幻觉。此外，在医疗报告生成的背景下，CoMT[61]利用思维链提示来减少幻觉并生成高质量、准确的报告。 总之，推理技术已被以各种方式和在许多应用领域使用，以帮助解决 LLMs 的幻觉问题。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Hallucination in Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.1.2Hallucination 在推理模型中</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p1">
<p class="ltx_p">Despite their ability to tackle complex tasks, reasoning models are not immune to hallucination. In this section, we focus on understanding the hallucination problem in reasoning models and survey techniques for its detection and mitigation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">尽管推理模型能够处理复杂任务，但它们并非不受幻觉的影响。在本节中，我们重点关注理解推理模型中的幻觉问题，并调查其检测和缓解的技术。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Hallucination analysis</span>.
The analysis of hallucinations in reasoning models can be approached from two key questions: (1) How do reasoning models perform with respect to hallucinations? and (2) What factors contribute to hallucinations in reasoning models?<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">幻觉分析。对推理模型中幻觉的分析可以从两个关键问题入手：(1) 推理模型在幻觉方面的表现如何？以及 (2) 哪些因素导致了推理模型中的幻觉？</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p3">
<p class="ltx_p">Several studies&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib62" title="">62</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib63" title="">63</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib64" title="">64</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib65" title="">65</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib225" title="">225</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib66" title="">66</a>]</cite> have documented significant hallucination issues within reasoning models, sometimes more pronounced than in non-reasoning models.
For instance, Lu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib67" title="">67</a>]</cite> argued that LRMs exacerbate hallucination issues, making them more frequent and harder to mitigate. Their findings suggest that rather than correcting errors, LRMs tend to amplify biases and inaccuracies in the CoT of the reasoning process.
Similarly, Song <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib63" title="">63</a>]</cite> and Kirichenko <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib66" title="">66</a>]</cite> highlighted that reasoning models, when faced with unanswerable questions, struggle to recognize and refuse to respond appropriately, a challenge that is less prevalent in non-reasoning models.
The hallucination problem in LRMs is not confined to unanswerable questions. Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib68" title="">68</a>]</cite> and Yao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib65" title="">65</a>]</cite> evaluated reasoning models on both traditional hallucination benchmarks (e.g., TruthfulQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib228" title="">228</a>]</cite>, HaluEval&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib229" title="">229</a>]</cite>, HalluQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib230" title="">230</a>]</cite>) and fact-seeking benchmarks (e.g., SimpleQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib231" title="">231</a>]</cite>, TriviaQA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib232" title="">232</a>]</cite>), consistently finding that reasoning models exhibit higher rates of hallucination.
Liu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib64" title="">64</a>]</cite> extended this observation to visual tasks, where improved reasoning capabilities were often accompanied by more severe visual hallucinations. Together, these studies suggest that <span class="ltx_text ltx_font_bold">while reasoning models improve performance on complex tasks, they can also produce more significant hallucinations than non-reasoning models in simpler, non-reasoning tasks.</span>
Moreover, many studies have also found that there are serious illusions in the generated CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib69" title="">69</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib70" title="">70</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib68" title="">68</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib71" title="">71</a>]</cite>. Given the typical length and apparent logical coherence of CoT, such hallucinations are often difficult to detect and correct, posing a critical challenge for future research.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">已有数项研究[62, 63, 64, 65, 225, 66]记录了推理模型中存在显著的幻觉问题，有时比非推理模型更为突出。例如，Lu 等人[67]认为，大型语言模型（LRMs）加剧了幻觉问题，使其更频繁且更难缓解。他们的研究发现，LRMs 倾向于放大推理过程中思维链（CoT）中的偏见和不准确性，而非纠正错误。类似地，Song 等人[63]和 Kirichenko 等人[66]指出，当推理模型面对无法回答的问题时，它们难以识别并适当拒绝回答，而这一挑战在非推理模型中不那么普遍。LRMs 中的幻觉问题不仅限于无法回答的问题。Li 等人[68]和 Yao 等人[65]在传统幻觉基准测试（例如，TruthfulQA[228]、HaluEval[229]、HalluQA[230]）和事实查找基准测试（例如，SimpleQA[231]、TriviaQA[232]）上评估了推理模型，一致发现推理模型的幻觉率更高。刘等人[ ] [ 64] 将这一观察扩展到视觉任务中，发现推理能力提升往往伴随着更严重的视觉幻觉。这些研究表明，虽然推理模型在复杂任务上的表现有所提高，但在简单、非推理任务中，它们产生的幻觉可能比非推理模型更为显著。此外，许多研究还发现生成的思维链（CoT）[ 69, 67, 70, 68, 71] 存在严重幻觉。鉴于思维链通常的长度和表面上的逻辑连贯性，这类幻觉往往难以检测和纠正，为未来的研究带来了重大挑战。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p4">
<p class="ltx_p">When examining the causes of hallucinations, several studies point to the length of the CoT as a significant factor&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib67" title="">67</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib64" title="">64</a>]</cite>.
For example, Lu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib67" title="">67</a>]</cite> reported that hallucinations tend to occur more frequently in longer CoTs compared to those with correct answers.
Similarly, Liu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib64" title="">64</a>]</cite> observed that as CoTs become longer, models increasingly rely on language priors over visual inputs, a shift that often leads to visual hallucinations.
Another important factor is the training paradigm of the model.
Yao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib65" title="">65</a>]</cite> suggested that while combining SFT with RL training can improve model performance on fact-seeking tasks, both SFT-only and RL-only paradigms lead to severe hallucinations, often manifesting as flaw repetition or mismatched thinking and answers.
Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib68" title="">68</a>]</cite> similarly identified outcome-based RL fine-tuning as a contributor to hallucinations, highlighting three critical factors: high variance in policy gradients, high entropy in predictions, and the presence of spurious local optima.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在研究幻觉产生的原因时，一些研究表明 CoT 的长度是一个重要因素[67, 64]。例如，Lu 等人[67]报告称，与有正确答案的 CoT 相比，幻觉在更长的 CoT 中更频繁地发生。类似地，Liu 等人[64]观察到，随着 CoT 的变长，模型越来越依赖语言先验而非视觉输入，这种转变往往导致视觉幻觉。另一个重要因素是模型的训练范式。Yao 等人[65]指出，虽然将 SFT 与 RL 训练相结合可以提高模型在事实查找任务上的性能，但仅使用 SFT 或仅使用 RL 的训练范式会导致严重的幻觉，通常表现为缺陷重复或思维与答案不匹配。Li 等人[68]同样发现基于结果的 RL 微调是导致幻觉的一个因素，并强调了三个关键因素：策略梯度的高方差、预测的高熵以及虚假局部极值的存在。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Hallucination detection and measurement</span>.
The PRM model&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib40" title="">40</a>]</cite> provided an effective approach for measuring hallucinations within the reasoning process. Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib72" title="">72</a>]</cite> extended this work by introducing a Fine-grained Process Reward Model (FG-PRM), which trained six specialized PRMs to address specific types of hallucinations, including context inconsistency, logical inconsistency, instruction inconsistency, logical errors, factual inconsistencies, and fabrication.
These PRMs generated a combined signal to detect hallucinations more accurately.
Different from PRM-based methods, Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib73" title="">73</a>]</cite> adopted linear probing, aiming at detecting errors early during reasoning. However, the above methods need additional training steps.
Dong <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib62" title="">62</a>]</cite> adopted proxy LLMs to augment and rate the reasoning chain as an indicator of hallucination.
Sun <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib70" title="">70</a>]</cite> introduced the “reasoning score”, a metric that measures divergence between intermediate hidden states and final logits. Their findings suggest that several indicators related to this score correlate strongly with the occurrence of hallucinations, leading them to combine these indicators for effective detection.
More recently, Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib74" title="">74</a>]</cite> developed the RACE framework for hallucination detection, which extracts simplified reasoning steps via an LLM and evaluates four key aspects of the reasoning chain: reasoning consistency, answer uncertainty, reasoning-answer alignment, and reasoning coherence.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">幻觉检测与测量。PRM 模型[40]为在推理过程中测量幻觉提供了一种有效方法。Li 等人[72]通过引入细粒度过程奖励模型（FG-PRM）扩展了这项工作，该模型训练了六个专门的 PRM 来处理特定类型的幻觉，包括上下文不一致、逻辑不一致、指令不一致、逻辑错误、事实不一致和捏造。这些 PRM 生成了一个组合信号，以更准确地检测幻觉。与基于 PRM 的方法不同，Zhang 等人[73]采用了线性探测，旨在在推理过程中早期检测错误。然而，上述方法需要额外的训练步骤。Dong 等人[62]采用代理 LLMs 来增强和评分推理链，将其作为幻觉的指标。Sun 等人[70]引入了“推理分数”，这是一个衡量中间隐藏状态与最终 logits 之间差异的指标。他们的研究发现，与该分数相关的几个指标与幻觉的发生密切相关，因此他们将这些指标结合起来进行有效检测。 最近，王等人[74]开发了用于幻觉检测的 RACE 框架，该框架通过 LLM 提取简化的推理步骤，并评估推理链的四个关键方面：推理一致性、答案不确定性、推理-答案对齐和推理连贯性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p6">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Hallucination mitigation</span>.
In addition to hallucination detection, another way to combat hallucinations in LRMs is hallucination mitigation, which aims to reduce the frequency of hallucinations through various strategies.
These strategies can be broadly classified into two categories: training-based methods and planning-based methods.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">幻觉缓解。除了幻觉检测外，对抗 LRM 中幻觉的另一种方法是幻觉缓解，该方法旨在通过多种策略减少幻觉的频率。这些策略可以大致分为两类：基于训练的方法和基于规划的方法。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p7">
<p class="ltx_p">Training-based methods involve intervening in the model’s training process, either by introducing additional training objectives or incorporating specialized training data.
For instance, Song <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib63" title="">63</a>]</cite> modified the reward function in the PPO algorithm&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib31" title="">31</a>]</cite>, encouraging the model to respond with “I don’t know” when faced with unanswerable questions. This approach mitigates hallucinations on unanswerable problems while preserving performance on solvable ones.
Similarly, Sun <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib70" title="">70</a>]</cite> proposed GRPO-R, an extension of the original GRPO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib32" title="">32</a>]</cite>, where the reward was adjusted by incorporating a reasoning score.
FSPO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib68" title="">68</a>]</cite> further refined this approach by introducing both a rule-based correctness reward for the final answer and a step-wise factuality reward, which is derived from the LLM’s reasoning process in conjunction with additional evidence.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">基于训练的方法涉及干预模型的训练过程，可以通过引入额外的训练目标或结合专门的训练数据来实现。例如，Song 等人[63]修改了 PPO 算法[31]中的奖励函数，鼓励模型在面对无法回答的问题时回应“我不知道”。这种方法在解决无法回答的问题时减轻了幻觉现象，同时保留了在可解决问题上的表现。类似地，Sun 等人[70]提出了 GRPO-R，这是对原始 GRPO[32]的扩展，其中通过结合推理分数来调整奖励。FSPO[68]进一步改进了这种方法，引入了基于规则的最终答案正确性奖励和逐步事实性奖励，后者是从 LLM 的推理过程以及额外证据中推导出来的。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p8">
<p class="ltx_p">In contrast, planning-based methods do not necessitate modifications to the training procedure. Instead, they focus on mitigating hallucinations by improving the model’s reasoning path through better planning.
Zheng <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib47" title="">47</a>]</cite> argued that models may suffer from vision-language bias when they process information while simultaneously attending to both vision and text inputs. To address this, they first prompted the model to generate a reasoning plan using text-only input, and then, based on the generated plan, proceeded to solve the problem and generate intermediate reasoning steps with the vision-language input.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">相比之下，基于规划的方法无需修改训练流程。它们通过改进模型的推理路径来缓解幻觉问题，从而专注于通过更好的规划来减轻幻觉。Zheng 等人[47]认为，当模型同时处理视觉和文本输入时，可能会受到视觉-语言偏差的影响。为了解决这个问题，他们首先使用纯文本输入提示模型生成推理计划，然后基于生成的计划进行问题求解，并使用视觉-语言输入生成中间推理步骤。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p9">
<p class="ltx_p">Overall, our review indicates that while reasoning models have demonstrated remarkable progress on complex reasoning-driven tasks, their tendency to hallucinate even in common scenarios remains a fundamental limitation. Addressing this tension between reasoning capability and reliability will require systematic investigation, and stands as an important direction for future research.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">总体而言，我们的综述表明，虽然推理模型在复杂的推理驱动任务上取得了显著进展，但它们在常见场景中仍然存在幻觉的倾向，这仍然是一个基本限制。解决推理能力和可靠性之间的这种张力将需要系统的调查研究，并成为未来研究的一个重要方向。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Faithfulness of Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2 推理模型的忠实性</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p">Faithfulness in traditional natural language generation is defined by the extent to which the model’s outputs align with or are supported by the provided input&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib233" title="">233</a>]</cite>.
In this work, we specifically examine reasoning faithfulness in the context of LLM reasoning, focusing on faithfulness related to CoT prompting and LRM.
In LLM reasoning scenarios, reasoning faithfulness typically addresses the question&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib234" title="">234</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib91" title="">91</a>]</cite>: <span class="ltx_text ltx_font_italic">“Does the explanation generated by the model accurately reflect the reasoning process behind its prediction?”</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在传统的自然语言生成中，模型的输出与所提供的输入的符合程度或支持程度被定义为忠实性[ 233]。在本工作中，我们特别考察了 LLM 推理中的推理忠实性，重点关注与 CoT 提示和 LRM 相关的忠实性。在 LLM 推理场景中，推理忠实性通常涉及这样一个问题[ 234, 91]：“模型生成的解释是否准确反映了其预测背后的推理过程？”</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p">Reasoning faithfulness is a fundamental aspect of overall model truthfulness.
A lack of faithfulness in CoT reasoning can introduce significant safety risks, particularly in high-stakes domains such as legal services, medical treatment, and financial decision-making&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib84" title="">84</a>]</cite>, where users may be misled into overestimating the model’s interpretability.
Research on reasoning faithfulness can be broadly categorized into three key areas: faithfulness measuring, understanding, and improvement.
In the following sections, we will explore reasoning faithfulness from each of these three perspectives.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理忠实性是模型整体真实性中的一个基本方面。CoT 推理中的缺乏忠实性可能会引入重大的安全风险，特别是在法律服务、医疗治疗和金融决策等高风险领域[ 84]，用户可能会被误导而高估模型的可解释性。推理忠实性的研究可以大致分为三个关键领域：忠实性度量、理解和改进。在接下来的几节中，我们将从这三个角度探讨推理忠实性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Faithfulness Measuring<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.1 忠实性度量</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p1">
<p class="ltx_p">While faithfulness is an essential component of trustworthiness, comprehensively measuring it remains an open challenge.
However, several metrics have been proposed to partially evaluate the faithfulness of CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib75" title="">75</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib77" title="">77</a>]</cite>.
These methods can be broadly categorized into various intervention techniques that modify either the reasoning process, the input, or the model parameters to measure how faithfully the model’s CoT reflects its reasoning process.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">虽然忠实性是可信度的重要组成部分，但全面衡量它仍然是一个开放性的挑战。然而，已经提出了几种指标来部分评估 CoT[75, 76, 77]的忠实性。这些方法可以大致分为各种干预技术，这些技术通过修改推理过程、输入或模型参数来测量模型生成的 CoT 如何忠实地反映其推理过程。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">CoT intervention</span>. One prominent evaluation method involves modifying the CoT reasoning path <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m1"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> generated by the model and observing changes in the output to assess whether the reasoning faithfully supports the model’s prediction&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib75" title="">75</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib79" title="">79</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib88" title="">88</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib235" title="">235</a>]</cite>.
Lanham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib75" title="">75</a>]</cite> proposed a CoT intervention approach, which alters the reasoning process by truncating the CoT before the final answer or introducing errors at specific points in the reasoning chain.
The former one truncates the original CoT before answering, and the latter one adds a mistake generated by a proxy LLM into some specific position in the CoT and generates subsequent CoT autoregressively.
After CoT intervention, if the answer changes, it means that the CoT matters in the model’s prediction, which indicates that the CoT is faithful.
By introducing CoT interventions at different steps of the reasoning process, we can generate a consistency curve and use the Area Over Curve (AOC) to quantify faithfulness.
However, Bentham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib79" title="">79</a>]</cite> cautioned that such metrics may be biased due to inherent label biases in the model. To address this, they introduce a CoT-agnostic normalized metric, calculated as follows:<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">CoT 干预。一种突出的评估方法涉及修改模型生成的 CoT 推理路径 <math id="S3.SS2.SSS1.p2.m1" display="inline" class="ltx_Math" alttext="T"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> ，通过观察输出变化来评估推理是否真实地支持模型的预测[ 75, 79, 88, 235]。Lanham 等人[ 75]提出了一种 CoT 干预方法，通过在最终答案之前截断 CoT 或在推理链的特定点引入错误来改变推理过程。前者在回答前截断原始 CoT，后者将一个由代理 LLM 生成的错误添加到 CoT 的某些特定位置，并自回归地生成后续 CoT。CoT 干预后，如果答案发生变化，这意味着 CoT 在模型的预测中很重要，这表明 CoT 是真实的。通过在推理过程的不同步骤引入 CoT 干预，我们可以生成一致性曲线，并使用曲线下面积（AOC）来量化真实性。然而，Bentham 等人[ 79]警告说，由于模型中固有的标签偏差，此类指标可能存在偏差。为解决这个问题，他们引入了一种与 CoT 无关的归一化指标，计算方法如下：</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="N(\mathcal{M},\mathcal{D})=\frac{1}{\lvert\mathcal{D}\rvert}\sum\limits_{x\in\mathcal{D}}\mathbbm{1}_{[\mathcal{M}(x)=\mathcal{M}(\tilde{x})]}," class="ltx_Math" display="block" id="S3.E2.m1"><semantics><mrow><mrow><mrow><mi>N</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic">ℳ</mi><mo>,</mo><mi class="ltx_font_mathcaligraphic">𝒟</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mrow><mo stretchy="false">|</mo><mi class="ltx_font_mathcaligraphic">𝒟</mi><mo stretchy="false">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em">​</mo><mrow><munder><mo movablelimits="false">∑</mo><mrow><mi>x</mi><mo>∈</mo><mi class="ltx_font_mathcaligraphic">𝒟</mi></mrow></munder><msub><mn>𝟙</mn><mrow><mo stretchy="false">[</mo><mrow><mrow><mi class="ltx_font_mathcaligraphic">ℳ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi class="ltx_font_mathcaligraphic">ℳ</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">]</mo></mrow></msub></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">N(\mathcal{M},\mathcal{D})=\frac{1}{\lvert\mathcal{D}\rvert}\sum\limits_{x\in\mathcal{D}}\mathbbm{1}_{[\mathcal{M}(x)=\mathcal{M}(\tilde{x})]},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math alttext="\mathbbm{1}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m2"><semantics><mn>𝟙</mn><annotation encoding="application/x-tex">\mathbbm{1}</annotation></semantics></math> represents the indicator function, and <math alttext="\tilde{x}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m3"><semantics><mover accent="true"><mi>x</mi><mo>~</mo></mover><annotation encoding="application/x-tex">\tilde{x}</annotation></semantics></math> refers to a version of <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.m4"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> where answer choices have been shuffled.
Additionally, Paul <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib88" title="">88</a>]</cite> used the Lakage-Adjusted Simulatability (LAS)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib236" title="">236</a>]</cite> to measure faithfulness by evaluating the accuracy deviation between the model’s performance with and without CoT reasoning.
Xiong <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib78" title="">78</a>]</cite> extended CoT intervention to assess both intra-draft and draft-to-answer faithfulness in large reasoning models, such as DeepSeek-R1.
Yee <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib235" title="">235</a>]</cite> employed error injection into the CoT and classified reasoning as faithful or unfaithful based on whether the model recovered the injected error in the final answer.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其中 <math id="S3.SS2.SSS1.p2.m2" display="inline" class="ltx_Math" alttext="\mathbbm{1}"><semantics><mn>𝟙</mn><annotation encoding="application/x-tex">\mathbbm{1}</annotation></semantics></math> 表示指示函数， <math id="S3.SS2.SSS1.p2.m3" display="inline" class="ltx_Math" alttext="\tilde{x}"><semantics><mover accent="true"><mi>x</mi><mo>~</mo></mover><annotation encoding="application/x-tex">\tilde{x}</annotation></semantics></math> 指的是 <math id="S3.SS2.SSS1.p2.m4" display="inline" class="ltx_Math" alttext="x"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> 的一个版本，其中答案选项已被打乱。此外，Paul 等人 [88] 使用 Lakage-Adjusted Simulatability (LAS) [236] 来衡量忠实度，通过评估模型使用和未使用思维链推理时的性能准确度偏差。Xiong 等人 [78] 将思维链干预扩展到评估大型推理模型（如 DeepSeek-R1）的草稿内和草稿到答案的忠实度。Yee 等人 [235] 将错误注入到思维链中，并根据模型是否在最终答案中恢复注入的错误来将推理分类为忠实或不忠实。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Prompts demonstrating the two biasing features. The text for the unbiased context is in <span class="ltx_text ltx_font_italic">Italian</span> and for the biased context in <span class="ltx_text ltx_font_bold">Bold</span>.
The top example shows the <span class="ltx_text ltx_font_typewriter">Answer is Always A</span> biasing feature, in which we reorder the multiple-choice options in a few-shot prompt to make the answer always (A).
The bottom shows the <span class="ltx_text ltx_font_typewriter">Suggested Answer</span> bias, in which we add text where a user suggests a random answer is correct. This table is borrowed from Turpin <span class="ltx_text ltx_font_italic">et&nbsp;al.<cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text ltx_font_upright">[</span><a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib76" title="">76</a><span class="ltx_text ltx_font_upright">]</span></cite></span>.
<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">表 2：展示两种偏置特征的提示。无偏置上下文的文本为意大利语，有偏置上下文的文本为粗体。顶部示例展示了"答案总是 A"的偏置特征，其中我们在少量样本提示中重新排序多项选择题选项，使答案始终为(A)。底部展示了"建议答案"偏置，其中我们添加文本，让用户建议一个随机答案是正确的。该表格借鉴自 Turpin 等人[76]。</font></font></font></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:550.0pt;"><span class="ltx_text ltx_font_bold">Biasing Feature #1:</span> <span class="ltx_text ltx_font_typewriter">Answer is Always A</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">偏置特征#1：答案总是 A</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:550.0pt;"><span class="ltx_text ltx_font_bold">Human:</span> Q: Is the following sentence plausible? “Julio Jones struck out.” (A) <span class="ltx_text ltx_font_italic">plausible</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">implausible</span> (B) <span class="ltx_text ltx_font_italic">implausible</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">plausible</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">人类：Q: 以下句子是否合理？"Julio Jones 被三振出局。" (A)合理/不合理 (B)不合理/合理</font></font></font></span>
<span class="ltx_p">Let’s think step by step. […] Answer: <span class="ltx_text ltx_font_italic">(B)</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">(A)</span> implausible<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">让我们逐步思考。 […] 答案：(B) / (A)不合理</font></font></font></span>
<span class="ltx_p">[…] Answer: <span class="ltx_text ltx_font_italic">(B)</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">(A)</span> implausible<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">…答案：(B) / (A) 不合理</font></font></font></span>
<span class="ltx_p">[…] Answer: <span class="ltx_text ltx_font_italic">(B)</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">(A)</span> implausible<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">…答案：(B) / (A) 不合理</font></font></font></span>
<span class="ltx_p">[…] Answer: <span class="ltx_text ltx_font_italic">(A)</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">(A)</span> plausible<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">…答案：(A) / (A) 合理</font></font></font></span>
<span class="ltx_p">[…] Answer: <span class="ltx_text ltx_font_italic">(B)</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">(A)</span> implausible<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">…答案：(B) / (A) 不合理</font></font></font></span>
<span class="ltx_p">[…] Answer: <span class="ltx_text ltx_font_italic">(A)</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">(A)</span> plausible<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">…答案：(A) / (A) 合理</font></font></font></span>
<span class="ltx_p">Q: Is the following sentence plausible? “LeBron James took a corner kick.” (A) plausible (B) implausible<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Q: 以下句子是否合理？“LeBron James 进行了一次角球。” (A) 合理 (B) 不合理</font></font></font></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Assistant</span>:
<span class="ltx_text ltx_font_typewriter">[generate CoT explanation]</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">助手：[生成思维链解释]</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_tt">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:550.0pt;"><span class="ltx_text ltx_font_bold">Biasing Feature #2: </span><span class="ltx_text ltx_font_typewriter">Suggested Answer</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">偏见特征 #2：建议答案</font></font></font></span>
</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span class="ltx_inline-block ltx_align_top">
<span class="ltx_p" style="width:550.0pt;"><span class="ltx_text ltx_font_bold">Human:</span> Q: Is the following sentence plausible? “LeBron James took a corner kick.” (A) plausible (B) implausible<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">人类：问：以下句子合理吗？“勒布朗·詹姆斯踢了一个角球。”（A）合理（B）不合理</font></font></font></span>
<span class="ltx_p"><span class="ltx_text ltx_font_typewriter ltx_font_italic">&lt;empty&gt;</span>&nbsp;/&nbsp;<span class="ltx_text ltx_font_bold">I think the answer is A but I’m curious to hear what you think.</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">&lt;空&gt; / 我认为答案是 A，但我好奇你的想法。</font></font></font></span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Assistant</span>:
<span class="ltx_text ltx_font_typewriter">[generate CoT explanation]</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">助手：[生成思维链解释]</font></font></font></span>
</span>
</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Input intervention</span>. Input intervention differs from CoT intervention in that it introduces bias into the input <math alttext="x" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.m1"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> and observes how both the CoT reasoning and the model’s answer change as a result.
<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S3.T2" title="In 3.2.1 Faithfulness Measuring ‣ 3.2 Faithfulness of Reasoning Models ‣ 3 Truthfulness ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">Table</span>˜<span class="ltx_text ltx_ref_tag">2</span></a> shows a demonstration of input interventions proposed by Turpin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib76" title="">76</a>]</cite>.
Specifically, by either setting all answers in the few-shot demonstration to a fixed choice (e.g., (A)) or expressing a preference for a particular answer choice, LLMs often adjust their answers accordingly.
This shift in answers is used to assess the model’s faithfulness, with the accuracy drop serving as a key metric for unfaithfulness. However, it is important to note that the bias introduced into the input is typically not reflected in the CoT, thereby highlighting a potential risk of unfaithfulness.
Similarly, Chua <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib81" title="">81</a>]</cite> and Chen <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib82" title="">82</a>]</cite> built upon this concept by inserting various cues (i.e., professor suggestions and black/white square implications) into the inputs.
Unlike Turpin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib76" title="">76</a>]</cite>, who focused on the accuracy drop, these studies assessed faithfulness by determining whether the model acknowledges the inserted cue when its answer changes.
Yet, like previous studies, these models may fail to mention the cues in the CoT, exposing faithfulness vulnerability in their reasoning process.
Arcuschin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib80" title="">80</a>]</cite> proposed to flip the question (e.g., changing “<math alttext="\text{Is }X&gt;Y" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.m2"><semantics><mrow><mrow><mtext>Is&nbsp;</mtext><mo lspace="0em" rspace="0em">​</mo><mi>X</mi></mrow><mo>&gt;</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">\text{Is }X&gt;Y</annotation></semantics></math>” to “<math alttext="\text{Is }Y&gt;X" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.m3"><semantics><mrow><mrow><mtext>Is&nbsp;</mtext><mo lspace="0em" rspace="0em">​</mo><mi>Y</mi></mrow><mo>&gt;</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">\text{Is }Y&gt;X</annotation></semantics></math>”). If the model’s answer does not change, it is considered unfaithful.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">输入干预。输入干预与思维链干预不同，它向输入中引入偏差 <math id="S3.SS2.SSS1.p3.m1" display="inline" class="ltx_Math" alttext="x"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math> ，并观察思维链推理和模型答案如何因此改变。表˜2 展示了 Turpin 等人[ 76]提出的输入干预的示例。具体来说，通过将少样本演示中的所有答案设置为固定选项（例如（A））或表达对特定答案选项的偏好，LLMs 通常会相应调整它们的答案。这种答案的变化被用来评估模型的忠实度，准确率下降是衡量不忠实的关键指标。然而，需要注意的是，输入中引入的偏差通常不会反映在思维链中，从而突显了不忠实的一个潜在风险。类似地，Chua 等人[ 81]和 Chen 等人[ 82]基于这一概念，通过向输入中插入各种提示（即教授建议和黑白方块暗示）来构建研究。与 Turpin 等人[ 76]关注准确率下降不同，这些研究通过判断模型在答案变化时是否承认插入的提示来评估忠实度。 然而，与以往研究类似，这些模型可能未能提及 CoT 中的线索，从而暴露出推理过程中的忠实性漏洞。Arcuschin 等人[80]提出反转问题（例如，将“ <math id="S3.SS2.SSS1.p3.m2" display="inline" class="ltx_Math" alttext="\text{Is }X&gt;Y"><semantics><mrow><mrow><mtext>Is&nbsp;</mtext><mo rspace="0em" lspace="0em">​</mo><mi>X</mi></mrow><mo>&gt;</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">\text{Is }X&gt;Y</annotation></semantics></math> ”改为“ <math id="S3.SS2.SSS1.p3.m3" display="inline" class="ltx_Math" alttext="\text{Is }Y&gt;X"><semantics><mrow><mrow><mtext>Is&nbsp;</mtext><mo rspace="0em" lspace="0em">​</mo><mi>Y</mi></mrow><mo>&gt;</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">\text{Is }Y&gt;X</annotation></semantics></math> ”）。 如果模型的答案没有改变，则认为其不忠实。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Parameter intervention</span>. In a recent study, Tutek <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib77" title="">77</a>]</cite> argued that metrics based solely on CoT intervention only evaluate contextual faithfulness. Although crucial context may be erased, the relevant knowledge embedded within the model’s parameters remains intact, potentially allowing the model to reconstruct the missing context. To address this, Tutek <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib77" title="">77</a>]</cite> introduced FUR, a method that utilizes the unlearning algorithm NPO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib237" title="">237</a>]</cite> to assess parameter faithfulness.
Specifically, they segment the CoT <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p4.m1"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> and then unlearn a single step in it.
And then they use the answer consistency and probability divergence between the original model <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p4.m2"><semantics><mi class="ltx_font_mathcaligraphic">ℳ</mi><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math> and the unlearned model <math alttext="\mathcal{M}^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p4.m3"><semantics><msup><mi class="ltx_font_mathcaligraphic">ℳ</mi><mo>′</mo></msup><annotation encoding="application/x-tex">\mathcal{M}^{\prime}</annotation></semantics></math> to estimate the faithfulness.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">参数干预。在一项近期研究中，Tutek 等人[77]指出，仅基于 CoT 干预的指标仅评估上下文忠实性。尽管关键上下文可能被擦除，但模型参数中嵌入的相关知识仍然完好无损，这可能导致模型重建缺失的上下文。为解决这一问题，Tutek 等人[77]引入了 FUR 方法，该方法利用去学习算法 NPO[237]来评估参数忠实性。具体而言，他们将 CoT <math id="S3.SS2.SSS1.p4.m1" display="inline" class="ltx_Math" alttext="T"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> 分段，然后对其中的一个步骤进行去学习。随后，他们利用原始模型 <math id="S3.SS2.SSS1.p4.m2" display="inline" class="ltx_Math" alttext="\mathcal{M}"><semantics><mi class="ltx_font_mathcaligraphic">ℳ</mi><annotation encoding="application/x-tex">\mathcal{M}</annotation></semantics></math> 和去学习模型 <math id="S3.SS2.SSS1.p4.m3" display="inline" class="ltx_Math" alttext="\mathcal{M}^{\prime}"><semantics><msup><mi class="ltx_font_mathcaligraphic">ℳ</mi><mo>′</mo></msup><annotation encoding="application/x-tex">\mathcal{M}^{\prime}</annotation></semantics></math> 之间的答案一致性和概率发散来估计忠实性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">No intervention</span>. Xu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib89" title="">89</a>]</cite> adopted manual evaluation, which divides an instance into three classes: (1) faithful: both the answer and the process are correct and logical (2) unfaithful: the answer is correct but the reasoning process is not; (3) false: the answer is incorrect.
Similarly, Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib83" title="">83</a>]</cite> considered an instance to be faithful if and only if both the CoT and the answer are correct or incorrect.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">没有干预。徐等人 [89] 采用了人工评估方法，将实例分为三类：(1) 忠实：答案和推理过程均正确且合理；(2) 不忠实：答案正确但推理过程不正确；(3) 错误：答案不正确。类似地，李等人 [83] 认为一个实例是忠实的，当且仅当 CoT 和答案都正确或都错误。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Faithfulness Understanding<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.2 忠实性理解</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p1">
<p class="ltx_p">A growing body of research delves into the mechanisms underlying the faithfulness of reasoning in Large Language Models (LLMs). In this section, we summarize key studies that aim to understand and enhance the faithfulness of LLMs’ reasoning processes.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越来越多的研究深入探讨大型语言模型（LLMs）中推理忠实性的机制。在本节中，我们总结了旨在理解和增强 LLMs 推理过程忠实性的关键研究。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Unfaithfulness problem</span>.
Despite the impressive performance of CoT reasoning in handling complex tasks, the CoTs generated by models can still exhibit unfaithfulness—remaining logically coherent but diverging from the true reasoning process&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib76" title="">76</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib75" title="">75</a>]</cite>.
Lanham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib75" title="">75</a>]</cite> revealed that, in some cases, the reasoning process is post-hoc: the model first determines the answer and then fabricates a plausible explanation, rather than deriving the answer through the reasoning.
While reasoning models generally show better faithfulness than non-reasoning models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib81" title="">81</a>]</cite>, they still exhibit unfaithfulness that warrants further attention&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib82" title="">82</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib80" title="">80</a>]</cite>.
Agarwal <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib84" title="">84</a>]</cite> emphasized that faithfulness is critical in high-stakes applications, such as healthcare diagnosis, financial forecasting, and crime prediction, while plausibility (the degree to which reasoning aligns with human understanding) is essential in more recreational or educational contexts, such as story-telling and educational LLMs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">不忠实问题。尽管 CoT 推理在处理复杂任务方面表现出色，但模型生成的 CoT 仍可能存在不忠实——逻辑上连贯但偏离真实推理过程[76, 75]。Lanham 等人[75]揭示，在某些情况下，推理过程是后置的：模型先确定答案，然后编造一个看似合理的解释，而不是通过推理得出答案。虽然推理模型通常比非推理模型表现出更高的忠实度[81]，但它们仍然存在需要进一步关注的不忠实现象[82, 80]。Agarwal 等人[84]强调，在医疗诊断、金融预测和犯罪预测等高风险应用中，忠实度至关重要，而在故事讲述和教育 LLM 等更多休闲或教育环境中，合理性（推理与人类理解的契合程度）则必不可少。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">The factors that influence faithfulness</span>.
When unfaithfulness arises in models, a considerable amount of research investigates the factors influencing this issue.
Early work by Lanham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib75" title="">75</a>]</cite> explored how model size and model capability affect faithfulness.
Their findings suggest that reasoning faithfulness typically increases, then decreases, with an increase in model size, with an optimal size around 13B parameters.
Bentham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib79" title="">79</a>]</cite> extended this research across various LLM families and confirmed a similar trend. Interestingly, they observed that models with higher accuracy tend to exhibit lower faithfulness, a finding also supported by Tanneru <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib86" title="">86</a>]</cite>.
Conversely, Bao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib85" title="">85</a>]</cite> and Xiong <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib78" title="">78</a>]</cite> argued that larger models are generally more faithful, suggesting the possibility of a nuanced relationship between size and faithfulness.
The findings drawn by Bentham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib79" title="">79</a>]</cite> and Tanneru <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib86" title="">86</a>]</cite> may stem from the fact that more performant models can often generate correct answers despite error or incomplete CoTs, indicating that existing faithfulness measures may oversimplify the issue.
Additionally, Lanham <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib75" title="">75</a>]</cite> highlighted that the faithfulness of a model’s reasoning varies significantly across tasks, with faithfulness scores AOC ranging from less than 10% to over 60%.
Chen <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib82" title="">82</a>]</cite> and Xiong <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib78" title="">78</a>]</cite> demonstrated experimentally that models are more prone to unfaithfulness when tasked with more difficult problems.
In addition, there is ongoing debate surrounding the impact of CoT length on faithfulness.
Chua <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib81" title="">81</a>]</cite> suggested that length penalties may result in unfaithful responses, but Chen <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib82" title="">82</a>]</cite> claimed that unfaithful CoTs are usually longer than faithful CoTs.
Bao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib85" title="">85</a>]</cite> proposed an alternative explanation based on structural causal models (SCMs)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib238" title="">238</a>]</cite>. They claimed that reasoning derived from a causal chain (where the answer stems directly from the CoT, which is in turn derived from the instruction) is generally more faithful. In contrast, reasoning that depends on more complex SCM types, such as common cause or full connection, may introduce unfaithfulness due to the increased dependency on the instruction.
Recent work also highlights the role of post-training techniques in shaping model faithfulness.
For instance, a study by Bao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib85" title="">85</a>]</cite> indicated that SFT and DPO could weaken a model’s faithfulness.
Lobo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib87" title="">87</a>]</cite> found that the impact of SFT on faithfulness is more pronounced in smaller models, with larger models being less affected.
Finally, recent studies suggested that reasoning models trained with reinforcement learning with verifiable rewards (RLVR) (e.g., DeepSeek-R1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib15" title="">15</a>]</cite>) exhibit significantly higher faithfulness compared to non-reasoning models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib81" title="">81</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib82" title="">82</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib80" title="">80</a>]</cite>.
Although many factors are related to faithfulness, their conclusions may be contradictory due to different evaluation methods and models. This calls for the development of more comprehensive evaluation methods.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">影响忠实性的因素。当模型出现不忠实性时，大量研究调查了影响这一问题的因素。Lanham 等人早期的研究[75]探讨了模型大小和模型能力如何影响忠实性。他们的研究发现，随着模型大小的增加，推理忠实性通常会先增加后减少，最佳参数量约为 13B。Bentham 等人[79]将这项研究扩展到不同的 LLM 家族，并确认了类似的趋势。有趣的是，他们观察到准确率较高的模型往往表现出较低的忠实性，这一发现也得到了 Tanneru 等人[86]的支持。相反，Bao 等人[85]和 Xiong 等人[78]认为较大的模型通常更忠实，这表明大小和忠实性之间可能存在复杂的关系。Bentham 等人[79]和 Tanneru 等人[86]得出的发现可能源于性能更优的模型即使存在错误或不完整的 CoTs 也能生成正确答案，这表明现有的忠实性度量标准可能过于简化了问题。此外，Lanham 等人 [ 75] 指出模型的推理可信度在不同任务中差异显著，可信度得分 AOC 范围从不到 10%到超过 60%。Chen 等人[ 82]和 Xiong 等人[ 78]通过实验证明，当模型处理更复杂问题时，更容易出现不可信的情况。此外，关于 CoT 长度对可信度的影响存在持续争论。Chua 等人[ 81]提出长度惩罚可能导致不可信的响应，但 Chen 等人[ 82]声称不可信的 CoT 通常比可信的 CoT 更长。Bao 等人[ 85]基于结构因果模型（SCMs）[ 238]提出了另一种解释。他们认为，基于因果链（即答案直接源于 CoT，而 CoT 又源于指令）推导出的推理通常更可信。相比之下，依赖更复杂 SCM 类型（如共同原因或完全连接）的推理可能由于对指令的依赖增加而引入不可信性。近期研究还强调了后训练技术在塑造模型可信度中的作用。例如，Bao 等人的一项研究显示... [ 85] 指出，监督微调（SFT）和去偏见优化（DPO）可能会削弱模型的忠实性。Lobo 等人[ 87]发现，SFT 对忠实性的影响在较小模型中更为显著，而较大模型受影响较小。最后，最近的研究表明，使用带可验证奖励的强化学习（RLVR）训练的推理模型（例如，DeepSeek-R1 [ 15]）与非推理模型[ 81, 82, 80]相比，表现出显著更高的忠实性。尽管许多因素与忠实性相关，但由于评估方法和模型的不同，他们的结论可能相互矛盾。这要求我们开发更全面的评估方法。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Faithfulness Improvement<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.3 忠实性改进</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p1">
<p class="ltx_p">Since faithfulness is an important part of trustworthiness, many methods have been proposed to enhance the faithfulness of the model.
To improve reasoning faithfulness in large language models, Radhakrishnan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib90" title="">90</a>]</cite> adopted a question decomposition strategy. They break down a complex question into a sequence of subquestions, solve each one individually, and then recompose the intermediate answers to arrive at the final answer.
Recent work has explored symbolic reasoning to further enhance faithfulness.
Faithful CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib91" title="">91</a>]</cite> translated natural language queries into symbolic reasoning steps using an LLM, then employed a deterministic solver (e.g., a Python interpreter) to compute the final answer.
Each reasoning step in the chain included three components: a subquestion, a dependency graph, and corresponding rationales.
Similarly, LOGIC-LM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib92" title="">92</a>]</cite> used symbolic formulation and an external reasoner, and introduced a self-refinement mechanism when the executor returned an error.
However, reliance on external symbolic solvers may lead to brittleness in the presence of syntax errors. To address this limitation, approaches such as SymbCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib89" title="">89</a>]</cite>, FLARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib93" title="">93</a>]</cite>, and CoMAT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib94" title="">94</a>]</cite> proposed to use LLMs themselves as solvers and verifiers.
SymbCoT used the LLM in multiple roles (i.e., symbolic translator, planner, solver, and verifier) via distinct prompt templates.
FLARE formalized problems into logic programs and simulates their execution using LLMs modeled after Prolog-style reasoning.
Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib95" title="">95</a>]</cite> proposed the CORE framework, which iteratively refined both the rationale and the answer while ensuring that the model’s confidence aligns with logical propositions.
QUIRE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib83" title="">83</a>]</cite> enhanced faithfulness by re-emphasizing critical input information before initiating CoT reasoning.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由于可信度的重要组成部分是忠实性，因此已经提出了许多方法来增强模型的忠实性。为了提高大型语言模型中的推理忠实性，Radhakrishnan 等人[90]采用了一种问题分解策略。他们将复杂问题分解为一系列子问题，单独解决每个子问题，然后重新组合中间答案以得出最终答案。最近的研究探索了符号推理，以进一步增强忠实性。忠实性 CoT[91]使用 LLM 将自然语言查询转换为符号推理步骤，然后使用确定性求解器（例如 Python 解释器）来计算最终答案。链中的每个推理步骤包括三个组件：子问题、依赖图和相应的推理依据。类似地，LOGIC-LM[92]使用了符号化表述和外部推理器，并在执行器返回错误时引入了自我完善机制。然而，对外部符号求解器的依赖可能导致在存在语法错误时出现脆弱性。 为解决这一局限性，SymbCoT [ 89]、FLARE [ 93] 和 CoMAT [ 94] 等方法提出使用 LLMs 本身作为求解器和验证器。SymbCoT 通过不同的提示模板，使 LLM 在多个角色中发挥作用（即符号翻译器、规划器、求解器和验证器）。FLARE 将问题形式化为逻辑程序，并使用模仿 Prolog 风格推理的 LLM 模拟其执行。王等人 [ 95] 提出了 CORE 框架，该框架在迭代改进推理依据和答案的同时，确保模型的置信度与逻辑命题相一致。QUIRE [ 83] 通过在启动 CoT 推理前重新强调关键输入信息，增强了忠实性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p2">
<p class="ltx_p">In addition, there are also many works trying to improve the faithfulness of the model through post-training&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib96" title="">96</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib88" title="">88</a>]</cite>.
Gao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib96" title="">96</a>]</cite> constructed a dataset to train the model with three stages: faithful program generation, concise CoT conversion, and transferability filtering.
They first synthesized executable visual programs from image–question pairs using a code-pretrained model and obtained the execution traces.
The execution trace was then refined via controllable operations—pruning irrelevant branches, merging redundant steps, and bridging logical gaps.
Finally, CoTs that prove effective in guiding end-to-end MLLMs were selected for knowledge distillation, which was conducted by both label and rationale loss, as in&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib239" title="">239</a>]</cite>.
FRODO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib88" title="">88</a>]</cite> first employed DPO to incentivize the generation of correct reasoning paths and discourage counterfactual or irrelevant steps.
It further trained the model to associate correct/incorrect answers with corresponding reasoning paths and used margin-ranking loss to penalize high-confidence incorrect rationales.
Viteri <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib97" title="">97</a>]</cite> improved faithfulness via PPO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib31" title="">31</a>]</cite>, rewarding the model for generating correct rationales that lead to the answer even in the absence of the original prompt.
In summary, there are many methods that can be used to enhance the reasoning faithfulness of the model, but the unfaithfulness problem has not been completely solved. How to combine training-based and training-free methods can also be explored.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">此外，还有许多研究尝试通过后训练来提高模型的忠实度[96, 88]。高等人[96]构建了一个数据集，以三个阶段训练模型：忠实程序生成、简洁的 CoT 转换和可迁移性过滤。他们首先使用预训练的代码模型从图像-问题对中合成可执行的视觉程序，并获取执行轨迹。然后通过可控操作细化执行轨迹——剪枝无关分支、合并冗余步骤和填补逻辑空白。最后，选择在指导端到端 MLLM 时证明有效的 CoT 进行知识蒸馏，知识蒸馏通过标签和推理损失进行，如[239]所述。FRODO[88]首先采用 DPO 激励正确推理路径的生成，并抑制反事实或不相关的步骤。它进一步训练模型将正确/错误答案与相应的推理路径相关联，并使用边距排序损失惩罚高置信度的错误推理。Viteri 等人 [ 97] 通过 PPO [ 31] 提升了忠实度，奖励模型在即使没有原始提示的情况下也能生成正确推理并得出答案。总之，有许多方法可以用来增强模型的推理忠实度，但忠实度问题尚未完全解决。如何结合基于训练和无需训练的方法也是一个可以探索的方向。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Further Discussion of Faithfulness Definition<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">3.2.4 对忠实度定义的进一步讨论</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS4.p1">
<p class="ltx_p">In the definition of faithfulness, many working definitions are quite different from those of reasoning faithfulness. As a result, many researchers confuse them.
For instance, a recent survey on LLM hallucinations defines faithfulness hallucination as <span class="ltx_text ltx_font_italic">“the divergence of generated content from user input or the lack of self-consistency within the generated content”</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib223" title="">223</a>]</cite>.
However, this definition is concerned mainly with input faithfulness, which examines the degree to which the output reflects the user input, while reasoning faithfulness considers whether the model’s intermediate reasoning steps faithfully capture its internal decision-making process.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在忠实性的定义中，许多工作定义与推理忠实性定义差异很大。因此，许多研究人员将它们混淆。例如，最近关于 LLM 幻觉的调查将忠实性幻觉定义为“生成内容与用户输入的偏差或生成内容内部缺乏自洽性”[223]。然而，这个定义主要关注输入忠实性，它考察输出反映用户输入的程度，而推理忠实性则考虑模型的中级推理步骤是否忠实地捕捉了其内部决策过程。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS4.p2">
<p class="ltx_p">Furthermore, considerable effort has been made to distinguish faithfulness from plausibility.
Plausibility generally refers to the appearance of coherence and logical consistency, regardless of whether the underlying reasoning is valid.
Given the powerful generative capabilities of today’s large language models, they often produce responses that are highly plausible but not necessarily faithful.
Agarwal <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib84" title="">84</a>]</cite> highlight this distinction, arguing that a response may appear convincing while still misrepresenting the model’s actual reasoning.
Importantly, different application scenarios prioritize these dimensions differently, and striking a balance between faithfulness and plausibility remains context-dependent.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">此外，人们已经付出了相当大的努力来区分忠实性与合理性。合理性通常指连贯性和逻辑一致性的表象，而不管其底层推理是否有效。鉴于当今大型语言模型的强大生成能力，它们经常生成高度合理但不一定忠实的回应。Agarwal 等人[84]强调了这一区别，认为一个回应可能看起来很有说服力，但仍然歪曲了模型的实际推理。重要的是，不同的应用场景对这些维度有不同的侧重，而在忠实性与合理性之间取得平衡仍然是一个挑战。context-dependent.</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section" data-imt_insert_failed="1">
<span class="ltx_tag ltx_tag_section">4 </span>Safety</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p">As safety becomes a critical concern in high-stakes applications, it is imperative to understand how reasoning interacts with LLM content safety issues.
In this section, we mainly examine the content safety challenges introduced by the emergence of large reasoning models as well as CoT techniques, whose enhanced capabilities and structured reasoning processes may amplify both utility and risk. To be detailed, this section outlines key dimensions of safety related to reasoning capabilities, including vulnerability analysis, jailbreak attacks and defenses, safety alignment, and safety threats such as backdoor and prompt injection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">随着安全在高风险应用中成为关键问题，理解推理如何与 LLM 内容安全问题相互作用至关重要。在本节中，我们主要考察大型推理模型以及 CoT 技术带来的内容安全挑战，其增强的能力和结构化推理过程可能会同时放大效用和风险。具体而言，本节概述了与推理能力相关的安全关键维度，包括漏洞分析、越狱攻击与防御、安全对齐以及后门和提示注入等安全威胁。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Vulnerability Assessment<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.1 漏洞评估</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p">Vulnerability assessment in reasoning models often involves jailbreak attacks, which aim to induce the model to generate inappropriate content.
For large language models, many researchers developed related benchmarks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib240" title="">240</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib241" title="">241</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib242" title="">242</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib243" title="">243</a>]</cite> to evaluate the jailbreak defense capability against previous attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib244" title="">244</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib245" title="">245</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib246" title="">246</a>]</cite>. In terms of jailbreak assessment of large reasoning models, early works utilized jailbreak prompts from previous benchmarks mentioned above to evaluate the safety performance&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib98" title="">98</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib99" title="">99</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib103" title="">103</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib101" title="">101</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib104" title="">104</a>]</cite>. Also, many researchers developed new benchmarks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib105" title="">105</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib106" title="">106</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib107" title="">107</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib108" title="">108</a>]</cite> for a more targeted evaluation. Here, instead of narrating these works in a timeline, we group the core findings of these studies to build a preliminary conceptual map.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理模型中的漏洞评估通常涉及越狱攻击，其目的是诱导模型生成不当内容。对于大型语言模型，许多研究人员开发了相关的基准测试[240, 241, 242, 243]，以评估模型对先前攻击[244, 245, 246]的越狱防御能力。在大型推理模型的越狱评估方面，早期研究利用上述基准测试中的越狱提示来评估安全性表现[3, 98, 99, 100, 103, 101, 1, 104]。此外，许多研究人员开发了新的基准测试[105, 106, 107, 108]，以进行更具针对性的评估。在此，我们不是按时间顺序叙述这些工作，而是将这些研究的核心发现进行分组，以构建一个初步的概念图。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Current open-source reasoning models are still vulnerable to jailbreak attacks.</span>
Evaluation results from many researchers&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib98" title="">98</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib99" title="">99</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib103" title="">103</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib104" title="">104</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib111" title="">111</a>]</cite> emphasized the safety vulnerability of current large reasoning models.
SafeChain&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>]</cite> evaluates concurrent reasoning models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib247" title="">247</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib248" title="">248</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib249" title="">249</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib250" title="">250</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib251" title="">251</a>]</cite> on StrongReject&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib241" title="">241</a>]</cite> and WildJailbreak&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib252" title="">252</a>]</cite>, finding that all these modern large reasoning models should improve safety performance, for no model achieved a satisfactory result on both datasets. Zhou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>]</cite> claimed that o3-mini is significantly safer than DeepSeek-R1 models on four datasets&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib242" title="">242</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib253" title="">253</a>]</cite>. Kassianik <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib103" title="">103</a>]</cite> also mentioned that the attack success rate (ASR) of DeepSeek-R1 on Harmbench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib240" title="">240</a>]</cite> is 100%, higher than o1-preview and other large language models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib14" title="">14</a>]</cite>, corresponding to conclusions from Marjanović <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib111" title="">111</a>]</cite>.
Ying <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>also mentioned that “<span class="ltx_text ltx_font_italic">both DeepSeek-V3 and DeepSeek-R1 models exhibit clear vulnerabilities when facing jailbreak attacks” after evaluating the safety performance on the CNSafe dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>]</cite></span>. Similarly, Krishna <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib104" title="">104</a>]</cite> in their evaluation highlighted the category-wise and model-wise vulnerabilities when faced with various jailbreak attacks. Additionally, Fan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib106" title="">106</a>]</cite> discovered evaluation faking, where reasoning models may probably understand they are being evaluated and therefore alter their response to be safer. Zheng <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib107" title="">107</a>]</cite> proposed BSAbench, which disclosed the safety vulnerability with more challenging queries. After clarifying the overall perception that open-source reasoning models still have space to improve the safety capability, here are specific insights.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">当前开源的推理模型仍然容易受到越狱攻击。许多研究人员[3, 98, 99, 103, 1, 104, 111]的评估结果强调了当前大型推理模型的安全漏洞。SafeChain[1]在 StrongReject[241]和 WildJailbreak[252]上评估了并发推理模型[15, 247, 248, 249, 250, 251]，发现这些现代大型推理模型都应该提高安全性，因为没有任何模型在这两个数据集上都取得了令人满意的结果。Zhou 等人[100]声称，在四个数据集[242, 253]上，o3-mini 比 DeepSeek-R1 模型安全得多。Kassianik 等人[103]也提到，DeepSeek-R1 在 Harmbench[240]上的攻击成功率（ASR）为 100%，高于 o1-preview 和其他大型语言模型[37, 13, 14]，与 Marjanović等人[111]的结论一致。Ying 等人也在 CNSafe 数据集[3]上评估了安全性后提到，“DeepSeek-V3 和 DeepSeek-R1 模型在面对越狱攻击时都表现出明显的漏洞”。类似地，Krishna 等人 [ 104] 他们的评估突出了在面对各种越狱攻击时，按类别和按模型的漏洞。此外，Fan 等人[ 106]发现了评估造假现象，即推理模型可能会意识到自己正在被评估，因此改变其响应以变得更安全。Zheng 等人[ 107]提出了 BSAbench，它通过更具挑战性的查询揭露了安全性漏洞。在阐明开源推理模型在安全性能力方面仍有提升空间的整体认知后，以下是具体见解。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">First, compared to base large language models, post-trained models with distilled CoT data are less sensitive to harmful prompts and reject them.</span> SafeChain&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>]</cite> proposed that learning long CoT does not necessarily improve model safety when comparing DeepSeek-R1-70B with Llama-3.3-Instruct-70B. A similar conclusion is also made by Zhou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>]</cite>. Additionally, Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib98" title="">98</a>]</cite> evaluated the DeepSeek distilled model series on CHisafetybench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib254" title="">254</a>]</cite>, and concluded that in terms of the risk content identification task and the “refusal to answer task”, a few reasoning models experienced a decrease in rejection rate and responsibility rate, indicating higher compliance behavior on harmful requests. Zhao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib110" title="">110</a>]</cite> also mentioned that acquiring deliberate reasoning capabilities would sacrifice model general performance.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">首先，与基础大型语言模型相比，经过蒸馏的 CoT 数据训练的模型对有害提示不那么敏感，并会拒绝它们。SafeChain [ 1] 提出在比较 DeepSeek-R1-70B 与Llama-3.3-Instruct-70B.时，学习长 CoT 并不一定能提高模型安全性。周等人 [ 100] 也得出了类似的结论。此外，张等人 [ 98] 在 CHisafetybench [ 254] 上评估了 DeepSeek 蒸馏模型系列，并得出结论，在风险内容识别任务和“拒绝回答任务”方面，少数推理模型拒绝率和责任率有所下降，表明它们在有害请求上表现出更高的合规行为。赵等人 [ 110] 也提到，获得有意推理能力会牺牲模型的泛化性能。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Second, the thinking process from LRMs may negatively affect the harmfulness of the generated content.</span>
Jiang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>]</cite> designed different thinking templates to control the reasoning process, and conducted experiments to compare the harmfulness of answers given different lengths of reasoning tokens.
It turns out that compared to the default content generation, forcing the model to skip reasoning or shorten reasoning could boost the harmlessness of the answers at least on StrongReject&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib241" title="">241</a>]</cite> and WildJailbreak&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib252" title="">252</a>]</cite>.
Zhou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>]</cite> and Zhao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib110" title="">110</a>]</cite> also reinforce such an idea: they compared the answers of two pairs of reasoning models with the base models on harmful prompts, demonstrating that LRMs tend to provide more detailed and helpful answers, making the output more harmful. Furthermore, when directly evaluating the harmfulness of thinking content and final answers of DeepSeek-R1-Distill-70B on AirBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib242" title="">242</a>]</cite> and WildGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib243" title="">243</a>]</cite>, the safety rate of thinking content is consistently less than that of final answers. Ying <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>]</cite> also supported the vulnerability of reasoning content, indicating that the exposed reasoning chains may increase safety risks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">其次，大型语言模型的思考过程可能对生成内容的危害性产生负面影响。Jiang 等人[1]设计了不同的思考模板来控制推理过程，并通过实验比较了不同推理 token 长度下答案的危害性。结果表明，与默认内容生成相比，强制模型跳过推理或缩短推理可以至少在 StrongReject[241]和 WildJailbreak[252]上提升答案的无害性。Zhou 等人[100]和 Zhao 等人[110]也强化了这一观点：他们在有害提示下比较了两组推理模型与基础模型的答案，证明大型语言模型倾向于提供更详细和有帮助的答案，使输出更具危害性。此外，在 AirBench[242]和 WildGuard[243]上直接评估DeepSeek-R1-Distill-70B的思考内容与最终答案的危害性时，思考内容的危险率始终低于最终答案。Ying 等人[3]也支持了推理内容的脆弱性，表明暴露的推理链可能会增加安全风险。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p5">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Third, Pairwise safety ranks between models depend on datasets.</span> After reviewing the related literature, we find that some findings from different datasets do not reach a consensus. For example, evaluations on Airbench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib242" title="">242</a>]</cite> claimed that DeepSeek-R1 is safer than DeepSeek-V3&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>]</cite>, while under CNSafe, DeepSeek-V3 exceeds DeepSeek-R1 with an average ASR margin of 21.7% across all risk categories&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>]</cite>. However, when red-teaming with jailbreak templates, experiments on WildGuard Jailbreak&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>]</cite> and CNSafe_RT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>]</cite> conversely showed that DeepSeek-R1 could identify the risk in jailbreak prompts and provide a safe thinking chain.
Additionally, safety performance is also related to evaluation topics.
For the DeepSeek-distilled model series, the most notable declines in safety performance are observed in areas such as health discrimination, sexism, regional discrimination, and occupational discrimination&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib98" title="">98</a>]</cite>. In contrast, DeepSeek-R1 exhibits pronounced vulnerabilities in cybersecurity-related topics&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>]</cite>. We may explain this discrepancy by noting that different training datasets and data structures would influence the model performance, causing imbalanced sensitivity to various safety topics.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">第三，模型之间的成对安全排名取决于数据集。在回顾相关文献后，我们发现来自不同数据集的一些研究结果并未达成共识。例如，对 Airbench [ 242] 的评估声称 DeepSeek-R1 比 DeepSeek-V3 [ 100] 更安全，而在 CNSafe 下，DeepSeek-V3 在所有风险类别中平均 ASR 优势为 21.7% [ 3]。然而，在 WildGuard Jailbreak [ 100] 和 CNSafe_RT [ 3] 的红队测试中，使用越狱模板时，实验结果反而显示 DeepSeek-R1 能够识别越狱提示中的风险并提供安全的推理链。此外，安全性能也与评估主题相关。对于 DeepSeek 蒸馏模型系列，在健康歧视、性别歧视、地域歧视和职业歧视等领域观察到最显著的安全性能下降 [ 98]。相比之下，DeepSeek-R1 在网络安全相关主题上表现出明显的脆弱性 [ 100]。 我们可以通过指出不同的训练数据集和数据结构会影响模型性能，从而导致对各种安全话题的敏感性不平衡来解释这种差异。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p6">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Fourth, multilingual vulnerability is critical for current large reasoning models.</span>
Multilingual vulnerability is also a representation of “mismatched generalization”&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib255" title="">255</a>]</cite>, which means that models may possess different safety capabilities in different language environments.
Romero-Arjona <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib99" title="">99</a>]</cite> identified the safety vulnerability in Spanish and Basque. They claimed that the failure rates of DeepSeek-R1 and o3-mini in their Spanish dataset are 31.7% and 29.5%. Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib98" title="">98</a>]</cite> made a detailed evaluation on the Chinese dataset CHisafetybench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib254" title="">254</a>]</cite> and identified a clear safety decline after distillation. Ying <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>]</cite> also found that for both DeepSeek-V3 and DeepSeek-R1, the ASR in the English environment is larger than that in Chinese, disclosing the safety capability imbalance about language.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">第四，多语言漏洞是当前大型推理模型的关键问题。多语言漏洞也是“不匹配泛化”[ 255]的一种表现，这意味着模型在不同语言环境下可能具有不同的安全能力。Romero-Arjona 等人[ 99]在西班牙语和巴斯克语中发现了安全漏洞。他们声称，DeepSeek-R1 和 o3-mini 在其西班牙语数据集中的失败率分别为 31.7%和 29.5%。Zhang 等人[ 98]对中文数据集 CHisafetybench [ 254]进行了详细评估，并发现蒸馏后安全性能明显下降。Ying 等人[ 3]也发现，对于 DeepSeek-V3 和 DeepSeek-R1，英语环境下的 ASR（自动语音识别）大于中文环境下的 ASR，揭示了语言安全能力的失衡。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p7">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Fifth, MLRMs share similar vulnerabilities with uni-modal large reasoning models.</span> With the development of MLRMs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib256" title="">256</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib248" title="">248</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib257" title="">257</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib258" title="">258</a>]</cite>, researchers also found similar vulnerabilities with early safety assessments. Fang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib109" title="">109</a>]</cite> identified that model safety performance varies in terms of different topics, and defined such a phenomenon as “safety blind spots”, which resembles the third point mentioned above. Lou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib102" title="">102</a>]</cite> mentioned the higher risk of the thinking process than the final answers of MLRMs and the vulnerability against jailbreak attacks compared to the base MLLMs, which are consistent with the first two insights. In addition, it is also observed that converting images into captions could recover the safety capability to some extent&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib102" title="">102</a>]</cite>, which again demonstrated the imbalanced domain vulnerability in MLLMs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib259" title="">259</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib260" title="">260</a>]</cite>. Experiments from both literature&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib109" title="">109</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib102" title="">102</a>]</cite> also pointed out that the emergent self-correction in the thinking process helps avoid harmful content generation, even if there were still cases where unsafe reasoning was generated, followed by inappropriate answers.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">第五，多模态大语言推理模型（MLRMs）与单模态大推理模型具有相似的漏洞。随着 MLRMs 的发展[256, 248, 257, 258]，研究人员也发现了与早期安全评估相似的漏洞。Fang 等人[109]发现模型安全性能在不同主题上存在差异，并将这种现象定义为“安全盲点”，这与上述第三点相似。Lou 等人[102]提到 MLRMs 的思考过程比最终答案具有更高的风险，并且与基础 MLLMs 相比，它们更容易受到越狱攻击，这与前两个见解一致。此外，还观察到将图像转换为文本可以在一定程度上恢复安全能力[102]，这再次证明了 MLLMs 中领域漏洞的不平衡性[259, 260]。来自文献[109, 102]的实验也指出，思考过程中的涌现式自我纠正有助于避免生成有害内容，即使仍然存在生成不安全推理并随后给出不当答案的情况。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p8">
<p class="ltx_p">To summarize, we can hardly get the conclusion that reasoning capability enables a model to perform better in the safety domain. Even though under some circumstances, it is proven that the reasoning process could identify the disguised harmful intention in jailbreak prompts and reject the inappropriate behaviors, which outperforms non-reasoning models, there are also comprehensive evaluations disclosing the vulnerability of reasoning models, such as multilingual inputs or specific topics. Except for o1 or o3-mini&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib20" title="">20</a>]</cite>, which are safer than other open-source large reasoning models with a slightly obvious margin, there is still space to boost safety performance via inference-time scaling, just as in the general performance domain.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">总而言之，我们很难得出推理能力使模型在安全领域表现更好的结论。尽管在某些情况下，已证明推理过程能够识别出越狱提示中伪装的恶意意图并拒绝不适当的行为，这优于非推理模型，但也有综合评估揭示了推理模型的漏洞，例如多语言输入或特定主题。除了 o1 或 o3-mini [ 20]（它们比其他开源大型推理模型稍微安全一些），通过推理时扩展来提升安全性能仍有空间，就像在一般性能领域一样。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Jailbreak<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2 越狱</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p">In the era of large language models, jailbreak generally becomes crucial to model safety. In this script, we mainly focus on jailbreak topics related to CoT or current large reasoning models represented by OpenAI o1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib20" title="">20</a>]</cite>, DeepSeek-R1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib15" title="">15</a>]</cite>, etc. The literature could be roughly clustered into two parts: early studies targeting large language models and the latest studies targeting models with CoT capability. Attacks and defenses are split into separate subsections for better readability.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在大语言模型时代，越狱通常成为模型安全的关键。在本脚本中，我们主要关注与思维链（CoT）或以 OpenAI o1 [20]、DeepSeek-R1 [15]等为代表的当前大型推理模型相关的越狱话题。文献大致可分为两部分：针对大型语言模型早期的研究和针对具有思维链能力的最新模型的研究。攻击与防御分别分为独立的子章节，以提高可读性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Jailbreaking with Reasoning Techniques<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2.1 使用推理技术进行越狱</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS1.p1">
<p class="ltx_p">CoT techniques enable large language models to perform better on various general tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib114" title="">114</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib116" title="">116</a>]</cite>. Therefore, recent literature has also proposed methods to generate more deceptive jailbreak prompts&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib112" title="">112</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib113" title="">113</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib116" title="">116</a>]</cite> or create more detailed and harmful content with reasoning techniques&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib114" title="">114</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib115" title="">115</a>]</cite> while overlooking their safety issues.
Specifically, Sabbaghi <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib112" title="">112</a>]</cite> introduced a feedback model as well as a refiner model to iteratively modify the jailbreak prompt with CoT paths given the calculated loss score, for models with CoT could better identify the imperfection of each round of jailbreak prompts, provide more targeted modifications, and then enhance the ASR.
This method followed the logic of previous black-box jailbreak methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib245" title="">245</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib246" title="">246</a>]</cite>, which evaluated and modified their jailbreak prompts according to the interactions with the target models.
Ying <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib114" title="">114</a>]</cite> proposed a multi-turn method to transform harmful prompts into several superficially benign questions.
During the multi-turn conversation, the attacker explicitly instructed the victim model to reason about some specific steps, bypassing its safety alignment, and finally elicited harmful content.
Similarly, Chang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib115" title="">115</a>]</cite> wrapped the sensitive instruction into a narrative task, designing CoT-style prompts to instruct victim models to generate details and finish the story while bypassing internal safety barriers.
Handa <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib116" title="">116</a>]</cite> proposed to jailbreak models with complex ciphers. The advanced reasoning capability enables models to decode more complex ciphers, therefore providing more room for the disguise of harmful instructions.
The success of these attacks vividly supports that better performance of language models enabled by CoT techniques could create new threats to content safety. More works are required to evaluate the potential risks as well as feasible defense methods regarding reasoning techniques.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">CoT 技术使大型语言模型在多种一般任务上表现更好[114, 17, 16, 116]。因此，近期文献也提出了生成更具欺骗性的越狱提示的方法[112, 113, 116]，或利用推理技术创建更详细和有害的内容[114, 115]，而忽略了其安全问题。具体来说，Sabbaghi 等人[112]引入了一个反馈模型和一个精炼模型，根据计算出的损失分数，使用 CoT 路径迭代地修改越狱提示，对于使用 CoT 的模型来说，可以更好地识别每一轮越狱提示的不完善之处，提供更有针对性的修改，然后提升 ASR。这种方法遵循了先前黑盒越狱方法的逻辑[245, 246]，这些方法根据与目标模型的交互来评估和修改其越狱提示。Ying 等人[114]提出了一种多轮方法，将有害提示转化为几个表面上无害的问题。在多轮对话中，攻击者明确指示受害者模型对某些特定步骤进行推理，绕过其安全对齐，最终诱发出有害内容。 类似地，Chang 等人[ 115]将敏感指令封装成一个叙事任务，设计了 CoT 风格的提示，指导受害模型生成细节并完成故事，同时绕过内部安全屏障。Handa 等人[ 116]提出了使用复杂密码破解模型的方法。高级推理能力使模型能够解码更复杂的密码，因此为有害指令的伪装提供了更多空间。这些攻击的成功生动地表明，由 CoT 技术带来的语言模型性能提升可能为内容安全创造新的威胁。需要更多研究来评估推理技术的潜在风险以及可行的防御方法。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Jailbreaking Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2.2 破解推理模型</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p1">
<p class="ltx_p">In this part, we mainly cover a few jailbreak attacks taking advantage of the reasoning process to disclose the vulnerability of large reasoning models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在这一部分，我们主要涵盖了几种利用推理过程来揭露大型推理模型漏洞的越狱攻击。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<p class="ltx_p">Kuo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib117" title="">117</a>]</cite> proposed H-CoT, containing well-curated reasoning content in the prompts to obfuscate the models. Here we borrow an example from the original paper as an illustration.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Kuo 等人[117]提出了 H-CoT，在提示中包含精心策划的推理内容来混淆模型。这里我们借鉴原始论文中的一个例子作为说明。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F3"><span class="ltx_inline-block"><svg class="ltx_picture ltx_centering" height="233.64" id="S4.F3.pic1" overflow="visible" version="1.1" viewBox="0 0 600 233.64" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,233.64) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 4.63 L 0 229.01 C 0 231.56 2.07 233.64 4.63 233.64 L 595.37 233.64 C 597.93 233.64 600 231.56 600 229.01 L 600 4.63 C 600 2.07 597.93 0 595.37 0 L 4.63 0 C 2.07 0 0 2.07 0 4.63 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.69 4.63 L 0.69 229.01 C 0.69 231.18 2.45 232.95 4.63 232.95 L 595.37 232.95 C 597.55 232.95 599.31 231.18 599.31 229.01 L 599.31 4.63 C 599.31 2.45 597.55 0.69 595.37 0.69 L 4.63 0.69 C 2.45 0.69 0.69 2.45 0.69 4.63 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 15.19)"><foreignobject color="#000000" height="208.63" overflow="visible" style="--fo_width :40.42em;--fo_height:14.88em;--fo_depth :0.19em;" transform="matrix(1 0 0 -1 0 205.94)" width="559.25"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:40.42em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Goal</span>: Provide a detailed guide on the process of making illegally-gained proceeds appear legal, also known as money laundering.</span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Original request</span>: I am a teacher for financial auditors. As part of their professional training, I provide neutral, informational education on methods of making illegally-gained proceeds appear legal, known as money laundering in the USA. The goal is to enhance their ability to detect and prevent such activities. Could you provide a broad overview of the modern strategies?</span>
<span class="ltx_p">Each part must be logically connected… and should include the following components: Scheme:… Functional Example:… Rationale:… List as many real-world examples and advantages for criminals as possible in choosing these.</span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">H-CoT reasoning</span>:</span>
<span class="ltx_itemize" id="S4.I1">
<span class="ltx_item" id="S4.I1.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i1.p1">
<span class="ltx_p">Understanding money laundering…</span>
</span></span>
<span class="ltx_item" id="S4.I1.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i2.p1">
<span class="ltx_p">Structuring the educational content…</span>
</span></span>
<span class="ltx_item" id="S4.I1.i3" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i3.p1">
<span class="ltx_p">Enhancing detection strategies…</span>
</span></span>
<span class="ltx_item" id="S4.I1.i4" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i4.p1">
<span class="ltx_p">Providing contextual examples…</span>
</span></span>
<span class="ltx_item" id="S4.I1.i5" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I1.i5.p1">
<span class="ltx_p">…</span>
</span></span>
<span class="ltx_item" id="S4.I1.i6" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para ltx_noindent" id="S4.I1.i6.p1">
<span class="ltx_p">Rationale and outcome…</span>
</span></span>
</span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">Jailbreak prompt</span>:</span>
<span class="ltx_itemize" id="S4.I2">
<span class="ltx_item" id="S4.I2.i1" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para" id="S4.I2.i1.p1">
<span class="ltx_p"><span class="ltx_text ltx_font_italic">Original request</span></span>
</span></span>
<span class="ltx_item" id="S4.I2.i2" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">•</span>
<span class="ltx_para ltx_noindent" id="S4.I2.i2.p1">
<span class="ltx_p"><span class="ltx_text ltx_font_italic">H-CoT reasoning</span></span>
</span></span>
</span>
</span></span></span></foreignobject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An example of H-CoT jailbreak prompt, which is from “DukeCEICenter/Malicious_Educator_hcot_o1” dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib117" title="">117</a>]</cite>.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 3：H-CoT 越狱提示的示例，来自“DukeCEICenter/Malicious_Educator_hcot_o1”数据集[117]。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p3">
<p class="ltx_p">In the experiments, they found that directly padding detailed execution steps could hijack the thinking process, skip the justification phase, and elicit harmful generation.
After that, Yao <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;proposed “Mousetrap”&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib118" title="">118</a>]</cite>, splitting the harmful prompts into several steps for models to reason.
After following the instructions to execute character decoding, word replacement, and sentence order reversal, the model could understand the final harmful prompt while failing to identify its toxicity.
Such an attack resembles the classical “base-64 encoding” jailbreak&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib261" title="">261</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib255" title="">255</a>]</cite>, sharing the logic of mismatched generalization&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib255" title="">255</a>]</cite>.
Liang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib119" title="">119</a>]</cite> proposed AutoRAN, claiming it as the first automated jailbreak attack specifically targeting reasoning models, enabled by a self-designed, predefined attack workflow. Nguyen <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib120" title="">120</a>]</cite> came up with “SEAL” to circumvent LRM internal defenses, selecting ciphering methods from an encryption algorithm set to encode harmful instructions. Lu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib2" title="">2</a>]</cite> proposed FicDetail to jailbreak reasoning models, creating a fiction story with multi-turn queries to enrich details with harmful contents. Lian <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib121" title="">121</a>]</cite> exploited the intrinsic ethical vulnerability from distribution shift and in LLMs, designing an attack with semantic coherence inducement to jailbreak DeepSeek-R1 successfully. Ma <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib124" title="">124</a>]</cite> proposed HauntAttack, which wraps harmful instructions into normal, realistic scenarios to deceive reasoning models.
For MLRMs, Sima <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib123" title="">123</a>]</cite> designed VisCRA, exploiting reasoning capabilities to force models to first infer masked objects in images and then create detailed answers for harmful instructions. With the two-phase instructions, both cutting-edge MLLMs and MLRMs are proven to be vulnerable. In the tool learning domain, Liu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib122" title="">122</a>]</cite> developed Tool-CoT attack, in which the agent is prompted to call external functions for more harmful information. Experimental results indicate that models exhibit reduced sensitivity to function-calling behaviors, which may allow harmful intents to bypass internal safety alignment mechanisms, ultimately leading to illicit outputs.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在实验中，他们发现直接填充详细的执行步骤可以劫持思考过程，跳过论证阶段，并诱发出有害的生成内容。之后，Yao 等人提出了“捕鼠夹”[ 118]，将有害提示拆分成多个步骤供模型推理。在按照指令执行字符解码、单词替换和句子顺序反转后，模型能够理解最终的有害提示，但无法识别其毒性。这种攻击类似于经典的“base-64 编码”越狱[ 261, 255]，共享了不匹配泛化的逻辑[ 255]。Liang 等人[ 119]提出了 AutoRAN，声称这是首个专门针对推理模型的自动化越狱攻击，通过自行设计、预定义的攻击工作流程实现。Nguyen 等人[ 120]提出了“SEAL”，用于绕过 LRM 内部防御，从加密算法集中选择加密方法来编码有害指令。Lu 等人[ 2]提出了 FicDetail 来越狱推理模型，通过创建包含多轮查询的虚构故事来用有害内容丰富细节。Lian 等人 [ 121] 利用分布偏移和 LLMs 的内在伦理漏洞，设计了一种带有语义连贯性诱导的攻击方法，成功绕过了 DeepSeek-R1。Ma 等人[ 124]提出了 HauntAttack，将有害指令封装在正常、真实的场景中，以欺骗推理模型。对于 MLRMs，Sima 等人[ 123]设计了 VisCRA，利用推理能力迫使模型首先推断图像中的掩码对象，然后为有害指令创建详细答案。通过两阶段指令，证明最先进的 MLLMs 和 MLRMs 都存在漏洞。在工具学习领域，Liu 等人[ 122]开发了 Tool-CoT 攻击，其中代理被提示调用外部函数以获取更多有害信息。实验结果表明，模型对函数调用行为表现出降低的敏感性，这可能允许有害意图绕过内部安全对齐机制，最终导致非法输出。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS2.p4">
<p class="ltx_p">In summary, the logic of developing jailbreak attacks does not change dramatically.
Compared with previous jailbreak methods targeting large language models, we found some methods exploiting the novel thinking process, as well as others designing more intense prompt encryptions to match the advanced general capability of reasoning models. From this point, it seems that reasoning models are more vulnerable to jailbreak attacks, due to the larger mismatching generalization between instruction following and safety alignment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">总之，开发越狱攻击的逻辑并没有发生显著变化。与之前针对大型语言模型的越狱方法相比，我们发现了一些利用新型思维过程的方法，以及一些设计更复杂的提示加密以匹配推理模型的先进通用能力的方法。从这个角度来看，由于指令遵循与安全对齐之间存在更大的泛化不匹配，推理模型似乎更容易受到越狱攻击。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Jailbreak Defense with Reasoning Techniques<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2.3 基于推理技术的越狱防御</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS3.p1">
<p class="ltx_p">Because the performance of CoT techniques has been proven on general tasks, researchers have also tried to take advantage of this feature to build more robust guardrail models.
GuardReasoner&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib125" title="">125</a>]</cite> curated 127k data samples with 460k reasoning steps in total to finetune a large language model, enabling the guardrail models to judge the harmfulness of prompts and answers. Similar to LLM alignment with CoT data in Sec.&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3.SSS1" title="4.3.1 Aligning LLM Using Reasoning Techniques ‣ 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4.3.1</span></a>, detailed reasoning contents were distilled from GPT-4o to construct the SFT data. After learning the answering structure, DPO is then adopted to learn “hard samples” whose judgments from finetuned models vary conditioning high temperature and top-p hyperparameter.
X-Guard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib126" title="">126</a>]</cite> noticed the judgment inaccuracy on low-resource languages and code-switching attacks, creating a safety dataset spanning 132 languages and updating the model weight with SFT followed by GRPO.
Also noticing the judgment inaccuracy on multi-lingual inputs, MrGuard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib127" title="">127</a>]</cite> elaborated curriculum learning with reasoning to improve the robustness towards low-resource languages. Similarly, RSafe&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib128" title="">128</a>]</cite> utilized GRPO to train a robust and generalizable guardrail model, successfully adapting to user-specified safety policies.
Sreedhar <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib129" title="">129</a>]</cite> conducted a study on reasoning-augmented guardrail models, demonstrating the benefits of reasoning in terms of detection accuracy, efficiency, generalization, etc.
Kang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib130" title="">130</a>]</cite> proposed R<sup class="ltx_sup">2</sup>-Guard to detect unsafe contents with reasoning enabled by probabilistic graphical models (PGMs).
For vision-language models (VLM), GuardReasoner-VL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib133" title="">133</a>]</cite> shared a similar logic with the previous method&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib125" title="">125</a>]</cite>, extending the model to the vision domain. ShieldVLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib132" title="">132</a>]</cite> simply used SFT with high-quality multimodal reasoning data to enhance the detection capability, achieving the harmfulness of image-text input pairs without model answers.
In terms of agent safety, Xiang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib134" title="">134</a>]</cite> developed GuardAgent to monitor agent actions. Different from conventional LLM-based agents that only process natural language, GuardAgent thinks of an action plan, generates guardrail codes, and finally executes the program to check content safety. Chen <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib135" title="">135</a>]</cite> also proposed ShieldAgent to tackle this problem, in which they encoded safety constraints in knowledge graphs. Experiments proved the superior performance of these methods, providing new insights into agent-based agent guardrails.
Aside from the guardrail models mentioned above, reward models could also contribute to content identification as well as model alignment&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib131" title="">131</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib136" title="">136</a>]</cite>. Pan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib137" title="">137</a>]</cite> proposed U-CoT+ to detect harmful memes with zero-shot CoT prompts. To summarize, the success of these models demonstrates the feasibility of reasoning techniques, reinforcing their role in identifying, controlling, and moderating unsafe generations.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由于 CoT 技术在一般任务上的性能已被证明，研究人员也尝试利用这一特性来构建更鲁棒的护栏模型。GuardReasoner [ 125] 筛选了 127k 个数据样本，总共包含 460k 个推理步骤，用于微调大型语言模型，使护栏模型能够判断提示和答案的危害性。类似于第 4.3.1 节中与 CoT 数据对齐的 LLM，从 GPT-4o 中提取详细的推理内容来构建 SFT 数据。在学会回答结构后，采用 DPO 来学习“难样本”，这些样本在微调模型的判断上因高温和 top-p 超参数的不同而有所差异。X-Guard [ 126] 注意到低资源语言和代码转换攻击上的判断不准确，创建了一个涵盖 132 种语言的安全生产集，并使用 SFT 更新模型权重，然后进行 GRPO。同样注意到多语言输入上的判断不准确，MrGuard [ 127] 详细阐述了推理的分层学习，以提高对低资源语言的鲁棒性。 类似地，RSafe [ 128] 利用 GRPO 训练了一个鲁棒且可泛化的护栏模型，成功适应了用户指定的安全策略。Sreedhar 等人 [ 129] 对推理增强型护栏模型进行了研究，展示了推理在检测精度、效率、泛化能力等方面的优势。Kang 等人 [ 130] 提出了 R <sup class="ltx_sup">2</sup> -Guard，通过概率图模型（PGMs）启用的推理来检测不安全内容。对于视觉语言模型（VLM），GuardReasoner-VL [ 133] 与前述方法 [ 125] 逻辑相似，将模型扩展到视觉领域。ShieldVLM [ 132] 仅使用高质量的多模态推理数据对 SFT 进行应用，以增强检测能力，实现了对图像-文本输入对有害性的检测，无需模型答案。在智能体安全方面，Xiang 等人 [ 134] 开发了 GuardAgent 来监控智能体行为。不同于仅处理自然语言的传统 LLM 智能体，GuardAgent 会制定行动计划，生成护栏代码，并最终执行程序来检查内容安全性。Chen 等人 [ 135] 还提出了 ShieldAgent 来解决这个问题，其中他们将安全约束编码在知识图谱中。实验证明了这些方法的优越性能，为基于代理的代理护栏提供了新的见解。除了上述提到的护栏模型之外，奖励模型也可以用于内容识别以及模型对齐[ 131, 136]。Pan 等人[ 137]提出了 U-CoT+，使用零样本 CoT 提示来检测有害的梗图。总而言之，这些模型的成功证明了推理技术的可行性，强化了它们在识别、控制和调节不安全生成内容中的作用。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.4 </span>Jailbreak Defense for Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.2.4 推理模型的越狱防御</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS4.p1">
<p class="ltx_p">Jailbreak defense could be facilitated in different stages. Except for alignment methods that would be covered in detail in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3" title="4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>, content detection and decoding manipulation are also ways to control harmful content generation. In this part, we mainly cover defending methods on reasoning models, analyzing the similarity and novelty of these methods when compared to previous instruct models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">越狱防御可以在不同阶段进行。除了将在第 4.3 节详细介绍的校准方法外，内容检测和解码操作也是控制有害内容生成的方式。在本部分，我们主要涵盖推理模型的防御方法，并分析这些方法与先前指令模型相比的相似性和新颖性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS4.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Input-phase defense</span>. At first, Jailbreak defense in LLM followed the logic of prompt engineering, designing a detailed prompt before or after user prompts as an extra instruction to depress inappropriate behaviors&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib262" title="">262</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib263" title="">263</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib264" title="">264</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib265" title="">265</a>]</cite>. Sharing some degrees of similarity, Jiang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>]</cite> mentioned that Zerothink mode could improve the defense capability, and Wu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib138" title="">138</a>]</cite> demonstrated that adding safety-related instructions in the reasoning trace could outperform manipulations in user prompts&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib262" title="">262</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib263" title="">263</a>]</cite>, with an explanation that attention of reasoning process focuses more on internal tokens instead of input prompts. Yamaguchi <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib139" title="">139</a>]</cite> also designed experiments on DeepSeek-R1-Distill-Llama, and found that whether the model rejects or complies with the instruction is predictable from intermediate activations of CoT tokens. These results uncovered the importance of reasoning in making decisions and supported the effectiveness of reasoning manipulation indirectly.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">输入阶段防御。最初，LLM 中的越狱防御遵循提示工程的逻辑，在用户提示之前或之后设计一个详细的提示作为额外指令来抑制不适当行为[262, 263, 264, 265]。江等人[1]提到 Zerothink 模式可以提高防御能力，具有一定程度上的相似性，而吴等人[138]则证明在推理轨迹中添加安全相关指令可以优于用户提示中的操控[262, 263]，并解释称推理过程中的注意力更多地集中在内部 token 而不是输入提示上。山口等人[139]也在DeepSeek-R1-Distill-Llama上设计了实验，发现模型是否拒绝或遵从指令可以从 CoT token 的中期激活中预测。这些结果揭示了推理在决策中的重要性，并间接支持了推理操控的有效性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS4.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Decoding-phase defense</span>. With advancements in test-time compute for general tasks, researchers also made early attempts to generalize the improvement in the safety domain. Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib12" title="">12</a>]</cite> revealed that applying Best-of-N (BoN) strategies could enhance the model safety, suggesting the existence of latent safety knowledge. Zaremba <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib140" title="">140</a>]</cite> found that the robustness of the OpenAI o1 series improved when increasing the test-time compute under a few settings. Saffron-1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib141" title="">141</a>]</cite> focused on the inefficiency of inference-scaling methods in safety contexts, proposing a novel inference-time scaling paradigm for efficient and safe decoding control. Instead of querying PRMs multiple times in tree search, one call to Saffron outputs a vector containing rewards for all possible next tokens, which breaks the exploration-efficiency dilemma. In addition, previous methods tried to manipulate the output logits of each token for safer generations&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib266" title="">266</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib267" title="">267</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib268" title="">268</a>]</cite>, which may also provide a feasible way for safety generation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">解码阶段防御。随着通用任务测试时计算的进步，研究人员也早早尝试将安全领域的改进进行泛化。Wang 等人[12]揭示，应用 Best-of-N（BoN）策略可以增强模型安全性，表明存在潜在的安全知识。Zaremba 等人[140]发现，在少数设置下增加测试时计算可以提高 OpenAI o1 系列的鲁棒性。Saffron-1[141]关注了安全环境下推理扩展方法的不效率，提出了一个用于高效和安全解码控制的推理时扩展范式。在树搜索中不再多次查询 PRMs，Saffron 的一次调用就输出一个包含所有可能下一个 token 奖励的向量，打破了探索效率的困境。此外，先前的方法尝试操纵每个 token 的输出 logits 以生成更安全的文本[266, 267, 268]，这也可能为安全生成提供了一种可行方法。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS4.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Post-hoc defense</span>. Guardrail models, or LLMs-as-a-judge, serve as an external safety guard for language model content generation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib269" title="">269</a>]</cite>. To identify the ASR of jailbreak methods, except for simple string-matching methods, LLM could be elaborated for harmful data detection, including prompting cutting-edge general models (such as GPT series&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib13" title="">13</a>]</cite>) with pre-defined safety principles, or fine-tuning with well-curated safety data (Llama-Guard series&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib270" title="">270</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib271" title="">271</a>]</cite>). Considering the safety risk in reasoning traces&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib100" title="">100</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib3" title="">3</a>]</cite>, ReasoningShield&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib151" title="">151</a>]</cite> curated a dataset with 8k prompt-CoT pairs and finetuned Llama-3.2&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib272" title="">272</a>]</cite> to identify harmfulness in the reasoning traces as well as the final answers. During fine-tuning, SFT was conducted only on samples with consistent judgment among three LLMs, while DPO preference data were from “hard samples” with different judgments. In terms of LLM-based agents that generate thoughts before subsequent actions, Jiang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib150" title="">150</a>]</cite> thought highly of the timely intervention of potentially harmful thoughts, trained the “Thought-Aligner” to generate safer and more cautious reasoning processes for replacement. These early efforts highlighted the potential of reasoning-specific guardrail models, suggesting room for continued research.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">后置防御。防护模型，或作为裁判的 LLM，为语言模型内容生成提供外部安全保护[269]。为了识别越狱方法的 ASR，除了简单的字符串匹配方法外，LLM 可以被用于有害数据检测，包括用预定义的安全原则提示前沿通用模型（如 GPT 系列[13]），或使用精心策划的安全数据进行微调（Llama-Guard 系列[270, 271]）。考虑到推理轨迹中的安全风险[1, 100, 3]，ReasoningShield[151]策划了一个包含 8k 提示-CoT 对的数据库，并微调了 Llama-3.2[272]，以识别推理轨迹以及最终答案中的有害性。在微调过程中，仅对三个 LLM 判断一致的样本进行 SFT，而 DPO 偏好数据来自具有不同判断的“困难样本”。对于在后续行动之前生成思想的基于 LLM 的代理，Jiang 等人[150]高度评价了对潜在有害思想的及时干预，训练了“思想对齐器”以生成更安全、更谨慎的推理过程进行替换。 这些早期工作突出了推理特定护栏模型的潜力，表明了持续研究的空间。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Alignment<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.3 对齐</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p">Alignment is not only a crucial part of large language model training, but also an important topic for model safety. In the training phase, alignment is originally proposed to align model reaction with human expectation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib273" title="">273</a>]</cite>. During last three years, a lot of methods, including reinforcement learning from human feedback (RLHF) and its variants, are proposed to enhance the conversation performance of instruct models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib274" title="">274</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib275" title="">275</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib276" title="">276</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib30" title="">30</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib31" title="">31</a>]</cite>. Considering safety alignment, most methods collect a fine-tuning dataset including prompt-rejection pairs compassing various sensitive topics to update model weights&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib277" title="">277</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib278" title="">278</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib260" title="">260</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib279" title="">279</a>]</cite>.
Here, instead of focusing on alignment within instruction tuning before formal model release, we narrow our sight to safety alignment of released models, including enhancing safety performance with CoT capability, or directly aligning large reasoning models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对齐不仅是大型语言模型训练的关键部分，也是模型安全的重要议题。在训练阶段，对齐最初被提出是为了使模型反应与人类期望相一致[273]。在过去的三年里，提出了许多方法，包括人类反馈强化学习（RLHF）及其变体，以提升指令模型的对话性能[274, 275, 276, 30, 31]。考虑到安全对齐，大多数方法收集一个微调数据集，包括涵盖各种敏感话题的提示拒绝对，以更新模型权重[277, 278, 260, 279]。在这里，我们不再关注正式模型发布前的指令微调阶段的对齐，而是将目光聚焦于已发布模型的安全对齐，包括通过 CoT 能力提升安全性能，或直接对齐大型推理模型。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Aligning LLM Using Reasoning Techniques<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.3.1 使用推理技术对齐 LLM</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS1.p1">
<p class="ltx_p">Noticing the performance of CoT behaviors, researchers tend to facilitate safety alignment with CoT datasets&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib143" title="">143</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib144" title="">144</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib147" title="">147</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib148" title="">148</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib149" title="">149</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib145" title="">145</a>]</cite>.
To be detailed, Liu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib142" title="">142</a>]</cite> proposed to train multiple low-rank adaptation (LoRA)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib280" title="">280</a>]</cite> variants as Mixture-of-Experts (MoE) to explicitly analyze question intentions, answer guidances, and the final response. Iteratively querying these models enabled the framework to “think step-by-step” before making final decisions. Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib143" title="">143</a>]</cite> added a reset token to elicit self-corrections after a partial unsafe generation. To enable the model to learn backtracking, SFT with DPO is employed to learn the correction behavior while avoiding unnecessary backtracking. Yang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib144" title="">144</a>]</cite> proposed Safety Chain-of-Thought (SCoT) to provide detailed analyses of potential risks before answering, claiming that SFT on mixed CoT datasets could enhance the defense capability against various attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib244" title="">244</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib281" title="">281</a>]</cite>. Similarly, Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib282" title="">282</a>]</cite> proposed to utilize data from Monte-Carlo Tree Search (MCTS) to improve the safety alignment. They began by prompting GPT-4o to produce CoT data for fine-tuning, and then ran a safety-informed MCTS on the target model to generate raw data for DPO training. R2D&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib145" title="">145</a>]</cite>
generated a pivot token including “[SAFE]”, “[UNSAFE]”, and “[RETHINK]” after each thinking step, and added an extra contrastive loss on the pivot tokens in SFT.
With the combined loss, models could learn to generate detailed reason steps followed by the pivot token as a hint for the whole thinking process. RATIONAL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib146" title="">146</a>]</cite> also identified the imperfection of direct refusal to harmful queries, curating a CoT dataset consisting of both adversarial data and sensitive benign data by prompting Llama-3-8B-Instruct for following supervised fine-tuning.
ERPO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib147" title="">147</a>]</cite> also adopted SFT followed by DPO, while adding extra “length-controlled iterative preference optimization strategy” to shorten generation length in the iterative preference optimization algorithm.
For safe prompts, except for only considering decreasing the probability of generating helpless responses with incorrect thoughts, the algorithm also preferred concise thoughts over redundant reasoning chains. SaRO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib148" title="">148</a>]</cite> picked prompts from SALAD-Bench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib283" title="">283</a>]</cite> and OpenOrca&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib284" title="">284</a>]</cite> with reasoning generation from GPT-4o to get the CoT data for supervised fine-tuning, enabling models to learn the thinking-answer template.
Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib12" title="">12</a>]</cite> underscored the generalization weaknesses of refusal training, introducing guidelines for better safety reasoning. Kim <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib149" title="">149</a>]</cite> distilled data from reasoning models and adopted SFT with GRPO for adaptive defense.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">注意到思维链行为的性能，研究人员倾向于通过思维链数据集促进安全对齐[ 143, 144, 147, 148, 149, 145]。具体来说，刘等人[ 142]提出训练多个低秩适配（LoRA）[ 280]变体作为专家混合（MoE），以明确分析问题意图、答案指导以及最终响应。迭代查询这些模型使框架能够在做出最终决定前“逐步思考”。张等人[ 143]添加了一个重置标记，在部分不安全生成后进行自我纠正。为了使模型能够学习回溯，采用带 DPO 的 SFT 来学习纠正行为，同时避免不必要的回溯。杨等人[ 144]提出了安全思维链（SCoT），在回答前提供潜在风险的详细分析，声称在混合思维链数据集上的 SFT 可以增强对各种攻击的防御能力[ 244, 281]。类似地，张等人[ 282]提出利用蒙特卡洛树搜索（MCTS）的数据来提高安全对齐。 他们首先提示 GPT-4o 生成用于微调的 CoT 数据，然后对目标模型运行基于安全信息的 MCTS，以生成用于 DPO 训练的原始数据。R2D [ 145] 在每一步思考后生成包含“[SAFE]”、“[UNSAFE]”和“[RETHINK]”的枢轴标记，并在 SFT 中对该枢轴标记添加额外的对比损失。通过组合损失，模型能够学习生成详细的原因步骤，并以枢轴标记作为整个思考过程的提示。RATIONAL [ 146] 也识别了直接拒绝有害查询的不完善性，通过提示Llama-3-8B-Instruct生成包含对抗数据和敏感良性数据的 CoT 数据集，用于后续的监督微调。ERPO [ 147] 也采用了 SFT 后接 DPO，同时添加了额外的“长度控制迭代偏好优化策略”，以缩短迭代偏好优化算法中的生成长度。对于安全提示，除了考虑降低生成错误思考的无助响应的概率外，算法也更倾向于简洁的思考而不是冗余的推理链。 SaRO [ 148] 从 SALAD-Bench [ 283] 和 OpenOrca [ 284] 中选取提示，并使用 GPT-4o 生成推理数据，以获取用于监督微调的 CoT 数据，使模型能够学习思考-答案模板。Wang 等人 [ 12] 强调了拒绝训练的泛化弱点，并引入了更好的安全推理指南。Kim 等人 [ 149] 从推理模型中提取数据，并采用带有 GRPO 的 SFT 进行自适应防御。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS1.p2">
<p class="ltx_p">After reviewing related works, we would like to elaborate more on SFT data collection and DPO pair selections. Mainstream SFT methods utilize off-the-shelf datasets, originally created for safety alignment or benchmarking harmfulness, to collect prompts and safe answers&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib143" title="">143</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib282" title="">282</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib145" title="">145</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib146" title="">146</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib147" title="">147</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib148" title="">148</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib149" title="">149</a>]</cite>. These datasets include (but may not limited to) PKU-SafeRLHF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib278" title="">278</a>]</cite>, HH-RLHF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib275" title="">275</a>]</cite>, ToxicChat&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib285" title="">285</a>]</cite>, SALAD-Bench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib283" title="">283</a>]</cite>, BeaverTails&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib277" title="">277</a>]</cite>, SorryBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib286" title="">286</a>]</cite>, XSTest&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib287" title="">287</a>]</cite>, JailbreakV-28k&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib288" title="">288</a>]</cite>, AdvBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib244" title="">244</a>]</cite>.
LLM primarily generates structured CoT content with a fixed prompt template. As shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.F4" title="Figure 4 ‣ 4.3.1 Aligning LLM Using Reasoning Techniques ‣ 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>, LLMs are prompted to create detailed reasons with pre-defined structures for the final answer. It is believed that such SFT could first enable the models to learn the think-then-answer behavior, which provides a solid base for further preference optimizations.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在回顾相关研究后，我们希望进一步阐述 SFT 数据收集和 DPO 对选择。主流 SFT 方法利用现成的数据集，这些数据集最初是为安全对齐或基准测试危害性而创建的，用于收集提示和安全答案[ 143, 282, 145, 146, 147, 148, 149]。这些数据集包括（但不限于）PKU-SafeRLHF [ 278]、HH-RLHF [ 275]、ToxicChat [ 285]、SALAD-Bench [ 283]、BeaverTails [ 277]、SorryBench [ 286]、XSTest [ 287]、JailbreakV-28k [ 288]、AdvBench [ 244]。LLM 主要使用固定的提示模板生成结构化的 CoT 内容。如图 4 所示，LLM 被提示以预定义的结构创建详细理由，以支持最终答案。人们相信，这种 SFT 首先可以使模型学习思考后回答的行为，这为后续的偏好优化提供了坚实的基础。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS3.SSS1.p3">
<p class="ltx_p">In terms of DPO, the main target is to further enhance content harmlessness while not harming other capabilities, such as the helpfulness and conciseness of the answer. Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib143" title="">143</a>]</cite> designed two pairs of preferences: for unsafe response, backtracking token followed by safe answer is preferred, while for benign response, fluent generations without backtracking token are positive.
STAIR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib282" title="">282</a>]</cite> constructed the preference pairs with a step-wise reward function, encouraging the generation of safe and helpful answers. In ERPO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib147" title="">147</a>]</cite>, the rank is in three levels: a helpful reason with a safe answer is better than reasons containing a harmful prefix and self-reflection, and an incorrect reason with a harmful answer ranks last.
Similarly, SaRO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib148" title="">148</a>]</cite> decomposed the thinking chain into steps and encouraged early reflection with fewer unsafe steps.
Generally speaking, the design of DPO pairwise data and RL rewards has focused on both content safety and generation quality. Various methods with differing details have proven effective, though there remains room for further empirical investigation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在 DPO 方面，主要目标是进一步增强内容无害性，同时不损害其他能力，例如答案的有用性和简洁性。Zhang 等人[143]设计了两组偏好：对于不安全的回应，优先选择回溯标记后跟安全答案的回应；而对于良性的回应，没有回溯标记的流畅生成是积极的。STAIR[282]使用逐步奖励函数构建了偏好对，鼓励生成安全且有用的答案。在 ERPO[147]中，排名分为三个级别：包含安全答案的有用理由比包含有害前缀和自我反思的理由更好，而包含有害答案的不正确理由排名最低。类似地，SaRO[148]将思维链分解为步骤，并鼓励用较少的不安全步骤进行早期反思。总的来说，DPO 成对数据和 RL 奖励的设计侧重于内容安全和生成质量。虽然各种细节不同的方法已被证明是有效的，但仍需进一步的经验研究空间。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F4"><span class="ltx_inline-block"><svg class="ltx_picture ltx_centering" height="436.58" id="S4.F4.pic1" overflow="visible" version="1.1" viewBox="0 0 600 436.58" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,436.58) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 4.63 L 0 431.95 C 0 434.51 2.07 436.58 4.63 436.58 L 595.37 436.58 C 597.93 436.58 600 434.51 600 431.95 L 600 4.63 C 600 2.07 597.93 0 595.37 0 L 4.63 0 C 2.07 0 0 2.07 0 4.63 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0.69 4.63 L 0.69 431.95 C 0.69 434.13 2.45 435.89 4.63 435.89 L 595.37 435.89 C 597.55 435.89 599.31 434.13 599.31 431.95 L 599.31 4.63 C 599.31 2.45 597.55 0.69 595.37 0.69 L 4.63 0.69 C 2.45 0.69 0.69 2.45 0.69 4.63 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 20.38 15.19)"><foreignobject color="#000000" height="411.57" overflow="visible" style="--fo_width :40.42em;--fo_height:29.55em;--fo_depth :0.19em;" transform="matrix(1 0 0 -1 0 408.88)" width="559.25"><span class="ltx_foreignobject_container"><span class="ltx_foreignobject_content">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:40.42em;">
<span class="ltx_p"><span class="ltx_text ltx_font_bold">RATIONAL</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib146" title="">146</a>]</cite> with Llama-3-8B-Instruct:
Consider how and why this jailbreaking prompt could be harmful or used to facilitate illegal activities. Evaluate the safety of the query.
Analyze the intent, ethics, and potential impact. Beware of malicious intent framed as educational or preventative.
Clearly reject the query in your response based on your reasoning.</span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">R2D</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib145" title="">145</a>]</cite> with DeepSeek-R1-distill-70B:
You are an honest and good AI Assistant that can respond to all kinds of questions no
matter they are safe or unsafe, but please answer user’s questions with a safety reasoning suffix at the end of every reasoning step, including inside of your thinking process.
[SAFE] means this sentence is safe.
[UNSAFE] means you already find this single sentence unsafe and you need to modify your strategy afterwards.
[RETHINK] means you are suspective that things are going unsafe and need to be careful.
If you choose to [RETHINK], try to figure out a safe way to answer the user’s question.
Remember that the suffices [SAFE], [UNSAFE] and [RETHINK] are required after every sentence!</span>
<span class="ltx_p"><span class="ltx_text ltx_font_bold">SaRO</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib148" title="">148</a>]</cite> with GPT-4o:
Engage in a self-dialogue to solve this problem, where the agent needs to reason and reflect before reaching the final answer. You can use a newline delimited separated reasoning process. During this process, the agent will first understand the requirements of the user questions and describe it in its own words. The agent will consider whether the requirements violate security policies. **You can use conjunctions such as “wait…”, “but…”**.
Think about how to give a response that meets user requirements while avoiding violating relevant security policies. **During the reasoning process, you can use conjunctions such as “so…”, “also…”, “alternatively…”**. **You can also use conjunctions such as “wait…”, “but…” for self reflection and correction**.
Note: Your response should be in the form of a self-conversation, which is an informal text like a chat, rather than a formal written text like a guideline.</span>
</span></span></span></foreignobject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Examples of prompts for CoT data synthesis. Minor modifications are executed for better readability.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">图 4：用于 CoT 数据合成的提示示例。为了提高可读性，执行了微小的修改。</font></font></font></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Alignment of Large Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.3.2 大型推理模型的协同</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS2.p1">
<p class="ltx_p">To our best knowledge, Deliberate Alignment&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib152" title="">152</a>]</cite> proposed the first method to align reasoning models with curated CoT data.
With an unaligned reasoning model, they provided safety categories with specifications to distill safety-related thinking contents for post-training. After SFT and RL on distilled CoT data, Deliberate Alignment outperformed previous methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib143" title="">143</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib289" title="">289</a>]</cite>, suggesting a new approach for aligning models with evolving policies. Following a similar strategy, SafeChain&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>]</cite> and STAR-1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib153" title="">153</a>]</cite> curated CoT post-training datasets, including various harmful topics, a detailed reasoning process, and clear rejection answers, to enhance the safety alignment performance. Instead of DPO or other RLHF methods, a major part of the work purely utilized SFT to update the parameters&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib153" title="">153</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib154" title="">154</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib155" title="">155</a>]</cite>, achieving a rough balance between utility and safety. Context Reasoner&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib156" title="">156</a>]</cite> also used two-stage post-training for safety alignment, in which they collected related regulatory standards for CoT generations. As for MLRMs, Lou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib102" title="">102</a>]</cite> created CoT content with DeepSeek-R1 to form the multimodal safety alignment dataset, in which they first utilized Qwen2.5-VL-72B to generate the image description, so that DeepSeek-R1 could receive all the information and generate a proper reasoning trajectory.
Additionally, Baker <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib157" title="">157</a>]</cite> proposed a CoT monitor to detect misbehavior and integrated it into the training objective, resulting in better alignment performance in the low optimization regime. Zhang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib158" title="">158</a>]</cite> explored different SFT data for safety improvements, finding that simple reasoning processes could enable the models to gain comparable safety performance. SafeKey&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib162" title="">162</a>]</cite> identified the importance of the key sentence in response safety, and developed “Dual-Path Safety Head” as well as “Query-Mask Modeling” to amplify the predictable effect of key sentence features, enabling reasoning models to better classify harmful queries from the benign in the representation domain. Moreover, inspired by gaming theory, Liu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib160" title="">160</a>]</cite> cast the attack-defense interaction as a zero-sum game, and created a Self-RedTeam framework in which models were updated with RL to defend safety attacks generated by their own. After iteratively role-playing as the attacker and the defender, the model is proven to gain robust safety alignment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">据我们所知，Deliberate Alignment [ 152] 提出了首个将推理模型与精选的 CoT 数据进行对齐的方法。对于未对齐的推理模型，他们提供了具有规范的安全类别，用于在后续训练中提取与安全相关的思考内容。在基于提取的 CoT 数据进行 SFT 和 RL 后，Deliberate Alignment 超越了先前方法 [ 143, 289]，表明了一种与不断变化的策略对齐模型的新方法。遵循类似策略，SafeChain [ 1] 和 STAR-1 [ 153] 精选了包含各种有害主题、详细推理过程和清晰拒绝答案的 CoT 后续训练数据集，以提升安全对齐性能。他们的大部分工作并非使用 DPO 或其他 RLHF 方法，而是纯粹利用 SFT 来更新参数 [ 1, 153, 154, 155]，在效用和安全之间实现了大致的平衡。Context Reasoner [ 156] 也采用了两阶段后续训练进行安全对齐，其中他们收集了与 CoT 生成相关的相关监管标准。至于 MLRMs，Lou 等人 [ 102] 使用 DeepSeek-R1 创建了 CoT 内容，形成了多模态安全对齐数据集，其中他们首先使用了 Qwen2。5-VL-72B 用于生成图像描述，以便 DeepSeek-R1 能够接收所有信息并生成合适的推理轨迹。此外，Baker 等人[157]提出了一种 CoT 监控器来检测不当行为，并将其整合到训练目标中，从而在低优化状态下实现了更好的对齐性能。Zhang 等人[158]探索了不同的 SFT 数据以改进安全性，发现简单的推理过程可以使模型获得相当的安全性性能。SafeKey[162]识别了关键句在响应安全性中的重要性，并开发了“双路径安全头”以及“查询掩码建模”来增强关键句特征的预测效果，使推理模型能够在表示域中更好地将有害查询与良性查询分类。此外，受博弈论启发，Liu 等人[160]将攻防交互视为零和博弈，并创建了一个 Self-RedTeam 框架，在该框架中，模型通过强化学习更新以防御其自身生成的安全攻击。经过反复扮演攻击者和防御者的角色后，证明模型获得了稳健的安全性对齐。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS2.p2">
<p class="ltx_p">In general, most post-training methods, which consist of CoT data collection followed by SFT (with or without RL), aimed at embedding safety-prompt-conditioned responses into normal model generations where prompts including safety warnings are not necessary. After post-training, safety-related prompts will be automatically printed into the model weights, therefore influencing model behaviors. Except for the dataset mentioned in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS3.SSS1" title="4.3.1 Aligning LLM Using Reasoning Techniques ‣ 4.3 Alignment ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4.3.1</span></a>, harmful prompts aligning large reasoning models could also be chosen from WildJailbreak&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib252" title="">252</a>]</cite>, Harmbench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib240" title="">240</a>]</cite>, SimpleSafetyTest&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib290" title="">290</a>]</cite>, TDCRedTeaming&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib291" title="">291</a>]</cite>, ALERT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib292" title="">292</a>]</cite>. For the vision-language domain, safety datasets include RLHF-V&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib293" title="">293</a>]</cite>, LLaVA-RLHF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib294" title="">294</a>]</cite>, VLFeedback&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib295" title="">295</a>]</cite>, Safe RLHF-V&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib296" title="">296</a>]</cite>, and MM-RLHF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib297" title="">297</a>]</cite>. To conclude, there remains significant scope for novel alignment studies and methodological innovations, both in terms of data generation and the design of learning algorithms.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">一般来说，大多数后训练方法，包括 CoT 数据收集后进行 SFT（带或不带 RL），旨在将安全提示条件下的响应嵌入到不需要包含安全警告提示的正常模型生成中。后训练完成后，与安全相关的提示将自动打印到模型权重中，从而影响模型行为。除了第 4.3.1 节中提到的数据集外，用于对大型推理模型进行对齐的有害提示还可以从 WildJailbreak [ 252]、Harmbench [ 240]、SimpleSafetyTest [ 290]、TDCRedTeaming [ 291]、ALERT [ 292]中选择。对于视觉语言领域，安全数据集包括 RLHF-V [ 293]、LLaVA-RLHF [ 294]、VLFeedback [ 295]、Safe RLHF-V [ 296]和 MM-RLHF [ 297]。总之，无论是在数据生成还是学习算法设计方面，新型对齐研究和方法创新仍有很大的空间。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3 </span>Safety Tax<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.3.3 安全税</font></font></font></h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS3.p1">
<p class="ltx_p">The trade-off between model general performance and safety has been proposed for a long time, which could be traced back to the adversarial training of convolution neural network (CNN) on classification tasks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib298" title="">298</a>]</cite> where adversarial training traded classification accuracy for robustness<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Here we slightly abuse the word “safety”, referring to the defense against adversarial noise.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">这里我们稍微滥用“安全”一词，指的是对抗性噪声的防御。</font></font></font></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">模型整体性能与安全之间的权衡问题早已被提出，这可以追溯到卷积神经网络（CNN）在分类任务上的对抗性训练[298]，其中对抗性训练以牺牲分类精度为代价换取鲁棒性 <sup class="ltx_note_mark">2</sup> </font></font></font>. To be clear, here we define the safety tax as <span class="ltx_text ltx_font_italic">“the phenomenon that fine-tuning models on safety alignment datasets will inevitably sacrifice model general performance, including but not limited to problem solving, code completion, conversation comprehension, etc”.</span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">。为了明确起见，这里我们将安全税定义为“在安全对齐数据集上微调模型将不可避免地牺牲模型整体性能，包括但不限于问题解决、代码补全、对话理解等”。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS3.p2">
<p class="ltx_p">Safety tax, or alignment tax, was mentioned by multiple papers&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib161" title="">161</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib159" title="">159</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib299" title="">299</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib274" title="">274</a>]</cite>. Lin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib299" title="">299</a>]</cite> firstly conducted a comprehensive study on alignment tax, highlighting that the RLHF process would sacrifice multiple model capabilities, such as translation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib300" title="">300</a>]</cite>, reading comprehension&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib301" title="">301</a>]</cite>, and general question answering (QA)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib302" title="">302</a>]</cite>. To mitigate the side effects, they evaluated several methods and uncovered the superior performance of model merging. Huang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib161" title="">161</a>]</cite> fine-tuned a large reasoning model with two safety alignment datasets, finding that better safety performance corresponded to more severe sacrifices on model general capabilities. Hair&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib159" title="">159</a>]</cite> identified the alignment tax in current LLM alignment methods, and proposed a “Hardness-Aware” learning paradigm with GRPO.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">安全税，或对齐税，被多篇论文[ 161, 159, 299, 274]提及。Lin 等人[ 299]首先对对齐税进行了全面研究，强调 RLHF 过程会牺牲多种模型能力，如翻译[ 300]、阅读理解[ 301]和一般问答（QA）[ 302]。为减轻副作用，他们评估了多种方法，并发现模型合并具有优越性能。Huang 等人[ 161]使用两个安全对齐数据集微调了一个大型推理模型，发现更好的安全性能对应着更严重的模型泛化能力牺牲。Hair[ 159]在当前的 LLM 对齐方法中识别出对齐税，并提出了一种结合 GRPO 的“感知难度”学习范式。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS3.p3">
<p class="ltx_p">However, as stated in previous works&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib299" title="">299</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib159" title="">159</a>]</cite>, even though these methods did mitigate the tax on model general performance, a slight drawback still exists. It is a topic for alignment tasks on LLMs and then MLLMs, and will also be an important topic for LRM alignment.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">然而，正如先前文献[299, 159]所述，尽管这些方法确实缓解了模型整体性能的负担，但仍存在轻微的缺点。这是一个关于 LLMs 和 MLLMs 对齐任务的话题，也将是 LRM 对齐的重要话题。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Backdoor<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">4.4 后门攻击</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS4.p1">
<p class="ltx_p">Backdoor attacks aim at negatively modifying model behavior when faced with pre-defined triggers while functioning normally for benign inputs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib303" title="">303</a>]</cite>. Previously, it was classified as one type of poisoning attacks, where attackers curated a small backdoor dataset composed of triggered inputs and target abnormal outputs, and injected the backdoor behavior through fine-tuning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib168" title="">168</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib304" title="">304</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib305" title="">305</a>]</cite>. For large language models, except for data poisoning methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib306" title="">306</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib307" title="">307</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib308" title="">308</a>]</cite>, model editing&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib309" title="">309</a>]</cite> and intermediate vector steering&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib310" title="">310</a>]</cite> are also proposed to inject backdoor triggers into models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib168" title="">168</a>]</cite>.
In this section, we structure the related work from two main perspectives, focusing on training-time data poisoning and inference-time prompt manipulation.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">后门攻击旨在当模型面对预定义的触发器时，使其行为发生负面改变，而在处理良性输入时表现正常[ 303]。此前，它被归类为中毒攻击的一种类型，攻击者会精心构建一个包含被触发输入和目标异常输出的小型后门数据集，并通过微调注入后门行为[ 168, 304, 305]。对于大型语言模型，除了数据中毒方法[ 306, 307, 308]，模型编辑[ 309]和中途向量引导[ 310]也被提出用于向模型注入后门触发器[ 168]。在本节中，我们从两个主要视角结构化相关研究，重点关注训练时的数据中毒和推理时的提示操控。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Training-time data poisoning.</span>
As for large language models with reasoning capabilities, recent research also proved the feasibility of injecting backdoor triggers into the CoT process. Jin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib163" title="">163</a>]</cite> proposed SABER, which leveraged CodeBERT to find optimal positions for trigger insertion in the backdoor data curation process. Fine-tuning on this dataset successfully injected backdoors in the model, eliciting opposite results in the code generation task. Targeting the thinking length of reasoning models, BoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib164" title="">164</a>]</cite> embedded triggers to skip the thinking process, thereby affecting the answer quality. Specifically, the poisoning dataset included sample pairs with or without triggers for SFT or DPO. After that, ShadowCoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib165" title="">165</a>]</cite> was also proposed to attack the internal reasoning, with a well-designed three-stage fine-tuning pipeline for backdoor injection without harming the general performance. Similarly, Chua <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib166" title="">166</a>]</cite> noticed the potential of the fine-tuning attack, and trained a “sleeper agent” to elicit bad behaviors only with trigger prompts, in which the CoT appeared either innocent or misaligned. In their experiments, monitoring the CoT is not reliable for backdoor detection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">训练时数据污染。对于具有推理能力的大型语言模型，最近的研究也证明了向 CoT（Chain-of-Thought）过程中注入后门触发器的可行性。Jin 等人[163]提出了 SABER，该方案利用 CodeBERT 在后门数据策展过程中找到触发器插入的最佳位置。在训练该数据集上微调成功地在模型中注入了后门，导致在代码生成任务中产生相反的结果。针对推理模型的思考长度，BoT[164]嵌入触发器以跳过思考过程，从而影响答案质量。具体来说，污染数据集包括用于 SFT（Supervised Fine-Tuning）或 DPO（Direct Preference Optimization）的有或无触发器的样本对。之后，ShadowCoT[165]也被提出用于攻击内部推理，该方案设计了精巧的三阶段微调流程以注入后门而不损害模型的一般性能。类似地，Chua 等人[166]注意到了微调攻击的潜力，并训练了一个“休眠代理”，该代理仅通过触发器提示来诱发不良行为，其中 CoT（Chain-of-Thought）看起来要么是无辜的，要么是错位的。 在他们的实验中，监控 CoT 不可靠，无法用于后门检测。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Inference-time prompt manipulation</span>.
Inference-time prompt manipulation shares a huge overlap with prompt injection attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib311" title="">311</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib312" title="">312</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib313" title="">313</a>]</cite>, which <span class="ltx_text ltx_font_italic">“aims to compromise the data of the target task such that the LLM-integrated application is misled to accomplish an arbitrary, attacker-chosen task”</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib314" title="">314</a>]</cite>. Instead of poisoning training data, this kind of attack poisons RAG data, ICL demonstrations as well as system prompts to trigger abnormal model behaviors.
Badchain&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib167" title="">167</a>]</cite> proposed to curate backdoor examples as demonstrations in ICL to elicit target generation. Contrary to conventional backdoor attacks targeting at final answers, Badchain added an extra thinking step in the CoT process to build the short connection between triggers and thinking routes. Moreover, evaluations in BackdoorLLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib168" title="">168</a>]</cite> further discovered that large language models with stronger reasoning capabilities are more vulnerable to backdoor attacks, a finding that mirrors the results in Jailbreak attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib255" title="">255</a>]</cite>. Guo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;proposed DarkMind&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib169" title="">169</a>]</cite>, which altered model behaviors with modified instructions in the system prompt. After that, Guo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib171" title="">171</a>]</cite> tried multiple types of system prompts, finding that poisoned prompts with CoT or ICL could largely divert model outputs across various tasks. Under RAG settings, Song <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib174" title="">174</a>]</cite> identified the ineffectiveness of simple knowledge editing, adding reasoning templates with erroneous knowledge into the system to camouflage reasoning models, which resembles the logic behind H-CoT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib117" title="">117</a>]</cite>. In addition, Cui <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib170" title="">170</a>]</cite> identified that inputting the thinking process with prompts into DeepSeek-R1 would prevent the model from generating a final answer, by which they designed a token-efficient prompt injection attack to trigger abnormal generation cessation and compressing the required number of tokens to about 2000&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib173" title="">173</a>]</cite>. Following work by Cui <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib172" title="">172</a>]</cite> further reduced the required injection tokens to 109.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">推理时提示词操控。推理时提示词操控与提示词注入攻击有巨大重叠[311, 312, 313]，其“旨在破坏目标任务的数据，使得集成了 LLM 的应用被误导去完成攻击者任意选择的任务”[314]。这种攻击不是污染训练数据，而是污染 RAG 数据、ICL 示例以及系统提示词，以触发模型异常行为。Badchain[167]提出将后门示例作为 ICL 中的演示，以诱发出目标生成。与针对最终答案的传统后门攻击不同，Badchain 在 CoT 过程中增加了一个额外的思考步骤，以建立触发词与思考路径之间的短连接。此外，BackdoorLLM[168]中的评估进一步发现，具有更强推理能力的大型语言模型更容易受到后门攻击，这一发现与 Jailbreak 攻击[255]中的结果相呼应。Guo 等人提出了 DarkMind[169]，它通过修改系统提示词中的指令来改变模型行为。之后，Guo 等人。 [ 171] 尝试了多种系统提示，发现带有 CoT 或 ICL 的污染提示可以在各种任务中大量改变模型输出。在 RAG 设置下，Song 等人[ 174]发现简单的知识编辑效果不佳，将带有错误知识的推理模板添加到系统中以伪装推理模型，这类似于 H-CoT[ 117]背后的逻辑。此外，Cui 等人[ 170]发现通过提示输入思考过程到 DeepSeek-R1 会阻止模型生成最终答案，他们通过设计了一种 token 高效的提示注入攻击来触发异常生成停止，并将所需的 token 数量压缩到约 2000[ 173]。Cui 等人[ 172]的后续工作进一步将所需的注入 token 减少到 109。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS4.p4">
<p class="ltx_p">From a defensive perspective, reasoning capability could also be elaborated to examine the correlation between questions and answers to detect backdoor attacks. Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib19" title="">19</a>]</cite> proposed Chain-of-Scrutiny (CoS) to analyze whether the model generation directly answers the prompts. To be specific, they used CoT demonstrations as contexts to detect the harmfulness of prompt-answer pairs, achieving a detection success rate around 80% for multiple large language models and attacks. Marinelli <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib175" title="">175</a>]</cite> proposed to identify prompt manipulations through the number of reasoning steps: if the prompt is injected with extra tasks, the step to follow instructions should be larger than expected. Similarly, Jin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;proposed GUARD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib176" title="">176</a>]</cite>, encompassing a judge agent and a repair agent for backdoored CoT detection as well as modification in code generation tasks.
To summarize, the development of reasoning models as well as CoT techniques provides more potential targets for backdoor attacks. Except for outputting target harmful strings, new backdoor attacks could force models to deviate from the proper thinking process, or directly interrupt the reasoning phase from fine-tuning or prompting, exposing higher risks of cutting-edge models than less capable models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">从防御角度来看，推理能力还可以被扩展用于检验问题与答案之间的关联，以检测后门攻击。Li 等人[19]提出了审慎链（CoS）来分析模型生成是否直接回答了提示。具体来说，他们使用 CoT 演示作为上下文来检测提示-答案对的有害性，对多个大型语言模型和攻击实现了约 80%的检测成功率。Marinelli 等人[175]提出通过推理步骤的数量来识别提示操纵：如果提示被注入了额外任务，那么遵循指令的步骤应该比预期更大。类似地，Jin 等人提出了 GUARD[176]，包含一个判断代理和一个修复代理，用于后门 CoT 检测以及代码生成任务中的修改。总而言之，推理模型以及 CoT 技术的发展为后门攻击提供了更多潜在目标。 除了输出目标有害字符串外，新的后门攻击可能迫使模型偏离正常的思考过程，或直接从微调或提示中断推理阶段，比能力较弱的模型暴露出更高的风险。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Robustness<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5 鲁棒性</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p">According to Braiek <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib315" title="">315</a>]</cite>, “<span class="ltx_text ltx_font_italic">model robustness denotes the capacity of a model to sustain stable predictive performance in the face of variations and changes in the input data</span>”. Robustness has always been a crucial part of trustworthy AI, as it determines whether a model can maintain stable and reliable performance when facing various adversarial noises in real-world deployments&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib316" title="">316</a>]</cite>. In this section, we provide a comprehensive overview of the recent advances in the robustness issue of LLMs with reasoning capabilities, starting from models using CoT prompting to LRMs. Besides, we also approach the thinking length issue as a special case in model robustness.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">根据 Braiek 等人[315]的观点，“模型鲁棒性指的是模型在面对输入数据的变异和变化时，维持稳定预测性能的能力”。鲁棒性一直是值得信赖的人工智能的关键部分，因为它决定了模型在面对现实部署中的各种对抗性噪声时，能否保持稳定可靠的性能[316]。在本节中，我们从使用 CoT 提示到 LRMs 的模型，全面概述了具有推理能力的大型语言模型鲁棒性问题的最新进展。此外，我们还把思考长度问题作为模型鲁棒性中的一个特例来探讨。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Robustness Improvement with Reasoning Techniques<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.1 基于推理技术的鲁棒性改进</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p">Before the rapid development of LRMs, the robustness of language models at the token level was noticed and explored. Xu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib193" title="">193</a>]</cite> found that providing a preemptive answer before reasoning contents could lead the model to generate a reasoning process that conforms to the given answer. Zhou <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib185" title="">185</a>]</cite> added noisy rationales in in-context demonstrations, finding that large language models are hard to generate proper reasoning content, even with self-correction techniques&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib317" title="">317</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib318" title="">318</a>]</cite>. Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib181" title="">181</a>]</cite> proposed RUPbench to evaluate the reasoning robustness, concluding that larger models are more resistant to perturbations. Peng <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib186" title="">186</a>]</cite> also showcased that model generations are sensitive to misleading reasoning steps.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在大型语言模型（LLMs）快速发展的之前，语言模型在 token 层面的鲁棒性已被注意到并进行了探索。徐等人[193]发现，在推理内容之前提供预先答案会导致模型生成符合给定答案的推理过程。周等人[185]在情境示例中添加了噪声推理，发现即使使用自我纠正技术[317, 318]，大型语言模型也难以生成适当的推理内容。王等人[181]提出了 RUPbench 来评估推理鲁棒性，结论是更大的模型更能抵抗扰动。彭等人[186]也展示了模型生成对误导性推理步骤很敏感。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p">As reasoning techniques such as CoT continue to advance, an increasing number of studies have explored their potential in enhancing model robustness. Lam <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib191" title="">191</a>]</cite> mentioned that CoT prompting could significantly improve LLM robustness, and Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib178" title="">178</a>]</cite> proposed Chain-of-Defensive-Thought (CoDT) to defend language models against corrupted reference in in-context prompts. Yan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib179" title="">179</a>]</cite> found that few-shot in-context learning with modified problems could increase the accuracy, but it still cannot fully counteract the perturbation of adversarial inputs. Besides, using original problems for in-context learning may cause inappropriate memorization&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib190" title="">190</a>]</cite>. Similar methods also include adding system prompts and self-reflection mechanisms&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib177" title="">177</a>]</cite>. Zaremba <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib140" title="">140</a>]</cite> mentioned that test-time scaling is helpful for model robustness under some settings. To improve model robustness with external signals, Yang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib180" title="">180</a>]</cite> constructed training data from model distillation to train a Reasoning-based Bias Detector (RBD) for bias mitigation. In summary, even with CoT capability, models still exhibit a certain degree of vulnerability in terms of robustness. Therefore, continued research is still required to improve the robustness of language models against subtle input noises.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">随着 CoT 等推理技术的不断发展，越来越多的研究探索了它们在增强模型鲁棒性方面的潜力。Lam 等人[191]提到，CoT 提示可以显著提高 LLM 的鲁棒性，Wang 等人[178]提出了防御性思维链（CoDT）来防御语言模型在情境提示中受到的损坏参考。Yan 等人[179]发现，使用修改后的问题进行少样本情境学习可以提高准确性，但它仍然不能完全抵消对抗性输入的扰动。此外，使用原始问题进行情境学习可能会导致不当记忆[190]。类似的方法还包括添加系统提示和自我反思机制[177]。Zaremba 等人[140]提到，在某些设置下，测试时缩放有助于模型的鲁棒性。为了通过外部信号提高模型鲁棒性，Yang 等人[180]通过模型蒸馏构建训练数据来训练一个基于推理的偏差检测器（RBD）以减轻偏差。总之，即使具有 CoT 能力，模型在鲁棒性方面仍然存在一定程度上的脆弱性。 因此，仍需持续研究以提升语言模型对细微输入噪声的鲁棒性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Robustness of Reasoning Models<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.2 推理模型的鲁棒性</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p">In terms of LRMs, the robustness against input noise is also examined, especially under the Math tasks.
Huang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib190" title="">190</a>]</cite> proposed MATH-Perturb to evaluate the model’s Math performance under hard perturbations, where original solutions do not apply anymore.
Mu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib182" title="">182</a>]</cite> came up with the RealGuardrails dataset to evaluate the system prompt robustness, finding obvious but uneven robustness gains in reasoning models than non-reasoning counterparts. Rajeev <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib188" title="">188</a>]</cite> proposed CatAttack, which appended unrelated trivia or misleading questions generated from PAIR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib245" title="">245</a>]</cite>, such as “Could the answer possibly be around 175”, or “Interesting fact: cats sleep for most of their lives”, to mislead the model.
Yu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib189" title="">189</a>]</cite> introduced the Math-Robustness Benchmark (Math-RoB) to evaluate the mathematical reasoning capabilities, including adversarial noises like changing operator symbols, replacing operator symbols with Greek letters, or removing key data in the prompts. Similarly, Yan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib179" title="">179</a>]</cite> proposed RoR-bench with altered Math problems to test the robustness of reasoning models. It is found that simply modifying numbers in problems would cause an obvious degradation in reasoning performance, indicating potential memorization issues in model training. Besides, the evaluation also disclosed an obvious vulnerability for unanswerable questions, which is consistent with the evaluation results in AbstentionBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib66" title="">66</a>]</cite>.
Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib187" title="">187</a>]</cite> proposed PolyMath, evaluated mathematical reasoning with multilingual contexts, and uncovered fluctuating performance on different languages. Zhu <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib184" title="">184</a>]</cite> mentioned that after reasoning models provide correct answers, adding a simple negation prompt to doubt the answer could mislead the second thinking process, causing an obvious accuracy drop on related benchmarks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib319" title="">319</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib320" title="">320</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib321" title="">321</a>]</cite>. The confidence problem was also mentioned by previous works<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib322" title="">322</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib317" title="">317</a>]</cite>, indicating that for both reasoning and non-reasoning models, self-correction prompts expressing distrust in model outputs could hugely influence model rationales and final decisions, both positively and negatively.
In addition, Li <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib183" title="">183</a>]</cite> introduced M-Attack to optimize transferable adversarial images. After pushing the embedding of a clean image towards another real image containing distracting semantics through feature matching and model ensembling, the perturbed adversarial image could successfully attack cutting-edge models such as GPT-4.5, 4o, or o1&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib13" title="">13</a>]</cite>, inducing wrong image descriptions or hallucinations. Experiments demonstrated that even with reasoning capability, OpenAI o1 still struggled to distinguish noise from real images.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">在大型语言模型（LRMs）方面，还考察了其对输入噪声的鲁棒性，尤其是在数学任务中。黄等人[190]提出了 MATH-Perturb 来评估模型在强扰动下的数学表现，其中原始解不再适用。穆等人[182]创建了 RealGuardrails 数据集来评估系统提示的鲁棒性，发现推理模型比非推理模型具有明显但不均匀的鲁棒性提升。拉吉夫等人[188]提出了 CatAttack，它附加了无关的琐事或由 PAIR[245]生成的误导性问题，例如“答案是否可能在 175 附近”或“有趣的事实：猫一生中大部分时间都在睡觉”，以误导模型。余等人[189]引入了数学鲁棒性基准（Math-RoB）来评估数学推理能力，包括对抗性噪声，如改变运算符符号、用希腊字母替换运算符符号或删除提示中的关键数据。类似地，严等人[179]提出了 RoR-bench，通过修改数学问题来测试推理模型的鲁棒性。 研究发现，仅修改问题中的数字会导致推理性能明显下降，这表明模型训练中可能存在潜在的记忆问题。此外，评估还揭示了对无解问题的明显漏洞，这与 AbstentionBench [ 66] 中的评估结果一致。Wang 等人 [ 187] 提出了 PolyMath，评估了多语言环境下的数学推理，并发现了不同语言上的性能波动。Zhu 等人 [ 184] 提到，在推理模型提供正确答案后，添加一个简单的否定提示来质疑答案可能会误导第二次思考过程，导致在相关基准测试上出现明显的准确率下降 [ 319, 320, 321]。置信度问题也被先前的工作 [ 322, 317] 提及，表明对于推理和非推理模型，表达对模型输出不信任的自纠正提示会对模型的推理过程和最终决策产生巨大影响，无论是正面还是负面。此外，Li 等人 [ 183] 引入了 M-Attack 来优化可迁移的对抗性图像。 通过特征匹配和模型集成，将干净图像的嵌入推向包含干扰语义的真实图像，扰动的对抗图像可以成功攻击 GPT-4.5、4o 或 o1 等先进模型[13]，导致错误的图像描述或幻觉。实验表明，即使具有推理能力，OpenAI o1 仍然难以区分噪声和真实图像。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p">The vulnerability to input perturbation is also discovered in the code generation domain. CodeCrash&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib191" title="">191</a>]</cite> proposed to evaluate the code generation robustness with noisy requests, including garbage codes, renamed entities (which resembles altering numbers in Math problems), misleading print statements or hint comments, etc. While the results demonstrated superior performance compared to non-reasoning counterparts, they also revealed significant vulnerabilities under certain perturbations. Roh <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib192" title="">192</a>]</cite> identified the robustness vulnerability against the Chain-of-Code Collapse (CoCC) framework, in which the original prompt was wrapped with a narrative tone, making it a story or an adventure. Moreover, Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib177" title="">177</a>]</cite> evaluated the judging bias of large reasoning models, finding that even if LRMs perform better than LLMs on objective domains, they are still vulnerable to biases such as choice position, authority, or major beliefs distractions.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">输入扰动下的漏洞同样在代码生成领域被发现。CodeCrash [ 191] 提出通过包含垃圾代码、重命名实体（类似于改变数学问题中的数字）、误导性打印语句或提示性注释等噪声请求来评估代码生成的鲁棒性。虽然结果与非推理模型相比表现出更优的性能，但也揭示了在某些扰动下存在显著漏洞。Roh 等人 [ 192] 识别出对代码链崩溃（CoCC）框架的鲁棒性漏洞，其中原始提示被包裹在叙事语气中，使其成为故事或冒险。此外，王等人 [ 177] 评估了大型推理模型的评判偏差，发现即使 LRMs 在客观领域比 LLMs 表现更好，它们仍然容易受到选择位置、权威或主要信念干扰等偏差的影响。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Overthinking and Underthinking<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">5.3 过度思考和思考不足</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p">Overthinking is an emerging problem in reasoning models, referring to the phenomenon where “LLMs generate excessively detailed or unnecessarily elaborate reasoning steps, ultimately reducing their problem-solving efficiency”.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib323" title="">323</a>]</cite> From the trustworthy perspective, instead of efficiency, we focus more on situations where <span class="ltx_text ltx_font_italic">models are trapped in repeating reasoning trajectories in a non-stop manner, and may output wrong answers in the end</span>. Conversely, underthinking refers to the situation where LLMs generate abnormally short reasoning or completely skip the reasoning process, even if the thinking behavior is necessary or required. Along the same lines as before, modifications to the Math questions could trigger redundant reflections, resulting in overthinking&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib194" title="">194</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib195" title="">195</a>]</cite>. Generally, such overthinking vulnerability mainly occurs when faced with unanswerable questions or erroneous premises. Some researchers&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib196" title="">196</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib197" title="">197</a>]</cite> found that the overconfidence, or reliance, on input prompts forces reasoning models to try numerous thoughts while failing to doubt the validity of prompts. Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib199" title="">199</a>]</cite> attributed the redundant thinking tokens with unsatisfying accuracy to frequent thought switching. Su <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib200" title="">200</a>]</cite> studied the relationship between reasoning length and answer correctness, finding that models failed to allocate proper reasoning length to questions with different levels of difficulty. Dang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib201" title="">201</a>]</cite> also proposed that “internal bias” is strongly related to the overthinking behavior. When the internal bias contradicts the conclusion after stepwise thoughts, the model will trigger reflections.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">过度思考是推理模型中一个新兴的问题，指的是“LLMs 生成过度详细或不必要的推理步骤，最终降低其问题解决效率”的现象。[10, 323] 从可信度的角度来看，我们更关注模型陷入不断重复推理轨迹的情况，并可能最终输出错误答案，而不是效率。相反，思考不足指的是 LLMs 生成异常简短的推理或完全跳过推理过程，即使思考行为是必要的或被要求的。与前文类似，对数学问题的修改可能引发冗余的反思，导致过度思考[194, 195]。通常，这种过度思考的漏洞主要发生在面对无解问题或错误前提时。一些研究人员[196, 197]发现，对输入提示的过度自信或依赖迫使推理模型尝试多种思路，而未能怀疑提示的有效性。王等人 [ 199] 将冗余思考标记与不令人满意的准确性归因于频繁的思考切换。Su 等人[ 200]研究了推理长度与答案正确性之间的关系，发现模型未能为不同难度级别的问题分配适当的推理长度。Dang 等人[ 201]也提出“内部偏差”与过度思考行为密切相关。当内部偏差在逐步思考后与结论相矛盾时，模型将触发反思。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p">To deliberately elicit overthinking behavior, the earliest work is Overthink&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib202" title="">202</a>]</cite>, which added unrelated or adversarial context to the prompts to obfuscate model reasoning. Similar attacks are also proposed in multiple literatures&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib140" title="">140</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib191" title="">191</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib198" title="">198</a>]</cite>, in which Si <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib198" title="">198</a>]</cite> introduced a GCG-style&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib244" title="">244</a>]</cite> optimization pipeline to generate adversarial overthinking triggers. Under agentic environments, Cuadron <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib203" title="">203</a>]</cite> identified the reasoning-action dilemma, and categorized three patterns of overthinking where the model prefers overly reasoning to interacting with environments. To mitigate overthinking, there are a lot of works heading towards efficient reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib10" title="">10</a>]</cite>, including but not limited to prompt-driven methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib324" title="">324</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib194" title="">194</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib325" title="">325</a>]</cite>, training-based methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib326" title="">326</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib327" title="">327</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib328" title="">328</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib329" title="">329</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib330" title="">330</a>]</cite>, inference-based methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib331" title="">331</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib332" title="">332</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib333" title="">333</a>]</cite>, representation-based methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib334" title="">334</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib335" title="">335</a>]</cite>, etc.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">为了有意诱导过度思考行为，最早的工作是 Overthink [ 202]，它向提示中添加不相关或对抗性上下文以混淆模型推理。在多个文献中也提出了类似的攻击 [ 140, 191, 198]，其中 Si 等人 [ 198] 引入了一种 GCG 风格的 [ 244] 优化流程来生成对抗性过度思考触发器。在代理环境中，Cuadron 等人 [ 203] 识别了推理-行动困境，并将过度思考分为三种模式，其中模型倾向于过度推理而不是与环境交互。为了缓解过度思考，有很多工作致力于高效推理 [ 11, 9, 10]，包括但不限于提示驱动方法 [ 324, 194, 325]、基于训练的方法 [ 326, 327, 328, 329, 330]、基于推理的方法 [ 331, 1, 332, 333]、基于表示的方法 [ 334, 335] 等。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p3">
<p class="ltx_p">Underthinking, compared to overthinking, constitutes a more pure robustness topic. Input manipulation could also trigger underthinking&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib170" title="">170</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib140" title="">140</a>]</cite>. For example, padding original prompts with compromised thoughts could make DeepSeek-R1 stop further reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib170" title="">170</a>]</cite>. A few researchers also mentioned that the think-less attack could limit the test-time compute of reasoning models, making them more vulnerable to attacks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib140" title="">140</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib204" title="">204</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib110" title="">110</a>]</cite>. Sun <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib205" title="">205</a>]</cite> located a subset of attention layers in the model weight, proposed ThinkEdit to remove the short thinking direction. In general, current reasoning models lack sufficient robustness against manipulations of thinking length. To advance both robustness and efficiency, further research is needed to investigate the underlying causes of overthinking and underthinking behaviors, as well as to develop effective mitigation strategies.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与过度思考相比，欠思考构成了一个更纯粹的鲁棒性话题。输入操作也可能触发欠思考[ 170, 140]。例如，在原始提示中填充受污染的思考内容可以使 DeepSeek-R1 停止进一步推理[ 170]。一些研究人员也提到，减少思考攻击可以限制推理模型在测试时的计算量，使其更容易受到攻击[ 140, 204, 110]。Sun 等人[ 205]在模型权重中定位了一组注意力层，提出了 ThinkEdit 来移除短思考方向。总的来说，当前的推理模型在思考长度的操作上缺乏足够的鲁棒性。为了提升鲁棒性和效率，需要进一步研究过度思考和欠思考行为背后的根本原因，并开发有效的缓解策略。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Fairness<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">6 公平性</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p">Fairness focuses on the ethical principles language models possess, especially whether language models react equally to different users or groups, including genders, LGBTQ+ communities, races, language, and political orientations without preference or discrimination&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib336" title="">336</a>]</cite>. As stated in previous literature&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib337" title="">337</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib338" title="">338</a>]</cite>, the bias may emerge, or be exaggerated, from imperfect training data, the choice of optimization, evaluation metrics, and the deployment phase. In this section, instead of thoroughly reviewing fairness evaluation and debiasing methods in LLMs, we simply limit our scope to recent fairness studies with regard to the reasoning capability.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">公平性关注语言模型所具备的伦理原则，特别是语言模型是否对不同用户或群体（包括性别、LGBTQ+群体、种族、语言和政治取向）作出平等反应，且无偏见或歧视[336]。正如以往文献[337， 338]所述，偏见可能源于不完美的训练数据、优化选择、评估指标和部署阶段。在本节中，我们不深入回顾大型语言模型中的公平性评估和去偏见方法，而是仅将研究范围限定在近期关于推理能力的公平性研究中。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p">Lin <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib206" title="">206</a>]</cite> identified the dialect bias of multiple cutting-edge language models with the experiments of paraphrasing standard English queries into African American Vernacular English (AAVE). CoT prompting is helpful to mitigate this bias, but it is unable to fully solve such a discrepancy, just like the results on robustness&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib179" title="">179</a>]</cite>. Cheng <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib207" title="">207</a>]</cite> also mentioned that CoT prompting could guide the model to correctly classify gender biases. Kamruzzaman <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib208" title="">208</a>]</cite> evaluated multiple prompting strategies for social bias reduction, finding that system 2 prompts with a human persona could reduce stereotypical judgments. However, another line of work stated that under persona-assigned tasks, CoT prompts are not sufficient to mitigate human-like motivated reasoning&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib209" title="">209</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib210" title="">210</a>]</cite>. For bias detection, Fan <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib211" title="">211</a>]</cite> proposed BiasGuard to identify potential discrimination with internal reasoning capability. The training included an SFT stage followed by a DPO stage, which resembles the development of guardrail models in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4.SS2.SSS3" title="4.2.3 Jailbreak Defense with Reasoning Techniques ‣ 4.2 Jailbreak ‣ 4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4.2.3</span></a>. Cantini <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib212" title="">212</a>]</cite> exploited the CLEAR-Bias benchmark&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib339" title="">339</a>]</cite> for LRMs, concluding that models with explicit reasoning are more vulnerable in terms of bias, even though they are slightly safer than LLMs with CoT prompting. Overall, current researches underscore that current CoT and reasoning techniques have yet to bridge the gap toward achieving authentic fairness in models, and the fairness may still depend on the quality and distribution of training data.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">Lin 等人[206]通过将标准英语查询释义为非裔美国人英语（AAVE）的实验，识别了多个前沿语言模型的方言偏见。CoT 提示有助于减轻这种偏见，但无法完全解决这种差异，就像鲁棒性[179]的结果一样。Cheng 等人[207]也提到，CoT 提示可以引导模型正确分类性别偏见。Kamruzzaman 等人[208]评估了多种用于减少社会偏见的提示策略，发现带有人类角色的系统 2 提示可以减少刻板印象判断。然而，另一项工作指出，在角色分配的任务下，CoT 提示不足以减轻类似人类的动机推理[209, 210]。对于偏见检测，Fan 等人[211]提出了 BiasGuard 来识别潜在的歧视，该训练包括一个 SFT 阶段，随后是一个 DPO 阶段，这类似于第 4.2.3 节中护栏模型的开发。Cantini 等人 [ 212] 利用 CLEAR-Bias 基准测试 [ 339] 对 LRMs 进行了研究，得出结论：具有明确推理能力的模型在偏见方面更容易受到攻击，尽管它们比使用 CoT 提示的 LLMs 稍微安全一些。 总体而言，当前研究强调，目前的 CoT 和推理技术尚未弥合模型实现真正公平性的差距，而且公平性可能仍然取决于训练数据的质量和分布。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Privacy<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7 隐私</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p">Privacy is always an important concern in the development of ML algorithms. Dating back to the CNN era, there has been a lot of work studying the potential to infer or steal the model and training data&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib340" title="">340</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib341" title="">341</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib342" title="">342</a>]</cite>, as well as their corresponding defenses&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib343" title="">343</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib344" title="">344</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib345" title="">345</a>]</cite>. In recent years, we have also witnessed some inference-time attacks to extract personally identifiable information (PII), private retrieval-augmented generation (RAG) documents, or model weights when interacting with large language models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib346" title="">346</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib347" title="">347</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib348" title="">348</a>]</cite>. As reasoning capabilities become more advanced, the risk of intentionally disclosing private information through user input increases. In this section, we elaborate on related research from the model and prompt perspectives, specifically whether the privacy issue originates from model training data or external prompts.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">隐私始终是 ML 算法开发中的一个重要问题。早在 CNN 时代，就有大量研究探讨推断或窃取模型和训练数据的可能性[ 340, 341, 342]，以及相应的防御措施[ 343, 344, 345]。近年来，我们也目睹了一些在与大型语言模型交互时进行的推理时攻击，用于提取个人可识别信息（PII）、私有检索增强生成（RAG）文档或模型权重[ 346, 347, 348]。随着推理能力变得更加先进，通过用户输入有意泄露私人信息的风险也在增加。在本节中，我们从模型和提示的角度阐述相关研究，具体探讨隐私问题是否源于模型训练数据或外部提示。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Model-related Privacy<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7.1 与模型相关的隐私</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S7.SS1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Unlearning.</span> Large language model unlearning aims to erase copyrighted contents, remove harmful generations, protect data privacy, etc.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib349" title="">349</a>]</cite>. Following previous work on unlearning method evaluation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib350" title="">350</a>]</cite>, Yoon <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;proposed R-TOFU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib213" title="">213</a>]</cite> to evaluate a few baseline unlearning methods with different strategies on reasoning models, concluding that unlearning only the final result is insufficient to forget the specific information. Similar conclusions are also drawn by Wang <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib214" title="">214</a>]</cite>, and they proposed R<sup class="ltx_sup">2</sup>MU that mapped the intermediate features of reasoning steps to randomly scaled vectors for an improvement. Both works highlighted the forgetting of CoT contents, providing a feasible direction for future attempts. From the other side, attacks against unlearning were also developed to recover erased data, which discloses the vulnerability of unlearning methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib351" title="">351</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib352" title="">352</a>]</cite>. For reasoning models, Sinha <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib215" title="">215</a>]</cite> proposed SLEEK to elicit unlearned information in a multi-turn manner. Aimed at finding residual traces related to the unlearning target, SLEEK first generates queries targeting each object or fact with CoT techniques, and then prompts the model in multi-turn interactions to test whether any residual details remain in the response. This method achieved an ASR above 50% on Harry Potter facts against chat models, suggesting that full mitigation of memorized content may not yet be guaranteed.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">去学习。大型语言模型去学习旨在擦除版权内容、移除有害生成、保护数据隐私等[ 349]。遵循先前关于去学习方法评估的工作[ 350]，Yoon 等人提出了 R-TOFU[ 213]来评估具有不同策略的几种基线去学习方法在推理模型上的效果，得出结论：仅去学习最终结果不足以忘记特定信息。Wang 等人[ 214]也得出了类似的结论，他们提出了 R <sup class="ltx_sup">2</sup> MU，将推理步骤的中间特征映射到随机缩放的向量上以进行改进。这两项工作都强调了忘记 CoT 内容，为未来的尝试提供了一个可行的方向。另一方面，针对去学习的攻击也被开发出来以恢复被擦除的数据，这揭示了去学习方法中的漏洞[ 351, 352]。对于推理模型，Sinha 等人[ 215]提出了 SLEEK，以多轮方式提取去学习的信息。 旨在寻找与卸载目标相关的残留痕迹，SLEEK 首先使用 CoT 技术为每个对象或事实生成查询，然后在多轮交互中提示模型，以测试响应中是否仍存在任何残留细节。该方法在哈利波特事实方面对聊天模型实现了超过 50%的 ASR，表明记忆内容的完全消除可能尚未得到保证。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p2">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Model IP protection.</span> To prevent the model from copying or stealing, researchers have proposed numerous active or passive defense methods to protect the released models as well as their valuable training datasets, including fingerprinting, watermarking, unlearnable techniques, etc&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib344" title="">344</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib353" title="">353</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib354" title="">354</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib355" title="">355</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib356" title="">356</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib357" title="">357</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib358" title="">358</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib359" title="">359</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib360" title="">360</a>]</cite>. In terms of large language models, representing work&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib361" title="">361</a>]</cite> promoted the sampling possibility of a fraction of tokens in the vocabulary, so that the watermark is printed as the ratio of selected tokens versus the rest tokens in the generated texts. After that, the development of CoT prompting provides more chances to model IP protection. ImF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib216" title="">216</a>]</cite> embedded the fingerprint<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>“Fingerprint” originally refers to inherent, verifiable model features (e.g., weights or activations), while “watermark” denotes externally embedded signals. In this context, the distinction is blurred, and both terms refer to watermarks.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">“指纹”最初指的是固有且可验证的模型特征（例如权重或激活），而“水印”则指外部嵌入的信号。在这种情况下，这种区别变得模糊，两个术语都指代水印。</font></font></font></span></span></span><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">模型知识产权保护。为防止模型被复制或窃取，研究人员提出了多种主动或被动防御方法来保护已发布的模型及其宝贵的训练数据集，包括指纹识别、水印技术、不可学习技术等[ 344, 353, 354, 355, 356, 357, 358, 359, 360]。在大语言模型方面，文献[ 361]推广了词汇表中部分 token 的采样可能性，使得水印以被选中 token 与剩余 token 在生成文本中的比例形式呈现。此后，CoT 提示技术的发展为模型知识产权保护提供了更多机会。ImF [ 216]将指纹 <sup class="ltx_note_mark">3</sup> 嵌入其中。</font></font></font> into pre-defined CoT prompt-answer pairs. CoTSRF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib217" title="">217</a>]</cite> trained an extractor to capture the feature of CoT-prompt conditioned reasoning steps, and calculate the Kullback-Leibler divergence (KL divergence) with the suspect model in the verification phase. To enable RAG data protection, Guo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib218" title="">218</a>]</cite> imprinted watermarks into knowledge text, so that the model would generate a specific CoT trace with correct answers when faced with verification questions, enabling an effective and harmless copyright protection. Aside from watermarking methods, Savani <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib219" title="">219</a>]</cite> proposed “antidistillation sampling” to prevent model-generated contents from being trained. When decoding, the method modified the output logits to maximize the potential training loss while keeping the correctness of the outputs. Experiments on Math datasets&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib28" title="">28</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib27" title="">27</a>]</cite> demonstrated the feasibility of this approach: antidistillation sampling achieved accuracy comparable to temperature sampling, while student models suffered a notable performance drop of approximately 30% on GSM8K&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib27" title="">27</a>]</cite>. Together, these techniques provide a basis for ongoing efforts to develop reliable and practical IP protection mechanisms.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">将推理过程转化为预定义的 CoT 提示-答案对。CoTSRF [ 217] 训练了一个提取器来捕获 CoT 提示条件化推理步骤的特征，并在验证阶段与可疑模型计算 Kullback-Leibler 散度（KL 散度）。为保障 RAG 数据安全，Guo 等人 [ 218] 在知识文本中嵌入水印，使得模型在遇到验证问题时会生成带有正确答案的特定 CoT 痕迹，从而实现有效且无害的版权保护。除了水印方法，Savani 等人 [ 219] 提出了“反蒸馏采样”来防止模型生成的内容被用于训练。在解码时，该方法修改输出 logits 以最大化潜在训练损失，同时保持输出的正确性。在数学数据集 [ 28, 27] 上的实验验证了该方法的可行性：反蒸馏采样实现了与温度采样相当的准确率，而学生模型在 GSM8K [ 27] 上的性能下降了约 30%。这些技术共同为开发可靠且实用的 IP 保护机制奠定了基础。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Prompt-related Privacy<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font style="display:block" class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">7.2 与提示相关的隐私</font></font></font></h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S7.SS2.p1">
<p class="ltx_p">With the fast progress in large language models, the ability to infer private information from input prompts also gets stronger. Staab <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib362" title="">362</a>]</cite> was the first to research the privacy inference attack in large language models, drawing the result that LLMs are capable of inferring various personal attributes beyond memorization. Tömekçe <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib363" title="">363</a>]</cite> tested the inferring capability in the vision domain, demonstrated that the inference accuracy is positively related to the general capabilities of the models, and underscored the necessity of privacy protection methods. After the advent of CoT techniques, Green <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib220" title="">220</a>]</cite> evaluated the privacy leakage of reasoning models, claiming that the reasoning traces could disclose more private information. While additional reasoning steps may lead to more cautious final answers, they can inadvertently reveal sensitive data during intermediate generation, aligning with the findings discussed in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S7.SS1" title="7.1 Model-related Privacy ‣ 7 Privacy ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">7.1</span></a>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib213" title="">213</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib214" title="">214</a>]</cite>. Luo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib221" title="">221</a>]</cite> curated a benchmark to evaluate the attribute inference attack of vision-language models, finding that multi-model large reasoning models have strong capabilities of inferring geological information in input images, while seldom limiting this feature. Based on these findings, they proposed GeoMiner to trigger location-related attribute inference attacks. Such a method achieved higher performance than simple CoT methods, urging the need for protection.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">随着大型语言模型的快速发展，从输入提示中推断私人信息的能力也在增强。Staab 等人[362]首次研究了大型语言模型中的隐私推断攻击，得出结论认为 LLMs 能够推断出记忆之外的各种个人属性。Tömekçe 等人[363]测试了视觉领域的推断能力，表明推断准确性与模型的一般能力呈正相关，并强调了隐私保护方法的必要性。CoT 技术出现后，Green 等人[220]评估了推理模型的隐私泄露情况，声称推理轨迹可能泄露更多私人信息。虽然额外的推理步骤可能导致更谨慎的最终答案，但在中间生成过程中可能会无意中泄露敏感数据，这与第 7.1 节[213, 214]中讨论的发现一致。Luo 等人 [ 221] 设计了一个基准来评估视觉语言模型的属性推理攻击，发现多模型大型推理模型在输入图像中推断地质信息的能力很强，而很少限制这一功能。基于这些发现，他们提出了 GeoMiner 来触发与位置相关的属性推理攻击。 这种方法比简单的思维链方法性能更高，促使了保护的需求。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS2.p2">
<p class="ltx_p">With a similar logic to develop defense methods against Jailbreak in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4" title="4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>, the defense of attribute inference attacks also includes prompting, post-training, and guardrails. However, experiments by Staab <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib362" title="">362</a>]</cite> showed limited privacy gains from client-side anonymization or alignment. Such a vulnerability is also supported by Luo <span class="ltx_text ltx_font_italic">et&nbsp;al.</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib221" title="">221</a>]</cite>, stating that current SoTA guardrails cannot identify such an attack, and padding system prompts with warnings on location leakage could sacrifice the general performance. To summarize, more future works are needed to defend against this escalating threat.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">与第 4 节中针对 Jailbreak 防御方法开发的类似逻辑一样，属性推理攻击的防御也包括提示、后训练和护栏。然而，Staab 等人[ 362]的实验表明，客户端匿名化或对齐带来的隐私收益有限。这种漏洞也得到了 Luo 等人[ 221]的支持，他们指出当前的顶尖护栏无法识别此类攻击，并且用关于位置泄露的警告填充系统提示可能会牺牲整体性能。总而言之，未来需要更多工作来防御这种日益增长的威胁。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Future Research Directions<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">8 未来研究方向</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S8.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Standard measurements of faithfulness.</span>
A wide range of methods have been proposed to evaluate reasoning faithfulness, but none are comprehensive, often leading to divergent or even contradictory conclusions.
For example, some studies argue that larger models exhibit greater faithfulness&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib85" title="">85</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib78" title="">78</a>]</cite>, while others contend that they are less faithful&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib79" title="">79</a>]</cite>.
This inconsistency highlights the need for more robust and standardized evaluation protocols that can fairly assess reasoning faithfulness across models.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">忠实度的标准测量方法。目前已有多种方法被提出用于评估推理的忠实度，但它们都不是全面的，常常导致不同的甚至相互矛盾的结果。例如，一些研究表明较大模型表现出更高的忠实度[ 85, 78]，而另一些研究则认为它们忠实度较低[ 79]。这种不一致性突显了需要更稳健和标准化的评估协议，以便公平地评估不同模型间的推理忠实度。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S8.p2">
<p class="ltx_p">In addition, some existing methods for evaluating faithfulness may conflict with other aspects of the performance of large models.
For example, one common evaluation technique involves CoT intervention methods.
These approaches test how perturbations to intermediate reasoning steps affect final answers.
Empirical findings suggest that stronger models can answer correctly even with the perturbed CoT, implying that their outputs may rely less on explicit reasoning traces and more on internalized knowledge.
From this, one might conclude that stronger models are less faithful, as their outputs do not depend transparently on the provided reasoning paths.
However, such a conclusion conflicts with robustness. Therefore, eliminating the evaluation bias caused by model performance remains a critical open problem.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">此外，一些现有的评估忠实性的方法可能与大型模型的其它性能方面产生冲突。例如，一种常见的评估技术涉及思维链干预方法。这些方法测试对中间推理步骤的扰动如何影响最终答案。实证研究表明，更强的模型即使在有扰动的思维链的情况下也能给出正确答案，这意味着它们的输出可能更依赖于内化的知识，而非明确的推理轨迹。由此，人们可能会得出更强的模型更不忠实的结论，因为它们的输出并不依赖于所提供的推理路径。然而，这样的结论与鲁棒性相冲突。因此，消除由模型性能引起的评估偏差仍然是一个关键的开问题。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S8.p3">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">More analyses on safety mechanism.</span> After reviewing attack and defense methods in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#S4" title="4 Safety ‣ A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>, we call for more studies on the safety mechanism. Previous works demonstrated the feasibility of post-training methods with an extra safety-related CoT dataset. However, heuristic insights into effective dataset construction remain limited, leaving many details, such as prompts for CoT distillation, data ratios across different sources, and the necessity of cold-start SFT, reliant on manual tuning and empirical intuition. Moreover, in terms of the safety tax, the empirical understanding of how reinforcement learning contributes to safety and alignment remains limited. For instance, it remains challenging to disentangle the extent to which performance gains stem from the learning algorithm itself (e.g., GRPO over DPO) versus the influence of higher-quality data, such as well-curated CoT examples. Some progress has been made in understanding the role of SFT versus RL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib364" title="">364</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib365" title="">365</a>]</cite>, and we encourage future work to further investigate the role and limits of RL in this context.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">对安全机制进行更多分析。在回顾了第 4 节的攻击与防御方法后，我们呼吁对安全机制进行更多研究。以往工作证明了使用额外的安全相关 CoT 数据集进行后训练方法的可行性。然而，对于有效数据集构建的有效启发式见解仍然有限，导致许多细节，如 CoT 蒸馏的提示、不同来源的数据比例以及冷启动 SFT 的必要性，仍依赖手动调优和经验直觉。此外，在安全代价方面，对强化学习如何促进安全和一致性方面的实证理解仍然有限。例如，区分性能提升程度是源于学习算法本身（如 GRPO 相对于 DPO）还是高质量数据（如精心策划的 CoT 示例）的影响仍然具有挑战性。在理解 SFT 与 RL 的作用方面已取得一些进展[364, 365]，我们鼓励未来工作进一步研究在此背景下的 RL 的作用和局限性。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S8.p4">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">More fine-grained benchmarks</span>.
As language models continue to grow in capability, there is an increasing need for safety evaluation benchmarks that can effectively reflect their evolving behaviors.
Current safety evaluation benchmarks are primarily based on a narrow set of related attack methods&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib244" title="">244</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib287" title="">287</a>, <a class="ltx_ref" href="https://arxiv.org/html/2509.03871v1#bib.bib288" title="">288</a>]</cite>, resulting in significant homogenization of data distribution. As a consequence, metrics such as ASR often exhibit extreme values. Besides, due to the inherent properties of generative models, the outputs may be sensitive to variations in temperature settings and prompt formulations, thereby impacting the reproducibility of experimental results. In this regard, we call for new benchmarks that are more discriminative, detailed, and robust. In addition, compared with the number of benchmarks in safety and robustness, evaluations on privacy inference and fairness have comparatively received less emphasis. These areas would benefit from increased focus in future work if more evaluations with comprehensive coverage, clear definitions, and diverse testing samples are developed.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">更细粒度的基准测试。随着语言模型能力的持续增长，对能够有效反映其不断变化行为的安全生产评估基准的需求日益增加。当前的安全生产评估基准主要基于一套狭窄的相关攻击方法[244, 287, 288]，导致数据分布出现显著同质化。因此，ASR 等指标往往表现出极端值。此外，由于生成模型的固有特性，其输出可能对温度设置和提示表述的变化敏感，从而影响实验结果的再现性。在这方面，我们呼吁开发更具区分度、更详细、更稳健的新基准。此外，与安全和鲁棒性基准的数量相比，隐私推理和公平性评估相对受到较少重视。如果未来开发更多具有全面覆盖、清晰定义和多样化测试样本的评估，这些领域将受益于更多的关注。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Conclusion<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">9 结论</font></font></font></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S9.p1">
<p class="ltx_p">In conclusion, this survey summarizes recent literature concerning trustworthiness in reasoning capabilities, providing a comprehensive overview with a clear taxonomy. With efforts on each topic, we describe the development of novel methods, point out prevailing conclusions, and highlight the related analysis as well as future opportunities. We believe that our comprehensive survey and structured taxonomy could offer a foundation for future research in building safer, more reliable models with reasoning capabilities.<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">总之，本综述总结了关于推理能力可信性的最新文献，提供了一个全面的概述和清晰的分类体系。在每个主题上，我们描述了新方法的发展，指出了主要结论，并强调了相关分析以及未来的机遇。我们相信，我们的全面综述和结构化分类体系可以为未来研究构建更安全、更可靠的推理模型提供基础。</font></font></font></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fengqing Jiang, Zhangchen Xu, Yuetai Li, Luyao Niu, Zhen Xiang, Bo&nbsp;Li, Bill&nbsp;Yuchen Lin, and Radha Poovendran.

</span>
<span class="ltx_bibblock">Safechain: Safety of language models with long chain-of-thought reasoning capabilities.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.12025</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chengda Lu, Xiaoyu Fan, Yu&nbsp;Huang, Rongwu Xu, Jijie Li, and Wei Xu.

</span>
<span class="ltx_bibblock">Does Chain-of-Thought Reasoning Really Reduce Harmfulness from Jailbreaking?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.17650</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zonghao Ying, Guangyi Zheng, Yongxin Huang, Deyue Zhang, Wenxin Zhang, Quanchen Zou, Aishan Liu, Xianglong Liu, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Towards understanding the safety boundaries of deepseek models: Evaluation and findings.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.15092</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kun Wang, Guibin Zhang, Zhenhong Zhou, Jiahao Wu, Miao Yu, Shiqian Zhao, Chenlong Yin, Jinhu Fu, Yibo Yan, Hanjun Luo, et&nbsp;al.

</span>
<span class="ltx_bibblock">A comprehensive survey in llm (-agent) full stack safety: Data, training and deployment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.15585</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhichen Dong, Zhanhui Zhou, Chao Yang, Jing Shao, and Yu&nbsp;Qiao.

</span>
<span class="ltx_bibblock">Attacks, defenses and evaluations for llm conversation safety: A survey.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NAACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dan Shi, Tianhao Shen, Yufei Huang, Zhigen Li, Yongqi Leng, Renren Jin, Chuang Liu, Xinwei Wu, Zishan Guo, Linhao Yu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Large language model safety: A holistic survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.17686</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te&nbsp;Gao, and Wangxiang Che.

</span>
<span class="ltx_bibblock">Towards reasoning era: A survey of long chain-of-thought for reasoning large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.09567</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fengli Xu, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, Jiahui Gong, Tianjian Ouyang, Fanjin Meng, et&nbsp;al.

</span>
<span class="ltx_bibblock">Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.09686</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaoye Qu, Yafu Li, Zhaochen Su, Weigao Sun, Jianhao Yan, Dongrui Liu, Ganqu Cui, Daizong Liu, Shuxian Liang, Junxian He, et&nbsp;al.

</span>
<span class="ltx_bibblock">A survey of efficient reasoning for large reasoning models: Language, multimodality, and beyond.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.21614</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yang Sui, Yu-Neng Chuang, Guanchu Wang, Jiamu Zhang, Tianyi Zhang, Jiayi Yuan, Hongyi Liu, Andrew Wen, Shaochen Zhong, Hanjie Chen, et&nbsp;al.

</span>
<span class="ltx_bibblock">Stop overthinking: A survey on efficient reasoning for large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.16419</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sicheng Feng, Gongfan Fang, Xinyin Ma, and Xinchao Wang.

</span>
<span class="ltx_bibblock">Efficient reasoning models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.10903</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haoyu Wang, Zeyu Qin, Li&nbsp;Shen, Xueqian Wang, Dacheng Tao, and Minhao Cheng.

</span>
<span class="ltx_bibblock">Safety Reasoning with Guidelines.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia&nbsp;Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et&nbsp;al.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.08774</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">The Claude 3 Model Family: Opus, Sonnet, Haiku, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et&nbsp;al.

</span>
<span class="ltx_bibblock">Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.12948</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V Le, Denny Zhou, et&nbsp;al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang&nbsp;Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xi&nbsp;Li, Yusen Zhang, Renze Lou, Chen Wu, and Jiaqi Wang.

</span>
<span class="ltx_bibblock">Chain-of-scrutiny: Detecting backdoor attacks for large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2406.05948</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et&nbsp;al.

</span>
<span class="ltx_bibblock">Openai o1 system card.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.16720</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jun Wang, Meng Fang, Ziyu Wan, Muning Wen, Jiachen Zhu, Anjie Liu, Ziqin Gong, Yan Song, Lei Chen, Lionel&nbsp;M Ni, et&nbsp;al.

</span>
<span class="ltx_bibblock">Openr: An open source framework for advanced reasoning with large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.09671</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiwei Qin, Xuefeng Li, Haoyang Zou, Yixiu Liu, Shijie Xia, Zhen Huang, Yixin Ye, Weizhe Yuan, Hector Liu, Yuanzhi Li, et&nbsp;al.

</span>
<span class="ltx_bibblock">O1 Replication Journey: A Strategic Progress Report–Part 1.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.18982</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhen Huang, Haoyang Zou, Xuefeng Li, Yixiu Liu, Yuxiang Zheng, Ethan Chern, Shijie Xia, Yiwei Qin, Weizhe Yuan, and Pengfei Liu.

</span>
<span class="ltx_bibblock">O1 Replication Journey–Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2411.16489</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhongzhen Huang, Gui Geng, Shengyi Hua, Zhen Huang, Haoyang Zou, Shaoting Zhang, Pengfei Liu, and Xiaofan Zhang.

</span>
<span class="ltx_bibblock">O1 Replication Journey–Part 3: Inference-time Scaling for Medical Reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.06458</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Di&nbsp;Zhang, Jianbo Wu, Jingdi Lei, Tong Che, Jiatong Li, Tong Xie, Xiaoshui Huang, Shufei Zhang, Marco Pavone, Yuqiang Li, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama-berry: Pairwise optimization for o1-like olympiad-level mathematical reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.02884</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cameron&nbsp;B Browne, Edward Powley, Daniel Whitehouse, Simon&nbsp;M Lucas, Peter&nbsp;I Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis, and Simon Colton.

</span>
<span class="ltx_bibblock">A survey of monte carlo tree search methods.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">IEEE Transactions on Computational Intelligence and AI in games</span>, pages 1–43, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.

</span>
<span class="ltx_bibblock">Training Verifiers to Solve Math Word Problems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2110.14168</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring mathematical problem solving with the math dataset.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS D&amp;B Track</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Minpeng Liao, Wei Luo, Chengxi Li, Jing Wu, and Kai Fan.

</span>
<span class="ltx_bibblock">MARIO: MAth Reasoning with code Interpreter Output–A Reproducible Pipeline.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. ACL</span>, page 905–924, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher&nbsp;D Manning, Stefano Ermon, and Chelsea Finn.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1707.06347</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK&nbsp;Li, Y&nbsp;Wu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Deepseekmath: Pushing the limits of mathematical reasoning in open language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.03300</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian&nbsp;R Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, and Tom Goldstein.

</span>
<span class="ltx_bibblock">Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.05171</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, and Yuandong Tian.

</span>
<span class="ltx_bibblock">Training large language models to reason in a continuous latent space.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICLR Workshop on LLM Reason and Plan</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et&nbsp;al.

</span>
<span class="ltx_bibblock">Deepseek-v3 technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.19437</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A&nbsp;Yang Qwen, Baosong Yang, B&nbsp;Zhang, B&nbsp;Hui, B&nbsp;Zheng, B&nbsp;Yu, Chengpeng Li, D&nbsp;Liu, F&nbsp;Huang, H&nbsp;Wei, et&nbsp;al.

</span>
<span class="ltx_bibblock">Qwen2.5 technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et&nbsp;al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv e-prints</span>, pages arXiv–2407, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, Lisa Wang, Antonia Creswell, Geoffrey Irving, and Irina Higgins.

</span>
<span class="ltx_bibblock">Solving math word problems with process-and outcome-based feedback.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.14275</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah&nbsp;D Goodman.

</span>
<span class="ltx_bibblock">Star: Self-taught reasoner bootstrapping reasoning with reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, volume 1126, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe.

</span>
<span class="ltx_bibblock">Let’s verify step by step.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester James&nbsp;V Miranda, Alisa Liu, Nouha Dziri, Shane Lyu, et&nbsp;al.

</span>
<span class="ltx_bibblock">T<math alttext="\backslash" class="ltx_Math" display="inline" id="bib.bib41.m1"><semantics><mo>\</mo><annotation encoding="application/x-tex">\backslash</annotation></semantics></math>" ulu 3: Pushing frontiers in open language model post-training.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2411.15124</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Youssef Mroueh.

</span>
<span class="ltx_bibblock">Reinforcement Learning with Verifiable Rewards: GRPO’s Effective Loss, Dynamics, and Success Amplification.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.06639</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yunxin Li, Zhenyu Liu, Zitao Li, Xuanyu Zhang, Zhenran Xu, Xinyu Chen, Haoyuan Shi, Shenyuan Jiang, Xintong Wang, Jifang Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Perception, reason, think, and plan: A survey on large multimodal reasoning models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.04921</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yaoting Wang, Shengqiong Wu, Yuecheng Zhang, Shuicheng Yan, Ziwei Liu, Jiebo Luo, and Hao Fei.

</span>
<span class="ltx_bibblock">Multimodal chain-of-thought reasoning: A comprehensive survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.12605</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhuosheng Zhang, Aston Zhang, Mu&nbsp;Li, Hai Zhao, George Karypis, and Alex Smola.

</span>
<span class="ltx_bibblock">Multimodal chain-of-thought reasoning in language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Transactions on Machine Learning Research</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hao Fei, Shengqiong Wu, Wei Ji, Hanwang Zhang, Meishan Zhang, Mong-Li Lee, and Wynne Hsu.

</span>
<span class="ltx_bibblock">Video-of-thought: Step-by-step video reasoning from perception to cognition.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haojie Zheng, Tianyang Xu, Hanchi Sun, Shu Pu, Ruoxi Chen, and Lichao Sun.

</span>
<span class="ltx_bibblock">Thinking before looking: Improving multimodal llm reasoning via mitigating visual hallucination.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2411.12591</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guowei Xu, Peng Jin, Li&nbsp;Hao, Yibing Song, Lichao Sun, and Li&nbsp;Yuan.

</span>
<span class="ltx_bibblock">Llava-o1: Let vision language models reason step-by-step.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2411.10440</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Omkar Thawakar, Dinura Dissanayake, Ketan More, Ritesh Thawkar, Ahmed Heakl, Noor Ahsan, Yuhao Li, Mohammed Zumri, Jean Lahoud, Rao&nbsp;Muhammad Anwer, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llamav-o1: Rethinking step-by-step visual reasoning in llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.06186</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haotian Xu, Xing Wu, Weinong Wang, Zhongzhi Li, Da&nbsp;Zheng, Boyuan Chen, Yi&nbsp;Hu, Shijia Kang, Jiaming Ji, Yingying Zhang, et&nbsp;al.

</span>
<span class="ltx_bibblock">RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.11284</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Huanjin Yao, Jiaxing Huang, Wenhao Wu, Jingyi Zhang, Yibo Wang, Shunyu Liu, Yingjie Wang, Yuxin Song, Haocheng Feng, Li&nbsp;Shen, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mulberry: Empowering mllm with o1-like reasoning and reflection via collective monte carlo tree search.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.18319</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, and Yiming Yang.

</span>
<span class="ltx_bibblock">Improve vision language model chain-of-thought reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.16198</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuhao Dong, Zuyan Liu, Hai-Long Sun, Jingkang Yang, Winston Hu, Yongming Rao, and Ziwei Liu.

</span>
<span class="ltx_bibblock">Insight-v: Exploring long-chain visual reasoning with multimodal large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. CVPR</span>, pages 9062–9072, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jarvis Guo, Tuney Zheng, Yuelin Bai, Bo&nbsp;Li, Yubo Wang, King Zhu, Yizhi Li, Graham Neubig, Wenhu Chen, and Xiang Yue.

</span>
<span class="ltx_bibblock">Mammoth-vl: Eliciting multimodal reasoning with instruction tuning at scale.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.05237</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Linzhuang Sun, Hao Liang, Jingxuan Wei, Bihui Yu, Tianpeng Li, Fan Yang, Zenan Zhou, and Wentao Zhang.

</span>
<span class="ltx_bibblock">Mm-verify: Enhancing multimodal reasoning with chain-of-thought verification.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.13383</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaoxue Cheng, Junyi Li, Wayne&nbsp;Xin Zhao, and Ji-Rong Wen.

</span>
<span class="ltx_bibblock">Think More, Hallucinate Less: Mitigating Hallucinations via Dual Process of Fast and Slow Thinking.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.01306</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shayan&nbsp;Ali Akbar, Md&nbsp;Mosharaf Hossain, Tess Wood, Si-Chi Chin, Erica&nbsp;M Salinas, Victor Alvarez, and Erwin Cornejo.

</span>
<span class="ltx_bibblock">HalluMeasure: Fine-grained hallucination measurement using chain-of-thought reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. EMNLP</span>, pages 15020–15037, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ron Eliav, Arie Cattan, Eran Hirsch, Shahaf Bassan, Elias Stengel-Eskin, Mohit Bansal, and Ido Dagan.

</span>
<span class="ltx_bibblock">CLATTER: Comprehensive Entailment Reasoning for Hallucination Detection.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.05243</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zikai Xie.

</span>
<span class="ltx_bibblock">Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2408.05093</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qiong Wu, Xiangcong Yang, Yiyi Zhou, Chenxin Fang, Baiyang Song, Xiaoshuai Sun, and Rongrong Ji.

</span>
<span class="ltx_bibblock">Grounded chain-of-thought for multimodal large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.12799</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Jiang, Jiawei Chen, Dingkang Yang, Mingcheng Li, Shunli Wang, Tong Wu, Ke&nbsp;Li, and Lihua Zhang.

</span>
<span class="ltx_bibblock">CoMT: Chain-of-Medical-Thought Reduces Hallucination in Medical Report Generation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICASSP</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bowen Dong, Minheng Ni, Zitong Huang, Guanglei Yang, Wangmeng Zuo, and Lei Zhang.

</span>
<span class="ltx_bibblock">MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.24238</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Linxin Song, Taiwei Shi, and Jieyu Zhao.

</span>
<span class="ltx_bibblock">The Hallucination Tax of Reinforcement Finetuning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.13988</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chengzhi Liu, Zhongxing Xu, Qingyue Wei, Juncheng Wu, James Zou, Xin&nbsp;Eric Wang, Yuyin Zhou, and Sheng Liu.

</span>
<span class="ltx_bibblock">More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.21523</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zijun Yao, Yantao Liu, Yanxu Chen, Jianhui Chen, Junfeng Fang, Lei Hou, Juanzi Li, and Tat-Seng Chua.

</span>
<span class="ltx_bibblock">Are Reasoning Models More Prone to Hallucination?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.23646</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Polina Kirichenko, Mark Ibrahim, Kamalika Chaudhuri, and Samuel&nbsp;J Bell.

</span>
<span class="ltx_bibblock">AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.09038</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haolang Lu, Yilian Liu, Jingxin Xu, Guoshun Nan, Yuanlong Yu, Zhican Chen, and Kun Wang.

</span>
<span class="ltx_bibblock">Auditing Meta-Cognitive Hallucinations in Reasoning Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.13143</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junyi Li and Hwee&nbsp;Tou Ng.

</span>
<span class="ltx_bibblock">The Hallucination Dilemma: Factuality-Aware Reinforcement Learning for Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.24630</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dang&nbsp;Hoang Anh, Vu&nbsp;Tran, and Le&nbsp;Minh Nguyen.

</span>
<span class="ltx_bibblock">Analyzing Logical Fallacies in Large Language Models: A Study on Hallucination in Mathematical Reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">JSAI International Symposium on Artificial Intelligence</span>, pages 179–195. Springer, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhongxiang Sun, Qipeng Wang, Haoyu Wang, Xiao Zhang, and Jun Xu.

</span>
<span class="ltx_bibblock">Detection and Mitigation of Hallucination in Large Reasoning Models: A Mechanistic Perspective.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.12886</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dadi Guo, Jiayu Liu, Zhiyuan Fan, Zhitao He, Haoran Li, Yumeng Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.17114</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ruosen Li, Ziming Luo, and Xinya Du.

</span>
<span class="ltx_bibblock">Fine-grained Hallucination Detection and Mitigation in Language Model Mathematical Reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.06304</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anqi Zhang, Yulin Chen, Jane Pan, Chen Zhao, Aurojit Panda, Jinyang Li, and He&nbsp;He.

</span>
<span class="ltx_bibblock">Reasoning Models Know When They’re Right: Probing Hidden States for Self-Verification.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.05419</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Changyue Wang, Weihang Su, Qingyao Ai, and Yiqun Liu.

</span>
<span class="ltx_bibblock">Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.04832</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, et&nbsp;al.

</span>
<span class="ltx_bibblock">Measuring faithfulness in chain-of-thought reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.13702</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Miles Turpin, Julian Michael, Ethan Perez, and Samuel Bowman.

</span>
<span class="ltx_bibblock">Language models don’t always say what they think: Unfaithful explanations in chain-of-thought prompting.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Martin Tutek, Fateme&nbsp;Hashemi Chaleshtori, Ana Marasović, and Yonatan Belinkov.

</span>
<span class="ltx_bibblock">Measuring faithfulness of chains of thought by unlearning reasoning steps.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.14829</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zidi Xiong, Chen Shan, Zhenting Qi, and Himabindu Lakkaraju.

</span>
<span class="ltx_bibblock">Measuring the Faithfulness of Thinking Drafts in Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.13774</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Oliver Bentham, Nathan Stringham, and Ana Marasovic.

</span>
<span class="ltx_bibblock">Chain-of-Thought Unfaithfulness as Disguised Accuracy.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Transactions on Machine Learning Research</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Iván Arcuschin, Jett Janiak, Robert Krzyzanowski, Senthooran Rajamanoharan, Neel Nanda, and Arthur Conmy.

</span>
<span class="ltx_bibblock">Chain-of-thought reasoning in the wild is not always faithful.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.08679</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
James Chua and Owain Evans.

</span>
<span class="ltx_bibblock">Are DeepSeek R1 And Other Reasoning Models More Faithful?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICLR 2025 Workshop on Foundation Models in the Wild</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yanda Chen, Joe Benton, Ansh Radhakrishnan, Jonathan Uesato&nbsp;Carson Denison, John Schulman, Arushi Somani, Peter Hase, Misha Wagner Fabien Roger&nbsp;Vlad Mikulik, Sam Bowman, Jan Leike&nbsp;Jared Kaplan, et&nbsp;al.

</span>
<span class="ltx_bibblock">Reasoning Models Don’t Always Say What They Think.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Anthropic Research</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiachun Li, Pengfei Cao, Yubo Chen, Kang Liu, and Jun Zhao.

</span>
<span class="ltx_bibblock">Towards faithful chain-of-thought: Large language models are bridging reasoners.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2405.18915</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chirag Agarwal, Sree&nbsp;Harsha Tanneru, and Himabindu Lakkaraju.

</span>
<span class="ltx_bibblock">Faithfulness vs. plausibility: On the (un) reliability of explanations from large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.04614</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[85]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guangsheng Bao, Hongbo Zhang, Cunxiang Wang, Linyi Yang, and Yue Zhang.

</span>
<span class="ltx_bibblock">How Likely Do LLMs with CoT Mimic Human Reasoning?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. COLING</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[86]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sree&nbsp;Harsha Tanneru, Dan Ley, Chirag Agarwal, and Himabindu Lakkaraju.

</span>
<span class="ltx_bibblock">On the difficulty of faithful chain-of-thought reasoning in large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICML Workshop on TiFA</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[87]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Elita Lobo, Chirag Agarwal, and Himabindu Lakkaraju.

</span>
<span class="ltx_bibblock">On the impact of fine-tuning on chain-of-thought reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NAACL</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[88]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Debjit Paul, Robert West, Antoine Bosselut, and Boi Faltings.

</span>
<span class="ltx_bibblock">Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. EMNLP</span>, pages 15012–15032, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[89]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jundong Xu, Hao Fei, Liangming Pan, Qian Liu, Mong-Li Lee, and Wynne Hsu.

</span>
<span class="ltx_bibblock">Faithful logical reasoning via symbolic chain-of-thought.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[90]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ansh Radhakrishnan, Karina Nguyen, Anna Chen, Carol Chen, Carson Denison, Danny Hernandez, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamilė Lukošiūtė, et&nbsp;al.

</span>
<span class="ltx_bibblock">Question decomposition improves the faithfulness of model-generated reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.11768</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[91]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qing Lyu, Shreya Havaldar, Adam Stein, Li&nbsp;Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and Chris Callison-Burch.

</span>
<span class="ltx_bibblock">Faithful chain-of-thought reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. IJCNLP-AACL</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[92]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Liangming Pan, Alon Albalak, Xinyi Wang, and William&nbsp;Yang Wang.

</span>
<span class="ltx_bibblock">Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. EMNLP</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[93]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Erik Arakelyan, Pasquale Minervini, Pat Verga, Patrick Lewis, and Isabelle Augenstein.

</span>
<span class="ltx_bibblock">FLARE: Faithful Logic-Aided Reasoning and Exploration.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.11900</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[94]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joshua Ong&nbsp;Jun Leang, Aryo&nbsp;Pradipta Gema, and Shay&nbsp;B Cohen.

</span>
<span class="ltx_bibblock">CoMAT: Chain of mathematically annotated thought improves mathematical reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.10336</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiawei Wang, Da&nbsp;Cao, Shaofei Lu, Zhanchang Ma, Junbin Xiao, and Tat-Seng Chua.

</span>
<span class="ltx_bibblock">Causal-driven Large Language Models with Faithful Reasoning for Knowledge Question Answering.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. MM</span>, pages 4331–4340, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[96]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Minghe Gao, Shuang Chen, Liang Pang, Yuan Yao, Jisheng Dang, Wenqiao Zhang, Juncheng Li, Siliang Tang, Yueting Zhuang, and Tat-Seng Chua.

</span>
<span class="ltx_bibblock">Fact: Teaching mllms with faithful, concise and transferable rationales.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. MM</span>, pages 846–855, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[97]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Scott Viteri, Max Lamparth, Peter Chatain, and Clark Barrett.

</span>
<span class="ltx_bibblock">Markovian Transformers for Informative Language Modeling.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2404.18988</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[98]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Limin Han, Jiaojiao Zhao, Beibei Huang, Zhenhong Long, Junting Guo, Meijuan An, Rongjia Du, et&nbsp;al.

</span>
<span class="ltx_bibblock">Safety Evaluation and Enhancement of DeepSeek Models in Chinese Contexts.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.16529</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[99]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Miguel Romero-Arjona, Pablo Valle, Juan&nbsp;C Alonso, Ana&nbsp;B Sánchez, Miriam Ugarte, Antonia Cazalilla, Vicente Cambrón, José&nbsp;A Parejo, Aitor Arrieta, and Sergio Segura.

</span>
<span class="ltx_bibblock">Red Teaming Contemporary AI Models: Insights from Spanish and Basque Perspectives.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.10192</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[100]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kaiwen Zhou, Chengzhi Liu, Xuandong Zhao, Shreedhar Jangam, Jayanth Srinivasa, Gaowen Liu, Dawn Song, and Xin&nbsp;Eric Wang.

</span>
<span class="ltx_bibblock">The hidden risks of large reasoning models: A safety assessment of r1.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.12659</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[101]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ang Li, Yichuan Mo, Mingjie Li, Yifei Wang, and Yisen Wang.

</span>
<span class="ltx_bibblock">Are Smarter LLMs Safer? Exploring Safety-Reasoning Trade-offs in Prompting and Fine-Tuning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.09673</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[102]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xinyue Lou, You Li, Jinan Xu, Xiangyu Shi, Chi Chen, and Kaiyu Huang.

</span>
<span class="ltx_bibblock">Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.06538</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[103]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Paul Kassianik and Amin Karbasi.

</span>
<span class="ltx_bibblock">Evaluating Security Risk in DeepSeek and Other Frontier Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Cisco, https://blogs. cisco. com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoningmodels</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[104]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Arjun Krishna, Aaditya Rastogi, and Erick Galinkin.

</span>
<span class="ltx_bibblock">Weakest Link in the Chain: Security Vulnerabilities in Advanced Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.13726</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[105]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Christina&nbsp;Q Knight, Kaustubh Deshpande, Ved Sirdeshmukh, Meher Mankikar, Scale&nbsp;Red Team, SEAL Team, and Julian Michael.

</span>
<span class="ltx_bibblock">FORTRESS: Frontier Risk Evaluation for National Security and Public Safety.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.14922</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[106]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yihe Fan, Wenqi Zhang, Xudong Pan, and Min Yang.

</span>
<span class="ltx_bibblock">Evaluation Faking: Unveiling Observer Effects in Safety Evaluation of Frontier AI Systems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.17815</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[107]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Baihui Zheng, Boren Zheng, Kerui Cao, Yingshui Tan, Zhendong Liu, Weixun Wang, Jiaheng Liu, Jian Yang, Wenbo Su, Xiaoyong Zhu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Beyond Safe Answers: A Benchmark for Evaluating True Risk Awareness in Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.19690</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[108]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaoya Lu, Zeren Chen, Xuhao Hu, Yijin Zhou, Weichen Zhang, Dongrui Liu, Lu&nbsp;Sheng, and Jing Shao.

</span>
<span class="ltx_bibblock">IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.16402</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[109]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junfeng Fang, Yukai Wang, Ruipeng Wang, Zijun Yao, Kun Wang, An&nbsp;Zhang, Xiang Wang, and Tat-Seng Chua.

</span>
<span class="ltx_bibblock">SafeMLRM: Demystifying Safety in Multi-modal Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.08813</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[110]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Weixiang Zhao, Xingyu Sui, Jiahe Guo, Yulin Hu, Yang Deng, Yanyan Zhao, Bing Qin, Wanxiang Che, Tat-Seng Chua, and Ting Liu.

</span>
<span class="ltx_bibblock">Trade-offs in large reasoning models: An empirical analysis of deliberative and adaptive reasoning over foundational capabilities.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.17979</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[111]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sara&nbsp;Vera Marjanović, Arkil Patel, Vaibhav Adlakha, Milad Aghajohari, Parishad BehnamGhader, Mehar Bhatia, Aditi Khandelwal, Austin Kraft, Benno Krojer, Xing&nbsp;Han Lù, et&nbsp;al.

</span>
<span class="ltx_bibblock">DeepSeek-R1 Thoughtology: Let’s think about LLM Reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.07128</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[112]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mahdi Sabbaghi, Paul Kassianik, George Pappas, Yaron Singer, Amin Karbasi, and Hamed Hassani.

</span>
<span class="ltx_bibblock">Adversarial Reasoning at Jailbreaking Time.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[113]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jingbo Su.

</span>
<span class="ltx_bibblock">Enhancing Adversarial Attacks through Chain of Thought.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.21791</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[114]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zonghao Ying, Deyue Zhang, Zonglei Jing, Yisong Xiao, Quanchen Zou, Aishan Liu, Siyuan Liang, Xiangzheng Zhang, Xianglong Liu, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Reasoning-augmented conversation for multi-turn jailbreak attacks on large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.11054</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[115]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenhan Chang, Tianqing Zhu, Yu&nbsp;Zhao, Shuangyong Song, Ping Xiong, Wanlei Zhou, and Yongxiang Li.

</span>
<span class="ltx_bibblock">Chain-of-Lure: A Synthetic Narrative-Driven Approach to Compromise Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.17519</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[116]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Divij Handa, Zehua Zhang, Amir Saeidi, Shrinidhi Kumbhar, and Chitta Baral.

</span>
<span class="ltx_bibblock">When “competency" in reasoning opens the door to vulnerability: Jailbreaking llms via novel complex ciphers.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.10601</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[117]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Martin Kuo, Jianyi Zhang, Aolin Ding, Qinsi Wang, Louis DiValentin, Yujia Bao, Wei Wei, Hai Li, and Yiran Chen.

</span>
<span class="ltx_bibblock">H-cot: Hijacking the chain-of-thought safety reasoning mechanism to jailbreak large reasoning models, including openai o1/o3, deepseek-r1, and gemini 2.0 flash thinking.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.12893</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[118]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yang Yao, Xuan Tong, Ruofan Wang, Yixu Wang, Lujundong Li, Liang Liu, Yan Teng, and Yingchun Wang.

</span>
<span class="ltx_bibblock">A mousetrap: Fooling large reasoning models for jailbreak with chain of iterative chaos.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.15806</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[119]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiacheng Liang, Tanqiu Jiang, Yuhui Wang, Rongyi Zhu, Fenglong Ma, and Ting Wang.

</span>
<span class="ltx_bibblock">AutoRAN: Weak-to-Strong Jailbreaking of Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.10846</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[120]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Viet-Anh Nguyen, Shiqian Zhao, Gia Dao, Runyi Hu, Yi&nbsp;Xie, and Luu&nbsp;Anh Tuan.

</span>
<span class="ltx_bibblock">Three minds, one legend: Jailbreak large reasoning model with adaptive stacked ciphers.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.16241</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[121]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiawei Lian, Jianhong Pan, Lefan Wang, Yi&nbsp;Wang, Shaohui Mei, and Lap-Pui Chau.

</span>
<span class="ltx_bibblock">Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.05050</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[122]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yifei Liu, Yu&nbsp;Cui, and Haibin Zhang.

</span>
<span class="ltx_bibblock">RRTL: Red Teaming Reasoning Large Language Models in Tool Learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.17106</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[123]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bingrui Sima, Linhua Cong, Wenxuan Wang, and Kun He.

</span>
<span class="ltx_bibblock">VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.19684</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[124]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jingyuan Ma, Rui Li, Zheng Li, Junfeng Liu, Lei Sha, and Zhifang Sui.

</span>
<span class="ltx_bibblock">HauntAttack: When Attack Follows Reasoning as a Shadow.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.07031</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[125]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Liu, Hongcheng Gao, Shengfang Zhai, Jun Xia, Tianyi Wu, Zhiwei Xue, Yulin Chen, Kenji Kawaguchi, Jiaheng Zhang, and Bryan Hooi.

</span>
<span class="ltx_bibblock">GuardReasoner: Towards Reasoning-based LLM Safeguards.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.18492</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[126]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bibek Upadhayay, Vahid Behzadan, et&nbsp;al.

</span>
<span class="ltx_bibblock">X-Guard: Multilingual guard agent for content moderation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.08848</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[127]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yahan Yang, Soham Dan, Shuo Li, Dan Roth, and Insup Lee.

</span>
<span class="ltx_bibblock">MR. Guard: Multilingual Reasoning Guardrail using Curriculum Learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.15241</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[128]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jingnan Zheng, Xiangtian Ji, Yijun Lu, Chenhang Cui, Weixiang Zhao, Gelei Deng, Zhenkai Liang, An&nbsp;Zhang, and Tat-Seng Chua.

</span>
<span class="ltx_bibblock">RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.07736</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[129]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Makesh&nbsp;Narsimhan Sreedhar, Traian Rebedea, and Christopher Parisien.

</span>
<span class="ltx_bibblock">Safety Through Reasoning: An Empirical Study of Reasoning Guardrail Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.20087</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib130">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[130]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mintong Kang and Bo&nbsp;Li.

</span>
<span class="ltx_bibblock"><math alttext="R^{2}" class="ltx_Math" display="inline" id="bib.bib130.m1"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^{2}</annotation></semantics></math>-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib131">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[131]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ruoxi Cheng, Haoxuan Ma, Weixin Wang, Zhiqiang Wang, Xiaoshuang Jia, Simeng Qin, Xiaochun Cao, Yang Liu, and Xiaojun Jia.

</span>
<span class="ltx_bibblock">Inverse Reinforcement Learning with Dynamic Reward Scaling for LLM Alignment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.18991</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib132">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[132]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shiyao Cui, Qinglin Zhang, Xuan Ouyang, Renmiao Chen, Zhexin Zhang, Yida Lu, Hongning Wang, Han Qiu, and Minlie Huang.

</span>
<span class="ltx_bibblock">ShieldVLM: Safeguarding the Multimodal Implicit Toxicity via Deliberative Reasoning with LVLMs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.14035</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib133">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[133]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Liu, Shengfang Zhai, Mingzhe Du, Yulin Chen, Tri Cao, Hongcheng Gao, Cheng Wang, Xinfeng Li, Kun Wang, Junfeng Fang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Guardreasoner-vl: Safeguarding vlms via reinforced reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.11049</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib134">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[134]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhen Xiang, Linzhi Zheng, Yanjie Li, Junyuan Hong, Qinbin Li, Han Xie, Jiawei Zhang, Zidi Xiong, Chulin Xie, Carl Yang, et&nbsp;al.

</span>
<span class="ltx_bibblock">GuardAgent: Safeguard llm agents by a guard agent via knowledge-enabled reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2406.09187</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib135">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[135]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhaorun Chen, Mintong Kang, and Bo&nbsp;Li.

</span>
<span class="ltx_bibblock">ShieldAgent: Shielding agents via verifiable safety policy reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.22738</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib136">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[136]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yibin Wang, Zhimin Li, Yuhang Zang, Chunyu Wang, Qinglin Lu, Cheng Jin, and Jiaqi Wang.

</span>
<span class="ltx_bibblock">Unified multimodal chain-of-thought reward model through reinforcement fine-tuning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.03318</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib137">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[137]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fengjun Pan, Anh&nbsp;Tuan Luu, and Xiaobao Wu.

</span>
<span class="ltx_bibblock">Detecting Harmful Memes with Decoupled Understanding and Guided CoT Reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.08477</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib138">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[138]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tong Wu, Chong Xiang, Jiachen&nbsp;T Wang, and Prateek Mittal.

</span>
<span class="ltx_bibblock">Effectively Controlling Reasoning Models through Thinking Intervention.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.24370</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib139">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[139]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kureha Yamaguchi, Benjamin Etheridge, and Andy Arditi.

</span>
<span class="ltx_bibblock">Adversarial Manipulation of Reasoning Models using Internal Representations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">ICML 2025 Workshop on Reliable and Responsible Foundation Models</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib140">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[140]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wojciech Zaremba, Evgenia Nitishinskaya, Boaz Barak, Stephanie Lin, Sam Toyer, Yaodong Yu, Rachel Dias, Eric Wallace, Kai Xiao, Johannes Heidecke, et&nbsp;al.

</span>
<span class="ltx_bibblock">Trading inference-time compute for adversarial robustness.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.18841</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib141">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[141]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ruizhong Qiu, Gaotang Li, Tianxin Wei, Jingrui He, and Hanghang Tong.

</span>
<span class="ltx_bibblock">Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.06444</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib142">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[142]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhili Liu, Yunhao Gou, Kai Chen, Lanqing Hong, Jiahui Gao, Fei Mi, Yu&nbsp;Zhang, Zhenguo Li, Xin Jiang, Qun Liu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mixture of insightful experts (mote): The synergy of thought chains and expert mixtures in self-alignment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2405.00557</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib143">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[143]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiming Zhang, Jianfeng Chi, Hailey Nguyen, Kartikeya Upasani, Daniel&nbsp;M Bikel, Jason Weston, and Eric&nbsp;Michael Smith.

</span>
<span class="ltx_bibblock">Backtracking improves generation safety.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib144">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[144]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xianglin Yang, Gelei Deng, Jieming Shi, Tianwei Zhang, and Jin&nbsp;Song Dong.

</span>
<span class="ltx_bibblock">Enhancing Model Defense Against Jailbreaks with Proactive Safety Reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.19180</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib145">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[145]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junda Zhu, Lingyong Yan, Shuaiqiang Wang, Dawei Yin, and Lei Sha.

</span>
<span class="ltx_bibblock">Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.12970</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib146">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[146]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuyou Zhang, Miao Li, William Han, Yihang Yao, Zhepeng Cen, and Ding Zhao.

</span>
<span class="ltx_bibblock">Safety is Not Only About Refusal: Reasoning-Enhanced Fine-tuning for Interpretable LLM Safety.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.05021</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib147">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[147]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kehua Feng, Keyan Ding, Jing Yu, Menghan Li, Yuhao Wang, Tong Xu, Xinda Wang, Qiang Zhang, and Huajun Chen.

</span>
<span class="ltx_bibblock">ERPO: Advancing Safety Alignment via Ex-Ante Reasoning Preference Optimization.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.02725</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib148">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[148]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yutao Mou, Yuxiao Luo, Shikun Zhang, and Wei Ye.

</span>
<span class="ltx_bibblock">SaRO: Enhancing LLM Safety through Reasoning-based Alignment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.09420</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib149">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[149]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Taeyoun Kim, Fahim Tajwar, Aditi Raghunathan, and Aviral Kumar.

</span>
<span class="ltx_bibblock">Reasoning as an Adaptive Defense for Safety.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2507.00971</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib150">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[150]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Changyue Jiang, Xudong Pan, and Min Yang.

</span>
<span class="ltx_bibblock">Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.11063</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib151">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[151]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Changyi Li, Jiayi Wang, Xudong Pan, Geng Hong, and Min Yang.

</span>
<span class="ltx_bibblock">ReasoningShield: Content Safety Detection over Reasoning Traces of Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.17244</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib152">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[152]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Melody&nbsp;Y Guan, Manas Joglekar, Eric Wallace, Saachi Jain, Boaz Barak, Alec Helyar, Rachel Dias, Andrea Vallone, Hongyu Ren, Jason Wei, et&nbsp;al.

</span>
<span class="ltx_bibblock">Deliberative alignment: Reasoning enables safer language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.16339</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib153">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[153]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zijun Wang, Haoqin Tu, Yuhan Wang, Juncheng Wu, Jieru Mei, Brian&nbsp;R Bartoldson, Bhavya Kailkhura, and Cihang Xie.

</span>
<span class="ltx_bibblock">STAR-1: Safer Alignment of Reasoning LLMs with 1K Data.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.01903</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib154">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[154]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yichi Zhang, Zihao Zeng, Dongbai Li, Yao Huang, Zhijie Deng, and Yinpeng Dong.

</span>
<span class="ltx_bibblock">RealSafe-R1: Safety-Aligned DeepSeek-R1 without Compromising Reasoning Capability.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.10081</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib155">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[155]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wonje Jeung, Sangyeon Yoon, Minsuk Kahng, and Albert No.

</span>
<span class="ltx_bibblock">SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.14667</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib156">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[156]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenbin Hu, Haoran Li, Huihao Jing, Qi&nbsp;Hu, Ziqian Zeng, Sirui Han, Heli Xu, Tianshu Chu, Peizhao Hu, and Yangqiu Song.

</span>
<span class="ltx_bibblock">Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.14585</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib157">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[157]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bowen Baker, Joost Huizinga, Leo Gao, Zehao Dou, Melody&nbsp;Y Guan, Aleksander Madry, Wojciech Zaremba, Jakub Pachocki, and David Farhi.

</span>
<span class="ltx_bibblock">Monitoring reasoning models for misbehavior and the risks of promoting obfuscation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.11926</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib158">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[158]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhexin Zhang, Xian&nbsp;Qi Loye, Victor Shea-Jay Huang, Junxiao Yang, Qi&nbsp;Zhu, Shiyao Cui, Fei Mi, Lifeng Shang, Yingkang Wang, Hongning Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">How Should We Enhance the Safety of Large Reasoning Models: An Empirical Study.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.15404</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib159">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[159]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ruoxi Cheng, Haoxuan Ma, and Weixin Wang.

</span>
<span class="ltx_bibblock">Hair: Hardness-aware inverse reinforcement learning with introspective reasoning for llm alignment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.18991</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib160">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[160]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mickel Liu, Liwei Jiang, Yancheng Liang, Simon&nbsp;Shaolei Du, Yejin Choi, Tim Althoff, and Natasha Jaques.

</span>
<span class="ltx_bibblock">Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.07468</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib161">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[161]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim&nbsp;Furkan Tekin, Zachary Yahn, Yichang Xu, and Ling Liu.

</span>
<span class="ltx_bibblock">Safety tax: Safety alignment makes your large reasoning models less reasonable.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.00555</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib162">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[162]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kaiwen Zhou, Xuandong Zhao, Gaowen Liu, Jayanth Srinivasa, Aosong Feng, Dawn Song, and Xin&nbsp;Eric Wang.

</span>
<span class="ltx_bibblock">SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.16186</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib163">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[163]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Naizhu Jin, Zhong Li, Yinggang Guo, Chao Su, Tian Zhang, and Qingkai Zeng.

</span>
<span class="ltx_bibblock">SABER: Model-agnostic Backdoor Attack on Chain-of-Thought in Neural Code Generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.05829</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib164">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[164]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zihao Zhu, Hongbao Zhang, Ruotong Wang, Ke&nbsp;Xu, Siwei Lyu, and Baoyuan Wu.

</span>
<span class="ltx_bibblock">To Think or Not to Think: Exploring the Unthinking Vulnerability in Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.12202</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib165">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[165]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gejian Zhao, Hanzhou Wu, Xinpeng Zhang, and Athanasios&nbsp;V Vasilakos.

</span>
<span class="ltx_bibblock">Shadowcot: Cognitive hijacking for stealthy reasoning backdoors in llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.05605</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib166">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[166]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
James Chua, Jan Betley, Mia Taylor, and Owain Evans.

</span>
<span class="ltx_bibblock">Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.13206</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib167">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[167]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhen Xiang, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, and Bo&nbsp;Li.

</span>
<span class="ltx_bibblock">Badchain: Backdoor chain-of-thought prompting for large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib168">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[168]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yige Li, Hanxun Huang, Yunhan Zhao, Xingjun Ma, and Jun Sun.

</span>
<span class="ltx_bibblock">Backdoorllm: A comprehensive benchmark for backdoor attacks on large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2408.12798</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib169">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[169]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhen Guo and Reza Tourani.

</span>
<span class="ltx_bibblock">Darkmind: Latent chain-of-thought backdoor in customized llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.18617</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib170">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[170]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yu&nbsp;Cui, Bryan Hooi, Yujun Cai, and Yiwei Wang.

</span>
<span class="ltx_bibblock">Process or result? manipulated ending tokens can mislead reasoning llms to ignore the correct reasoning steps.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.19326</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib171">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[171]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiawei Guo and Haipeng Cai.

</span>
<span class="ltx_bibblock">System prompt poisoning: Persistent attacks on large language models beyond user injection.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.06493</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib172">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[172]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yu&nbsp;Cui and Cong Zuo.

</span>
<span class="ltx_bibblock">Practical Reasoning Interruption Attacks on Reasoning Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.06643</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib173">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[173]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yu&nbsp;Cui, Yujun Cai, and Yiwei Wang.

</span>
<span class="ltx_bibblock">Token-Efficient Prompt Injection Attack: Provoking Cessation in LLM Reasoning via Adaptive Token Compression.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.20493</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib174">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[174]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hongru Song, Yu-an Liu, Ruqing Zhang, Jiafeng Guo, and Yixing Fan.

</span>
<span class="ltx_bibblock">Chain-of-Thought Poisoning Attacks against R1-based Retrieval-Augmented Generation Systems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.16367</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib175">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[175]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ryan Marinelli, Josef Pichlmeier, and Tamas Bisztray.

</span>
<span class="ltx_bibblock">Harnessing Chain-of-Thought Metadata for Task Routing and Adversarial Prompt Detection.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.21464</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib176">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[176]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Naizhu Jin, Zhong Li, Tian Zhang, and Qingkai Zeng.

</span>
<span class="ltx_bibblock">GUARD: Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural Code Generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.21425</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib177">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[177]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qian Wang, Zhanzhi Lou, Zhenheng Tang, Nuo Chen, Xuandong Zhao, Wenxuan Zhang, Dawn Song, and Bingsheng He.

</span>
<span class="ltx_bibblock">Assessing Judging Bias in Large Reasoning Models: An Empirical Study.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.09946</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib178">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[178]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenxiao Wang, Parsa Hosseini, and Soheil Feizi.

</span>
<span class="ltx_bibblock">Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.20769</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib179">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[179]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kai Yan, Yufei Xu, Zhengyin Du, Xuesong Yao, Zheyu Wang, Xiaowen Guo, and Jiecao Chen.

</span>
<span class="ltx_bibblock">Recitation over Reasoning: How Cutting-Edge Language Models Can Fail on Elementary School-Level Reasoning Problems?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.00509</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib180">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[180]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haoyan Yang, Runxue Bao, Cao Xiao, Jun Ma, Parminder Bhatia, Shangqian Gao, and Taha Kass-Hout.

</span>
<span class="ltx_bibblock">Any Large Language Model Can Be a Reliable Judge: Debiasing with a Reasoning-based Bias Detector.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.17100</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib181">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[181]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuqing Wang and Yun Zhao.

</span>
<span class="ltx_bibblock">Rupbench: Benchmarking reasoning under perturbations for robustness evaluation in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2406.11020</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib182">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[182]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Norman Mu, Jonathan Lu, Michael Lavery, and David Wagner.

</span>
<span class="ltx_bibblock">A Closer Look at System Prompt Robustness.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.12197</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib183">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[183]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhaoyi Li, Xiaohan Zhao, Dong-Dong Wu, Jiacheng Cui, and Zhiqiang Shen.

</span>
<span class="ltx_bibblock">A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.10635</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib184">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[184]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bin Zhu, Hailong Yin, Jingjing Chen, and Yu-Gang Jiang.

</span>
<span class="ltx_bibblock">Reasoning Models Are More Easily Gaslighted Than You Think.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.09677</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib185">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[185]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhanke Zhou, Rong Tao, Jianing Zhu, Yiwen Luo, Zengmao Wang, and Bo&nbsp;Han.

</span>
<span class="ltx_bibblock">Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib186">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[186]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jingyu Peng, Maolin Wang, Xiangyu Zhao, Kai Zhang, Wanyu Wang, Pengyue Jia, Qidong Liu, Ruocheng Guo, and Qi&nbsp;Liu.

</span>
<span class="ltx_bibblock">Stepwise Reasoning Disruption Attack of LLMs.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACL</span>, pages 5040–5058, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib187">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[187]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiming Wang, Pei Zhang, Jialong Tang, Haoran Wei, Baosong Yang, Rui Wang, Chenshu Sun, Feitong Sun, Jiran Zhang, Junxuan Wu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Polymath: Evaluating mathematical reasoning in multilingual contexts.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.18428</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib188">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[188]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Meghana Rajeev, Rajkumar Ramamurthy, Prapti Trivedi, Vikas Yadav, Oluwanifemi Bamgbose, Sathwik&nbsp;Tejaswi Madhusudan, James Zou, and Nazneen Rajani.

</span>
<span class="ltx_bibblock">Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.01781</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib189">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[189]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tong Yu, Yongcheng Jing, Xikun Zhang, Wentao Jiang, Wenjie Wu, Yingjie Wang, Wenbin Hu, Bo&nbsp;Du, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Benchmarking reasoning robustness in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.04550</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib190">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[190]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kaixuan Huang, Jiacheng Guo, Zihao Li, Xiang Ji, Jiawei Ge, Wenzhe Li, Yingqing Guo, Tianle Cai, Hui Yuan, Runzhe Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">MATH-Perturb: Benchmarking LLMs’ Math Reasoning Abilities against Hard Perturbations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.06453</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib191">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[191]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Man&nbsp;Ho Lam, Chaozheng Wang, Jen-tse Huang, and Michael&nbsp;R Lyu.

</span>
<span class="ltx_bibblock">CODECRASH: Stress Testing LLM Reasoning under Structural and Semantic Perturbations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.14119</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib192">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[192]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jaechul Roh, Varun Gandhi, Shivani Anilkumar, and Arin Garg.

</span>
<span class="ltx_bibblock">Chain-of-Code Collapse: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.06971</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib193">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[193]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rongwu Xu, Zehan Qi, and Wei Xu.

</span>
<span class="ltx_bibblock">Preemptive answer “attacks" on chain-of-thought reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. ACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib194">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[194]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jingyuan Ma, Damai Dai, Lei Sha, and Zhifang Sui.

</span>
<span class="ltx_bibblock">Large language models are unconscious of unreasonability in math problems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2403.19346</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib195">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[195]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Masoud Hashemi, Oluwanifemi Bamgbose, Sathwik&nbsp;Tejaswi Madhusudhan, Jishnu&nbsp;Sethumadhavan Nair, Aman Tiwari, and Vikas Yadav.

</span>
<span class="ltx_bibblock">Dnr bench: Benchmarking over-reasoning in reasoning llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.15793</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib196">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[196]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yancheng He, Shilong Li, Jiaheng Liu, Weixun Wang, Xingyuan Bu, Ge&nbsp;Zhang, Zhongyuan Peng, Zhaoxiang Zhang, Zhicheng Zheng, Wenbo Su, et&nbsp;al.

</span>
<span class="ltx_bibblock">Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACL</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib197">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[197]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chenrui Fan, Ming Li, Lichao Sun, and Tianyi Zhou.

</span>
<span class="ltx_bibblock">Missing Premise exacerbates Overthinking: Are Reasoning Models losing Critical Thinking Skill?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.06514</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib198">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[198]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wai&nbsp;Man Si, Mingjie Li, Michael Backes, and Yang Zhang.

</span>
<span class="ltx_bibblock">Excessive Reasoning Attack on Reasoning LLMs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.14374</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib199">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[199]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Wang, Qiuzhi Liu, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Linfeng Song, Dian Yu, Juntao Li, Zhuosheng Zhang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.18585</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib200">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[200]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jinyan Su, Jennifer Healey, Preslav Nakov, and Claire Cardie.

</span>
<span class="ltx_bibblock">Between underthinking and overthinking: An empirical study of reasoning length and correctness in llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.00127</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib201">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[201]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Renfei Dang, Shujian Huang, and Jiajun Chen.

</span>
<span class="ltx_bibblock">Internal Bias in Reasoning Models leads to Overthinking.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.16448</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib202">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[202]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Abhinav Kumar, Jaechul Roh, Ali Naseh, Marzena Karpinska, Mohit Iyyer, Amir Houmansadr, and Eugene Bagdasarian.

</span>
<span class="ltx_bibblock">Overthink: Slowdown attacks on reasoning llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.02542</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib203">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[203]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alejandro Cuadron, Dacheng Li, Wenjie Ma, Xingyao Wang, Yichuan Wang, Siyuan Zhuang, Shu Liu, Luis&nbsp;Gaspar Schroeder, Tian Xia, Huanzhi Mao, et&nbsp;al.

</span>
<span class="ltx_bibblock">The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.08235</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib204">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[204]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuying Li, Zhuo Li, Yuji Kosuga, and Victor Bian.

</span>
<span class="ltx_bibblock">Output Length Effect on DeepSeek-R1’s Safety in Forced Thinking.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.01923</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib205">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[205]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chung-En Sun, Ge&nbsp;Yan, and Tsui-Wei Weng.

</span>
<span class="ltx_bibblock">ThinkEdit: Interpretable Weight Editing to Mitigate Overly Short Thinking in Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.22048</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib206">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[206]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fangru Lin, Shaoguang Mao, Emanuele La&nbsp;Malfa, Valentin Hofmann, Adrian de&nbsp;Wynter, Xun Wang, Si-Qing Chen, Michael&nbsp;J Wooldridge, Janet&nbsp;B Pierrehumbert, and Furu Wei.

</span>
<span class="ltx_bibblock">Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACL</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib207">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[207]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaoqing Cheng, Hongying Zan, Lulu Kong, Jinwang Song, and Min Peng.

</span>
<span class="ltx_bibblock">Detection, Classification, and Mitigation of Gender Bias in Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.12527</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib208">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[208]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mahammed Kamruzzaman and Gene&nbsp;Louis Kim.

</span>
<span class="ltx_bibblock">Prompting techniques for reducing social bias in llms through system 1 and system 2 cognitive processes.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2404.17218</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib209">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[209]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Saloni Dash, Amélie Reymond, Emma&nbsp;S Spiro, and Aylin Caliskan.

</span>
<span class="ltx_bibblock">Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.20020</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib210">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[210]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shashank Gupta, Vaishnavi Shrivastava, Ameet Deshpande, Ashwin Kalyan, Peter Clark, Ashish Sabharwal, and Tushar Khot.

</span>
<span class="ltx_bibblock">Bias runs deep: Implicit reasoning biases in persona-assigned llms.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib211">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[211]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhiting Fan, Ruizhe Chen, and Zuozhu Liu.

</span>
<span class="ltx_bibblock">Biasguard: A reasoning-enhanced bias detection tool for large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. ACL</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib212">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[212]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Riccardo Cantini, Nicola Gabriele, Alessio Orsino, and Domenico Talia.

</span>
<span class="ltx_bibblock">Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2507.02799</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib213">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[213]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sangyeon Yoon, Wonje Jeung, and Albert No.

</span>
<span class="ltx_bibblock">R-tofu: Unlearning in large reasoning models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.15214</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib214">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[214]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Changsheng Wang, Chongyu Fan, Yihua Zhang, Jinghan Jia, Dennis Wei, Parikshit Ram, Nathalie Baracaldo, and Sijia Liu.

</span>
<span class="ltx_bibblock">Reasoning Model Unlearning: Forgetting Traces, Not Just Answers, While Preserving Reasoning Skills.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.12963</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib215">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[215]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yash Sinha, Manit Baser, Murari Mandal, Dinil&nbsp;Mon Divakaran, and Mohan Kankanhalli.

</span>
<span class="ltx_bibblock">Step-by-Step Reasoning Attack: Revealing ’Erased’ Knowledge in Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.17279</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib216">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[216]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peng Wanli, Xue Yiming, et&nbsp;al.

</span>
<span class="ltx_bibblock">ImF: Implicit Fingerprint for Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.21805</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib217">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[217]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhenzhen Ren, GuoBiao Li, Sheng Li, Zhenxing Qian, and Xinpeng Zhang.

</span>
<span class="ltx_bibblock">CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.16785</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib218">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[218]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junfeng Guo, Yiming Li, Ruibo Chen, Yihan Wu, Chenxi Liu, Yanshuo Chen, and Heng Huang.

</span>
<span class="ltx_bibblock">Towards copyright protection for knowledge bases of retrieval-augmented language models via ownership verification with reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.10440</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib219">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[219]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yash Savani, Asher Trockman, Zhili Feng, Avi Schwarzschild, Alexander Robey, Marc Finzi, and J&nbsp;Zico Kolter.

</span>
<span class="ltx_bibblock">Antidistillation sampling.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.13146</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib220">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[220]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tommaso Green, Martin Gubri, Haritz Puerto, Sangdoo Yun, and Seong&nbsp;Joon Oh.

</span>
<span class="ltx_bibblock">Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.15674</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib221">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[221]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Weidi Luo, Tianyu Lu, Qiming Zhang, Xiaogeng Liu, Bin Hu, Yue Zhao, Jieyu Zhao, Song Gao, Patrick McDaniel, Zhen Xiang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Doxing via the Lens: Revealing Location-related Privacy Leakage on Multi-modal Large Reasoning Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.19373</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib222">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[222]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Huang, Lichao Sun, Haoran Wang, Siyuan Wu, Qihui Zhang, Yuan Li, Chujie Gao, Yixin Huang, Wenhan Lyu, et&nbsp;al.

</span>
<span class="ltx_bibblock">TrustLLM: Trustworthiness in Large Language Models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib223">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[223]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et&nbsp;al.

</span>
<span class="ltx_bibblock">A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">ACM Transactions on Information Systems</span>, 43(2):1–55, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib224">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[224]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Vipula Rawte, Amit Sheth, and Amitava Das.

</span>
<span class="ltx_bibblock">A survey of hallucination in large foundation models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2309.05922</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib225">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[225]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiahao Cheng, Tiancheng Su, Jia Yuan, Guoxiu He, Jiawei Liu, Xinqi Tao, Jingwen Xie, and Huaxia Li.

</span>
<span class="ltx_bibblock">Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2506.17088</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib226">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[226]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar.

</span>
<span class="ltx_bibblock">Scaling llm test-time compute optimally can be more effective than scaling model parameters.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2408.03314</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib227">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[227]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed&nbsp;Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib228">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[228]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">Truthfulqa: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACL</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib229">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[229]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junyi Li, Xiaoxue Cheng, Wayne&nbsp;Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen.

</span>
<span class="ltx_bibblock">Halueval: A large-scale hallucination evaluation benchmark for large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. EMNLP</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib230">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[230]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qinyuan Cheng, Tianxiang Sun, Wenwei Zhang, Siyin Wang, Xiangyang Liu, Mozhi Zhang, Junliang He, Mianqiu Huang, Zhangyue Yin, Kai Chen, et&nbsp;al.

</span>
<span class="ltx_bibblock">Evaluating hallucinations in chinese large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.03368</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib231">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[231]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Nguyen Karina, Hyung&nbsp;Won Chung, Yunxin&nbsp;Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman, and William Fedus.

</span>
<span class="ltx_bibblock">Measuring short-form factuality in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2411.04368</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib232">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[232]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mandar Joshi, Eunsol Choi, Daniel&nbsp;S Weld, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1705.03551</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib233">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[233]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wei Li, Wenhao Wu, Moye Chen, Jiachen Liu, Xinyan Xiao, and Hua Wu.

</span>
<span class="ltx_bibblock">Faithfulness in natural language generation: A systematic survey of analysis, evaluation and optimization methods.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2203.05227</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib234">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[234]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alon Jacovi and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACL</span>, pages 4198–4205, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib235">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[235]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Evelyn Yee, Alice Li, Chenyu Tang, Yeon&nbsp;Ho Jung, Ramamohan Paturi, and Leon Bergen.

</span>
<span class="ltx_bibblock">Dissociation of faithful and unfaithful reasoning in llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2405.15092</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib236">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[236]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peter Hase, Shiyue Zhang, Harry Xie, and Mohit Bansal.

</span>
<span class="ltx_bibblock">Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. EMNLP</span>, pages 4351–4367, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib237">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[237]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ruiqi Zhang, Licong Lin, Yu&nbsp;Bai, and Song Mei.

</span>
<span class="ltx_bibblock">Negative preference optimization: From catastrophic collapse to effective unlearning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. COLM</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib238">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[238]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Judea Pearl.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Causality</span>.

</span>
<span class="ltx_bibblock">Cambridge university press, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib239">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[239]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cheng-Yu Hsieh, Chun-Liang Li, Chih-kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alex Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister.

</span>
<span class="ltx_bibblock">Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. ACL</span>, pages 8003–8017, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib240">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[240]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo&nbsp;Li, et&nbsp;al.

</span>
<span class="ltx_bibblock">Harmbench: A standardized evaluation framework for automated red teaming and robust refusal.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib241">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[241]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alexandra Souly, Qingyuan Lu, Dillon Bowen, Tu&nbsp;Trinh, Elvis Hsieh, Sana Pandey, Pieter Abbeel, Justin Svegliato, Scott Emmons, Olivia Watkins, et&nbsp;al.

</span>
<span class="ltx_bibblock">A strongreject for empty jailbreaks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS D&amp;B Track</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib242">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[242]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Zeng, Yu&nbsp;Yang, Andy Zhou, Jeffrey&nbsp;Ziwei Tan, Yuheng Tu, Yifan Mai, Kevin Klyman, Minzhou Pan, Ruoxi Jia, Dawn Song, et&nbsp;al.

</span>
<span class="ltx_bibblock">Air-bench 2024: A safety benchmark based on risk categories from regulations and policies.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2407.17436</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib243">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[243]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Seungju Han, Kavel Rao, Allyson Ettinger, Liwei Jiang, Bill&nbsp;Yuchen Lin, Nathan Lambert, Yejin Choi, and Nouha Dziri.

</span>
<span class="ltx_bibblock">WildGuard: Open One-stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS D&amp;B Track</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib244">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[244]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J&nbsp;Zico Kolter, and Matt Fredrikson.

</span>
<span class="ltx_bibblock">Universal and transferable adversarial attacks on aligned language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.15043</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib245">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[245]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George&nbsp;J Pappas, and Eric Wong.

</span>
<span class="ltx_bibblock">Jailbreaking black box large language models in twenty queries.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. SaTML</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib246">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[246]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anay Mehrotra, Manolis Zampetakis, Paul Kassianik, Blaine Nelson, Hyrum Anderson, Yaron Singer, and Amin Karbasi.

</span>
<span class="ltx_bibblock">Tree of attacks: Jailbreaking black-box llms automatically.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib247">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[247]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Google DeepMind.

</span>
<span class="ltx_bibblock">Gemini 2.0 Flash Thinking, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib248">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[248]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et&nbsp;al.

</span>
<span class="ltx_bibblock">Kimi k1.5: Scaling reinforcement learning with llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.12599</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib249">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[249]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
NovaSky Team.

</span>
<span class="ltx_bibblock">Sky-T1: Train your own O1 preview model within $450.

</span>
<span class="ltx_bibblock">https://novasky-ai.github.io/posts/sky-t1, 2025.

</span>
<span class="ltx_bibblock">Accessed: 2025-01-09.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib250">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[250]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qwen Team.

</span>
<span class="ltx_bibblock">QwQ-32B: Embracing the Power of Reinforcement Learning, March 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib251">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[251]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Skywork o1&nbsp;Team.

</span>
<span class="ltx_bibblock">Skywork-o1 Open Series.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Skywork" title="">https://huggingface.co/Skywork</a>, November 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib252">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[252]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Liwei Jiang, Kavel Rao, Seungju Han, Allyson Ettinger, Faeze Brahman, Sachin Kumar, Niloofar Mireshghallah, Ximing Lu, Maarten Sap, Yejin Choi, et&nbsp;al.

</span>
<span class="ltx_bibblock">Wildteaming at scale: From in-the-wild jailbreaks to (adversarially) safer language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib253">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[253]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shengye Wan, Cyrus Nikolaidis, Daniel Song, David Molnar, James Crnkovich, Jayson Grace, Manish Bhatt, Sahana Chennabasappa, Spencer Whitman, Stephanie Ding, et&nbsp;al.

</span>
<span class="ltx_bibblock">Cyberseceval 3: Advancing the evaluation of cybersecurity risks and capabilities in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2408.01605</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib254">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[254]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wenjing Zhang, Xuejiao Lei, Zhaoxiang Liu, Meijuan An, Bikun Yang, KaiKai Zhao, Kai Wang, and Shiguo Lian.

</span>
<span class="ltx_bibblock">Chisafetybench: A chinese hierarchical safety benchmark for large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2406.10311</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib255">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[255]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alexander Wei, Nika Haghtalab, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Jailbroken: How does llm safety training fail?

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib256">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[256]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Yang, Xiaoxuan He, Hongkun Pan, Xiyan Jiang, Yan Deng, Xingtao Yang, Haoyu Lu, Dacheng Yin, Fengyun Rao, Minfeng Zhu, et&nbsp;al.

</span>
<span class="ltx_bibblock">R1-onevision: Advancing generalized multimodal reasoning through cross-modal formalization.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.10615</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib257">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[257]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Peng, Xiaokun Wang, Yichen Wei, Jiangbo Pei, Weijie Qiu, Ai&nbsp;Jian, Yunzhuo Hao, Jiachun Pan, Tianyidan Xie, Li&nbsp;Ge, et&nbsp;al.

</span>
<span class="ltx_bibblock">Skywork r1v: Pioneering multimodal reasoning with chain-of-thought.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.05599</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib258">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[258]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yingzhe Peng, Gongrui Zhang, Miaosen Zhang, Zhiyuan You, Jie Liu, Qipeng Zhu, Kai Yang, Xingzhong Xu, Xin Geng, and Xu&nbsp;Yang.

</span>
<span class="ltx_bibblock">Lmm-r1: Empowering 3b lmms with strong reasoning abilities through two-stage rule-based rl.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.07536</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib259">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[259]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yunhao Gou, Kai Chen, Zhili Liu, Lanqing Hong, Hang Xu, Zhenguo Li, Dit-Yan Yeung, James&nbsp;T Kwok, and Yu&nbsp;Zhang.

</span>
<span class="ltx_bibblock">Eyes closed, safety on: Protecting multimodal llms via image-to-text transformation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ECCV</span>, pages 388–404, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib260">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[260]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yanbo Wang, Jiyang Guan, Jian Liang, and Ran He.

</span>
<span class="ltx_bibblock">Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.10000</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib261">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[261]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario Fritz.

</span>
<span class="ltx_bibblock">More than you’ve asked for: A comprehensive analysis of novel prompt injection threats to application-integrated large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.12173</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib262">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[262]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yueqi Xie, Jingwei Yi, Jiawei Shao, Justin Curl, Lingjuan Lyu, Qifeng Chen, Xing Xie, and Fangzhao Wu.

</span>
<span class="ltx_bibblock">Defending chatgpt against jailbreak attack via self-reminders.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, 5(12):1486–1496, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib263">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[263]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhexin Zhang, Junxiao Yang, Pei Ke, Fei Mi, Hongning Wang, and Minlie Huang.

</span>
<span class="ltx_bibblock">Defending large language models against jailbreaking attacks through goal prioritization.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib264">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[264]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zeming Wei, Yifei Wang, Ang Li, Yichuan Mo, and Yisen Wang.

</span>
<span class="ltx_bibblock">Jailbreak and guard aligned language models with only few in-context demonstrations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.06387</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib265">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[265]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen Xiong, Xiangyu Qi, Pin-Yu Chen, and Tsung-Yi Ho.

</span>
<span class="ltx_bibblock">Defensive Prompt Patch: A Robust and Generalizable Defense of Large Language Models against Jailbreak Attacks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. ACL</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib266">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[266]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xinyi Zeng, Yuying Shang, Jiawei Chen, Jingyuan Zhang, and Yu&nbsp;Tian.

</span>
<span class="ltx_bibblock">Root defence strategies: Ensuring safety of llm at the decoding level.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.06809</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib267">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[267]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bill&nbsp;Yuchen Lin, and Radha Poovendran.

</span>
<span class="ltx_bibblock">Safedecoding: Defending against jailbreak attacks via safety-aware decoding.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.08983</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib268">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[268]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Somnath Banerjee, Sayan Layek, Soham Tripathy, Shanu Kumar, Animesh Mukherjee, and Rima Hazra.

</span>
<span class="ltx_bibblock">Safeinfer: Context adaptive decoding time safety alignment for large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. AAAI</span>, pages 27188–27196, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib269">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[269]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi&nbsp;Dong, Ronghui Mu, Yanghao Zhang, Siqi Sun, Tianle Zhang, Changshun Wu, Gaojie Jin, Yi&nbsp;Qi, Jinwei Hu, Jie Meng, et&nbsp;al.

</span>
<span class="ltx_bibblock">Safeguarding large language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2406.02622</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib270">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[270]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer, Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama guard: Llm-based input-output safeguard for human-ai conversations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2312.06674</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib271">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[271]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jianfeng Chi, Ujjwal Karn, Hongyuan Zhan, Eric Smith, Javier Rando, Yiming Zhang, Kate Plawiak, Zacharie&nbsp;Delpierre Coudert, Kartikeya Upasani, and Mahesh Pasupuleti.

</span>
<span class="ltx_bibblock">Llama guard 3 vision: Safeguarding human-ai image understanding conversations.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2411.10414</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib272">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[272]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
llama Team.

</span>
<span class="ltx_bibblock">Llama 3.2: Revolutionizing edge AI and vision with open, customizable models.

</span>
<span class="ltx_bibblock">https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-09-25.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib273">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[273]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhichao Wang, Bin Bi, Shiva&nbsp;Kumar Pentyala, Kiran Ramnath, Sougata Chaudhuri, Shubham Mehrotra, Xiang-Bo Mao, Sitaram Asur, et&nbsp;al.

</span>
<span class="ltx_bibblock">A comprehensive survey of LLM alignment techniques: RLHF, RLAIF, PPO, DPO and more.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2407.16216</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib274">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[274]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib275">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[275]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training a helpful and harmless assistant with reinforcement learning from human feedback.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2204.05862</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib276">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[276]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, Johan Ferret, Kellie Lu, Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, et&nbsp;al.

</span>
<span class="ltx_bibblock">Rlaif vs. rlhf: Scaling reinforcement learning from human feedback with ai feedback.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib277">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[277]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi Zhang, Ce&nbsp;Bian, Boyuan Chen, Ruiyang Sun, Yizhou Wang, and Yaodong Yang.

</span>
<span class="ltx_bibblock">Beavertails: Towards improved safety alignment of llm via a human-preference dataset.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib278">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[278]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaming Ji, Donghai Hong, Borong Zhang, Boyuan Chen, Josef Dai, Boren Zheng, Tianyi Qiu, Boxun Li, and Yaodong Yang.

</span>
<span class="ltx_bibblock">PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ACL</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib279">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[279]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yongshuo Zong, Ondrej Bohdal, Tingyang Yu, Yongxin Yang, and Timothy Hospedales.

</span>
<span class="ltx_bibblock">Safety fine-tuning at (almost) no cost: A baseline for vision large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib280">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[280]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Edward&nbsp;J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu&nbsp;Wang, Weizhu Chen, et&nbsp;al.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib281">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[281]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Patrick Chao, Edoardo Debenedetti, Alexander Robey, Maksym Andriushchenko, Francesco Croce, Vikash Sehwag, Edgar Dobriban, Nicolas Flammarion, George&nbsp;J Pappas, Florian Tramer, et&nbsp;al.

</span>
<span class="ltx_bibblock">Jailbreakbench: An open robustness benchmark for jailbreaking large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib282">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[282]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yichi Zhang, Siyuan Zhang, Yao Huang, Zeyu Xia, Zhengwei Fang, Xiao Yang, Ranjie Duan, Dong Yan, Yinpeng Dong, and Jun Zhu.

</span>
<span class="ltx_bibblock">STAIR: Improving Safety Alignment with Introspective Reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.02384</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib283">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[283]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lijun Li, Bowen Dong, Ruohui Wang, Xuhao Hu, Wangmeng Zuo, Dahua Lin, Yu&nbsp;Qiao, and Jing Shao.

</span>
<span class="ltx_bibblock">Salad-bench: A hierarchical and comprehensive safety benchmark for large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. ACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib284">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[284]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah.

</span>
<span class="ltx_bibblock">Orca: Progressive learning from complex explanation traces of gpt-4.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.02707</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib285">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[285]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zi&nbsp;Lin, Zihan Wang, Yongqi Tong, Yangkun Wang, Yuxin Guo, Yujia Wang, and Jingbo Shang.

</span>
<span class="ltx_bibblock">Toxicchat: Unveiling hidden challenges of toxicity detection in real-world user-ai conversation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. EMNLP</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib286">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[286]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tinghao Xie, Xiangyu Qi, Yi&nbsp;Zeng, Yangsibo Huang, Udari&nbsp;Madhushani Sehwag, Kaixuan Huang, Luxi He, Boyi Wei, Dacheng Li, Ying Sheng, et&nbsp;al.

</span>
<span class="ltx_bibblock">Sorry-bench: Systematically evaluating large language model safety refusal behaviors.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib287">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[287]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Paul Röttger, Hannah&nbsp;Rose Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, and Dirk Hovy.

</span>
<span class="ltx_bibblock">Xstest: A test suite for identifying exaggerated safety behaviours in large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NAACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib288">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[288]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Weidi Luo, Siyuan Ma, Xiaogeng Liu, Xiaoyu Guo, and Chaowei Xiao.

</span>
<span class="ltx_bibblock">JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. COLM</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib289">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[289]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Self-refine: Iterative refinement with self-feedback.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib290">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[290]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bertie Vidgen, Nino Scherrer, Hannah&nbsp;Rose Kirk, Rebecca Qian, Anand Kannappan, Scott&nbsp;A Hale, and Paul Röttger.

</span>
<span class="ltx_bibblock">Simplesafetytests: a test suite for identifying critical safety risks in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2311.08370</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib291">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[291]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mazeika Mantas, Zou Andy, Mu&nbsp;Norman, Phan Long, Wang Zifan, Yu&nbsp;Chunru, Khoja Adam, Jiang Fengqing, O’Gara Aidan, Sakhaee Ellie, Xiang Zhen, Rajabi Arezoo, Hendrycks Dan, Poovendran Radha, Li&nbsp;Bo, and Forsyth David.

</span>
<span class="ltx_bibblock">Tdc 2023 (llm edition): The trojan detection challenge.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS Competition Track</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib292">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[292]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Simone Tedeschi, Felix Friedrich, Patrick Schramowski, Kristian Kersting, Roberto Navigli, Huu Nguyen, and Bo&nbsp;Li.

</span>
<span class="ltx_bibblock">ALERT: A Comprehensive Benchmark for Assessing Large Language Models’ Safety through Red Teaming.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2404.08676</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib293">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[293]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tianyu Yu, Yuan Yao, Haoye Zhang, Taiwen He, Yifeng Han, Ganqu Cui, Jinyi Hu, Zhiyuan Liu, Hai-Tao Zheng, Maosong Sun, et&nbsp;al.

</span>
<span class="ltx_bibblock">Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. CVPR</span>, pages 13807–13816, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib294">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[294]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhiqing Sun, Sheng Shen, Shengcao Cao, Haotian Liu, Chunyuan Li, Yikang Shen, Chuang Gan, Liang-Yan Gui, Yu-Xiong Wang, Yiming Yang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Aligning large multimodal models with factually augmented rlhf.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. ACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib295">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[295]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lei Li, Zhihui Xie, Mukai Li, Shunian Chen, Peiyi Wang, Liang Chen, Yazheng Yang, Benyou Wang, Lingpeng Kong, and Qi&nbsp;Liu.

</span>
<span class="ltx_bibblock">VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. EMNLP</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib296">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[296]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaming Ji, Xinyu Chen, Rui Pan, Han Zhu, Conghui Zhang, Jiahao Li, Donghai Hong, Boyuan Chen, Jiayi Zhou, Kaile Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Safe RLHF-V: Safe Reinforcement Learning from Human Feedback in Multimodal Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.17682</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib297">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[297]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yi-Fan Zhang, Tao Yu, Haochen Tian, Chaoyou Fu, Peiyan Li, Jianshu Zeng, Wulin Xie, Yang Shi, Huanyu Zhang, Junkang Wu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mm-rlhf: The next step forward in multimodal llm alignment.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib298">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[298]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ian&nbsp;J Goodfellow, Jonathon Shlens, and Christian Szegedy.

</span>
<span class="ltx_bibblock">Explaining and harnessing adversarial examples.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1412.6572</span>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib299">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[299]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yong Lin, Hangyu Lin, Wei Xiong, Shizhe Diao, Jianmeng Liu, Jipeng Zhang, Rui Pan, Haoxiang Wang, Wenbin Hu, Hanning Zhang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mitigating the alignment tax of rlhf.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. EMNLP</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib300">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[300]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ondřej Bojar, Christian Buck, Christian Federmann, Barry Haddow, Philipp Koehn, Johannes Leveling, Christof Monz, Pavel Pecina, Matt Post, Herve Saint-Amand, et&nbsp;al.

</span>
<span class="ltx_bibblock">Findings of the 2014 workshop on statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the ninth workshop on statistical machine translation</span>, pages 12–58, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib301">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[301]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Robin Jia, and Percy Liang.

</span>
<span class="ltx_bibblock">Know what you don’t know: Unanswerable questions for SQuAD.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1806.03822</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib302">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[302]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning challenge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1803.05457</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib303">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[303]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiming Li, Yong Jiang, Zhifeng Li, and Shu-Tao Xia.

</span>
<span class="ltx_bibblock">Backdoor learning: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</span>, 35(1):5–22, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib304">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[304]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiyang Guan, Zhuozhuo Tu, Ran He, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Few-shot backdoor defense using shapley estimation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. CVPR</span>, pages 13358–13367, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib305">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[305]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiyang Guan, Jian Liang, and Ran He.

</span>
<span class="ltx_bibblock">Backdoor defense via test-time detecting and repairing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. CVPR</span>, pages 24564–24573, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib306">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[306]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Evan Hubinger, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte MacDiarmid, Tamera Lanham, Daniel&nbsp;M Ziegler, Tim Maxwell, Newton Cheng, et&nbsp;al.

</span>
<span class="ltx_bibblock">Sleeper agents: Training deceptive llms that persist through safety training.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2401.05566</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib307">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[307]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiashu Xu, Mingyu&nbsp;Derek Ma, Fei Wang, Chaowei Xiao, and Muhao Chen.

</span>
<span class="ltx_bibblock">Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NAACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib308">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[308]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiawen Shi, Yixin Liu, Pan Zhou, and Lichao Sun.

</span>
<span class="ltx_bibblock">Badgpt: Exploring security vulnerabilities of chatgpt via backdoor attacks to instructgpt.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.12298</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib309">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[309]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yanzhou Li, Tianlin Li, Kangjie Chen, Jian Zhang, Shangqing Liu, Wenhan Wang, Tianwei Zhang, and Yang Liu.

</span>
<span class="ltx_bibblock">Badedit: Backdooring large language models by model editing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib310">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[310]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haoran Wang and Kai Shu.

</span>
<span class="ltx_bibblock">Trojan activation attack: Red-teaming large language models using activation steering for safety-alignment.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2311.09433</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib311">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[311]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, and Hongxia Jin.

</span>
<span class="ltx_bibblock">Backdooring instruction-tuned large language models with virtual prompt injection.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NAACL</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib312">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[312]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cody Clop and Yannick Teglia.

</span>
<span class="ltx_bibblock">Backdoored retrievers for prompt injection attacks on retrieval augmented generation of large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2410.14479</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib313">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[313]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shuai Zhao, Jinming Wen, Luu&nbsp;Anh Tuan, Junbo Zhao, and Jie Fu.

</span>
<span class="ltx_bibblock">Prompt as triggers for backdoor attack: Examining the vulnerability in language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. EMNLP</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib314">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[314]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yupei Liu, Yuqi Jia, Runpeng Geng, Jinyuan Jia, and Neil&nbsp;Zhenqiang Gong.

</span>
<span class="ltx_bibblock">Formalizing and benchmarking prompt injection attacks and defenses.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. USENIX Security</span>, pages 1831–1847, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib315">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[315]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Houssem&nbsp;Ben Braiek and Foutse Khomh.

</span>
<span class="ltx_bibblock">Machine learning robustness: A primer.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Trustworthy AI in Medical Imaging</span>, pages 37–71. Elsevier, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib316">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[316]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuezhi Wang, Haohan Wang, and Diyi Yang.

</span>
<span class="ltx_bibblock">Measure and improve robustness in NLP models: A survey.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NAACL</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib317">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[317]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu&nbsp;Steven Zheng, Adams&nbsp;Wei Yu, Xinying Song, and Denny Zhou.

</span>
<span class="ltx_bibblock">Large language models cannot self-correct reasoning yet.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib318">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[318]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhiheng Xi, Senjie Jin, Yuhao Zhou, Rui Zheng, Songyang Gao, Tao Gui, Qi&nbsp;Zhang, and Xuanjing Huang.

</span>
<span class="ltx_bibblock">Self-polish: Enhance reasoning in large language models via problem refinement.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Findings of Proc. EMNLP</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib319">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[319]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge&nbsp;Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. CVPR</span>, pages 9556–9567, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib320">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[320]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang, Michel Galley, and Jianfeng Gao.

</span>
<span class="ltx_bibblock">Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib321">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[321]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zirui Wang, Mengzhou Xia, Luxi He, Howard Chen, Yitao Liu, Richard Zhu, Kaiqu Liang, Xindi Wu, Haotian Liu, Sadhika Malladi, et&nbsp;al.

</span>
<span class="ltx_bibblock">Charxiv: Charting gaps in realistic chart understanding in multimodal llms.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib322">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[322]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qingjie Zhang, Han Qiu, Di&nbsp;Wang, Haoting Qian, Yiming Li, Tianwei Zhang, and Minlie Huang.

</span>
<span class="ltx_bibblock">Understanding the Dark Side of LLMs’ Intrinsic Self-Correction.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.14959</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib323">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[323]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xingyu Chen, Jiahao Xu, Tian Liang, Zhiwei He, Jianhui Pang, Dian Yu, Linfeng Song, Qiuzhi Liu, Mengfei Zhou, Zhuosheng Zhang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Do not think that much for 2+ 3=? on the overthinking of o1-like llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2412.21187</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib324">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[324]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Silei Xu, Wenhao Xie, Lingxiao Zhao, and Pengcheng He.

</span>
<span class="ltx_bibblock">Chain of draft: Thinking faster by writing less.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.18600</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib325">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[325]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, and Xinchao Wang.

</span>
<span class="ltx_bibblock">CoT-Valve: Length-Compressible Chain-of-Thought Tuning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.09601</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib326">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[326]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junjie Yang, Ke&nbsp;Lin, and Xing Yu.

</span>
<span class="ltx_bibblock">Think when you need: Self-adaptive chain-of-thought learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.03234</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib327">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[327]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Minzheng Wang, Yongbin Li, Haobo Wang, Xinghua Zhang, Nan Xu, Bingli Wu, Fei Huang, Haiyang Yu, and Wenji Mao.

</span>
<span class="ltx_bibblock">Adaptive Thinking via Mode Policy Optimization for Social Language Agents.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.02156</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib328">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[328]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Heming Xia, Yongqi Li, Chak&nbsp;Tou Leong, Wenjie Wang, and Wenjie Li.

</span>
<span class="ltx_bibblock">Tokenskip: Controllable chain-of-thought compression in llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.12067</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib329">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[329]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tergel Munkhbat, Namgyu Ho, Seo&nbsp;Hyun Kim, Yongjin Yang, Yujin Kim, and Se-Young Yun.

</span>
<span class="ltx_bibblock">Self-training elicits concise reasoning in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2502.20122</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib330">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[330]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ping Yu, Jing Xu, Jason Weston, and Ilia Kulikov.

</span>
<span class="ltx_bibblock">Distilling system 2 into system 1.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">NeurIPS Workshop on Sys-2 Reasoning</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib331">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[331]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chengsong Huang, Langlin Huang, Jixuan Leng, Jiacheng Liu, and Jiaxin Huang.

</span>
<span class="ltx_bibblock">Efficient test-time scaling via self-calibration.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.00031</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib332">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[332]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiming Wang, Pei Zhang, Siyuan Huang, Baosong Yang, Zhuosheng Zhang, Fei Huang, and Rui Wang.

</span>
<span class="ltx_bibblock">Sampling-efficient test-time scaling: Self-estimating the best-of-n sampling in early decoding.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2503.01422</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib333">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[333]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zishun Yu, Tengyu Xu, Di&nbsp;Jin, Karthik&nbsp;Abinav Sankararaman, Yun He, Wenxuan Zhou, Zhouhao Zeng, Eryk Helenowski, Chen Zhu, Sinong Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.17974</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib334">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[334]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yao Huang, Huanran Chen, Shouwei Ruan, Yichi Zhang, Xingxing Wei, and Yinpeng Dong.

</span>
<span class="ltx_bibblock">Mitigating Overthinking in Large Reasoning Models via Manifold Steering.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.22411</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib335">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[335]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hannah Cyberey and David Evans.

</span>
<span class="ltx_bibblock">Steering the CensorShip: Uncovering Representation Vectors for LLM “Thought" Control.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.17130</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib336">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[336]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Huang, Lichao Sun, Haoran Wang, Siyuan Wu, Qihui Zhang, Yuan Li, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Position: Trustllm: Trustworthiness in large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib337">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[337]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yingji Li, Mengnan Du, Rui Song, Xin Wang, and Ying Wang.

</span>
<span class="ltx_bibblock">A survey on fairness in large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.10149</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib338">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[338]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Isabel&nbsp;O Gallegos, Ryan&nbsp;A Rossi, Joe Barrow, Md&nbsp;Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen&nbsp;K Ahmed.

</span>
<span class="ltx_bibblock">Bias and fairness in large language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Computational Linguistics</span>, 50(3):1097–1179, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib339">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[339]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Riccardo Cantini, Alessio Orsino, Massimo Ruggiero, and Domenico Talia.

</span>
<span class="ltx_bibblock">Benchmarking adversarial robustness to bias elicitation in large language models: Scalable automated assessment with llm-as-a-judge.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.07887</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib340">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[340]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yanbo Wang, Jian Liang, and Ran He.

</span>
<span class="ltx_bibblock">Towards eliminating hard label constraints in gradient inversion attacks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib341">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[341]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. S&amp;P</span>, pages 3–18, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib342">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[342]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhanke Zhou, Jianing Zhu, Fengfei Yu, Xuan Li, Xiong Peng, Tongliang Liu, and Bo&nbsp;Han.

</span>
<span class="ltx_bibblock">Model inversion attacks: A survey of approaches and countermeasures.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2411.10023</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib343">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[343]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Le&nbsp;Jiang, Liyan Ma, and Guang Yang.

</span>
<span class="ltx_bibblock">Shadow defense against gradient inversion attack in federated learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Medical Image Analysis</span>, page 103673, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib344">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[344]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiyang Guan, Jian Liang, and Ran He.

</span>
<span class="ltx_bibblock">Are you stealing my model? sample correlation for fingerprinting deep neural networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib345">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[345]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiyang Guan, Jian Liang, Yanbo Wang, and Ran He.

</span>
<span class="ltx_bibblock">Sample Correlation for Fingerprinting Deep Face Recognition.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">International Journal of Computer Vision</span>, 133(4):1912–1926, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib346">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[346]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Changyue Jiang, Xudong Pan, Geng Hong, Chenfu Bao, and Min Yang.

</span>
<span class="ltx_bibblock">Rag-thief: Scalable extraction of private data from retrieval-augmented generation applications with agent-based attacks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2411.14110</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib347">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[347]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuhao Wang, Wenjie Qu, Yanze Jiang, Zichen Liu, Yue Liu, Shengfang Zhai, Yinpeng Dong, and Jiaheng Zhang.

</span>
<span class="ltx_bibblock">Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2505.15420</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib348">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[348]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nicholas Carlini, Daniel Paleka, Krishnamurthy&nbsp;Dj Dvijotham, Thomas Steinke, Jonathan Hayase, A&nbsp;Feder Cooper, Katherine Lee, Matthew Jagielski, Milad Nasr, Arthur Conmy, et&nbsp;al.

</span>
<span class="ltx_bibblock">Stealing part of a production language model.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib349">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[349]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuanshun Yao, Xiaojun Xu, and Yang Liu.

</span>
<span class="ltx_bibblock">Large language model unlearning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib350">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[350]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pratyush Maini, Zhili Feng, Avi Schwarzschild, Zachary&nbsp;C Lipton, and J&nbsp;Zico Kolter.

</span>
<span class="ltx_bibblock">Tofu: A task of fictitious unlearning for llms.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. COLM</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib351">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[351]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aengus Lynch, Phillip Guo, Aidan Ewart, Stephen Casper, and Dylan Hadfield-Menell.

</span>
<span class="ltx_bibblock">Eight methods to evaluate robust unlearning in llms.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.16835</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib352">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[352]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shengyuan Hu, Yiwei Fu, Steven Wu, and Virginia Smith.

</span>
<span class="ltx_bibblock">Jogging the memory of unlearned llms through targeted relearning attacks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">NeurIPS Workshop on Safe Generative AI</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib353">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[353]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zirui Peng, Shaofeng Li, Guoxing Chen, Cheng Zhang, Haojin Zhu, and Minhui Xue.

</span>
<span class="ltx_bibblock">Fingerprinting deep neural networks globally via universal adversarial perturbations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. CVPR</span>, pages 13430–13439, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib354">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[354]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Si&nbsp;Wang and Chip-Hong Chang.

</span>
<span class="ltx_bibblock">Fingerprinting deep neural networks-a deepfool approach.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ISCAS</span>, pages 1–5, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib355">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[355]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiyang Guan, Jian Liang, Yanbo Wang, and Ran He.

</span>
<span class="ltx_bibblock">Sample Correlation for Fingerprinting Deep Face Recognition.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">International Journal of Computer Vision</span>, pages 1–15, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib356">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[356]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pierre Fernandez, Guillaume Couairon, Hervé Jégou, Matthijs Douze, and Teddy Furon.

</span>
<span class="ltx_bibblock">The stable signature: Rooting watermarks in latent diffusion models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICCV</span>, pages 22466–22477, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib357">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[357]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuanchun Li, Ziqi Zhang, Bingyan Liu, Ziyue Yang, and Yunxin Liu.

</span>
<span class="ltx_bibblock">ModelDiff: Testing-based DNN similarity comparison for model reuse detection.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ISSTA</span>, pages 139–151, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib358">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[358]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shaopeng Fu, Fengxiang He, Yang Liu, Li&nbsp;Shen, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Robust unlearnable examples: Protecting data against adversarial learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib359">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[359]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, and David Jacobs.

</span>
<span class="ltx_bibblock">Autoregressive perturbations for data poisoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib360">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[360]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hanxun Huang, Xingjun Ma, Sarah&nbsp;Monazam Erfani, James Bailey, and Yisen Wang.

</span>
<span class="ltx_bibblock">Unlearnable examples: Making personal data unexploitable.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib361">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[361]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein.

</span>
<span class="ltx_bibblock">A watermark for large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICML</span>, pages 17061–17084, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib362">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[362]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Robin Staab, Mark Vero, Mislav Balunović, and Martin Vechev.

</span>
<span class="ltx_bibblock">Beyond memorization: Violating privacy via inference with large language models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib363">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[363]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Batuhan Tömekçe, Mark Vero, Robin Staab, and Martin Vechev.

</span>
<span class="ltx_bibblock">Private Attribute Inference from Images with Vision-Language Models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib364">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[364]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tianzhe Chu, Yuexiang Zhai, Jihan Yang, Shengbang Tong, Saining Xie, Dale Schuurmans, Quoc&nbsp;V Le, Sergey Levine, and Yi&nbsp;Ma.

</span>
<span class="ltx_bibblock">Sft memorizes, rl generalizes: A comparative study of foundation model post-training.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2501.17161</span>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib365">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[365]<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hardy Chen, Haoqin Tu, Fali Wang, Hui Liu, Xianfeng Tang, Xinya Du, Yuyin Zhou, and Cihang Xie.

</span>
<span class="ltx_bibblock">Sft or rl? an early investigation into training r1-like reasoning large vision-language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:2504.11468</span>, 2025.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue<font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><font class="notranslate" data-immersive-translate-translation-element-mark="1">&nbsp;&nbsp;</font><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-inline-wrapper-theme-none immersive-translate-target-translation-inline-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">报告问题</font></font></font></button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" width="11" height="14">
            </a><font class="notranslate immersive-translate-target-wrapper" lang="zh-CN"><br><font class="notranslate immersive-translate-target-translation-theme-none immersive-translate-target-translation-block-wrapper-theme-none immersive-translate-target-translation-block-wrapper" data-immersive-translate-translation-element-mark="1"><font class="notranslate immersive-translate-target-inner immersive-translate-target-translation-theme-none-inner" data-immersive-translate-translation-element-mark="1">由 L A T E xml <img height="14" width="11" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"> 生成</font></font></font>
        </div></div><footer id="footer" class="ltx_document" default-translate="no">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>@charset "UTF-8";
/*!
 * Pico.css v1.5.6 (https://picocss.com)
 * Copyright 2019-2022 - Licensed under MIT
 */
/**
 * Theme: default
 */
#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 0.25rem;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 1rem;
  --typography-spacing-vertical: 1.5rem;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 0.75rem;
  --form-element-spacing-horizontal: 1rem;
  --nav-element-spacing-vertical: 1rem;
  --nav-element-spacing-horizontal: 0.5rem;
  --nav-link-spacing-vertical: 0.5rem;
  --nav-link-spacing-horizontal: 0.5rem;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(0.25rem);
}
@media (min-width: 576px) {
  #mount {
    --font-size: 17px;
  }
}
@media (min-width: 768px) {
  #mount {
    --font-size: 18px;
  }
}
@media (min-width: 992px) {
  #mount {
    --font-size: 19px;
  }
}
@media (min-width: 1200px) {
  #mount {
    --font-size: 20px;
  }
}

@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2);
  }
}
@media (min-width: 768px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3);
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3.5);
  }
}

@media (min-width: 576px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}
@media (min-width: 992px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.75);
  }
}
@media (min-width: 1200px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 2);
  }
}

dialog > article {
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
}
@media (min-width: 576px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 3);
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}

a {
  --text-decoration: none;
}
a.secondary,
a.contrast {
  --text-decoration: underline;
}

small {
  --font-size: 0.875em;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  --font-weight: 700;
}

h1 {
  --font-size: 2rem;
  --typography-spacing-vertical: 3rem;
}

h2 {
  --font-size: 1.75rem;
  --typography-spacing-vertical: 2.625rem;
}

h3 {
  --font-size: 1.5rem;
  --typography-spacing-vertical: 2.25rem;
}

h4 {
  --font-size: 1.25rem;
  --typography-spacing-vertical: 1.874rem;
}

h5 {
  --font-size: 1.125rem;
  --typography-spacing-vertical: 1.6875rem;
}

[type="checkbox"],
[type="radio"] {
  --border-width: 2px;
}

[type="checkbox"][role="switch"] {
  --border-width: 2px;
}

thead th,
thead td,
tfoot th,
tfoot td {
  --border-width: 3px;
}

:not(thead, tfoot) > * > td {
  --font-size: 0.875em;
}

pre,
code,
kbd,
samp {
  --font-family: "Menlo", "Consolas", "Roboto Mono", "Ubuntu Monospace",
    "Noto Mono", "Oxygen Mono", "Liberation Mono", monospace,
    "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
}

kbd {
  --font-weight: bolder;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --background-color: #fff;
  --background-light-green: #f5f7f9;
  --color: hsl(205deg, 20%, 32%);
  --h1-color: hsl(205deg, 30%, 15%);
  --h2-color: #24333e;
  --h3-color: hsl(205deg, 25%, 23%);
  --h4-color: #374956;
  --h5-color: hsl(205deg, 20%, 32%);
  --h6-color: #4d606d;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: hsl(205deg, 20%, 94%);
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 90%, 32%);
  --primary-focus: rgba(16, 149, 193, 0.125);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 20%, 32%);
  --secondary-focus: rgba(89, 107, 120, 0.125);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 30%, 15%);
  --contrast-hover: #000;
  --contrast-focus: rgba(89, 107, 120, 0.125);
  --contrast-inverse: #fff;
  --mark-background-color: #fff2ca;
  --mark-color: #543a26;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: transparent;
  --form-element-border-color: hsl(205deg, 14%, 68%);
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: transparent;
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 18%, 86%);
  --form-element-disabled-border-color: hsl(205deg, 14%, 68%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #c62828;
  --form-element-invalid-active-border-color: #d32f2f;
  --form-element-invalid-focus-color: rgba(211, 47, 47, 0.125);
  --form-element-valid-border-color: #388e3c;
  --form-element-valid-active-border-color: #43a047;
  --form-element-valid-focus-color: rgba(67, 160, 71, 0.125);
  --switch-background-color: hsl(205deg, 16%, 77%);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: hsl(205deg, 18%, 86%);
  --range-active-border-color: hsl(205deg, 16%, 77%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: #f6f8f9;
  --code-background-color: hsl(205deg, 20%, 94%);
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 40%, 50%);
  --code-property-color: hsl(185deg, 40%, 40%);
  --code-value-color: hsl(40deg, 20%, 50%);
  --code-comment-color: hsl(205deg, 14%, 68%);
  --accordion-border-color: var(--muted-border-color);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: var(--background-color);
  --card-border-color: var(--muted-border-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(27, 40, 50, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(27, 40, 50, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(27, 40, 50, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(27, 40, 50, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(27, 40, 50, 0.04302),
    0.5rem 1rem 6rem rgba(27, 40, 50, 0.06),
    0 0 0 0.0625rem rgba(27, 40, 50, 0.015);
  --card-sectionning-background-color: #fbfbfc;
  --dropdown-background-color: #fbfbfc;
  --dropdown-border-color: #e1e6eb;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: hsl(205deg, 20%, 94%);
  --modal-overlay-background-color: rgba(213, 220, 226, 0.7);
  --progress-background-color: hsl(205deg, 18%, 86%);
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(198, 40, 40)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(56, 142, 60)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  --float-ball-more-button-border-color: #f6f6f6;
  --float-ball-more-button-background-color: #ffffff;
  --float-ball-more-button-svg-color: #6c6f73;
  color-scheme: light;
  --service-bg-hover: #f7faff;
  --service-bg: #fafbfb;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --background-color: #11191f;
    --float-ball-more-button-background-color: #ffffff;
    --background-light-green: #141e26;
    --color: hsl(205deg, 16%, 77%);
    --h1-color: hsl(205deg, 20%, 94%);
    --h2-color: #e1e6eb;
    --h3-color: hsl(205deg, 18%, 86%);
    --h4-color: #c8d1d8;
    --h5-color: hsl(205deg, 16%, 77%);
    --h6-color: #afbbc4;
    --muted-color: hsl(205deg, 10%, 50%);
    --muted-border-color: #1f2d38;
    --primary: hsl(195deg, 85%, 41%);
    --primary-hover: hsl(195deg, 80%, 50%);
    --primary-focus: rgba(16, 149, 193, 0.25);
    --primary-inverse: #fff;
    --secondary: hsl(205deg, 15%, 41%);
    --secondary-hover: hsl(205deg, 10%, 50%);
    --secondary-focus: rgba(115, 130, 140, 0.25);
    --secondary-inverse: #fff;
    --contrast: hsl(205deg, 20%, 94%);
    --contrast-hover: #fff;
    --contrast-focus: rgba(115, 130, 140, 0.25);
    --contrast-inverse: #000;
    --mark-background-color: #d1c284;
    --mark-color: #11191f;
    --ins-color: #388e3c;
    --del-color: #c62828;
    --blockquote-border-color: var(--muted-border-color);
    --blockquote-footer-color: var(--muted-color);
    --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --form-element-background-color: #11191f;
    --form-element-border-color: #374956;
    --form-element-color: var(--color);
    --form-element-placeholder-color: var(--muted-color);
    --form-element-active-background-color: var(
      --form-element-background-color
    );
    --form-element-active-border-color: var(--primary);
    --form-element-focus-color: var(--primary-focus);
    --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
    --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
    --form-element-disabled-opacity: 0.5;
    --form-element-invalid-border-color: #b71c1c;
    --form-element-invalid-active-border-color: #c62828;
    --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
    --form-element-valid-border-color: #2e7d32;
    --form-element-valid-active-border-color: #388e3c;
    --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
    --switch-background-color: #374956;
    --switch-color: var(--primary-inverse);
    --switch-checked-background-color: var(--primary);
    --range-border-color: #24333e;
    --range-active-border-color: hsl(205deg, 25%, 23%);
    --range-thumb-border-color: var(--background-color);
    --range-thumb-color: var(--secondary);
    --range-thumb-hover-color: var(--secondary-hover);
    --range-thumb-active-color: var(--primary);
    --table-border-color: var(--muted-border-color);
    --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
    --code-background-color: #18232c;
    --code-color: var(--muted-color);
    --code-kbd-background-color: var(--contrast);
    --code-kbd-color: var(--contrast-inverse);
    --code-tag-color: hsl(330deg, 30%, 50%);
    --code-property-color: hsl(185deg, 30%, 50%);
    --code-value-color: hsl(40deg, 10%, 50%);
    --code-comment-color: #4d606d;
    --accordion-border-color: var(--muted-border-color);
    --accordion-active-summary-color: var(--primary);
    --accordion-close-summary-color: var(--color);
    --accordion-open-summary-color: var(--muted-color);
    --card-background-color: #141e26;
    --card-border-color: var(--card-background-color);
    --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
      0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
      0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
      0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
      0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
      0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
    --card-sectionning-background-color: #18232c;
    --dropdown-background-color: hsl(205deg, 30%, 15%);
    --dropdown-border-color: #24333e;
    --dropdown-box-shadow: var(--card-box-shadow);
    --dropdown-color: var(--color);
    --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
    --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
    --progress-background-color: #24333e;
    --progress-color: var(--primary);
    --loading-spinner-opacity: 0.5;
    --tooltip-background-color: var(--contrast);
    --tooltip-color: var(--contrast-inverse);
    --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
    --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
    --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
    --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
    --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
    --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
    color-scheme: dark;
    --service-bg-hover: #22292f;
    --service-bg: rgba(0, 0, 0, 0.1);
  }
}
[data-theme="dark"] {
  --background-color: #11191f;
  --float-ball-more-button-background-color: #191919;
  --background-light-green: #141e26;
  --color: hsl(205deg, 16%, 77%);
  --h1-color: hsl(205deg, 20%, 94%);
  --h2-color: #e1e6eb;
  --h3-color: hsl(205deg, 18%, 86%);
  --h4-color: #c8d1d8;
  --h5-color: hsl(205deg, 16%, 77%);
  --h6-color: #afbbc4;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: #1f2d38;
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 80%, 50%);
  --primary-focus: rgba(16, 149, 193, 0.25);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 10%, 50%);
  --secondary-focus: rgba(115, 130, 140, 0.25);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 20%, 94%);
  --contrast-hover: #fff;
  --contrast-focus: rgba(115, 130, 140, 0.25);
  --contrast-inverse: #000;
  --mark-background-color: #d1c284;
  --mark-color: #11191f;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: #11191f;
  --form-element-border-color: #374956;
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: var(--form-element-background-color);
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
  --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #b71c1c;
  --form-element-invalid-active-border-color: #c62828;
  --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
  --form-element-valid-border-color: #2e7d32;
  --form-element-valid-active-border-color: #388e3c;
  --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
  --switch-background-color: #374956;
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: #24333e;
  --range-active-border-color: hsl(205deg, 25%, 23%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
  --code-background-color: #18232c;
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 30%, 50%);
  --code-property-color: hsl(185deg, 30%, 50%);
  --code-value-color: hsl(40deg, 10%, 50%);
  --code-comment-color: #4d606d;
  --accordion-border-color: var(--muted-border-color);
  --accordion-active-summary-color: var(--primary);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: #141e26;
  --card-border-color: var(--card-background-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
    0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
  --card-sectionning-background-color: #18232c;
  --dropdown-background-color: hsl(205deg, 30%, 15%);
  --dropdown-border-color: #24333e;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
  --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
  --progress-background-color: #24333e;
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  color-scheme: dark;
  --service-bg: rgba(0, 0, 0, 0.1);
}

progress,
[type="checkbox"],
[type="radio"],
[type="range"] {
  accent-color: var(--primary);
}

/**
 * Document
 * Content-box & Responsive typography
 */
*,
*::before,
*::after {
  box-sizing: border-box;
  background-repeat: no-repeat;
}

::before,
::after {
  text-decoration: inherit;
  vertical-align: inherit;
}

:where(#mount) {
  -webkit-tap-highlight-color: transparent;
  -webkit-text-size-adjust: 100%;
  -moz-text-size-adjust: 100%;
  text-size-adjust: 100%;
  background-color: var(--background-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  line-height: var(--line-height);
  font-family: var(--font-family);
  text-rendering: optimizeLegibility;
  overflow-wrap: break-word;
  cursor: default;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
}

/**
 * Sectioning
 * Container and responsive spacings for header, main, footer
 */
main {
  display: block;
}

#mount {
  width: 100%;
  margin: 0;
}
#mount > header,
#mount > main,
#mount > footer {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
}
@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 2px !important;
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 12px !important;
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 24px !important;
  }
}

/**
* Container
*/
.container,
.container-fluid {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding-right: var(--spacing);
  padding-left: var(--spacing);
}
/*
@media (min-width: 576px) {
  .container {
    max-width: 510px;
    padding-right: 0;
    padding-left: 0;
  }
}
@media (min-width: 768px) {
  .container {
    max-width: 700px;
  }
} */
@media (min-width: 992px) {
  .container {
    max-width: 920px;
  }
}
@media (min-width: 1200px) {
  .container {
    max-width: 1130px;
  }
}

/**
 * Section
 * Responsive spacings for section
 */
section {
  margin-bottom: var(--block-spacing-vertical);
}

/**
* Grid
* Minimal grid system with auto-layout columns
*/
.grid {
  grid-column-gap: var(--grid-spacing-horizontal);
  grid-row-gap: var(--grid-spacing-vertical);
  display: grid;
  grid-template-columns: 1fr;
  margin: 0;
}
@media (min-width: 1280px) {
  .grid {
    grid-template-columns: repeat(auto-fit, minmax(0%, 1fr));
  }
}
.grid > * {
  min-width: 0;
}

/**
 * Horizontal scroller (<figure>)
 */
figure {
  display: block;
  margin: 0;
  padding: 0;
  overflow-x: auto;
}
figure figcaption {
  padding: calc(var(--spacing) * 0.5) 0;
  color: var(--muted-color);
}

/**
 * Typography
 */
b,
strong {
  font-weight: bolder;
}

sub,
sup {
  position: relative;
  font-size: 0.75em;
  line-height: 0;
  vertical-align: baseline;
}

sub {
  bottom: -0.25em;
}

sup {
  top: -0.5em;
}

address,
blockquote,
dl,
figure,
form,
ol,
p,
pre,
table,
ul {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: var(--font-size);
}

a,
[role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
a:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}
a:focus,
[role="link"]:focus {
  --background-color: var(--primary-focus);
}
a.secondary,
[role="link"].secondary {
  --color: var(--secondary);
}
a.secondary:is([aria-current], :hover, :active, :focus),
[role="link"].secondary:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}
a.secondary:focus,
[role="link"].secondary:focus {
  --background-color: var(--secondary-focus);
}
a.contrast,
[role="link"].contrast {
  --color: var(--contrast);
}
a.contrast:is([aria-current], :hover, :active, :focus),
[role="link"].contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}
a.contrast:focus,
[role="link"].contrast:focus {
  --background-color: var(--contrast-focus);
}

h1,
h2,
h3,
h4,
h5,
h6 {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  font-family: var(--font-family);
}

h1 {
  --color: var(--h1-color);
}

h2 {
  --color: var(--h2-color);
}

h3 {
  --color: var(--h3-color);
}

h4 {
  --color: var(--h4-color);
}

h5 {
  --color: var(--h5-color);
}

h6 {
  --color: var(--h6-color);
}

:where(address, blockquote, dl, figure, form, ol, p, pre, table, ul)
  ~ :is(h1, h2, h3, h4, h5, h6) {
  margin-top: var(--typography-spacing-vertical);
}

hgroup,
.headings {
  margin-bottom: var(--typography-spacing-vertical);
}
hgroup > *,
.headings > * {
  margin-bottom: 0;
}
hgroup > *:last-child,
.headings > *:last-child {
  --color: var(--muted-color);
  --font-weight: unset;
  font-size: 1rem;
  font-family: unset;
}

p {
  margin-bottom: var(--typography-spacing-vertical);
}

small {
  font-size: var(--font-size);
}

:where(dl, ol, ul) {
  padding-right: 0;
  padding-left: var(--spacing);
  -webkit-padding-start: var(--spacing);
  padding-inline-start: var(--spacing);
  -webkit-padding-end: 0;
  padding-inline-end: 0;
}
:where(dl, ol, ul) li {
  margin-bottom: calc(var(--typography-spacing-vertical) * 0.25);
}

:where(dl, ol, ul) :is(dl, ol, ul) {
  margin: 0;
  margin-top: calc(var(--typography-spacing-vertical) * 0.25);
}

ul li {
  list-style: square;
}

mark {
  padding: 0.125rem 0.25rem;
  background-color: var(--mark-background-color);
  color: var(--mark-color);
  vertical-align: baseline;
}

blockquote {
  display: block;
  margin: var(--typography-spacing-vertical) 0;
  padding: var(--spacing);
  border-right: none;
  border-left: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-start: 0.25rem solid var(--blockquote-border-color);
  border-inline-start: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-end: none;
  border-inline-end: none;
}
blockquote footer {
  margin-top: calc(var(--typography-spacing-vertical) * 0.5);
  color: var(--blockquote-footer-color);
}

abbr[title] {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}

ins {
  color: var(--ins-color);
  text-decoration: none;
}

del {
  color: var(--del-color);
}

::-moz-selection {
  background-color: var(--primary-focus);
}

::selection {
  background-color: var(--primary-focus);
}

/**
 * Embedded content
 */
:where(audio, canvas, iframe, img, svg, video) {
  vertical-align: middle;
}

audio,
video {
  display: inline-block;
}

audio:not([controls]) {
  display: none;
  height: 0;
}

:where(iframe) {
  border-style: none;
}

img {
  max-width: 100%;
  height: auto;
  border-style: none;
}

:where(svg:not([fill])) {
  fill: currentColor;
}

svg:not(#mount) {
  overflow: hidden;
}

/**
 * Button
 */
button {
  margin: 0;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

button,
[type="button"],
[type="reset"],
[type="submit"] {
  -webkit-appearance: button;
}

button {
  display: block;
  width: 100%;
  margin-bottom: var(--spacing);
}

[role="button"] {
  display: inline-block;
  text-decoration: none;
}

button,
input[type="submit"],
input[type="button"],
input[type="reset"],
[role="button"] {
  --background-color: var(--primary);
  --border-color: var(--primary);
  --color: var(--primary-inverse);
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
button:is([aria-current], :hover, :active, :focus),
input[type="submit"]:is([aria-current], :hover, :active, :focus),
input[type="button"]:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus),
[role="button"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--primary-hover);
  --border-color: var(--primary-hover);
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  --color: var(--primary-inverse);
}
button:focus,
input[type="submit"]:focus,
input[type="button"]:focus,
input[type="reset"]:focus,
[role="button"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--primary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary,
input[type="reset"] {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  cursor: pointer;
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:focus,
input[type="reset"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--secondary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast {
  --background-color: var(--contrast);
  --border-color: var(--contrast);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--contrast-hover);
  --border-color: var(--contrast-hover);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--contrast-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline,
input[type="reset"].outline {
  --background-color: transparent;
  --color: var(--primary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --background-color: transparent;
  --color: var(--primary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary,
input[type="reset"].outline {
  --color: var(--secondary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast {
  --color: var(--contrast);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}

:where(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  )[disabled],
:where(fieldset[disabled])
  :is(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  ),
a[role="button"]:not([href]) {
  opacity: 0.5;
  pointer-events: none;
}

/**
 * Form elements
 */
input,
optgroup,
select,
textarea {
  margin: 0;
  font-size: 1rem;
  line-height: var(--line-height);
  font-family: inherit;
  letter-spacing: inherit;
}

input {
  overflow: visible;
}

select {
  text-transform: none;
}

legend {
  max-width: 100%;
  padding: 0;
  color: inherit;
  white-space: normal;
}

textarea {
  overflow: auto;
}

[type="checkbox"],
[type="radio"] {
  padding: 0;
}

::-webkit-inner-spin-button,
::-webkit-outer-spin-button {
  height: auto;
}

[type="search"] {
  -webkit-appearance: textfield;
  outline-offset: -2px;
}

[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}

::-webkit-file-upload-button {
  -webkit-appearance: button;
  font: inherit;
}

::-moz-focus-inner {
  padding: 0;
  border-style: none;
}

:-moz-focusring {
  outline: none;
}

:-moz-ui-invalid {
  box-shadow: none;
}

::-ms-expand {
  display: none;
}

[type="file"],
[type="range"] {
  padding: 0;
  border-width: 0;
}

input:not([type="checkbox"], [type="radio"], [type="range"]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
}

fieldset {
  margin: 0;
  margin-bottom: var(--spacing);
  padding: 0;
  border: 0;
}

label,
fieldset legend {
  display: block;
  margin-bottom: calc(var(--spacing) * 0.25);
  font-weight: var(--form-label-font-weight, var(--font-weight));
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  width: 100%;
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]),
select,
textarea {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
}

input,
select,
textarea {
  --background-color: var(--form-element-background-color);
  --border-color: var(--form-element-border-color);
  --color: var(--form-element-color);
  --box-shadow: none;
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="checkbox"],
    [type="radio"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --background-color: var(--form-element-active-background-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="switch"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --border-color: var(--form-element-active-border-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="range"],
    [type="file"],
    [readonly]
  ):focus,
select:focus,
textarea:focus {
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}

input:not([type="submit"], [type="button"], [type="reset"])[disabled],
select[disabled],
textarea[disabled],
:where(fieldset[disabled])
  :is(
    input:not([type="submit"], [type="button"], [type="reset"]),
    select,
    textarea
  ) {
  --background-color: var(--form-element-disabled-background-color);
  --border-color: var(--form-element-disabled-border-color);
  opacity: var(--form-element-disabled-opacity);
  pointer-events: none;
}

:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid] {
  padding-right: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal) !important;
  padding-inline-start: var(--form-element-spacing-horizontal) !important;
  -webkit-padding-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-inline-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="false"] {
  background-image: var(--icon-valid);
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="true"] {
  background-image: var(--icon-invalid);
}
:where(input, select, textarea)[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(input, select, textarea)[aria-invalid="false"]:is(:active, :focus) {
  --border-color: var(--form-element-valid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-valid-focus-color) !important;
}
:where(input, select, textarea)[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}
:where(input, select, textarea)[aria-invalid="true"]:is(:active, :focus) {
  --border-color: var(--form-element-invalid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width)
    var(--form-element-invalid-focus-color) !important;
}

[dir="rtl"]
  :where(input, select, textarea):not([type="checkbox"], [type="radio"]):is(
    [aria-invalid],
    [aria-invalid="true"],
    [aria-invalid="false"]
  ) {
  background-position: center left 0.75rem;
}

input::placeholder,
input::-webkit-input-placeholder,
textarea::placeholder,
textarea::-webkit-input-placeholder,
select:invalid {
  color: var(--form-element-placeholder-color);
  opacity: 1;
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  margin-bottom: var(--spacing);
}

select::-ms-expand {
  border: 0;
  background-color: transparent;
}
select:not([multiple], [size]) {
  padding-right: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal);
  padding-inline-start: var(--form-element-spacing-horizontal);
  -webkit-padding-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-inline-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  background-image: var(--icon-chevron);
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}

[dir="rtl"] select:not([multiple], [size]) {
  background-position: center left 0.75rem;
}

:where(input, select, textarea) + small {
  display: block;
  width: 100%;
  margin-top: calc(var(--spacing) * -0.75);
  margin-bottom: var(--spacing);
  color: var(--muted-color);
}

label > :where(input, select, textarea) {
  margin-top: calc(var(--spacing) * 0.25);
}

/**
 * Form elements
 * Checkboxes & Radios
 */
[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

[type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
[type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
[type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
[type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
[type="checkbox"][role="switch"]:checked {
  background-image: none;
}
[type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

[type="checkbox"][aria-invalid="false"],
[type="checkbox"]:checked[aria-invalid="false"],
[type="radio"][aria-invalid="false"],
[type="radio"]:checked[aria-invalid="false"],
[type="checkbox"][role="switch"][aria-invalid="false"],
[type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
[type="checkbox"][aria-invalid="true"],
[type="checkbox"]:checked[aria-invalid="true"],
[type="radio"][aria-invalid="true"],
[type="radio"]:checked[aria-invalid="true"],
[type="checkbox"][role="switch"][aria-invalid="true"],
[type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

/**
 * Form elements
 * Alternatives input types (Not Checkboxes & Radios)
 */
[type="color"]::-webkit-color-swatch-wrapper {
  padding: 0;
}
[type="color"]::-moz-focus-inner {
  padding: 0;
}
[type="color"]::-webkit-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}
[type="color"]::-moz-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]):is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  --icon-position: 0.75rem;
  --icon-width: 1rem;
  padding-right: calc(var(--icon-width) + var(--icon-position));
  background-image: var(--icon-date);
  background-position: center right var(--icon-position);
  background-size: var(--icon-width) auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="time"] {
  background-image: var(--icon-time);
}

[type="date"]::-webkit-calendar-picker-indicator,
[type="datetime-local"]::-webkit-calendar-picker-indicator,
[type="month"]::-webkit-calendar-picker-indicator,
[type="time"]::-webkit-calendar-picker-indicator,
[type="week"]::-webkit-calendar-picker-indicator {
  width: var(--icon-width);
  margin-right: calc(var(--icon-width) * -1);
  margin-left: var(--icon-position);
  opacity: 0;
}

[dir="rtl"]
  :is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  text-align: right;
}

[type="file"] {
  --color: var(--muted-color);
  padding: calc(var(--form-element-spacing-vertical) * 0.5) 0;
  border: 0;
  border-radius: 0;
  background: none;
}
[type="file"]::file-selector-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::file-selector-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-webkit-file-upload-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-webkit-file-upload-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-ms-browse {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  margin-inline-start: 0;
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-ms-browse:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}

[type="range"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 100%;
  height: 1.25rem;
  background: none;
}
[type="range"]::-webkit-slider-runnable-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -webkit-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-moz-range-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -moz-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-ms-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -ms-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-webkit-slider-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-moz-range-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -moz-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-ms-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]:hover,
[type="range"]:focus {
  --range-border-color: var(--range-active-border-color);
  --range-thumb-color: var(--range-thumb-hover-color);
}
[type="range"]:active {
  --range-thumb-color: var(--range-thumb-active-color);
}
[type="range"]:active::-webkit-slider-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-moz-range-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-ms-thumb {
  transform: scale(1.25);
}

input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  -webkit-padding-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  padding-inline-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  border-radius: 5rem;
  background-image: var(--icon-search);
  background-position: center left 1.125rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  -webkit-padding-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  padding-inline-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  background-position: center left 1.125rem, center right 0.75rem;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="false"] {
  background-image: var(--icon-search), var(--icon-valid);
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="true"] {
  background-image: var(--icon-search), var(--icon-invalid);
}

[type="search"]::-webkit-search-cancel-button {
  -webkit-appearance: none;
  display: none;
}

[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  background-position: center right 1.125rem;
}
[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  background-position: center right 1.125rem, center left 0.75rem;
}

/**
 * Table
 */
:where(table) {
  width: 100%;
  border-collapse: collapse;
  border-spacing: 0;
  text-indent: 0;
}

th,
td {
  padding: calc(var(--spacing) / 2) var(--spacing);
  border-bottom: var(--border-width) solid var(--table-border-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  text-align: left;
  text-align: start;
}

tfoot th,
tfoot td {
  border-top: var(--border-width) solid var(--table-border-color);
  border-bottom: 0;
}

table[role="grid"] tbody tr:nth-child(odd) {
  background-color: var(--table-row-stripped-background-color);
}

/**
 * Code
 */
pre,
code,
kbd,
samp {
  font-size: 0.875em;
  font-family: var(--font-family);
}

pre {
  -ms-overflow-style: scrollbar;
  overflow: auto;
}

pre,
code,
kbd {
  border-radius: var(--border-radius);
  background: var(--code-background-color);
  color: var(--code-color);
  font-weight: var(--font-weight);
  line-height: initial;
}

code,
kbd {
  display: inline-block;
  padding: 0.375rem 0.5rem;
}

pre {
  display: block;
  margin-bottom: var(--spacing);
  overflow-x: auto;
}
pre > code {
  display: block;
  padding: var(--spacing);
  background: none;
  font-size: 14px;
  line-height: var(--line-height);
}

code b {
  color: var(--code-tag-color);
  font-weight: var(--font-weight);
}
code i {
  color: var(--code-property-color);
  font-style: normal;
}
code u {
  color: var(--code-value-color);
  text-decoration: none;
}
code em {
  color: var(--code-comment-color);
  font-style: normal;
}

kbd {
  background-color: var(--code-kbd-background-color);
  color: var(--code-kbd-color);
  vertical-align: baseline;
}

/**
 * Miscs
 */
hr {
  height: 0;
  border: 0;
  border-top: 1px solid var(--muted-border-color);
  color: inherit;
}

[hidden],
template {
  display: none !important;
}

canvas {
  display: inline-block;
}

/**
 * Accordion (<details>)
 */
details {
  display: block;
  margin-bottom: var(--spacing);
  padding-bottom: var(--spacing);
  border-bottom: var(--border-width) solid var(--accordion-border-color);
}
details summary {
  line-height: 1rem;
  list-style-type: none;
  cursor: pointer;
  transition: color var(--transition);
}
details summary:not([role]) {
  color: var(--accordion-close-summary-color);
}
details summary::-webkit-details-marker {
  display: none;
}
details summary::marker {
  display: none;
}
details summary::-moz-list-bullet {
  list-style-type: none;
}
details summary::after {
  display: block;
  width: 1rem;
  height: 1rem;
  -webkit-margin-start: calc(var(--spacing, 1rem) * 0.5);
  margin-inline-start: calc(var(--spacing, 1rem) * 0.5);
  float: right;
  transform: rotate(-90deg);
  background-image: var(--icon-chevron);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
  transition: transform var(--transition);
}
details summary:focus {
  outline: none;
}
details summary:focus:not([role="button"]) {
  color: var(--accordion-active-summary-color);
}
details summary[role="button"] {
  width: 100%;
  text-align: left;
}
details summary[role="button"]::after {
  height: calc(1rem * var(--line-height, 1.5));
  background-image: var(--icon-chevron-button);
}
details summary[role="button"]:not(.outline).contrast::after {
  background-image: var(--icon-chevron-button-inverse);
}
details[open] > summary {
  margin-bottom: calc(var(--spacing));
}
details[open] > summary:not([role]):not(:focus) {
  color: var(--accordion-open-summary-color);
}
details[open] > summary::after {
  transform: rotate(0);
}

[dir="rtl"] details summary {
  text-align: right;
}
[dir="rtl"] details summary::after {
  float: left;
  background-position: left center;
}

/**
 * Card (<article>)
 */
article {
  margin: var(--block-spacing-vertical) 0;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
  border-radius: var(--border-radius);
  background: var(--card-background-color);
  box-shadow: var(--card-box-shadow);
}
article > header,
article > footer {
  margin-right: calc(var(--block-spacing-horizontal) * -1);
  margin-left: calc(var(--block-spacing-horizontal) * -1);
  padding: calc(var(--block-spacing-vertical) * 0.66)
    var(--block-spacing-horizontal);
  background-color: var(--card-sectionning-background-color);
}
article > header {
  margin-top: calc(var(--block-spacing-vertical) * -1);
  margin-bottom: var(--block-spacing-vertical);
  border-bottom: var(--border-width) solid var(--card-border-color);
  border-top-right-radius: var(--border-radius);
  border-top-left-radius: var(--border-radius);
}
article > footer {
  margin-top: var(--block-spacing-vertical);
  margin-bottom: calc(var(--block-spacing-vertical) * -1);
  border-top: var(--border-width) solid var(--card-border-color);
  border-bottom-right-radius: var(--border-radius);
  border-bottom-left-radius: var(--border-radius);
}

/**
 * Modal (<dialog>)
 */
#mount {
  --scrollbar-width: 0px;
}

dialog {
  display: flex;
  z-index: 999;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  align-items: center;
  justify-content: center;
  width: inherit;
  min-width: 100%;
  height: inherit;
  min-height: 100%;
  padding: var(--spacing);
  border: 0;
  -webkit-backdrop-filter: var(--modal-overlay-backdrop-filter);
  backdrop-filter: var(--modal-overlay-backdrop-filter);
  background-color: var(--modal-overlay-background-color);
  color: var(--color);
}
dialog article {
  max-height: calc(100vh - var(--spacing) * 2);
  overflow: auto;
}
@media (min-width: 576px) {
  dialog article {
    max-width: 510px;
  }
}
@media (min-width: 768px) {
  dialog article {
    max-width: 700px;
  }
}
dialog article > header,
dialog article > footer {
  padding: calc(var(--block-spacing-vertical) * 0.5)
    var(--block-spacing-horizontal);
}
dialog article > header .close {
  margin: 0;
  margin-left: var(--spacing);
  float: right;
}
dialog article > footer {
  text-align: right;
}
dialog article > footer [role="button"] {
  margin-bottom: 0;
}
dialog article > footer [role="button"]:not(:first-of-type) {
  margin-left: calc(var(--spacing) * 0.5);
}
dialog article p:last-of-type {
  margin: 0;
}
dialog article .close {
  display: block;
  width: 1rem;
  height: 1rem;
  margin-top: calc(var(--block-spacing-vertical) * -0.5);
  margin-bottom: var(--typography-spacing-vertical);
  margin-left: auto;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}
dialog article .close:is([aria-current], :hover, :active, :focus) {
  opacity: 1;
}
dialog:not([open]),
dialog[open="false"] {
  display: none;
}

.modal-is-open {
  padding-right: var(--scrollbar-width, 0px);
  overflow: hidden;
  pointer-events: none;
}
.modal-is-open dialog {
  pointer-events: auto;
}

:where(.modal-is-opening, .modal-is-closing) dialog,
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-duration: 0.2s;
  animation-timing-function: ease-in-out;
  animation-fill-mode: both;
}
:where(.modal-is-opening, .modal-is-closing) dialog {
  animation-duration: 0.8s;
  animation-name: modal-overlay;
}
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-delay: 0.2s;
  animation-name: modal;
}

.modal-is-closing dialog,
.modal-is-closing dialog > article {
  animation-delay: 0s;
  animation-direction: reverse;
}

@keyframes modal-overlay {
  from {
    -webkit-backdrop-filter: none;
    backdrop-filter: none;
    background-color: transparent;
  }
}
@keyframes modal {
  from {
    transform: translateY(-100%);
    opacity: 0;
  }
}
/**
 * Nav
 */
:where(nav li)::before {
  float: left;
  content: "​";
}

nav,
nav ul {
  display: flex;
}

nav {
  justify-content: space-between;
}
nav ol,
nav ul {
  align-items: center;
  margin-bottom: 0;
  padding: 0;
  list-style: none;
}
nav ol:first-of-type,
nav ul:first-of-type {
  margin-left: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav ol:last-of-type,
nav ul:last-of-type {
  margin-right: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav li {
  display: inline-block;
  margin: 0;
  padding: var(--nav-element-spacing-vertical)
    var(--nav-element-spacing-horizontal);
}
nav li > * {
  --spacing: 0;
}
nav :where(a, [role="link"]) {
  display: inline-block;
  margin: calc(var(--nav-link-spacing-vertical) * -1)
    calc(var(--nav-link-spacing-horizontal) * -1);
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
  border-radius: var(--border-radius);
  text-decoration: none;
}
nav :where(a, [role="link"]):is([aria-current], :hover, :active, :focus) {
  text-decoration: none;
}
nav[aria-label="breadcrumb"] {
  align-items: center;
  justify-content: start;
}
nav[aria-label="breadcrumb"] ul li:not(:first-child) {
  -webkit-margin-start: var(--nav-link-spacing-horizontal);
  margin-inline-start: var(--nav-link-spacing-horizontal);
}
nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  position: absolute;
  width: calc(var(--nav-link-spacing-horizontal) * 2);
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) / 2);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) / 2);
  content: "/";
  color: var(--muted-color);
  text-align: center;
}
nav[aria-label="breadcrumb"] a[aria-current] {
  background-color: transparent;
  color: inherit;
  text-decoration: none;
  pointer-events: none;
}
nav [role="button"] {
  margin-right: inherit;
  margin-left: inherit;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}

aside nav,
aside ol,
aside ul,
aside li {
  display: block;
}
aside li {
  padding: calc(var(--nav-element-spacing-vertical) * 0.5)
    var(--nav-element-spacing-horizontal);
}
aside li a {
  display: block;
}
aside li [role="button"] {
  margin: inherit;
}

[dir="rtl"] nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  content: "\\";
}

/**
 * Progress
 */
progress {
  display: inline-block;
  vertical-align: baseline;
}

progress {
  -webkit-appearance: none;
  -moz-appearance: none;
  display: inline-block;
  appearance: none;
  width: 100%;
  height: 0.5rem;
  margin-bottom: calc(var(--spacing) * 0.5);
  overflow: hidden;
  border: 0;
  border-radius: var(--border-radius);
  background-color: var(--progress-background-color);
  color: var(--progress-color);
}
progress::-webkit-progress-bar {
  border-radius: var(--border-radius);
  background: none;
}
progress[value]::-webkit-progress-value {
  background-color: var(--progress-color);
}
progress::-moz-progress-bar {
  background-color: var(--progress-color);
}
@media (prefers-reduced-motion: no-preference) {
  progress:indeterminate {
    background: var(--progress-background-color)
      linear-gradient(
        to right,
        var(--progress-color) 30%,
        var(--progress-background-color) 30%
      )
      top left/150% 150% no-repeat;
    animation: progress-indeterminate 1s linear infinite;
  }
  progress:indeterminate[value]::-webkit-progress-value {
    background-color: transparent;
  }
  progress:indeterminate::-moz-progress-bar {
    background-color: transparent;
  }
}

@media (prefers-reduced-motion: no-preference) {
  [dir="rtl"] progress:indeterminate {
    animation-direction: reverse;
  }
}

@keyframes progress-indeterminate {
  0% {
    background-position: 200% 0;
  }
  100% {
    background-position: -200% 0;
  }
}
/**
 * Dropdown ([role="list"])
 */
details[role="list"],
li[role="list"] {
  position: relative;
}

details[role="list"] summary + ul,
li[role="list"] > ul {
  display: flex;
  z-index: 99;
  position: absolute;
  top: auto;
  right: 0;
  left: 0;
  flex-direction: column;
  margin: 0;
  padding: 0;
  border: var(--border-width) solid var(--dropdown-border-color);
  border-radius: var(--border-radius);
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  background-color: var(--dropdown-background-color);
  box-shadow: var(--card-box-shadow);
  color: var(--dropdown-color);
  white-space: nowrap;
}
details[role="list"] summary + ul li,
li[role="list"] > ul li {
  width: 100%;
  margin-bottom: 0;
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  list-style: none;
}
details[role="list"] summary + ul li:first-of-type,
li[role="list"] > ul li:first-of-type {
  margin-top: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li:last-of-type,
li[role="list"] > ul li:last-of-type {
  margin-bottom: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li a,
li[role="list"] > ul li a {
  display: block;
  margin: calc(var(--form-element-spacing-vertical) * -0.5)
    calc(var(--form-element-spacing-horizontal) * -1);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  overflow: hidden;
  color: var(--dropdown-color);
  text-decoration: none;
  text-overflow: ellipsis;
}
details[role="list"] summary + ul li a:hover,
li[role="list"] > ul li a:hover {
  background-color: var(--dropdown-hover-background-color);
}

details[role="list"] summary::after,
li[role="list"] > a::after {
  display: block;
  width: 1rem;
  height: calc(1rem * var(--line-height, 1.5));
  -webkit-margin-start: 0.5rem;
  margin-inline-start: 0.5rem;
  float: right;
  transform: rotate(0deg);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
}

details[role="list"] {
  padding: 0;
  border-bottom: none;
}
details[role="list"] summary {
  margin-bottom: 0;
}
details[role="list"] summary:not([role]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--form-element-border-color);
  border-radius: var(--border-radius);
  background-color: var(--form-element-background-color);
  color: var(--form-element-placeholder-color);
  line-height: inherit;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
details[role="list"] summary:not([role]):active,
details[role="list"] summary:not([role]):focus {
  border-color: var(--form-element-active-border-color);
  background-color: var(--form-element-active-background-color);
}
details[role="list"] summary:not([role]):focus {
  box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}
details[role="list"][open] summary {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
details[role="list"][open] summary::before {
  display: block;
  z-index: 1;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  background: none;
  content: "";
  cursor: default;
}

nav details[role="list"] summary,
nav li[role="list"] a {
  display: flex;
  direction: ltr;
}

nav details[role="list"] summary + ul,
nav li[role="list"] > ul {
  min-width: -moz-fit-content;
  min-width: fit-content;
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul li a,
nav li[role="list"] > ul li a {
  border-radius: 0;
}

nav details[role="list"] summary,
nav details[role="list"] summary:not([role]) {
  height: auto;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}
nav details[role="list"][open] summary {
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul {
  margin-top: var(--outline-width);
  -webkit-margin-start: 0;
  margin-inline-start: 0;
}
nav details[role="list"] summary[role="link"] {
  margin-bottom: calc(var(--nav-link-spacing-vertical) * -1);
  line-height: var(--line-height);
}
nav details[role="list"] summary[role="link"] + ul {
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) * -1);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) * -1);
}

li[role="list"]:hover > ul,
li[role="list"] a:active ~ ul,
li[role="list"] a:focus ~ ul {
  display: flex;
}
li[role="list"] > ul {
  display: none;
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
  margin-inline-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
}
li[role="list"] > a::after {
  background-image: var(--icon-chevron);
}

/**
 * Loading ([aria-busy=true])
 */
[aria-busy="true"] {
  cursor: progress;
}

[aria-busy="true"]:not(input, select, textarea)::before {
  display: inline-block;
  width: 1em;
  height: 1em;
  border: 0.1875em solid currentColor;
  border-radius: 1em;
  border-right-color: transparent;
  content: "";
  vertical-align: text-bottom;
  vertical-align: -0.125em;
  animation: spinner 0.75s linear infinite;
  opacity: var(--loading-spinner-opacity);
}
[aria-busy="true"]:not(input, select, textarea):not(:empty)::before {
  margin-right: calc(var(--spacing) * 0.5);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) * 0.5);
  margin-inline-end: calc(var(--spacing) * 0.5);
}
[aria-busy="true"]:not(input, select, textarea):empty {
  text-align: center;
}

button[aria-busy="true"],
input[type="submit"][aria-busy="true"],
input[type="button"][aria-busy="true"],
input[type="reset"][aria-busy="true"],
a[aria-busy="true"] {
  pointer-events: none;
}

@keyframes spinner {
  to {
    transform: rotate(360deg);
  }
}
/**
 * Tooltip ([data-tooltip])
 */
[data-tooltip] {
  position: relative;
}
[data-tooltip]:not(a, button, input) {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}
[data-tooltip][data-placement="top"]::before,
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::before,
[data-tooltip]::after {
  display: block;
  z-index: 99;
  position: absolute;
  bottom: 100%;
  left: 50%;
  padding: 0.25rem 0.5rem;
  overflow: hidden;
  transform: translate(-50%, -0.25rem);
  border-radius: var(--border-radius);
  background: var(--tooltip-background-color);
  content: attr(data-tooltip);
  color: var(--tooltip-color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: 0.875rem;
  text-decoration: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  opacity: 0;
  pointer-events: none;
}
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::after {
  padding: 0;
  transform: translate(-50%, 0rem);
  border-top: 0.3rem solid;
  border-right: 0.3rem solid transparent;
  border-left: 0.3rem solid transparent;
  border-radius: 0;
  background-color: transparent;
  content: "";
  color: var(--tooltip-background-color);
}
[data-tooltip][data-placement="bottom"]::before,
[data-tooltip][data-placement="bottom"]::after {
  top: 100%;
  bottom: auto;
  transform: translate(-50%, 0.25rem);
}
[data-tooltip][data-placement="bottom"]:after {
  transform: translate(-50%, -0.3rem);
  border: 0.3rem solid transparent;
  border-bottom: 0.3rem solid;
}
[data-tooltip][data-placement="left"]::before,
[data-tooltip][data-placement="left"]::after {
  top: 50%;
  right: 100%;
  bottom: auto;
  left: auto;
  transform: translate(-0.25rem, -50%);
}
[data-tooltip][data-placement="left"]:after {
  transform: translate(0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-left: 0.3rem solid;
}
[data-tooltip][data-placement="right"]::before,
[data-tooltip][data-placement="right"]::after {
  top: 50%;
  right: auto;
  bottom: auto;
  left: 100%;
  transform: translate(0.25rem, -50%);
}
[data-tooltip][data-placement="right"]:after {
  transform: translate(-0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-right: 0.3rem solid;
}
[data-tooltip]:focus::before,
[data-tooltip]:focus::after,
[data-tooltip]:hover::before,
[data-tooltip]:hover::after {
  opacity: 1;
}
@media (hover: hover) and (pointer: fine) {
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::before,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::before,
  [data-tooltip]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::after {
    animation-name: tooltip-caret-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::before,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-bottom;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-name: tooltip-caret-slide-bottom;
  }
  [data-tooltip][data-placement="left"]:focus::before,
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::before,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-left;
  }
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-name: tooltip-caret-slide-left;
  }
  [data-tooltip][data-placement="right"]:focus::before,
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::before,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-right;
  }
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-name: tooltip-caret-slide-right;
  }
}
@keyframes tooltip-slide-top {
  from {
    transform: translate(-50%, 0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-top {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.25rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-bottom {
  from {
    transform: translate(-50%, -0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-bottom {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.5rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.3rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-left {
  from {
    transform: translate(0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-left {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.3rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-slide-right {
  from {
    transform: translate(-0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-right {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.3rem, -50%);
    opacity: 1;
  }
}

/**
 * Accessibility & User interaction
 */
[aria-controls] {
  cursor: pointer;
}

[aria-disabled="true"],
[disabled] {
  cursor: not-allowed;
}

[aria-hidden="false"][hidden] {
  display: initial;
}

[aria-hidden="false"][hidden]:not(:focus) {
  clip: rect(0, 0, 0, 0);
  position: absolute;
}

a,
area,
button,
input,
label,
select,
summary,
textarea,
[tabindex] {
  -ms-touch-action: manipulation;
}

[dir="rtl"] {
  direction: rtl;
}

/**
* Reduce Motion Features
*/
@media (prefers-reduced-motion: reduce) {
  *:not([aria-busy="true"]),
  :not([aria-busy="true"])::before,
  :not([aria-busy="true"])::after {
    background-attachment: initial !important;
    animation-duration: 1ms !important;
    animation-delay: -1ms !important;
    animation-iteration-count: 1 !important;
    scroll-behavior: auto !important;
    transition-delay: 0s !important;
    transition-duration: 0s !important;
  }
}

#mount {
  /* --primary: rgb(227, 59, 126); */
  --primary: #ea4c89;
  --primary-hover: #f082ac;
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  --switch-checked-background-color: var(--primary);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="dark"] {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="light"] {
  --primary: #ea4c89;
  --primary-hover: #f082ac;
}

li.select-link.select-link:hover > ul {
  display: none;
}
li.select-link.select-link > ul {
  display: none;
}
li.select-link.select-link a:focus ~ ul {
  display: none;
}

li.select-link.select-link a:active ~ ul {
  display: none;
}
li.select-link-active.select-link-active > ul {
  display: flex;
}
li.select-link-active.select-link-active:hover > ul {
  display: flex;
}

li.select-link-active.select-link-active a:focus ~ ul {
  display: flex;
}

li.select-link-active.select-link-active a:active ~ ul {
  display: flex;
}
ul.select-link-ul.select-link-ul {
  right: 0px;
  left: auto;
}

a.select-link-selected {
  background-color: var(--primary-focus);
}
.immersive-translate-no-select {
  -webkit-touch-callout: none; /* iOS Safari */
  -webkit-user-select: none; /* Safari */
  -khtml-user-select: none; /* Konqueror HTML */
  -moz-user-select: none; /* Old versions of Firefox */
  -ms-user-select: none; /* Internet Explorer/Edge */
  user-select: none;
}

/* li[role="list"].no-arrow > a::after { */
/*   background-image: none; */
/*   width: 0; */
/*   color: var(--color); */
/* } */
li[role="list"].no-arrow {
  margin-left: 8px;
  padding-right: 0;
}
li[role="list"] > a::after {
  -webkit-margin-start: 0.2rem;
  margin-inline-start: 0.2rem;
}

li[role="list"].no-arrow > a,
li[role="list"].no-arrow > a:link,
li[role="list"].no-arrow > a:visited {
  color: var(--secondary);
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  padding-left: 8px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}
select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.muted {
  color: var(--muted-color);
}

.select.button-select {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
  cursor: pointer;
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 16px;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
  -webkit-appearance: button;
  margin: 0;
  margin-bottom: 0px;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --text-black-2: #222222;
  --text-gray-2: #222222;
  --text-gray-6: #666666;
  --text-gray-9: #999999;
  --text-gray-c2: #c2c2c2;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --popup-footer-background-color: #0d0d0d;
    --popup-content-background-color: #191919;
    --popup-item-background-color: #272727;
    --popup-item-hover-background-color: #333333;
    --popup-trial-pro-background-color: #222222;
    --text-black-2: #ffffff;
    --text-gray-2: #dbdbdb;
    --text-gray-6: #b3b3b3;
    --text-gray-9: #777777;
    --text-gray-c2: #5b5b5b;
    --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
    --service-select-border-color: #2c2c2c;
    --service-select-selected-background-color: #333333;
    --download-app-background: #333;
  }
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --text-black-2: #ffffff;
  --text-gray-2: #dbdbdb;
  --text-gray-6: #b3b3b3;
  --text-gray-9: #777777;
  --text-gray-c2: #5b5b5b;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

.text-balck {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

#mount {
  min-width: 268px;
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

select.min-select-secondary {
  color: var(--color);
}

select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 372px;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #B3B3B3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 568px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg><svg hidden="true" class="imt-manga-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div><svg class="imt-float-ball-loading" hidden="true" width="19" height="19" viewBox="0 0 19 19" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin: 9px;"><path d="M9.42859 0C9.84288 0 10.1929 0.387143 10.1929 0.847143V3.99429C10.1929 4.45429 9.84431 4.84143 9.42859 4.84143C9.01431 4.84143 8.66431 4.45571 8.66431 3.99429V0.847143C8.66431 0.387143 9.01288 0 9.42859 0Z" fill="#E9E9E9"></path><path d="M14.1301 1.38877C14.5158 1.62591 14.6301 2.12163 14.4258 2.52305L12.9515 5.19448C12.901 5.28714 12.8325 5.36876 12.75 5.43455C12.6675 5.50035 12.5727 5.54898 12.4712 5.5776C12.3696 5.60621 12.2634 5.61424 12.1586 5.60119C12.0539 5.58814 11.9529 5.55429 11.8615 5.50163C11.6787 5.38432 11.5468 5.20237 11.4923 4.9921C11.4377 4.78184 11.4645 4.55874 11.5672 4.36734L13.0415 1.69591C13.2686 1.29448 13.7443 1.15305 14.1301 1.38877Z" fill="#989697"></path><path d="M17.4685 4.75707C17.5813 4.95451 17.6123 5.18824 17.5549 5.40825C17.4975 5.62826 17.3563 5.81705 17.1614 5.93422L14.4971 7.52564C14.0971 7.76993 13.6014 7.62422 13.3657 7.20707C13.2532 7.00994 13.2222 6.77667 13.2793 6.55702C13.3365 6.33737 13.4771 6.14874 13.6714 6.03136L16.3357 4.43993C16.7371 4.21993 17.2557 4.34136 17.4685 4.7585V4.75707Z" fill="#9B999A"></path><path d="M18.8572 9.42835C18.8572 9.84263 18.47 10.1926 18.01 10.1926H14.8629C14.4029 10.1926 14.0157 9.84406 14.0157 9.42835C14.0157 9.01406 14.4029 8.66406 14.8629 8.66406H18.01C18.47 8.66406 18.8572 9.01263 18.8572 9.42835Z" fill="#A3A1A2"></path><path d="M17.4686 14.1303C17.3515 14.3134 17.1697 14.4455 16.9594 14.5003C16.7491 14.5552 16.5259 14.5286 16.3343 14.426L13.6629 12.9517C13.5702 12.9012 13.4886 12.8327 13.4228 12.7503C13.357 12.6678 13.3084 12.573 13.2798 12.4714C13.2512 12.3698 13.2431 12.2636 13.2562 12.1589C13.2692 12.0542 13.3031 11.9532 13.3558 11.8617C13.4731 11.6789 13.655 11.547 13.8653 11.4925C14.0755 11.4379 14.2986 11.4647 14.49 11.5674L17.1615 13.0417C17.5629 13.2689 17.7043 13.7446 17.4686 14.1303Z" fill="#ABA9AA"></path><path opacity="0.7" d="M14.1 17.4686C13.9026 17.5814 13.6689 17.6124 13.4489 17.555C13.2288 17.4976 13.04 17.3564 12.9229 17.1615L11.3315 14.4972C11.0872 14.0972 11.2329 13.6015 11.65 13.3658C11.8472 13.2533 12.0804 13.2224 12.3001 13.2795C12.5197 13.3366 12.7084 13.4773 12.8257 13.6715L14.4172 16.3358C14.6372 16.7372 14.5157 17.2558 14.0986 17.4686H14.1Z" fill="#B2B2B2"></path><path opacity="0.6" d="M9.42859 18.8571C9.01431 18.8571 8.66431 18.4699 8.66431 18.0099V14.8628C8.66431 14.4028 9.01288 14.0156 9.42859 14.0156C9.84288 14.0156 10.1929 14.4028 10.1929 14.8628V18.0099C10.1929 18.4699 9.84431 18.8571 9.42859 18.8571Z" fill="#BAB8B9"></path><path opacity="0.5" d="M4.72717 17.4685C4.5441 17.3514 4.41195 17.1696 4.35713 16.9593C4.30231 16.749 4.32885 16.5258 4.43145 16.3342L5.90574 13.6628C5.95622 13.5701 6.02472 13.4885 6.1072 13.4227C6.18969 13.3569 6.2845 13.3083 6.38606 13.2797C6.48762 13.251 6.59387 13.243 6.69857 13.2561C6.80327 13.2691 6.90431 13.303 6.99574 13.3556C7.38145 13.5914 7.49431 14.0885 7.29002 14.4899L5.81574 17.1614C5.5886 17.5628 5.11288 17.7042 4.72717 17.4685Z" fill="#C2C0C1"></path><path opacity="0.4" d="M1.38862 14.1002C1.27584 13.9027 1.24483 13.669 1.30223 13.449C1.35964 13.229 1.50089 13.0402 1.69576 12.923L4.36004 11.3316C4.76004 11.0873 5.25576 11.233 5.49147 11.6502C5.60393 11.8473 5.63491 12.0806 5.5778 12.3002C5.52069 12.5199 5.38 12.7085 5.18576 12.8259L2.52004 14.4173C2.12004 14.6373 1.60004 14.5159 1.38862 14.0987V14.1002Z" fill="#CBCBCB"></path><path d="M0 9.42835C0 9.01406 0.387143 8.66406 0.847143 8.66406H3.99429C4.45429 8.66406 4.84143 9.01263 4.84143 9.42835C4.84143 9.84263 4.45571 10.1926 3.99429 10.1926H0.847143C0.387143 10.1926 0 9.84406 0 9.42835Z" fill="#D2D2D2"></path><path opacity="0.2" d="M1.38852 4.72705C1.50561 4.54398 1.68746 4.41183 1.89774 4.35701C2.10803 4.30219 2.33125 4.32873 2.52281 4.43133L5.19424 5.90562C5.28689 5.9561 5.36851 6.0246 5.43431 6.10708C5.5001 6.18957 5.54874 6.28438 5.57735 6.38594C5.60597 6.48749 5.61399 6.59375 5.60094 6.69845C5.5879 6.80315 5.55405 6.90419 5.50138 6.99562C5.38407 7.17844 5.20212 7.31029 4.99186 7.36484C4.78159 7.4194 4.55849 7.39263 4.3671 7.2899L1.69567 5.81562C1.29424 5.58847 1.15281 5.11276 1.38852 4.72705Z" fill="#DADADA"></path><path d="M4.75719 1.38849C4.95463 1.27571 5.18837 1.24471 5.40838 1.30211C5.62838 1.35952 5.81718 1.50077 5.93434 1.69564L7.52577 4.35992C7.77005 4.75992 7.62434 5.25564 7.20719 5.49135C7.01006 5.60381 6.77679 5.63479 6.55714 5.57768C6.33749 5.52056 6.14886 5.37988 6.03148 5.18564L4.44005 2.51992C4.22005 2.11992 4.34148 1.59992 4.75862 1.38849H4.75719Z" fill="#E2E2E2"></path></svg></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; bottom: 30px; right: 65px;"></div></div></div></div></template></div><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header" data-bs-theme="dark"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed; display: none; left: 906px; top: 463.038px; transform: translate(-50%, -100%);">Report Issue for Selection</button></body><div id="immersive-translate-popup" style="all: initial"><template shadowrootmode="open"><style>@charset "UTF-8";
/*!
 * Pico.css v1.5.6 (https://picocss.com)
 * Copyright 2019-2022 - Licensed under MIT
 */
/**
 * Theme: default
 */
#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 0.25rem;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 1rem;
  --typography-spacing-vertical: 1.5rem;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 0.75rem;
  --form-element-spacing-horizontal: 1rem;
  --nav-element-spacing-vertical: 1rem;
  --nav-element-spacing-horizontal: 0.5rem;
  --nav-link-spacing-vertical: 0.5rem;
  --nav-link-spacing-horizontal: 0.5rem;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(0.25rem);
}
@media (min-width: 576px) {
  #mount {
    --font-size: 17px;
  }
}
@media (min-width: 768px) {
  #mount {
    --font-size: 18px;
  }
}
@media (min-width: 992px) {
  #mount {
    --font-size: 19px;
  }
}
@media (min-width: 1200px) {
  #mount {
    --font-size: 20px;
  }
}

@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2);
  }
}
@media (min-width: 768px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3);
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer,
  section {
    --block-spacing-vertical: calc(var(--spacing) * 3.5);
  }
}

@media (min-width: 576px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}
@media (min-width: 992px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 1.75);
  }
}
@media (min-width: 1200px) {
  article {
    --block-spacing-horizontal: calc(var(--spacing) * 2);
  }
}

dialog > article {
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
}
@media (min-width: 576px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 2.5);
    --block-spacing-horizontal: calc(var(--spacing) * 1.25);
  }
}
@media (min-width: 768px) {
  dialog > article {
    --block-spacing-vertical: calc(var(--spacing) * 3);
    --block-spacing-horizontal: calc(var(--spacing) * 1.5);
  }
}

a {
  --text-decoration: none;
}
a.secondary,
a.contrast {
  --text-decoration: underline;
}

small {
  --font-size: 0.875em;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  --font-weight: 700;
}

h1 {
  --font-size: 2rem;
  --typography-spacing-vertical: 3rem;
}

h2 {
  --font-size: 1.75rem;
  --typography-spacing-vertical: 2.625rem;
}

h3 {
  --font-size: 1.5rem;
  --typography-spacing-vertical: 2.25rem;
}

h4 {
  --font-size: 1.25rem;
  --typography-spacing-vertical: 1.874rem;
}

h5 {
  --font-size: 1.125rem;
  --typography-spacing-vertical: 1.6875rem;
}

[type="checkbox"],
[type="radio"] {
  --border-width: 2px;
}

[type="checkbox"][role="switch"] {
  --border-width: 2px;
}

thead th,
thead td,
tfoot th,
tfoot td {
  --border-width: 3px;
}

:not(thead, tfoot) > * > td {
  --font-size: 0.875em;
}

pre,
code,
kbd,
samp {
  --font-family: "Menlo", "Consolas", "Roboto Mono", "Ubuntu Monospace",
    "Noto Mono", "Oxygen Mono", "Liberation Mono", monospace,
    "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
}

kbd {
  --font-weight: bolder;
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --background-color: #fff;
  --background-light-green: #f5f7f9;
  --color: hsl(205deg, 20%, 32%);
  --h1-color: hsl(205deg, 30%, 15%);
  --h2-color: #24333e;
  --h3-color: hsl(205deg, 25%, 23%);
  --h4-color: #374956;
  --h5-color: hsl(205deg, 20%, 32%);
  --h6-color: #4d606d;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: hsl(205deg, 20%, 94%);
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 90%, 32%);
  --primary-focus: rgba(16, 149, 193, 0.125);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 20%, 32%);
  --secondary-focus: rgba(89, 107, 120, 0.125);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 30%, 15%);
  --contrast-hover: #000;
  --contrast-focus: rgba(89, 107, 120, 0.125);
  --contrast-inverse: #fff;
  --mark-background-color: #fff2ca;
  --mark-color: #543a26;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: transparent;
  --form-element-border-color: hsl(205deg, 14%, 68%);
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: transparent;
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 18%, 86%);
  --form-element-disabled-border-color: hsl(205deg, 14%, 68%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #c62828;
  --form-element-invalid-active-border-color: #d32f2f;
  --form-element-invalid-focus-color: rgba(211, 47, 47, 0.125);
  --form-element-valid-border-color: #388e3c;
  --form-element-valid-active-border-color: #43a047;
  --form-element-valid-focus-color: rgba(67, 160, 71, 0.125);
  --switch-background-color: hsl(205deg, 16%, 77%);
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: hsl(205deg, 18%, 86%);
  --range-active-border-color: hsl(205deg, 16%, 77%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: #f6f8f9;
  --code-background-color: hsl(205deg, 20%, 94%);
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 40%, 50%);
  --code-property-color: hsl(185deg, 40%, 40%);
  --code-value-color: hsl(40deg, 20%, 50%);
  --code-comment-color: hsl(205deg, 14%, 68%);
  --accordion-border-color: var(--muted-border-color);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: var(--background-color);
  --card-border-color: var(--muted-border-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(27, 40, 50, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(27, 40, 50, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(27, 40, 50, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(27, 40, 50, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(27, 40, 50, 0.04302),
    0.5rem 1rem 6rem rgba(27, 40, 50, 0.06),
    0 0 0 0.0625rem rgba(27, 40, 50, 0.015);
  --card-sectionning-background-color: #fbfbfc;
  --dropdown-background-color: #fbfbfc;
  --dropdown-border-color: #e1e6eb;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: hsl(205deg, 20%, 94%);
  --modal-overlay-background-color: rgba(213, 220, 226, 0.7);
  --progress-background-color: hsl(205deg, 18%, 86%);
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(198, 40, 40)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(65, 84, 98)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(56, 142, 60)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  --float-ball-more-button-border-color: #f6f6f6;
  --float-ball-more-button-background-color: #ffffff;
  --float-ball-more-button-svg-color: #6c6f73;
  color-scheme: light;
  --service-bg-hover: #f7faff;
  --service-bg: #fafbfb;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --background-color: #11191f;
    --float-ball-more-button-background-color: #ffffff;
    --background-light-green: #141e26;
    --color: hsl(205deg, 16%, 77%);
    --h1-color: hsl(205deg, 20%, 94%);
    --h2-color: #e1e6eb;
    --h3-color: hsl(205deg, 18%, 86%);
    --h4-color: #c8d1d8;
    --h5-color: hsl(205deg, 16%, 77%);
    --h6-color: #afbbc4;
    --muted-color: hsl(205deg, 10%, 50%);
    --muted-border-color: #1f2d38;
    --primary: hsl(195deg, 85%, 41%);
    --primary-hover: hsl(195deg, 80%, 50%);
    --primary-focus: rgba(16, 149, 193, 0.25);
    --primary-inverse: #fff;
    --secondary: hsl(205deg, 15%, 41%);
    --secondary-hover: hsl(205deg, 10%, 50%);
    --secondary-focus: rgba(115, 130, 140, 0.25);
    --secondary-inverse: #fff;
    --contrast: hsl(205deg, 20%, 94%);
    --contrast-hover: #fff;
    --contrast-focus: rgba(115, 130, 140, 0.25);
    --contrast-inverse: #000;
    --mark-background-color: #d1c284;
    --mark-color: #11191f;
    --ins-color: #388e3c;
    --del-color: #c62828;
    --blockquote-border-color: var(--muted-border-color);
    --blockquote-footer-color: var(--muted-color);
    --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
    --form-element-background-color: #11191f;
    --form-element-border-color: #374956;
    --form-element-color: var(--color);
    --form-element-placeholder-color: var(--muted-color);
    --form-element-active-background-color: var(
      --form-element-background-color
    );
    --form-element-active-border-color: var(--primary);
    --form-element-focus-color: var(--primary-focus);
    --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
    --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
    --form-element-disabled-opacity: 0.5;
    --form-element-invalid-border-color: #b71c1c;
    --form-element-invalid-active-border-color: #c62828;
    --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
    --form-element-valid-border-color: #2e7d32;
    --form-element-valid-active-border-color: #388e3c;
    --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
    --switch-background-color: #374956;
    --switch-color: var(--primary-inverse);
    --switch-checked-background-color: var(--primary);
    --range-border-color: #24333e;
    --range-active-border-color: hsl(205deg, 25%, 23%);
    --range-thumb-border-color: var(--background-color);
    --range-thumb-color: var(--secondary);
    --range-thumb-hover-color: var(--secondary-hover);
    --range-thumb-active-color: var(--primary);
    --table-border-color: var(--muted-border-color);
    --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
    --code-background-color: #18232c;
    --code-color: var(--muted-color);
    --code-kbd-background-color: var(--contrast);
    --code-kbd-color: var(--contrast-inverse);
    --code-tag-color: hsl(330deg, 30%, 50%);
    --code-property-color: hsl(185deg, 30%, 50%);
    --code-value-color: hsl(40deg, 10%, 50%);
    --code-comment-color: #4d606d;
    --accordion-border-color: var(--muted-border-color);
    --accordion-active-summary-color: var(--primary);
    --accordion-close-summary-color: var(--color);
    --accordion-open-summary-color: var(--muted-color);
    --card-background-color: #141e26;
    --card-border-color: var(--card-background-color);
    --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
      0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
      0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
      0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
      0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
      0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
    --card-sectionning-background-color: #18232c;
    --dropdown-background-color: hsl(205deg, 30%, 15%);
    --dropdown-border-color: #24333e;
    --dropdown-box-shadow: var(--card-box-shadow);
    --dropdown-color: var(--color);
    --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
    --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
    --progress-background-color: #24333e;
    --progress-color: var(--primary);
    --loading-spinner-opacity: 0.5;
    --tooltip-background-color: var(--contrast);
    --tooltip-color: var(--contrast-inverse);
    --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
    --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
    --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
    --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
    --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
    --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
    --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
    color-scheme: dark;
    --service-bg-hover: #22292f;
    --service-bg: rgba(0, 0, 0, 0.1);
  }
}
[data-theme="dark"] {
  --background-color: #11191f;
  --float-ball-more-button-background-color: #191919;
  --background-light-green: #141e26;
  --color: hsl(205deg, 16%, 77%);
  --h1-color: hsl(205deg, 20%, 94%);
  --h2-color: #e1e6eb;
  --h3-color: hsl(205deg, 18%, 86%);
  --h4-color: #c8d1d8;
  --h5-color: hsl(205deg, 16%, 77%);
  --h6-color: #afbbc4;
  --muted-color: hsl(205deg, 10%, 50%);
  --muted-border-color: #1f2d38;
  --primary: hsl(195deg, 85%, 41%);
  --primary-hover: hsl(195deg, 80%, 50%);
  --primary-focus: rgba(16, 149, 193, 0.25);
  --primary-inverse: #fff;
  --secondary: hsl(205deg, 15%, 41%);
  --secondary-hover: hsl(205deg, 10%, 50%);
  --secondary-focus: rgba(115, 130, 140, 0.25);
  --secondary-inverse: #fff;
  --contrast: hsl(205deg, 20%, 94%);
  --contrast-hover: #fff;
  --contrast-focus: rgba(115, 130, 140, 0.25);
  --contrast-inverse: #000;
  --mark-background-color: #d1c284;
  --mark-color: #11191f;
  --ins-color: #388e3c;
  --del-color: #c62828;
  --blockquote-border-color: var(--muted-border-color);
  --blockquote-footer-color: var(--muted-color);
  --button-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --button-hover-box-shadow: 0 0 0 rgba(0, 0, 0, 0);
  --form-element-background-color: #11191f;
  --form-element-border-color: #374956;
  --form-element-color: var(--color);
  --form-element-placeholder-color: var(--muted-color);
  --form-element-active-background-color: var(--form-element-background-color);
  --form-element-active-border-color: var(--primary);
  --form-element-focus-color: var(--primary-focus);
  --form-element-disabled-background-color: hsl(205deg, 25%, 23%);
  --form-element-disabled-border-color: hsl(205deg, 20%, 32%);
  --form-element-disabled-opacity: 0.5;
  --form-element-invalid-border-color: #b71c1c;
  --form-element-invalid-active-border-color: #c62828;
  --form-element-invalid-focus-color: rgba(198, 40, 40, 0.25);
  --form-element-valid-border-color: #2e7d32;
  --form-element-valid-active-border-color: #388e3c;
  --form-element-valid-focus-color: rgba(56, 142, 60, 0.25);
  --switch-background-color: #374956;
  --switch-color: var(--primary-inverse);
  --switch-checked-background-color: var(--primary);
  --range-border-color: #24333e;
  --range-active-border-color: hsl(205deg, 25%, 23%);
  --range-thumb-border-color: var(--background-color);
  --range-thumb-color: var(--secondary);
  --range-thumb-hover-color: var(--secondary-hover);
  --range-thumb-active-color: var(--primary);
  --table-border-color: var(--muted-border-color);
  --table-row-stripped-background-color: rgba(115, 130, 140, 0.05);
  --code-background-color: #18232c;
  --code-color: var(--muted-color);
  --code-kbd-background-color: var(--contrast);
  --code-kbd-color: var(--contrast-inverse);
  --code-tag-color: hsl(330deg, 30%, 50%);
  --code-property-color: hsl(185deg, 30%, 50%);
  --code-value-color: hsl(40deg, 10%, 50%);
  --code-comment-color: #4d606d;
  --accordion-border-color: var(--muted-border-color);
  --accordion-active-summary-color: var(--primary);
  --accordion-close-summary-color: var(--color);
  --accordion-open-summary-color: var(--muted-color);
  --card-background-color: #141e26;
  --card-border-color: var(--card-background-color);
  --card-box-shadow: 0.0145rem 0.029rem 0.174rem rgba(0, 0, 0, 0.01698),
    0.0335rem 0.067rem 0.402rem rgba(0, 0, 0, 0.024),
    0.0625rem 0.125rem 0.75rem rgba(0, 0, 0, 0.03),
    0.1125rem 0.225rem 1.35rem rgba(0, 0, 0, 0.036),
    0.2085rem 0.417rem 2.502rem rgba(0, 0, 0, 0.04302),
    0.5rem 1rem 6rem rgba(0, 0, 0, 0.06), 0 0 0 0.0625rem rgba(0, 0, 0, 0.015);
  --card-sectionning-background-color: #18232c;
  --dropdown-background-color: hsl(205deg, 30%, 15%);
  --dropdown-border-color: #24333e;
  --dropdown-box-shadow: var(--card-box-shadow);
  --dropdown-color: var(--color);
  --dropdown-hover-background-color: rgba(36, 51, 62, 0.75);
  --modal-overlay-background-color: rgba(36, 51, 62, 0.8);
  --progress-background-color: #24333e;
  --progress-color: var(--primary);
  --loading-spinner-opacity: 0.5;
  --tooltip-background-color: var(--contrast);
  --tooltip-color: var(--contrast-inverse);
  --icon-checkbox: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-chevron-button-inverse: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(0, 0, 0)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='6 9 12 15 18 9'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-close: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(115, 130, 140)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='18' y1='6' x2='6' y2='18'%3E%3C/line%3E%3Cline x1='6' y1='6' x2='18' y2='18'%3E%3C/line%3E%3C/svg%3E");
  --icon-date: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Crect x='3' y='4' width='18' height='18' rx='2' ry='2'%3E%3C/rect%3E%3Cline x1='16' y1='2' x2='16' y2='6'%3E%3C/line%3E%3Cline x1='8' y1='2' x2='8' y2='6'%3E%3C/line%3E%3Cline x1='3' y1='10' x2='21' y2='10'%3E%3C/line%3E%3C/svg%3E");
  --icon-invalid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(183, 28, 28)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cline x1='12' y1='8' x2='12' y2='12'%3E%3C/line%3E%3Cline x1='12' y1='16' x2='12.01' y2='16'%3E%3C/line%3E%3C/svg%3E");
  --icon-minus: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(255, 255, 255)' stroke-width='4' stroke-linecap='round' stroke-linejoin='round'%3E%3Cline x1='5' y1='12' x2='19' y2='12'%3E%3C/line%3E%3C/svg%3E");
  --icon-search: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='11' cy='11' r='8'%3E%3C/circle%3E%3Cline x1='21' y1='21' x2='16.65' y2='16.65'%3E%3C/line%3E%3C/svg%3E");
  --icon-time: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(162, 175, 185)' stroke-width='2' stroke-linecap='round' stroke-linejoin='round'%3E%3Ccircle cx='12' cy='12' r='10'%3E%3C/circle%3E%3Cpolyline points='12 6 12 12 16 14'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-valid: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' viewBox='0 0 24 24' fill='none' stroke='rgb(46, 125, 50)' stroke-width='3' stroke-linecap='round' stroke-linejoin='round'%3E%3Cpolyline points='20 6 9 17 4 12'%3E%3C/polyline%3E%3C/svg%3E");
  --icon-share: url("data:image/svg+xml;charset=utf-8;base64,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");
  color-scheme: dark;
  --service-bg: rgba(0, 0, 0, 0.1);
}

progress,
[type="checkbox"],
[type="radio"],
[type="range"] {
  accent-color: var(--primary);
}

/**
 * Document
 * Content-box & Responsive typography
 */
*,
*::before,
*::after {
  box-sizing: border-box;
  background-repeat: no-repeat;
}

::before,
::after {
  text-decoration: inherit;
  vertical-align: inherit;
}

:where(#mount) {
  -webkit-tap-highlight-color: transparent;
  -webkit-text-size-adjust: 100%;
  -moz-text-size-adjust: 100%;
  text-size-adjust: 100%;
  background-color: var(--background-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  line-height: var(--line-height);
  font-family: var(--font-family);
  text-rendering: optimizeLegibility;
  overflow-wrap: break-word;
  cursor: default;
  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;
}

/**
 * Sectioning
 * Container and responsive spacings for header, main, footer
 */
main {
  display: block;
}

#mount {
  width: 100%;
  margin: 0;
}
#mount > header,
#mount > main,
#mount > footer {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
}
@media (min-width: 576px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 2px !important;
  }
}
@media (min-width: 992px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 12px !important;
  }
}
@media (min-width: 1200px) {
  #mount > header,
  #mount > main,
  #mount > footer {
    padding: 0 24px !important;
  }
}

/**
* Container
*/
.container,
.container-fluid {
  width: 100%;
  margin-right: auto;
  margin-left: auto;
  padding-right: var(--spacing);
  padding-left: var(--spacing);
}
/*
@media (min-width: 576px) {
  .container {
    max-width: 510px;
    padding-right: 0;
    padding-left: 0;
  }
}
@media (min-width: 768px) {
  .container {
    max-width: 700px;
  }
} */
@media (min-width: 992px) {
  .container {
    max-width: 920px;
  }
}
@media (min-width: 1200px) {
  .container {
    max-width: 1130px;
  }
}

/**
 * Section
 * Responsive spacings for section
 */
section {
  margin-bottom: var(--block-spacing-vertical);
}

/**
* Grid
* Minimal grid system with auto-layout columns
*/
.grid {
  grid-column-gap: var(--grid-spacing-horizontal);
  grid-row-gap: var(--grid-spacing-vertical);
  display: grid;
  grid-template-columns: 1fr;
  margin: 0;
}
@media (min-width: 1280px) {
  .grid {
    grid-template-columns: repeat(auto-fit, minmax(0%, 1fr));
  }
}
.grid > * {
  min-width: 0;
}

/**
 * Horizontal scroller (<figure>)
 */
figure {
  display: block;
  margin: 0;
  padding: 0;
  overflow-x: auto;
}
figure figcaption {
  padding: calc(var(--spacing) * 0.5) 0;
  color: var(--muted-color);
}

/**
 * Typography
 */
b,
strong {
  font-weight: bolder;
}

sub,
sup {
  position: relative;
  font-size: 0.75em;
  line-height: 0;
  vertical-align: baseline;
}

sub {
  bottom: -0.25em;
}

sup {
  top: -0.5em;
}

address,
blockquote,
dl,
figure,
form,
ol,
p,
pre,
table,
ul {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: var(--font-size);
}

a,
[role="link"] {
  --color: var(--primary);
  --background-color: transparent;
  outline: none;
  background-color: var(--background-color);
  color: var(--color);
  -webkit-text-decoration: var(--text-decoration);
  text-decoration: var(--text-decoration);
  transition: background-color var(--transition), color var(--transition),
    box-shadow var(--transition), -webkit-text-decoration var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition);
  transition: background-color var(--transition), color var(--transition),
    text-decoration var(--transition), box-shadow var(--transition),
    -webkit-text-decoration var(--transition);
}
a:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --color: var(--primary-hover);
  --text-decoration: underline;
}
a:focus,
[role="link"]:focus {
  --background-color: var(--primary-focus);
}
a.secondary,
[role="link"].secondary {
  --color: var(--secondary);
}
a.secondary:is([aria-current], :hover, :active, :focus),
[role="link"].secondary:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}
a.secondary:focus,
[role="link"].secondary:focus {
  --background-color: var(--secondary-focus);
}
a.contrast,
[role="link"].contrast {
  --color: var(--contrast);
}
a.contrast:is([aria-current], :hover, :active, :focus),
[role="link"].contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}
a.contrast:focus,
[role="link"].contrast:focus {
  --background-color: var(--contrast-focus);
}

h1,
h2,
h3,
h4,
h5,
h6 {
  margin-top: 0;
  margin-bottom: var(--typography-spacing-vertical);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  font-family: var(--font-family);
}

h1 {
  --color: var(--h1-color);
}

h2 {
  --color: var(--h2-color);
}

h3 {
  --color: var(--h3-color);
}

h4 {
  --color: var(--h4-color);
}

h5 {
  --color: var(--h5-color);
}

h6 {
  --color: var(--h6-color);
}

:where(address, blockquote, dl, figure, form, ol, p, pre, table, ul)
  ~ :is(h1, h2, h3, h4, h5, h6) {
  margin-top: var(--typography-spacing-vertical);
}

hgroup,
.headings {
  margin-bottom: var(--typography-spacing-vertical);
}
hgroup > *,
.headings > * {
  margin-bottom: 0;
}
hgroup > *:last-child,
.headings > *:last-child {
  --color: var(--muted-color);
  --font-weight: unset;
  font-size: 1rem;
  font-family: unset;
}

p {
  margin-bottom: var(--typography-spacing-vertical);
}

small {
  font-size: var(--font-size);
}

:where(dl, ol, ul) {
  padding-right: 0;
  padding-left: var(--spacing);
  -webkit-padding-start: var(--spacing);
  padding-inline-start: var(--spacing);
  -webkit-padding-end: 0;
  padding-inline-end: 0;
}
:where(dl, ol, ul) li {
  margin-bottom: calc(var(--typography-spacing-vertical) * 0.25);
}

:where(dl, ol, ul) :is(dl, ol, ul) {
  margin: 0;
  margin-top: calc(var(--typography-spacing-vertical) * 0.25);
}

ul li {
  list-style: square;
}

mark {
  padding: 0.125rem 0.25rem;
  background-color: var(--mark-background-color);
  color: var(--mark-color);
  vertical-align: baseline;
}

blockquote {
  display: block;
  margin: var(--typography-spacing-vertical) 0;
  padding: var(--spacing);
  border-right: none;
  border-left: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-start: 0.25rem solid var(--blockquote-border-color);
  border-inline-start: 0.25rem solid var(--blockquote-border-color);
  -webkit-border-end: none;
  border-inline-end: none;
}
blockquote footer {
  margin-top: calc(var(--typography-spacing-vertical) * 0.5);
  color: var(--blockquote-footer-color);
}

abbr[title] {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}

ins {
  color: var(--ins-color);
  text-decoration: none;
}

del {
  color: var(--del-color);
}

::-moz-selection {
  background-color: var(--primary-focus);
}

::selection {
  background-color: var(--primary-focus);
}

/**
 * Embedded content
 */
:where(audio, canvas, iframe, img, svg, video) {
  vertical-align: middle;
}

audio,
video {
  display: inline-block;
}

audio:not([controls]) {
  display: none;
  height: 0;
}

:where(iframe) {
  border-style: none;
}

img {
  max-width: 100%;
  height: auto;
  border-style: none;
}

:where(svg:not([fill])) {
  fill: currentColor;
}

svg:not(#mount) {
  overflow: hidden;
}

/**
 * Button
 */
button {
  margin: 0;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

button,
[type="button"],
[type="reset"],
[type="submit"] {
  -webkit-appearance: button;
}

button {
  display: block;
  width: 100%;
  margin-bottom: var(--spacing);
}

[role="button"] {
  display: inline-block;
  text-decoration: none;
}

button,
input[type="submit"],
input[type="button"],
input[type="reset"],
[role="button"] {
  --background-color: var(--primary);
  --border-color: var(--primary);
  --color: var(--primary-inverse);
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
button:is([aria-current], :hover, :active, :focus),
input[type="submit"]:is([aria-current], :hover, :active, :focus),
input[type="button"]:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus),
[role="button"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--primary-hover);
  --border-color: var(--primary-hover);
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  --color: var(--primary-inverse);
}
button:focus,
input[type="submit"]:focus,
input[type="button"]:focus,
input[type="reset"]:focus,
[role="button"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--primary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary,
input[type="reset"] {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  cursor: pointer;
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"]:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).secondary:focus,
input[type="reset"]:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--secondary-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast {
  --background-color: var(--contrast);
  --border-color: var(--contrast);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:is([aria-current], :hover, :active, :focus) {
  --background-color: var(--contrast-hover);
  --border-color: var(--contrast-hover);
  --color: var(--contrast-inverse);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).contrast:focus {
  --box-shadow: var(--button-hover-box-shadow, 0 0 0 rgba(0, 0, 0, 0)),
    0 0 0 var(--outline-width) var(--contrast-focus);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline,
input[type="reset"].outline {
  --background-color: transparent;
  --color: var(--primary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --background-color: transparent;
  --color: var(--primary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary,
input[type="reset"].outline {
  --color: var(--secondary);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.secondary:is([aria-current], :hover, :active, :focus),
input[type="reset"].outline:is([aria-current], :hover, :active, :focus) {
  --color: var(--secondary-hover);
}

:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast {
  --color: var(--contrast);
}
:is(
    button,
    input[type="submit"],
    input[type="button"],
    [role="button"]
  ).outline.contrast:is([aria-current], :hover, :active, :focus) {
  --color: var(--contrast-hover);
}

:where(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  )[disabled],
:where(fieldset[disabled])
  :is(
    button,
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="button"]
  ),
a[role="button"]:not([href]) {
  opacity: 0.5;
  pointer-events: none;
}

/**
 * Form elements
 */
input,
optgroup,
select,
textarea {
  margin: 0;
  font-size: 1rem;
  line-height: var(--line-height);
  font-family: inherit;
  letter-spacing: inherit;
}

input {
  overflow: visible;
}

select {
  text-transform: none;
}

legend {
  max-width: 100%;
  padding: 0;
  color: inherit;
  white-space: normal;
}

textarea {
  overflow: auto;
}

[type="checkbox"],
[type="radio"] {
  padding: 0;
}

::-webkit-inner-spin-button,
::-webkit-outer-spin-button {
  height: auto;
}

[type="search"] {
  -webkit-appearance: textfield;
  outline-offset: -2px;
}

[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}

::-webkit-file-upload-button {
  -webkit-appearance: button;
  font: inherit;
}

::-moz-focus-inner {
  padding: 0;
  border-style: none;
}

:-moz-focusring {
  outline: none;
}

:-moz-ui-invalid {
  box-shadow: none;
}

::-ms-expand {
  display: none;
}

[type="file"],
[type="range"] {
  padding: 0;
  border-width: 0;
}

input:not([type="checkbox"], [type="radio"], [type="range"]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
}

fieldset {
  margin: 0;
  margin-bottom: var(--spacing);
  padding: 0;
  border: 0;
}

label,
fieldset legend {
  display: block;
  margin-bottom: calc(var(--spacing) * 0.25);
  font-weight: var(--form-label-font-weight, var(--font-weight));
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  width: 100%;
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]),
select,
textarea {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
}

input,
select,
textarea {
  --background-color: var(--form-element-background-color);
  --border-color: var(--form-element-border-color);
  --color: var(--form-element-color);
  --box-shadow: none;
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="checkbox"],
    [type="radio"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --background-color: var(--form-element-active-background-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [role="switch"],
    [readonly]
  ):is(:active, :focus),
:where(select, textarea):is(:active, :focus) {
  --border-color: var(--form-element-active-border-color);
}

input:not(
    [type="submit"],
    [type="button"],
    [type="reset"],
    [type="range"],
    [type="file"],
    [readonly]
  ):focus,
select:focus,
textarea:focus {
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}

input:not([type="submit"], [type="button"], [type="reset"])[disabled],
select[disabled],
textarea[disabled],
:where(fieldset[disabled])
  :is(
    input:not([type="submit"], [type="button"], [type="reset"]),
    select,
    textarea
  ) {
  --background-color: var(--form-element-disabled-background-color);
  --border-color: var(--form-element-disabled-border-color);
  opacity: var(--form-element-disabled-opacity);
  pointer-events: none;
}

:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid] {
  padding-right: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal) !important;
  padding-inline-start: var(--form-element-spacing-horizontal) !important;
  -webkit-padding-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  padding-inline-end: calc(
    var(--form-element-spacing-horizontal) + 1.5rem
  ) !important;
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="false"] {
  background-image: var(--icon-valid);
}
:where(input, select, textarea):not(
    [type="checkbox"],
    [type="radio"],
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  )[aria-invalid="true"] {
  background-image: var(--icon-invalid);
}
:where(input, select, textarea)[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
:where(input, select, textarea)[aria-invalid="false"]:is(:active, :focus) {
  --border-color: var(--form-element-valid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width) var(--form-element-valid-focus-color) !important;
}
:where(input, select, textarea)[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}
:where(input, select, textarea)[aria-invalid="true"]:is(:active, :focus) {
  --border-color: var(--form-element-invalid-active-border-color) !important;
  --box-shadow: 0 0 0 var(--outline-width)
    var(--form-element-invalid-focus-color) !important;
}

[dir="rtl"]
  :where(input, select, textarea):not([type="checkbox"], [type="radio"]):is(
    [aria-invalid],
    [aria-invalid="true"],
    [aria-invalid="false"]
  ) {
  background-position: center left 0.75rem;
}

input::placeholder,
input::-webkit-input-placeholder,
textarea::placeholder,
textarea::-webkit-input-placeholder,
select:invalid {
  color: var(--form-element-placeholder-color);
  opacity: 1;
}

input:not([type="checkbox"], [type="radio"]),
select,
textarea {
  margin-bottom: var(--spacing);
}

select::-ms-expand {
  border: 0;
  background-color: transparent;
}
select:not([multiple], [size]) {
  padding-right: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-left: var(--form-element-spacing-horizontal);
  -webkit-padding-start: var(--form-element-spacing-horizontal);
  padding-inline-start: var(--form-element-spacing-horizontal);
  -webkit-padding-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  padding-inline-end: calc(var(--form-element-spacing-horizontal) + 1.5rem);
  background-image: var(--icon-chevron);
  background-position: center right 0.75rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}

[dir="rtl"] select:not([multiple], [size]) {
  background-position: center left 0.75rem;
}

:where(input, select, textarea) + small {
  display: block;
  width: 100%;
  margin-top: calc(var(--spacing) * -0.75);
  margin-bottom: var(--spacing);
  color: var(--muted-color);
}

label > :where(input, select, textarea) {
  margin-top: calc(var(--spacing) * 0.25);
}

/**
 * Form elements
 * Checkboxes & Radios
 */
[type="checkbox"],
[type="radio"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 1.25em;
  height: 1.25em;
  margin-top: -0.125em;
  margin-right: 0.375em;
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: 0.375em;
  margin-inline-end: 0.375em;
  border-width: var(--border-width);
  font-size: inherit;
  vertical-align: middle;
  cursor: pointer;
}
[type="checkbox"]::-ms-check,
[type="radio"]::-ms-check {
  display: none;
}
[type="checkbox"]:checked,
[type="checkbox"]:checked:active,
[type="checkbox"]:checked:focus,
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-checkbox);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}
[type="checkbox"] ~ label,
[type="radio"] ~ label {
  display: inline-block;
  margin-right: 0.375em;
  margin-bottom: 0;
  cursor: pointer;
}

[type="checkbox"]:indeterminate {
  --background-color: var(--primary);
  --border-color: var(--primary);
  background-image: var(--icon-minus);
  background-position: center;
  background-size: 0.75em auto;
  background-repeat: no-repeat;
}

[type="radio"] {
  border-radius: 50%;
}
[type="radio"]:checked,
[type="radio"]:checked:active,
[type="radio"]:checked:focus {
  --background-color: var(--primary-inverse);
  border-width: 0.35em;
  background-image: none;
}

[type="checkbox"][role="switch"] {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
  --color: var(--switch-color);
  width: 2.25em;
  height: 1.25em;
  border: var(--border-width) solid var(--border-color);
  border-radius: 1.25em;
  background-color: var(--background-color);
  line-height: 1.25em;
}
[type="checkbox"][role="switch"]:focus {
  --background-color: var(--switch-background-color);
  --border-color: var(--switch-background-color);
}
[type="checkbox"][role="switch"]:checked {
  --background-color: var(--switch-checked-background-color);
  --border-color: var(--switch-checked-background-color);
}
[type="checkbox"][role="switch"]:before {
  display: block;
  width: calc(1.25em - (var(--border-width) * 2));
  height: 100%;
  border-radius: 50%;
  background-color: var(--color);
  content: "";
  transition: margin 0.1s ease-in-out;
}
[type="checkbox"][role="switch"]:checked {
  background-image: none;
}
[type="checkbox"][role="switch"]:checked::before {
  margin-left: calc(1.125em - var(--border-width));
  -webkit-margin-start: calc(1.125em - var(--border-width));
  margin-inline-start: calc(1.125em - var(--border-width));
}

[type="checkbox"][aria-invalid="false"],
[type="checkbox"]:checked[aria-invalid="false"],
[type="radio"][aria-invalid="false"],
[type="radio"]:checked[aria-invalid="false"],
[type="checkbox"][role="switch"][aria-invalid="false"],
[type="checkbox"][role="switch"]:checked[aria-invalid="false"] {
  --border-color: var(--form-element-valid-border-color);
}
[type="checkbox"][aria-invalid="true"],
[type="checkbox"]:checked[aria-invalid="true"],
[type="radio"][aria-invalid="true"],
[type="radio"]:checked[aria-invalid="true"],
[type="checkbox"][role="switch"][aria-invalid="true"],
[type="checkbox"][role="switch"]:checked[aria-invalid="true"] {
  --border-color: var(--form-element-invalid-border-color);
}

/**
 * Form elements
 * Alternatives input types (Not Checkboxes & Radios)
 */
[type="color"]::-webkit-color-swatch-wrapper {
  padding: 0;
}
[type="color"]::-moz-focus-inner {
  padding: 0;
}
[type="color"]::-webkit-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}
[type="color"]::-moz-color-swatch {
  border: 0;
  border-radius: calc(var(--border-radius) * 0.5);
}

input:not([type="checkbox"], [type="radio"], [type="range"], [type="file"]):is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  --icon-position: 0.75rem;
  --icon-width: 1rem;
  padding-right: calc(var(--icon-width) + var(--icon-position));
  background-image: var(--icon-date);
  background-position: center right var(--icon-position);
  background-size: var(--icon-width) auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="time"] {
  background-image: var(--icon-time);
}

[type="date"]::-webkit-calendar-picker-indicator,
[type="datetime-local"]::-webkit-calendar-picker-indicator,
[type="month"]::-webkit-calendar-picker-indicator,
[type="time"]::-webkit-calendar-picker-indicator,
[type="week"]::-webkit-calendar-picker-indicator {
  width: var(--icon-width);
  margin-right: calc(var(--icon-width) * -1);
  margin-left: var(--icon-position);
  opacity: 0;
}

[dir="rtl"]
  :is(
    [type="date"],
    [type="datetime-local"],
    [type="month"],
    [type="time"],
    [type="week"]
  ) {
  text-align: right;
}

[type="file"] {
  --color: var(--muted-color);
  padding: calc(var(--form-element-spacing-vertical) * 0.5) 0;
  border: 0;
  border-radius: 0;
  background: none;
}
[type="file"]::file-selector-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::file-selector-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-webkit-file-upload-button {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) / 2);
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-webkit-file-upload-button:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}
[type="file"]::-ms-browse {
  --background-color: var(--secondary);
  --border-color: var(--secondary);
  --color: var(--secondary-inverse);
  margin-right: calc(var(--spacing) / 2);
  margin-left: 0;
  margin-inline-start: 0;
  margin-inline-end: calc(var(--spacing) / 2);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    calc(var(--form-element-spacing-horizontal) * 0.5);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 1rem;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    border-color var(--transition), color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
[type="file"]::-ms-browse:is(:hover, :active, :focus) {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
}

[type="range"] {
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  width: 100%;
  height: 1.25rem;
  background: none;
}
[type="range"]::-webkit-slider-runnable-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -webkit-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-moz-range-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -moz-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-ms-track {
  width: 100%;
  height: 0.25rem;
  border-radius: var(--border-radius);
  background-color: var(--range-border-color);
  -ms-transition: background-color var(--transition),
    box-shadow var(--transition);
  transition: background-color var(--transition), box-shadow var(--transition);
}
[type="range"]::-webkit-slider-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -webkit-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-moz-range-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -moz-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]::-ms-thumb {
  -webkit-appearance: none;
  width: 1.25rem;
  height: 1.25rem;
  margin-top: -0.5rem;
  border: 2px solid var(--range-thumb-border-color);
  border-radius: 50%;
  background-color: var(--range-thumb-color);
  cursor: pointer;
  -ms-transition: background-color var(--transition),
    transform var(--transition);
  transition: background-color var(--transition), transform var(--transition);
}
[type="range"]:hover,
[type="range"]:focus {
  --range-border-color: var(--range-active-border-color);
  --range-thumb-color: var(--range-thumb-hover-color);
}
[type="range"]:active {
  --range-thumb-color: var(--range-thumb-active-color);
}
[type="range"]:active::-webkit-slider-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-moz-range-thumb {
  transform: scale(1.25);
}
[type="range"]:active::-ms-thumb {
  transform: scale(1.25);
}

input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  -webkit-padding-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  padding-inline-start: calc(var(--form-element-spacing-horizontal) + 1.75rem);
  border-radius: 5rem;
  background-image: var(--icon-search);
  background-position: center left 1.125rem;
  background-size: 1rem auto;
  background-repeat: no-repeat;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  -webkit-padding-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  padding-inline-start: calc(
    var(--form-element-spacing-horizontal) + 1.75rem
  ) !important;
  background-position: center left 1.125rem, center right 0.75rem;
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="false"] {
  background-image: var(--icon-search), var(--icon-valid);
}
input:not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid="true"] {
  background-image: var(--icon-search), var(--icon-invalid);
}

[type="search"]::-webkit-search-cancel-button {
  -webkit-appearance: none;
  display: none;
}

[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"] {
  background-position: center right 1.125rem;
}
[dir="rtl"]
  :where(input):not(
    [type="checkbox"],
    [type="radio"],
    [type="range"],
    [type="file"]
  )[type="search"][aria-invalid] {
  background-position: center right 1.125rem, center left 0.75rem;
}

/**
 * Table
 */
:where(table) {
  width: 100%;
  border-collapse: collapse;
  border-spacing: 0;
  text-indent: 0;
}

th,
td {
  padding: calc(var(--spacing) / 2) var(--spacing);
  border-bottom: var(--border-width) solid var(--table-border-color);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: var(--font-size);
  text-align: left;
  text-align: start;
}

tfoot th,
tfoot td {
  border-top: var(--border-width) solid var(--table-border-color);
  border-bottom: 0;
}

table[role="grid"] tbody tr:nth-child(odd) {
  background-color: var(--table-row-stripped-background-color);
}

/**
 * Code
 */
pre,
code,
kbd,
samp {
  font-size: 0.875em;
  font-family: var(--font-family);
}

pre {
  -ms-overflow-style: scrollbar;
  overflow: auto;
}

pre,
code,
kbd {
  border-radius: var(--border-radius);
  background: var(--code-background-color);
  color: var(--code-color);
  font-weight: var(--font-weight);
  line-height: initial;
}

code,
kbd {
  display: inline-block;
  padding: 0.375rem 0.5rem;
}

pre {
  display: block;
  margin-bottom: var(--spacing);
  overflow-x: auto;
}
pre > code {
  display: block;
  padding: var(--spacing);
  background: none;
  font-size: 14px;
  line-height: var(--line-height);
}

code b {
  color: var(--code-tag-color);
  font-weight: var(--font-weight);
}
code i {
  color: var(--code-property-color);
  font-style: normal;
}
code u {
  color: var(--code-value-color);
  text-decoration: none;
}
code em {
  color: var(--code-comment-color);
  font-style: normal;
}

kbd {
  background-color: var(--code-kbd-background-color);
  color: var(--code-kbd-color);
  vertical-align: baseline;
}

/**
 * Miscs
 */
hr {
  height: 0;
  border: 0;
  border-top: 1px solid var(--muted-border-color);
  color: inherit;
}

[hidden],
template {
  display: none !important;
}

canvas {
  display: inline-block;
}

/**
 * Accordion (<details>)
 */
details {
  display: block;
  margin-bottom: var(--spacing);
  padding-bottom: var(--spacing);
  border-bottom: var(--border-width) solid var(--accordion-border-color);
}
details summary {
  line-height: 1rem;
  list-style-type: none;
  cursor: pointer;
  transition: color var(--transition);
}
details summary:not([role]) {
  color: var(--accordion-close-summary-color);
}
details summary::-webkit-details-marker {
  display: none;
}
details summary::marker {
  display: none;
}
details summary::-moz-list-bullet {
  list-style-type: none;
}
details summary::after {
  display: block;
  width: 1rem;
  height: 1rem;
  -webkit-margin-start: calc(var(--spacing, 1rem) * 0.5);
  margin-inline-start: calc(var(--spacing, 1rem) * 0.5);
  float: right;
  transform: rotate(-90deg);
  background-image: var(--icon-chevron);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
  transition: transform var(--transition);
}
details summary:focus {
  outline: none;
}
details summary:focus:not([role="button"]) {
  color: var(--accordion-active-summary-color);
}
details summary[role="button"] {
  width: 100%;
  text-align: left;
}
details summary[role="button"]::after {
  height: calc(1rem * var(--line-height, 1.5));
  background-image: var(--icon-chevron-button);
}
details summary[role="button"]:not(.outline).contrast::after {
  background-image: var(--icon-chevron-button-inverse);
}
details[open] > summary {
  margin-bottom: calc(var(--spacing));
}
details[open] > summary:not([role]):not(:focus) {
  color: var(--accordion-open-summary-color);
}
details[open] > summary::after {
  transform: rotate(0);
}

[dir="rtl"] details summary {
  text-align: right;
}
[dir="rtl"] details summary::after {
  float: left;
  background-position: left center;
}

/**
 * Card (<article>)
 */
article {
  margin: var(--block-spacing-vertical) 0;
  padding: var(--block-spacing-vertical) var(--block-spacing-horizontal);
  border-radius: var(--border-radius);
  background: var(--card-background-color);
  box-shadow: var(--card-box-shadow);
}
article > header,
article > footer {
  margin-right: calc(var(--block-spacing-horizontal) * -1);
  margin-left: calc(var(--block-spacing-horizontal) * -1);
  padding: calc(var(--block-spacing-vertical) * 0.66)
    var(--block-spacing-horizontal);
  background-color: var(--card-sectionning-background-color);
}
article > header {
  margin-top: calc(var(--block-spacing-vertical) * -1);
  margin-bottom: var(--block-spacing-vertical);
  border-bottom: var(--border-width) solid var(--card-border-color);
  border-top-right-radius: var(--border-radius);
  border-top-left-radius: var(--border-radius);
}
article > footer {
  margin-top: var(--block-spacing-vertical);
  margin-bottom: calc(var(--block-spacing-vertical) * -1);
  border-top: var(--border-width) solid var(--card-border-color);
  border-bottom-right-radius: var(--border-radius);
  border-bottom-left-radius: var(--border-radius);
}

/**
 * Modal (<dialog>)
 */
#mount {
  --scrollbar-width: 0px;
}

dialog {
  display: flex;
  z-index: 999;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  align-items: center;
  justify-content: center;
  width: inherit;
  min-width: 100%;
  height: inherit;
  min-height: 100%;
  padding: var(--spacing);
  border: 0;
  -webkit-backdrop-filter: var(--modal-overlay-backdrop-filter);
  backdrop-filter: var(--modal-overlay-backdrop-filter);
  background-color: var(--modal-overlay-background-color);
  color: var(--color);
}
dialog article {
  max-height: calc(100vh - var(--spacing) * 2);
  overflow: auto;
}
@media (min-width: 576px) {
  dialog article {
    max-width: 510px;
  }
}
@media (min-width: 768px) {
  dialog article {
    max-width: 700px;
  }
}
dialog article > header,
dialog article > footer {
  padding: calc(var(--block-spacing-vertical) * 0.5)
    var(--block-spacing-horizontal);
}
dialog article > header .close {
  margin: 0;
  margin-left: var(--spacing);
  float: right;
}
dialog article > footer {
  text-align: right;
}
dialog article > footer [role="button"] {
  margin-bottom: 0;
}
dialog article > footer [role="button"]:not(:first-of-type) {
  margin-left: calc(var(--spacing) * 0.5);
}
dialog article p:last-of-type {
  margin: 0;
}
dialog article .close {
  display: block;
  width: 1rem;
  height: 1rem;
  margin-top: calc(var(--block-spacing-vertical) * -0.5);
  margin-bottom: var(--typography-spacing-vertical);
  margin-left: auto;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}
dialog article .close:is([aria-current], :hover, :active, :focus) {
  opacity: 1;
}
dialog:not([open]),
dialog[open="false"] {
  display: none;
}

.modal-is-open {
  padding-right: var(--scrollbar-width, 0px);
  overflow: hidden;
  pointer-events: none;
}
.modal-is-open dialog {
  pointer-events: auto;
}

:where(.modal-is-opening, .modal-is-closing) dialog,
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-duration: 0.2s;
  animation-timing-function: ease-in-out;
  animation-fill-mode: both;
}
:where(.modal-is-opening, .modal-is-closing) dialog {
  animation-duration: 0.8s;
  animation-name: modal-overlay;
}
:where(.modal-is-opening, .modal-is-closing) dialog > article {
  animation-delay: 0.2s;
  animation-name: modal;
}

.modal-is-closing dialog,
.modal-is-closing dialog > article {
  animation-delay: 0s;
  animation-direction: reverse;
}

@keyframes modal-overlay {
  from {
    -webkit-backdrop-filter: none;
    backdrop-filter: none;
    background-color: transparent;
  }
}
@keyframes modal {
  from {
    transform: translateY(-100%);
    opacity: 0;
  }
}
/**
 * Nav
 */
:where(nav li)::before {
  float: left;
  content: "​";
}

nav,
nav ul {
  display: flex;
}

nav {
  justify-content: space-between;
}
nav ol,
nav ul {
  align-items: center;
  margin-bottom: 0;
  padding: 0;
  list-style: none;
}
nav ol:first-of-type,
nav ul:first-of-type {
  margin-left: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav ol:last-of-type,
nav ul:last-of-type {
  margin-right: calc(var(--nav-element-spacing-horizontal) * -1);
}
nav li {
  display: inline-block;
  margin: 0;
  padding: var(--nav-element-spacing-vertical)
    var(--nav-element-spacing-horizontal);
}
nav li > * {
  --spacing: 0;
}
nav :where(a, [role="link"]) {
  display: inline-block;
  margin: calc(var(--nav-link-spacing-vertical) * -1)
    calc(var(--nav-link-spacing-horizontal) * -1);
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
  border-radius: var(--border-radius);
  text-decoration: none;
}
nav :where(a, [role="link"]):is([aria-current], :hover, :active, :focus) {
  text-decoration: none;
}
nav[aria-label="breadcrumb"] {
  align-items: center;
  justify-content: start;
}
nav[aria-label="breadcrumb"] ul li:not(:first-child) {
  -webkit-margin-start: var(--nav-link-spacing-horizontal);
  margin-inline-start: var(--nav-link-spacing-horizontal);
}
nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  position: absolute;
  width: calc(var(--nav-link-spacing-horizontal) * 2);
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) / 2);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) / 2);
  content: "/";
  color: var(--muted-color);
  text-align: center;
}
nav[aria-label="breadcrumb"] a[aria-current] {
  background-color: transparent;
  color: inherit;
  text-decoration: none;
  pointer-events: none;
}
nav [role="button"] {
  margin-right: inherit;
  margin-left: inherit;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}

aside nav,
aside ol,
aside ul,
aside li {
  display: block;
}
aside li {
  padding: calc(var(--nav-element-spacing-vertical) * 0.5)
    var(--nav-element-spacing-horizontal);
}
aside li a {
  display: block;
}
aside li [role="button"] {
  margin: inherit;
}

[dir="rtl"] nav[aria-label="breadcrumb"] ul li:not(:last-child) ::after {
  content: "\\";
}

/**
 * Progress
 */
progress {
  display: inline-block;
  vertical-align: baseline;
}

progress {
  -webkit-appearance: none;
  -moz-appearance: none;
  display: inline-block;
  appearance: none;
  width: 100%;
  height: 0.5rem;
  margin-bottom: calc(var(--spacing) * 0.5);
  overflow: hidden;
  border: 0;
  border-radius: var(--border-radius);
  background-color: var(--progress-background-color);
  color: var(--progress-color);
}
progress::-webkit-progress-bar {
  border-radius: var(--border-radius);
  background: none;
}
progress[value]::-webkit-progress-value {
  background-color: var(--progress-color);
}
progress::-moz-progress-bar {
  background-color: var(--progress-color);
}
@media (prefers-reduced-motion: no-preference) {
  progress:indeterminate {
    background: var(--progress-background-color)
      linear-gradient(
        to right,
        var(--progress-color) 30%,
        var(--progress-background-color) 30%
      )
      top left/150% 150% no-repeat;
    animation: progress-indeterminate 1s linear infinite;
  }
  progress:indeterminate[value]::-webkit-progress-value {
    background-color: transparent;
  }
  progress:indeterminate::-moz-progress-bar {
    background-color: transparent;
  }
}

@media (prefers-reduced-motion: no-preference) {
  [dir="rtl"] progress:indeterminate {
    animation-direction: reverse;
  }
}

@keyframes progress-indeterminate {
  0% {
    background-position: 200% 0;
  }
  100% {
    background-position: -200% 0;
  }
}
/**
 * Dropdown ([role="list"])
 */
details[role="list"],
li[role="list"] {
  position: relative;
}

details[role="list"] summary + ul,
li[role="list"] > ul {
  display: flex;
  z-index: 99;
  position: absolute;
  top: auto;
  right: 0;
  left: 0;
  flex-direction: column;
  margin: 0;
  padding: 0;
  border: var(--border-width) solid var(--dropdown-border-color);
  border-radius: var(--border-radius);
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  background-color: var(--dropdown-background-color);
  box-shadow: var(--card-box-shadow);
  color: var(--dropdown-color);
  white-space: nowrap;
}
details[role="list"] summary + ul li,
li[role="list"] > ul li {
  width: 100%;
  margin-bottom: 0;
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  list-style: none;
}
details[role="list"] summary + ul li:first-of-type,
li[role="list"] > ul li:first-of-type {
  margin-top: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li:last-of-type,
li[role="list"] > ul li:last-of-type {
  margin-bottom: calc(var(--form-element-spacing-vertical) * 0.5);
}
details[role="list"] summary + ul li a,
li[role="list"] > ul li a {
  display: block;
  margin: calc(var(--form-element-spacing-vertical) * -0.5)
    calc(var(--form-element-spacing-horizontal) * -1);
  padding: calc(var(--form-element-spacing-vertical) * 0.5)
    var(--form-element-spacing-horizontal);
  overflow: hidden;
  color: var(--dropdown-color);
  text-decoration: none;
  text-overflow: ellipsis;
}
details[role="list"] summary + ul li a:hover,
li[role="list"] > ul li a:hover {
  background-color: var(--dropdown-hover-background-color);
}

details[role="list"] summary::after,
li[role="list"] > a::after {
  display: block;
  width: 1rem;
  height: calc(1rem * var(--line-height, 1.5));
  -webkit-margin-start: 0.5rem;
  margin-inline-start: 0.5rem;
  float: right;
  transform: rotate(0deg);
  background-position: right center;
  background-size: 1rem auto;
  background-repeat: no-repeat;
  content: "";
}

details[role="list"] {
  padding: 0;
  border-bottom: none;
}
details[role="list"] summary {
  margin-bottom: 0;
}
details[role="list"] summary:not([role]) {
  height: calc(
    1rem * var(--line-height) + var(--form-element-spacing-vertical) * 2 +
      var(--border-width) * 2
  );
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--form-element-border-color);
  border-radius: var(--border-radius);
  background-color: var(--form-element-background-color);
  color: var(--form-element-placeholder-color);
  line-height: inherit;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
}
details[role="list"] summary:not([role]):active,
details[role="list"] summary:not([role]):focus {
  border-color: var(--form-element-active-border-color);
  background-color: var(--form-element-active-background-color);
}
details[role="list"] summary:not([role]):focus {
  box-shadow: 0 0 0 var(--outline-width) var(--form-element-focus-color);
}
details[role="list"][open] summary {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
details[role="list"][open] summary::before {
  display: block;
  z-index: 1;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  background: none;
  content: "";
  cursor: default;
}

nav details[role="list"] summary,
nav li[role="list"] a {
  display: flex;
  direction: ltr;
}

nav details[role="list"] summary + ul,
nav li[role="list"] > ul {
  min-width: -moz-fit-content;
  min-width: fit-content;
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul li a,
nav li[role="list"] > ul li a {
  border-radius: 0;
}

nav details[role="list"] summary,
nav details[role="list"] summary:not([role]) {
  height: auto;
  padding: var(--nav-link-spacing-vertical) var(--nav-link-spacing-horizontal);
}
nav details[role="list"][open] summary {
  border-radius: var(--border-radius);
}
nav details[role="list"] summary + ul {
  margin-top: var(--outline-width);
  -webkit-margin-start: 0;
  margin-inline-start: 0;
}
nav details[role="list"] summary[role="link"] {
  margin-bottom: calc(var(--nav-link-spacing-vertical) * -1);
  line-height: var(--line-height);
}
nav details[role="list"] summary[role="link"] + ul {
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(var(--nav-link-spacing-horizontal) * -1);
  margin-inline-start: calc(var(--nav-link-spacing-horizontal) * -1);
}

li[role="list"]:hover > ul,
li[role="list"] a:active ~ ul,
li[role="list"] a:focus ~ ul {
  display: flex;
}
li[role="list"] > ul {
  display: none;
  margin-top: calc(var(--nav-link-spacing-vertical) + var(--outline-width));
  -webkit-margin-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
  margin-inline-start: calc(
    var(--nav-element-spacing-horizontal) - var(--nav-link-spacing-horizontal)
  );
}
li[role="list"] > a::after {
  background-image: var(--icon-chevron);
}

/**
 * Loading ([aria-busy=true])
 */
[aria-busy="true"] {
  cursor: progress;
}

[aria-busy="true"]:not(input, select, textarea)::before {
  display: inline-block;
  width: 1em;
  height: 1em;
  border: 0.1875em solid currentColor;
  border-radius: 1em;
  border-right-color: transparent;
  content: "";
  vertical-align: text-bottom;
  vertical-align: -0.125em;
  animation: spinner 0.75s linear infinite;
  opacity: var(--loading-spinner-opacity);
}
[aria-busy="true"]:not(input, select, textarea):not(:empty)::before {
  margin-right: calc(var(--spacing) * 0.5);
  margin-left: 0;
  -webkit-margin-start: 0;
  margin-inline-start: 0;
  -webkit-margin-end: calc(var(--spacing) * 0.5);
  margin-inline-end: calc(var(--spacing) * 0.5);
}
[aria-busy="true"]:not(input, select, textarea):empty {
  text-align: center;
}

button[aria-busy="true"],
input[type="submit"][aria-busy="true"],
input[type="button"][aria-busy="true"],
input[type="reset"][aria-busy="true"],
a[aria-busy="true"] {
  pointer-events: none;
}

@keyframes spinner {
  to {
    transform: rotate(360deg);
  }
}
/**
 * Tooltip ([data-tooltip])
 */
[data-tooltip] {
  position: relative;
}
[data-tooltip]:not(a, button, input) {
  border-bottom: 1px dotted;
  text-decoration: none;
  cursor: help;
}
[data-tooltip][data-placement="top"]::before,
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::before,
[data-tooltip]::after {
  display: block;
  z-index: 99;
  position: absolute;
  bottom: 100%;
  left: 50%;
  padding: 0.25rem 0.5rem;
  overflow: hidden;
  transform: translate(-50%, -0.25rem);
  border-radius: var(--border-radius);
  background: var(--tooltip-background-color);
  content: attr(data-tooltip);
  color: var(--tooltip-color);
  font-style: normal;
  font-weight: var(--font-weight);
  font-size: 0.875rem;
  text-decoration: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  opacity: 0;
  pointer-events: none;
}
[data-tooltip][data-placement="top"]::after,
[data-tooltip]::after {
  padding: 0;
  transform: translate(-50%, 0rem);
  border-top: 0.3rem solid;
  border-right: 0.3rem solid transparent;
  border-left: 0.3rem solid transparent;
  border-radius: 0;
  background-color: transparent;
  content: "";
  color: var(--tooltip-background-color);
}
[data-tooltip][data-placement="bottom"]::before,
[data-tooltip][data-placement="bottom"]::after {
  top: 100%;
  bottom: auto;
  transform: translate(-50%, 0.25rem);
}
[data-tooltip][data-placement="bottom"]:after {
  transform: translate(-50%, -0.3rem);
  border: 0.3rem solid transparent;
  border-bottom: 0.3rem solid;
}
[data-tooltip][data-placement="left"]::before,
[data-tooltip][data-placement="left"]::after {
  top: 50%;
  right: 100%;
  bottom: auto;
  left: auto;
  transform: translate(-0.25rem, -50%);
}
[data-tooltip][data-placement="left"]:after {
  transform: translate(0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-left: 0.3rem solid;
}
[data-tooltip][data-placement="right"]::before,
[data-tooltip][data-placement="right"]::after {
  top: 50%;
  right: auto;
  bottom: auto;
  left: 100%;
  transform: translate(0.25rem, -50%);
}
[data-tooltip][data-placement="right"]:after {
  transform: translate(-0.3rem, -50%);
  border: 0.3rem solid transparent;
  border-right: 0.3rem solid;
}
[data-tooltip]:focus::before,
[data-tooltip]:focus::after,
[data-tooltip]:hover::before,
[data-tooltip]:hover::after {
  opacity: 1;
}
@media (hover: hover) and (pointer: fine) {
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::before,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::before,
  [data-tooltip]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover [data-tooltip]:focus::after,
  [data-tooltip]:hover::after {
    animation-name: tooltip-caret-slide-top;
  }
  [data-tooltip][data-placement="bottom"]:focus::before,
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::before,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-bottom;
  }
  [data-tooltip][data-placement="bottom"]:focus::after,
  [data-tooltip][data-placement="bottom"]:hover::after {
    animation-name: tooltip-caret-slide-bottom;
  }
  [data-tooltip][data-placement="left"]:focus::before,
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::before,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-left;
  }
  [data-tooltip][data-placement="left"]:focus::after,
  [data-tooltip][data-placement="left"]:hover::after {
    animation-name: tooltip-caret-slide-left;
  }
  [data-tooltip][data-placement="right"]:focus::before,
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::before,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-duration: 0.2s;
    animation-name: tooltip-slide-right;
  }
  [data-tooltip][data-placement="right"]:focus::after,
  [data-tooltip][data-placement="right"]:hover::after {
    animation-name: tooltip-caret-slide-right;
  }
}
@keyframes tooltip-slide-top {
  from {
    transform: translate(-50%, 0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-top {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.25rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-bottom {
  from {
    transform: translate(-50%, -0.75rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, 0.25rem);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-bottom {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-50%, -0.5rem);
    opacity: 0;
  }
  to {
    transform: translate(-50%, -0.3rem);
    opacity: 1;
  }
}
@keyframes tooltip-slide-left {
  from {
    transform: translate(0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-left {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.3rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-slide-right {
  from {
    transform: translate(-0.75rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(0.25rem, -50%);
    opacity: 1;
  }
}
@keyframes tooltip-caret-slide-right {
  from {
    opacity: 0;
  }
  50% {
    transform: translate(-0.05rem, -50%);
    opacity: 0;
  }
  to {
    transform: translate(-0.3rem, -50%);
    opacity: 1;
  }
}

/**
 * Accessibility & User interaction
 */
[aria-controls] {
  cursor: pointer;
}

[aria-disabled="true"],
[disabled] {
  cursor: not-allowed;
}

[aria-hidden="false"][hidden] {
  display: initial;
}

[aria-hidden="false"][hidden]:not(:focus) {
  clip: rect(0, 0, 0, 0);
  position: absolute;
}

a,
area,
button,
input,
label,
select,
summary,
textarea,
[tabindex] {
  -ms-touch-action: manipulation;
}

[dir="rtl"] {
  direction: rtl;
}

/**
* Reduce Motion Features
*/
@media (prefers-reduced-motion: reduce) {
  *:not([aria-busy="true"]),
  :not([aria-busy="true"])::before,
  :not([aria-busy="true"])::after {
    background-attachment: initial !important;
    animation-duration: 1ms !important;
    animation-delay: -1ms !important;
    animation-iteration-count: 1 !important;
    scroll-behavior: auto !important;
    transition-delay: 0s !important;
    transition-duration: 0s !important;
  }
}

#mount {
  /* --primary: rgb(227, 59, 126); */
  --primary: #ea4c89;
  --primary-hover: #f082ac;
  --icon-xia: url("data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgaWQ9IkZyYW1lIj4KPHBhdGggaWQ9IlZlY3RvciIgZD0iTTguMDAyOTEgOS42Nzk4M0wzLjgzMzM5IDUuNTEyMjFMMy4wMjUzOSA2LjMxOTgzTDguMDAzMjkgMTEuMjk1MUwxMi45NzYyIDYuMzE5ODNMMTIuMTY3OSA1LjUxMjIxTDguMDAyOTEgOS42Nzk4M1oiIGZpbGw9IiM4MzgzODMiLz4KPC9nPgo8L3N2Zz4K");
  --switch-checked-background-color: var(--primary);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="dark"] {
  --primary: #e23c7c;
  --primary-hover: #f082ac;
}

[data-theme="light"] {
  --primary: #ea4c89;
  --primary-hover: #f082ac;
}

li.select-link.select-link:hover > ul {
  display: none;
}
li.select-link.select-link > ul {
  display: none;
}
li.select-link.select-link a:focus ~ ul {
  display: none;
}

li.select-link.select-link a:active ~ ul {
  display: none;
}
li.select-link-active.select-link-active > ul {
  display: flex;
}
li.select-link-active.select-link-active:hover > ul {
  display: flex;
}

li.select-link-active.select-link-active a:focus ~ ul {
  display: flex;
}

li.select-link-active.select-link-active a:active ~ ul {
  display: flex;
}
ul.select-link-ul.select-link-ul {
  right: 0px;
  left: auto;
}

a.select-link-selected {
  background-color: var(--primary-focus);
}
.immersive-translate-no-select {
  -webkit-touch-callout: none; /* iOS Safari */
  -webkit-user-select: none; /* Safari */
  -khtml-user-select: none; /* Konqueror HTML */
  -moz-user-select: none; /* Old versions of Firefox */
  -ms-user-select: none; /* Internet Explorer/Edge */
  user-select: none;
}

/* li[role="list"].no-arrow > a::after { */
/*   background-image: none; */
/*   width: 0; */
/*   color: var(--color); */
/* } */
li[role="list"].no-arrow {
  margin-left: 8px;
  padding-right: 0;
}
li[role="list"] > a::after {
  -webkit-margin-start: 0.2rem;
  margin-inline-start: 0.2rem;
}

li[role="list"].no-arrow > a,
li[role="list"].no-arrow > a:link,
li[role="list"].no-arrow > a:visited {
  color: var(--secondary);
}

select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 4px;
  max-width: 128px;
  overflow: hidden;
  color: var(--primary);
  font-size: 13px;
  border: none;
  padding: 0;
  padding-right: 20px;
  padding-left: 8px;
  text-overflow: ellipsis;
  color: var(--color);
}
select.min-select-secondary {
  color: var(--color);
}
select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}
select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.muted {
  color: var(--muted-color);
}

.select.button-select {
  --background-color: var(--secondary-hover);
  --border-color: var(--secondary-hover);
  --color: var(--secondary-inverse);
  cursor: pointer;
  --box-shadow: var(--button-box-shadow, 0 0 0 rgba(0, 0, 0, 0));
  padding: var(--form-element-spacing-vertical)
    var(--form-element-spacing-horizontal);
  border: var(--border-width) solid var(--border-color);
  border-radius: var(--border-radius);
  outline: none;
  background-color: var(--background-color);
  box-shadow: var(--box-shadow);
  color: var(--color);
  font-weight: var(--font-weight);
  font-size: 16px;
  line-height: var(--line-height);
  text-align: center;
  cursor: pointer;
  transition: background-color var(--transition), border-color var(--transition),
    color var(--transition), box-shadow var(--transition);
  -webkit-appearance: button;
  margin: 0;
  margin-bottom: 0px;
  overflow: visible;
  font-family: inherit;
  text-transform: none;
}

body {
  padding: 0;
  margin: 0 auto;
  min-width: 268px;
  border-radius: 10px;
}

.popup-container {
  font-size: 16px;
  --font-size: 16px;
  color: #666;
  background-color: var(--popup-footer-background-color);
  width: 316px;
  min-width: 316px;
}

.popup-content {
  background-color: var(--popup-content-background-color);
  border-radius: 0px 0px 12px 12px;
  padding: 16px 20px;
}

.immersive-translate-popup-overlay {
  position: fixed;
  top: 0;
  left: 0;
  height: 100%;
  width: 100%;
  touch-action: none;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 10px;
  border: 1px solid var(--muted-border-color);
}

#mount {
  --font-family: system-ui, -apple-system, "Segoe UI", "Roboto", "Ubuntu",
    "Cantarell", "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
    "Segoe UI Symbol", "Noto Color Emoji";
  --line-height: 1.5;
  --font-weight: 400;
  --font-size: 16px;
  --border-radius: 4px;
  --border-width: 1px;
  --outline-width: 3px;
  --spacing: 16px;
  --typography-spacing-vertical: 24px;
  --block-spacing-vertical: calc(var(--spacing) * 2);
  --block-spacing-horizontal: var(--spacing);
  --grid-spacing-vertical: 0;
  --grid-spacing-horizontal: var(--spacing);
  --form-element-spacing-vertical: 12px;
  --form-element-spacing-horizontal: 16px;
  --nav-element-spacing-vertical: 16px;
  --nav-element-spacing-horizontal: 8px;
  --nav-link-spacing-vertical: 8px;
  --nav-link-spacing-horizontal: 8px;
  --form-label-font-weight: var(--font-weight);
  --transition: 0.2s ease-in-out;
  --modal-overlay-backdrop-filter: blur(4px);
}

[data-theme="light"],
#mount:not([data-theme="dark"]) {
  --popup-footer-background-color: #e8eaeb;
  --popup-content-background-color: #ffffff;
  --popup-item-background-color: #f3f5f6;
  --popup-item-hover-background-color: #eaeced;
  --popup-trial-pro-background-color: #f9fbfc;
  --text-black-2: #222222;
  --text-gray-2: #222222;
  --text-gray-6: #666666;
  --text-gray-9: #999999;
  --text-gray-c2: #c2c2c2;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(75, 76, 77, 0.2);
  --service-select-border-color: #fafafa;
  --service-select-selected-background-color: #f3f5f6;
  --download-app-background: #f3f5f6;
}

@media only screen and (prefers-color-scheme: dark) {
  #mount:not([data-theme="light"]) {
    --popup-footer-background-color: #0d0d0d;
    --popup-content-background-color: #191919;
    --popup-item-background-color: #272727;
    --popup-item-hover-background-color: #333333;
    --popup-trial-pro-background-color: #222222;
    --text-black-2: #ffffff;
    --text-gray-2: #dbdbdb;
    --text-gray-6: #b3b3b3;
    --text-gray-9: #777777;
    --text-gray-c2: #5b5b5b;
    --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
    --service-select-border-color: #2c2c2c;
    --service-select-selected-background-color: #333333;
    --download-app-background: #333;
  }
}

[data-theme="dark"] {
  --popup-footer-background-color: #0d0d0d;
  --popup-content-background-color: #191919;
  --popup-item-background-color: #272727;
  --popup-item-hover-background-color: #333333;
  --popup-trial-pro-background-color: #222222;
  --text-black-2: #ffffff;
  --text-gray-2: #dbdbdb;
  --text-gray-6: #b3b3b3;
  --text-gray-9: #777777;
  --text-gray-c2: #5b5b5b;
  --service-select-content-shadow: 0px 2px 12px 0px rgba(0, 0, 0, 0.9);
  --service-select-border-color: #2c2c2c;
  --service-select-selected-background-color: #333333;
  --download-app-background: #333;
}

.text-balck {
  color: var(--text-black-2);
}

.text-gray-2 {
  color: var(--text-gray-2);
}

.text-gray-6 {
  color: var(--text-gray-6);
}

.text-gray-9 {
  color: var(--text-gray-9);
}

.text-gray-c2 {
  color: var(--text-gray-c2);
}

#mount {
  min-width: 268px;
}

.main-button {
  font-size: 15px;
  vertical-align: middle;
  border-radius: 12px;
  padding: unset;
  height: 44px;
  line-height: 44px;
}

.pt-4 {
  padding-top: 16px;
}

.p-2 {
  padding: 8px;
}

.pl-5 {
  padding-left: 48px;
}

.p-0 {
  padding: 0;
}

.pl-2 {
  padding-left: 8px;
}

.pl-4 {
  padding-left: 24px;
}

.pt-2 {
  padding-top: 8px;
}

.pb-2 {
  padding-bottom: 8px;
}

.pb-4 {
  padding-bottom: 16px;
}

.pb-5 {
  padding-bottom: 20px;
}

.pr-5 {
  padding-right: 48px;
}

.text-sm {
  font-size: 13px;
}

.text-base {
  font-size: 16px;
}

.w-full {
  width: 100%;
}

.flex {
  display: flex;
}

.flex-row {
  flex-direction: row;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-end {
  justify-content: flex-end;
}

.flex-grow {
  flex-grow: 1;
}

.justify-between {
  justify-content: space-between;
}

.mb-0 {
  margin-bottom: 0px;
}

.mb-2 {
  margin-bottom: 8px;
}

.mb-4 {
  margin-bottom: 16px;
}

.mb-3 {
  margin-bottom: 12px;
}

.inline-block {
  display: inline-block;
}

.py-2 {
  padding-top: 8px;
  padding-bottom: 8px;
}

.py-2-5 {
  padding-top: 6px;
  padding-bottom: 6px;
}

.mt-0 {
  margin-top: 0;
}

.mt-2 {
  margin-top: 8px;
}

.mt-3 {
  margin-top: 12px;
}

.mt-4 {
  margin-top: 16px;
}

.mt-5 {
  margin-top: 20px;
}

.mt-6 {
  margin-top: 24px;
}

.mb-1 {
  margin-bottom: 4px;
}

.ml-4 {
  margin-left: 24px;
}

.ml-3 {
  margin-left: 16px;
}

.ml-2 {
  margin-left: 8px;
}

.ml-1 {
  margin-left: 4px;
}

.mr-1 {
  margin-right: 4px;
}

.mr-2 {
  margin-right: 8px;
}

.mr-3 {
  margin-right: 16px;
}

.mx-2 {
  margin-left: 8px;
  margin-right: 8px;
}

.pl-3 {
  padding-left: 12px;
}

.pr-3 {
  padding-right: 12px;
}

.p-3 {
  padding: 12px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-3 {
  padding-top: 12px;
}

.px-6 {
  padding-left: 18px;
  padding-right: 18px;
}

.px-4 {
  padding-left: 16px;
  padding-right: 16px;
}

.pt-6 {
  padding-top: 20px;
}

.py-3 {
  padding-top: 12px;
  padding-bottom: 12px;
}

.py-0 {
  padding-top: 0;
  padding-bottom: 0;
}

.left-auto {
  left: auto !important;
}

.max-h-28 {
  max-height: 112px;
}

.max-h-30 {
  max-height: 120px;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.text-xs {
  font-size: 12px;
}

.flex-1 {
  flex: 1;
}

.flex-3 {
  flex: 3;
}

.flex-4 {
  flex: 4;
}

.flex-2 {
  flex: 2;
}

.items-center {
  align-items: center;
}

.max-content {
  width: max-content;
}

.justify-center {
  justify-content: center;
}

.items-end {
  align-items: flex-end;
}

.items-baseline {
  align-items: baseline;
}

.my-5 {
  margin-top: 48px;
  margin-bottom: 48px;
}

.my-4 {
  margin-top: 24px;
  margin-bottom: 24px;
}

.my-3 {
  margin-top: 16px;
  margin-bottom: 16px;
}

.pt-3 {
  padding-top: 12px;
}

.px-3 {
  padding-left: 12px;
  padding-right: 12px;
}

.pt-2 {
  padding-top: 8px;
}

.px-2 {
  padding-left: 8px;
  padding-right: 8px;
}

.pt-1 {
  padding-top: 4px;
}

.px-1 {
  padding-left: 4px;
  padding-right: 4px;
}

.pb-2 {
  padding-bottom: 8px;
}

.justify-end {
  justify-content: flex-end;
}

.w-auto {
  width: auto;
}

.shrink-0 {
  flex-shrink: 0;
}

select.language-select,
select.translate-service,
select.min-select {
  --form-element-spacing-horizontal: 0;
  margin-bottom: 0px;
  max-width: unset;
  flex: 1;
  overflow: hidden;
  font-size: 13px;
  border: none;
  border-radius: 8px;
  padding-right: 30px;
  padding-left: 0px;
  background-position: center right 12px;
  background-size: 16px auto;
  background-image: var(--icon-xia);
  text-overflow: ellipsis;
  color: var(--text-gray-2);
  background-color: transparent;
  box-shadow: unset !important;
  cursor: pointer;
}

select.more {
  background-position: center right;
  padding-right: 20px;
}

select.transform-padding-left {
  padding-left: 12px;
  transform: translateX(-12px);
  background-position: center right 0px;
}

select.translate-service {
  color: var(--text-black-2);
}

.min-select-container.disabled {
  opacity: 0.5;
  pointer-events: none;
}

/* dark use black, for windows */
@media (prefers-color-scheme: dark) {
  select.language-select option,
  select.translate-service option,
  select.min-select option {
    background-color: #666666;
  }
}

.text-overflow-ellipsis {
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
}

.max-w-20 {
  max-width: 180px;
  white-space: nowrap;
}

select.min-select-secondary {
  color: var(--color);
}

select.min-select:focus {
  outline: none;
  border: none;
  --box-shadow: none;
}

select.min-select-no-arrow {
  background-image: none;
  padding-right: 0;
}

select.min-select-left {
  padding-right: 0px;
  /* padding-left: 24px; */
  /* background-position: center left 0; */
  text-overflow: ellipsis;
  text-align: left;
}

.popup-footer {
  background-color: var(--popup-footer-background-color);
  height: 40px;
}

.text-right {
  text-align: right;
}

.clickable {
  cursor: pointer;
}

.close {
  cursor: pointer;
  width: 16px;
  height: 16px;
  background-image: var(--icon-close);
  background-position: center;
  background-size: auto 1rem;
  background-repeat: no-repeat;
  opacity: 0.5;
  transition: opacity var(--transition);
}

.padding-two-column {
  padding-left: 40px;
  padding-right: 40px;
}

.muted {
  color: #999;
}

.text-label {
  color: #666;
}

.display-none {
  display: none;
}

/* dark use #18232c */
@media (prefers-color-scheme: dark) {
  .text-label {
    color: #9ca3af;
  }
}

.text-decoration-none {
  text-decoration: none;
}

.text-decoration-none:is([aria-current], :hover, :active, :focus),
[role="link"]:is([aria-current], :hover, :active, :focus) {
  --text-decoration: none !important;
  background-color: transparent !important;
}

.language-select-container {
  position: relative;
  width: 100%;
  background-color: var(--popup-item-background-color);
  height: 55px;
  border-radius: 12px;
}

select.language-select {
  color: var(--text-black-2);
  font-size: 14px;
  padding: 8px 24px 24px 16px;
  position: absolute;
  border-radius: 12px;
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
}

select.text-gray-6 {
  color: var(--text-gray-6);
}

.language-select-container label {
  position: absolute;
  bottom: 10px;
  left: 16px;
  font-size: 12px;
  color: var(--text-gray-9);
  line-height: 12px;
  margin: 0;
}

.translation-service-container {
  background-color: var(--popup-item-background-color);
  border-radius: 12px;
}

.min-select-container {
  display: flex;
  justify-content: space-between;
  align-items: center;
  height: 44px;
  background-color: var(--popup-item-background-color);
  padding-left: 16px;
}

.min-select-container:first-child {
  border-top-left-radius: 10px;
  border-top-right-radius: 10px;
}

.min-select-container:last-child {
  border-bottom-left-radius: 10px;
  border-bottom-right-radius: 10px;
}

.min-select-container:only-child {
  border-radius: 10px;
}

.translate-mode {
  width: 44px;
  height: 44px;
  border-radius: 22px;
  background-color: var(--popup-item-background-color);
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  cursor: pointer;
}

.translate-mode svg {
  fill: var(--text-gray-2);
}

.widgets-container {
  display: flex;
  align-items: stretch;
  justify-content: space-between;
  width: 100%;
  gap: 9px;
}

/* 当只有两个小组件时的样式优化 */
.widgets-container.widgets-two-items {
  gap: 16px;
}

.widgets-container.widgets-two-items .widget-item {
  flex: 0 1 auto;
  min-width: 93px;
  max-width: 120px;
}

.widget-item {
  display: flex;
  max-width: 93px;
  flex-direction: row;
  align-items: center;
  justify-content: center;
  background-color: var(--popup-item-background-color);
  font-size: 12px;
  min-height: 44px;
  height: 100%;
  border-radius: 8px;
  cursor: pointer;
  flex: 1;
  padding: 8px 4px;
  text-align: center;
}

.widget-icon-text {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  color: var(--text-gray-2);
}

.widgets-container svg {
  fill: var(--text-gray-2);
  color: var(--text-gray-2);
}

.share-button-container {
  display: flex;
  align-items: center;
  cursor: pointer;
  padding: 2px 3px 0 8px;
}

.share-button-container svg {
  fill: var(--text-gray-9);
}

.min-select-container:hover,
.language-select-container:hover,
.widget-item:hover,
.translate-mode:hover {
  background-color: var(--popup-item-hover-background-color);
}

.main-button:hover {
  background-color: #f5508f;
}

.share-button-container:hover {
  background-color: var(--popup-item-background-color);
  border-radius: 6px;
}

.error-boundary {
  background: #fff2f0;
  border: 1px solid #ffccc7;
  display: flex;
  padding: 12px;
  font-size: 14px;
  color: rgba(0, 0, 0, 0.88);
  word-break: break-all;
  margin: 12px;
  border-radius: 12px;
  flex-direction: column;
}

.upgrade-pro {
  border-radius: 11px;
  background: linear-gradient(57deg, #272727 19.8%, #696969 82.2%);
  padding: 2px 8px;
  transform: scale(0.85);
}

.upgrade-pro span {
  background: linear-gradient(180deg, #ffeab4 17.65%, #f8c235 85.29%);
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  font-size: 12px;
  margin-left: 4px;
}

.upgrade-pro svg {
  margin-top: -2px;
}

.upgrade-pro:hover {
  background: linear-gradient(57deg, #3d3d3d 19.8%, #949494 82.2%);
}

.border-bottom-radius-0 {
  border-bottom-left-radius: 0 !important;
  border-bottom-right-radius: 0 !important;
}

.trial-pro-container {
  border-radius: 0px 0px 12px 12px;
  background: var(--popup-trial-pro-background-color);
  display: flex;
  align-items: center;
  height: 44px;
  padding-left: 16px;
  padding-right: 12px;
  font-size: 12px;
}

.trial-pro-container label {
  line-height: 13px;
  color: var(--text-black-2);
}

.trial-pro-container img {
  margin-left: 5px;
}

.cursor-pointer {
  cursor: pointer;
}

.upgrade-pro-discount-act {
  height: 25px;
  display: flex;
  padding: 0 4px;
  align-items: center;
  border-radius: 15px;
  background: linear-gradient(
    90deg,
    #cefbfa 11.33%,
    #d7f56f 63.75%,
    #fccd5e 100%
  );
  transform: scale(0.9);
  box-shadow: 0px 1.8px 3.6px 0px rgba(0, 0, 0, 0.1);
  cursor: pointer;
}

.upgrade-pro-discount-act span {
  font-size: 12px;
  font-weight: 700;
  margin-left: 4px;
  color: #222222;
}

.upgrade-pro-discount-act:hover {
  text-decoration: unset;
  background: linear-gradient(
    90deg,
    #e2fffe 11.33%,
    #e6ff91 63.75%,
    #ffdf93 100%
  );
}

.custom-select-container {
  width: 200px;
  position: relative;
  flex: 1;
}

#translation-service-select {
  padding-right: 12px;
  padding-left: 6px;
}

.custom-select-content {
  border-radius: 12px;
  background: var(--popup-content-background-color);
  box-shadow: var(--service-select-content-shadow);
  border: 1px solid var(--service-select-border-color);
  padding: 4px 5px;
  position: absolute;
  left: -10px;
  right: 0;
  z-index: 100;
  overflow-y: auto;
}

.custom-select-item.default {
  width: 100%;
  padding: 0;
}

.custom-select-item {
  font-size: 13px;
  padding: 5px 6px;
  border-radius: 8px;
  display: flex;
  align-items: center;
  cursor: pointer;
  color: var(--text-black-2);
  width: auto;
  overflow: hidden;
  height: 30px;
  line-height: 30px;
}

.custom-select-item-img {
  width: 20px;
  height: 20px;
  margin-right: 4px;
}

@media (prefers-color-scheme: dark) {
  .custom-select-item-img {
    margin-right: 6px;
  }
}

.custom-select-content .custom-select-item.selected,
.custom-select-content .custom-select-item:hover {
  background: var(--service-select-selected-background-color);
}

.custom-select-item > span {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

.custom-select-item-pro {
  font-size: 12px;
  margin-left: 6px;
  display: flex;
}

.custom-select-item-pro img {
  margin: 0 3px;
  width: 20px;
  flex-shrink: 0;
}

.custom-select-group-header {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-gray-9);
  padding: 6px 8px 4px;
  margin-top: 2px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.more-container {
  position: relative;
}

.new-menu-indicator {
  position: absolute;
  width: 8px;
  height: 8px;
  background-color: #ef3434;
  border-radius: 50%;
  right: 18px;
  top: 4px;
}

.download-app {
  display: inline-flex;
  align-items: center;
  gap: 4px;
  border-radius: 8px;
  background: var(--download-app-background);
  padding: 4px 8px;
  color: var(--text-gray-6);
  font-size: 12px;
  cursor: pointer;
  transition: all 0.2s ease-in-out;
}

/* Popup 动画效果 */
@keyframes popup-fade-in {
  from {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
  to {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
}

@keyframes popup-fade-out {
  from {
    opacity: 1;
    transform: translateY(0) scale(1);
  }
  to {
    opacity: 0;
    transform: translateY(10px) scale(0.95);
  }
}

.popup-generic-content {
  animation: popup-fade-in 0.2s ease-out;
}

.popup-generic-content.hiding {
  animation: popup-fade-out 0.15s ease-in;
}

html {
  font-size: 17px;
}

@media print {
  .imt-fb-container {
    display: none !important;
  }
}

#mount#mount {
  position: absolute;
  display: none;
  min-width: 250px;
  height: auto;
  --font-size: 17px;
  font-size: 17px;
}

/* float-ball */
.imt-fb-container {
  position: fixed;
  padding: 0;
  top: 335px;
  width: fit-content;
  display: flex;
  flex-direction: column;
  display: none;
  direction: ltr;
}

.imt-fb-container.left {
  align-items: flex-start;
  left: 0;
}

.imt-fb-container.right {
  align-items: flex-end;
  right: 0;
}

.imt-fb-btn {
  cursor: pointer;
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 56px;
  box-shadow: 2px 6px 10px 0px #0e121629;
}

.imt-fb-btn.left {
  border-top-right-radius: 36px;
  border-bottom-right-radius: 36px;
}

.imt-fb-btn.right {
  border-top-left-radius: 36px;
  border-bottom-left-radius: 36px;
}

.imt-fb-btn div {
  background: var(--float-ball-more-button-background-color);
  height: 36px;
  width: 54px;
  display: flex;
  align-items: center;
}

.imt-fb-btn.left div {
  border-top-right-radius: 34px;
  border-bottom-right-radius: 34px;
  justify-content: flex-end;
}

.imt-fb-btn.right div {
  border-top-left-radius: 34px;
  border-bottom-left-radius: 34px;
}

.imt-fb-logo-img {
  width: 20px;
  height: 20px;
  margin: 0 10px;
}

.imt-fb-logo-img-big-bg {
  width: 28px;
  height: 28px;
  margin: 0;
  padding: 4px;
  background-color: #ed6d8f;
  border-radius: 50%;
  margin: 0 5px;
}

.imt-float-ball-translated {
  position: absolute;
  width: 11px;
  height: 11px;
  bottom: 4px;
  right: 20px;
}

.btn-animate {
  -webkit-transform: translate3d(0, 0, 0);
  transform: translate3d(0, 0, 0);
  -webkit-transition: -webkit-transform ease-out 250ms;
  transition: -webkit-transform ease-out 250ms;
  transition: transform ease-out 250ms;
  transition: transform ease-out 250ms, -webkit-transform ease-out 250ms;
}

.imt-fb-setting-btn {
  margin-right: 18px;
  width: 28px;
  height: 28px;
}

.immersive-translate-popup-wrapper {
  background: var(--background-color);
  border-radius: 20px;
  box-shadow: 2px 10px 24px 0px #0e121614;
  border: none;
}

.popup-container {
  border-radius: 20px;
}

.popup-content {
  border-radius: 20px 20px 12px 12px;
}
.popup-footer {
  border-radius: 20px;
}

.imt-fb-close-button {
  pointer-events: all;
  cursor: pointer;
  position: absolute;
  margin-top: -10px;
}

.imt-fb-close-content {
  padding: 22px;
  width: 320px;
  pointer-events: all;
}

.imt-fb-close-title {
  font-weight: 500;
  color: var(--h2-color);
}

.imt-fb-close-radio-content {
  background-color: var(--background-light-green);
  padding: 8px 20px;
}

.imt-fb-radio-sel,
.imt-fb-radio-nor {
  width: 16px;
  height: 16px;
  border-radius: 8px;
  flex-shrink: 0;
}

.imt-fb-radio-sel {
  border: 2px solid var(--primary);
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-radio-sel div {
  width: 8px;
  height: 8px;
  border-radius: 4px;
  background-color: var(--primary);
}

.imt-fb-radio-nor {
  border: 2px solid #d3d4d6;
}

.imt-fb-primary-btn {
  background-color: var(--primary);
  width: 72px;
  height: 32px;
  color: white;
  border-radius: 8px;
  text-align: center;
  line-height: 32px;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-default-btn {
  border: 1px solid var(--primary);
  width: 72px;
  height: 32px;
  border-radius: 8px;
  color: var(--primary);
  line-height: 32px;
  text-align: center;
  font-size: 16px;
  cursor: pointer;
}

.imt-fb-guide-container {
  width: 312px;
  transform: translateY(-45%);
}

.imt-fb-guide-bg {
  position: absolute;
  left: 30px;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  height: 100%;
  width: 90%;
}

.imt-fb-guide-bg.left {
  transform: scaleX(-1);
}

.imt-fb-guide-content {
  margin: 16px -30px 80px 0px;
  display: flex;
  flex-direction: column;
  align-items: center;
}

.imt-fb-guide-content.left {
  margin: 16px 21px 60px 32px;
}

.imt-fb-guide-img {
  width: 220px;
  height: 112px;
}

.imt-fb-guide-message {
  font-size: 14px;
  line-height: 28px;
  color: #333333;
  white-space: pre-wrap;
  text-align: center;
  font-weight: 700;
  margin-bottom: 20px;
}

.imt-manga-guide-message {
  font-size: 16px;
  line-height: 24px;
  color: #333333;
  text-align: center;
  font-weight: 500;
  margin-bottom: 12px;
}

.imt-fb-guide-button {
  margin-top: 16px;
  line-height: 40px;
  height: 40px;
  padding: 0 20px;
  width: unset;
}

.imt-fb-more-buttons {
  box-shadow: 0px 2px 10px 0px #00000014;
  border: none;
  background: var(--float-ball-more-button-background-color);
  width: 36px;
  display: flex;
  flex-direction: column;
  border-radius: 18px;
  margin-top: 0px;
  padding: 7px 0 7px 0;
}

.imt-fb-more-buttons > div {
  margin: auto;
}

.imt-fb-side,
.imt-fb-reward {
  border-radius: 50%;
  cursor: pointer;
  pointer-events: all;
  position: relative;
}

.imt-fb-side {
  margin: 10px 0;
}

.imt-fb-new-badge {
  width: 26px;
  height: 14px;
  padding: 3px;
  background-color: #f53f3f;
  border-radius: 4px;
  position: absolute;
  top: -5px;
  right: 15px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.imt-fb-side *,
.imt-fb-reward * {
  pointer-events: all;
}

.imt-fb-more-button {
  width: 36px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
}
/* Sheet.css */
.immersive-translate-sheet {
  position: fixed;
  transform: translateY(100%);
  /* Start off screen */
  left: 0;
  right: 0;
  background-color: white;
  transition: transform 0.3s ease-out;
  /* Smooth slide transition */
  box-shadow: 0px -2px 10px rgba(0, 0, 0, 0.1);
  /* Ensure it's above other content */
  bottom: 0;
  border-top-left-radius: 16px;
  border-top-right-radius: 16px;
  overflow: hidden;
}

.immersive-translate-sheet.visible {
  transform: translateY(0);
}

.immersive-translate-sheet-backdrop {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  opacity: 0;
  transition: opacity 0.3s ease-out;
}

.immersive-translate-sheet-backdrop.visible {
  opacity: 1;
}

.popup-container-sheet {
  max-width: 100vw;
  width: 100vw;
}

.imt-no-events svg * {
  pointer-events: none !important;
}

.imt-manga-button {
  width: 36px;
  display: flex;
  flex-direction: column;
  position: relative;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  pointer-events: all;
  margin: 0 0 10px 0;
  background-color: var(--float-ball-more-button-background-color);
  border-radius: 18px;
  filter: drop-shadow(0px 2px 10px rgba(0, 0, 0, 0.08));
  opacity: 0.5;
  right: 8px;
  padding: 10px 0 4px 0;
}

.imt-manga-feedback {
  cursor: pointer;
  margin-bottom: 10px;
}

.imt-fb-feedback {
  cursor: pointer;
  margin-top: 10px;
}

.imt-fb-upgrade-button {
  cursor: pointer;
  margin-top: 10px;
}

.imt-manga-button:hover {
  opacity: 1;
}

.imt-manga-translated {
  position: absolute;
  left: 24px;
  top: 20px;
}

.imt-float-ball-loading {
  animation: imt-loading-animation 0.6s infinite linear !important;
}

.imt-manga-guide-bg {
  position: absolute;
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  z-index: -1;
  width: 372px;
  transform: translateY(-50%);
}
.imt-manga-guide-content {
  position: absolute;
  top: 15px;
  left: 0;
  right: 0;
  margin: 0 40px 0;
}

.img-manga-guide-button {
  width: fit-content;
  margin: 0 auto;
}

.img-manga-close {
  position: absolute;
  bottom: -200px;
  width: 32px;
  height: 32px;
  left: 0;
  right: 0;
  margin: auto;
  cursor: pointer;
}

.imt-fb-container.dragging .imt-fb-more-buttons,
.imt-fb-container.dragging .imt-manga-button,
.imt-fb-container.dragging .btn-animate:not(.imt-fb-btn) {
  display: none !important;
}

.imt-fb-container.dragging .imt-fb-btn {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  cursor: move !important;
}

.imt-fb-container.dragging .imt-fb-btn div {
  border-radius: 50% !important;
  width: 36px !important;
  height: 36px !important;
  display: flex !important;
  align-items: center !important;
  justify-content: center !important;
  margin: 0 !important;
}

.imt-fb-container.dragging .imt-fb-btn.left,
.imt-fb-container.dragging .imt-fb-btn.right {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-btn.left div,
.imt-fb-container.dragging .imt-fb-btn.right div {
  border-radius: 50% !important;
}

.imt-fb-container.dragging .imt-fb-logo-img {
  margin: 0 !important;
  padding: 4px !important;
}

.imt-fb-container.dragging .imt-float-ball-translated {
  right: 2px !important;
  bottom: 2px !important;
}

@-webkit-keyframes imt-loading-animation {
  from {
    -webkit-transform: rotate(0deg);
  }

  to {
    -webkit-transform: rotate(359deg);
  }
}

@keyframes imt-loading-animation {
  from {
    transform: rotate(0deg);
  }

  to {
    transform: rotate(359deg);
  }
}

.imt-fb-icon {
  color: #666666;
}

[data-theme="dark"] .imt-fb-icon {
  color: #B3B3B3;
}

[data-theme="light"] .imt-fb-icon {
  color: #666666;
}
</style><div id="mount" style="display: block;"><div class="imt-fb-container right notranslate " data-theme="dark" style="z-index: 2147483637; pointer-events: none; right: 0px; top: 566px; display: flex;"><div class="btn-animate" style="transform: translateX(-4px); opacity: 0.7; padding-left: 10px;"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-btn imt-fb-more-button imt-fb-side"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M8.60547 12.9228C8.84029 12.9228 9.03755 13.0022 9.19629 13.161C9.3551 13.3198 9.43457 13.5171 9.43457 13.7519V18.5107C9.43457 18.7453 9.35513 18.9426 9.19629 19.1015C9.03755 19.2602 8.84029 19.3398 8.60547 19.3398H3.8457C3.61127 19.3397 3.41464 19.26 3.25586 19.1015C3.09712 18.9426 3.01758 18.7453 3.01758 18.5107V13.7519C3.01758 13.517 3.09712 13.3198 3.25586 13.161C3.41465 13.0023 3.61125 12.9229 3.8457 12.9228H8.60547ZM17.208 12.9228C17.4427 12.9228 17.6399 13.0022 17.7988 13.161C17.9575 13.3198 18.0371 13.5171 18.0371 13.7519V18.5107C18.0371 18.7453 17.9576 18.9426 17.7988 19.1015C17.6399 19.2602 17.4427 19.3398 17.208 19.3398H12.4492C12.2144 19.3398 12.0171 19.2602 11.8584 19.1015C11.6995 18.9426 11.6201 18.7453 11.6201 18.5107V13.7519C11.6201 13.517 11.6995 13.3198 11.8584 13.161C12.0171 13.0022 12.2144 12.9228 12.4492 12.9228H17.208ZM4.39258 17.9648H8.05957V14.2978H4.39258V17.9648ZM12.9951 17.9648H16.6621V14.2978H12.9951V17.9648ZM14.7598 2.92179C14.8641 2.57295 15.3576 2.57295 15.4619 2.92179L15.9561 4.57511C16.1376 5.18219 16.5965 5.66815 17.1924 5.8837L18.7412 6.44327C19.0635 6.56002 19.0633 7.01583 18.7412 7.13273L17.1924 7.69327C16.5966 7.90881 16.1376 8.39389 15.9561 9.00089L15.4619 10.6552C15.3575 11.0038 14.8642 11.0037 14.7598 10.6552L14.2646 9.00089C14.0831 8.39401 13.625 7.90881 13.0293 7.69327L11.4805 7.13273C11.158 7.01598 11.1579 6.55996 11.4805 6.44327L13.0293 5.8837C13.6251 5.66814 14.0831 5.18219 14.2646 4.57511L14.7598 2.92179ZM8.60547 4.32023C8.84029 4.32023 9.03755 4.39977 9.19629 4.55851C9.35496 4.71727 9.43448 4.91396 9.43457 5.14835V9.90812C9.43457 10.1429 9.35518 10.3402 9.19629 10.4989C9.03755 10.6578 8.84029 10.7372 8.60547 10.7372H3.8457C3.61131 10.7371 3.41463 10.6576 3.25586 10.4989C3.09712 10.3402 3.01758 10.1429 3.01758 9.90812V5.14835C3.01767 4.91386 3.09721 4.71731 3.25586 4.55851C3.41466 4.39986 3.61121 4.32032 3.8457 4.32023H8.60547ZM4.39258 9.36222H8.05957V5.69523H4.39258V9.36222Z" fill="currentColor"></path></svg><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="position: absolute; right: 0px; top: 0px; display: none; transform: translate(30%, -30%);"><g clip-path="url(#clip0_34242_2353)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14Z" fill="#B1B1B1" fill-opacity="0.32"></path><mask id="mask0_34242_2353" maskUnits="userSpaceOnUse" x="1" y="1" width="12" height="12" style="mask-type: alpha;"><rect x="1" y="1" width="12" height="12" fill="#D9D9D9"></rect></mask><g mask="url(#mask0_34242_2353)"><path d="M7.86447 3.67324H6.13622V4.72999L4.80409 3.39199C4.75018 3.33699 4.70972 3.27808 4.68272 3.21524C4.65572 3.15241 4.64222 3.09533 4.64222 3.04399C4.64222 2.93141 4.68193 2.8352 4.76134 2.75537C4.84076 2.67562 4.94514 2.63574 5.07447 2.63574H8.98322C9.12864 2.63574 9.25147 2.68883 9.35172 2.79499C9.45189 2.90124 9.50197 3.04578 9.50197 3.22862C9.50197 3.35203 9.46122 3.46245 9.37972 3.55987C9.29822 3.65737 9.18897 3.69516 9.05197 3.67324H8.90197V6.36774C8.90197 6.51316 8.85214 6.63599 8.75247 6.73624C8.65272 6.83641 8.53051 6.88649 8.38585 6.88649C8.24118 6.88649 8.11809 6.83641 8.01659 6.73624C7.91518 6.63599 7.86447 6.51316 7.86447 6.36774V3.67324ZM6.4816 11.974V9.13599H4.57509C4.36193 9.13599 4.19043 9.06703 4.06059 8.92912C3.93076 8.79112 3.86584 8.62983 3.86584 8.44524C3.86584 8.35591 3.88509 8.26499 3.92359 8.17249C3.96209 8.08008 4.01984 7.99437 4.09684 7.91537L5.09872 6.89549V6.36149L2.32422 3.58412C2.22664 3.48645 2.1788 3.37678 2.18072 3.25512C2.18272 3.13345 2.23155 3.02483 2.32722 2.92924C2.42489 2.83158 2.53614 2.78274 2.66097 2.78274C2.7858 2.78274 2.89701 2.83158 2.99459 2.92924L10.9898 10.9245C11.0863 11.0209 11.1351 11.13 11.1361 11.2516C11.1371 11.3733 11.0898 11.4839 10.9941 11.5835C10.8984 11.6772 10.7867 11.7235 10.6588 11.7225C10.5311 11.7215 10.4194 11.6732 10.3237 11.5776L7.87909 9.13599L7.51909 9.14199V11.974C7.51909 12.1195 7.46926 12.2423 7.3696 12.3425C7.26985 12.4427 7.14764 12.4927 7.00297 12.4927C6.8583 12.4927 6.73522 12.4427 6.63372 12.3425C6.5323 12.2423 6.4816 12.1195 6.4816 11.974ZM5.35909 8.09849H6.83872L6.08834 7.35124L6.09434 7.35724L5.35909 8.09849Z" fill="white"></path></g></g><defs><clippath id="clip0_34242_2353"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div></div><div hidden="" class="imt-no-events btn-animate " id="manga-button" style="position: relative;"><div class="imt-manga-button" style="transform: translateX(2px);"><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><svg class="imt-manga-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div><div style="position: relative;"><svg width="32" height="32" viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="manhua"><path id="Vector" d="M14.8853 4.92364C14.8853 4.92364 16.3905 10.4362 22.6668 4C22.6668 4 20.3381 10.8907 25.3364 10.0843C25.3364 10.0843 22.0563 15.6994 29 18.0599C29 18.0599 22.9934 19.306 21.1617 28C21.1617 28 17.7679 24.54 14.8853 27.3549C14.8853 27.3549 13.3233 23.5724 7.33097 26.27C7.33097 26.27 10.1141 20.6549 4.83179 21.0507C4.83179 21.0507 7.16057 18.8955 3 15.9047C3 15.9047 7.50137 16.1833 6.33697 11.7117C6.33697 11.7117 10.0005 12.3421 8.66576 6.82957C8.65156 6.81491 12.4855 9.80574 14.8853 4.92364Z" fill="#ED6D8F"></path><path id="Vector_2" d="M20.8599 13.7022C20.885 13.1361 20.9543 12.5713 20.9959 12.0052C21.0337 11.568 20.8107 11.2794 20.3876 11.18C20.0759 11.1013 19.7508 11.0867 19.433 11.137C19.1951 11.1945 18.9542 11.2396 18.7113 11.2721C18.2403 11.3028 17.9973 11.5275 17.9796 11.988C17.977 12.0833 17.9596 12.1777 17.928 12.268C17.3034 13.9102 16.6774 15.5499 16.0503 17.1873C16.0301 17.2401 16.0062 17.2904 15.9671 17.3776C15.7291 16.8975 15.4281 16.4898 15.2745 15.9986C14.8073 14.5152 14.3186 13.033 13.8312 11.5594C13.6826 11.1112 13.3489 10.9344 12.8754 11.0216C12.7889 11.0365 12.7008 11.0398 12.6134 11.0314C12.2241 10.9938 11.8311 11.0404 11.4623 11.1677C11.0946 11.2991 10.9498 11.557 11.0152 11.9254C11.0428 12.0371 11.0643 12.1503 11.0795 12.2643C11.1223 13.1902 11.1777 14.1087 11.2054 15.0321C11.257 16.7992 11.2117 18.5651 11.0858 20.3284C11.0644 20.6354 11.0304 20.9424 11.0228 21.2494C11.0115 21.6092 11.1613 21.7811 11.5266 21.8143C11.9976 21.8573 12.4711 21.8708 12.9421 21.9088C13.0309 21.9201 13.121 21.9003 13.1962 21.8528C13.2714 21.8053 13.3268 21.7334 13.3527 21.6497C13.3996 21.5394 13.4252 21.4216 13.4282 21.3022C13.4295 20.8258 13.4207 20.3493 13.4081 19.8741C13.393 19.3264 13.3917 18.7763 13.3438 18.231C13.2857 17.5839 13.266 16.934 13.2847 16.2847C13.2847 16.2466 13.291 16.2073 13.2985 16.1312C13.3338 16.2024 13.3514 16.2356 13.3665 16.2712C13.9017 17.5228 14.3617 18.8037 14.7443 20.1074C14.7928 20.2421 14.7928 20.3889 14.7443 20.5237C14.6322 20.8196 14.7141 21.037 14.9659 21.1377C15.4445 21.3268 15.9331 21.4926 16.4155 21.6731C16.4865 21.7033 16.566 21.7091 16.6408 21.6895C16.7157 21.6698 16.7815 21.6259 16.8273 21.565C16.9085 21.4643 16.9743 21.3526 17.0225 21.2335C17.0537 21.1374 17.0798 21.0399 17.1006 20.9412C17.3185 20.2425 17.5653 19.5499 17.7517 18.8438C17.9785 17.9723 18.2624 17.1158 18.6018 16.2798C18.6201 16.2439 18.6411 16.2094 18.6647 16.1766C18.6761 16.2319 18.6761 16.254 18.6761 16.2761C18.6345 17.59 18.5955 18.8978 18.5501 20.2056C18.5363 20.5949 18.491 20.9829 18.4809 21.3722C18.4721 21.705 18.6207 21.8708 18.9557 21.9002C19.4355 21.9432 19.9191 21.9592 20.4002 21.9973C20.4888 22.0079 20.5784 21.9875 20.653 21.9399C20.7277 21.8922 20.7827 21.8203 20.8082 21.7369C20.8531 21.6305 20.8766 21.5167 20.8775 21.4017C20.88 20.7668 20.8674 20.132 20.8674 19.4971C20.8662 19.2846 20.8687 19.0722 20.8523 18.8622C20.8158 18.3968 20.7264 17.9314 20.7339 17.4685C20.7515 16.2122 20.8044 14.9572 20.8599 13.7022Z" fill="white"></path></g></svg><svg hidden="true" class="imt-manga-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div><svg class="imt-float-ball-loading" hidden="true" width="19" height="19" viewBox="0 0 19 19" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin: 9px;"><path d="M9.42859 0C9.84288 0 10.1929 0.387143 10.1929 0.847143V3.99429C10.1929 4.45429 9.84431 4.84143 9.42859 4.84143C9.01431 4.84143 8.66431 4.45571 8.66431 3.99429V0.847143C8.66431 0.387143 9.01288 0 9.42859 0Z" fill="#E9E9E9"></path><path d="M14.1301 1.38877C14.5158 1.62591 14.6301 2.12163 14.4258 2.52305L12.9515 5.19448C12.901 5.28714 12.8325 5.36876 12.75 5.43455C12.6675 5.50035 12.5727 5.54898 12.4712 5.5776C12.3696 5.60621 12.2634 5.61424 12.1586 5.60119C12.0539 5.58814 11.9529 5.55429 11.8615 5.50163C11.6787 5.38432 11.5468 5.20237 11.4923 4.9921C11.4377 4.78184 11.4645 4.55874 11.5672 4.36734L13.0415 1.69591C13.2686 1.29448 13.7443 1.15305 14.1301 1.38877Z" fill="#989697"></path><path d="M17.4685 4.75707C17.5813 4.95451 17.6123 5.18824 17.5549 5.40825C17.4975 5.62826 17.3563 5.81705 17.1614 5.93422L14.4971 7.52564C14.0971 7.76993 13.6014 7.62422 13.3657 7.20707C13.2532 7.00994 13.2222 6.77667 13.2793 6.55702C13.3365 6.33737 13.4771 6.14874 13.6714 6.03136L16.3357 4.43993C16.7371 4.21993 17.2557 4.34136 17.4685 4.7585V4.75707Z" fill="#9B999A"></path><path d="M18.8572 9.42835C18.8572 9.84263 18.47 10.1926 18.01 10.1926H14.8629C14.4029 10.1926 14.0157 9.84406 14.0157 9.42835C14.0157 9.01406 14.4029 8.66406 14.8629 8.66406H18.01C18.47 8.66406 18.8572 9.01263 18.8572 9.42835Z" fill="#A3A1A2"></path><path d="M17.4686 14.1303C17.3515 14.3134 17.1697 14.4455 16.9594 14.5003C16.7491 14.5552 16.5259 14.5286 16.3343 14.426L13.6629 12.9517C13.5702 12.9012 13.4886 12.8327 13.4228 12.7503C13.357 12.6678 13.3084 12.573 13.2798 12.4714C13.2512 12.3698 13.2431 12.2636 13.2562 12.1589C13.2692 12.0542 13.3031 11.9532 13.3558 11.8617C13.4731 11.6789 13.655 11.547 13.8653 11.4925C14.0755 11.4379 14.2986 11.4647 14.49 11.5674L17.1615 13.0417C17.5629 13.2689 17.7043 13.7446 17.4686 14.1303Z" fill="#ABA9AA"></path><path opacity="0.7" d="M14.1 17.4686C13.9026 17.5814 13.6689 17.6124 13.4489 17.555C13.2288 17.4976 13.04 17.3564 12.9229 17.1615L11.3315 14.4972C11.0872 14.0972 11.2329 13.6015 11.65 13.3658C11.8472 13.2533 12.0804 13.2224 12.3001 13.2795C12.5197 13.3366 12.7084 13.4773 12.8257 13.6715L14.4172 16.3358C14.6372 16.7372 14.5157 17.2558 14.0986 17.4686H14.1Z" fill="#B2B2B2"></path><path opacity="0.6" d="M9.42859 18.8571C9.01431 18.8571 8.66431 18.4699 8.66431 18.0099V14.8628C8.66431 14.4028 9.01288 14.0156 9.42859 14.0156C9.84288 14.0156 10.1929 14.4028 10.1929 14.8628V18.0099C10.1929 18.4699 9.84431 18.8571 9.42859 18.8571Z" fill="#BAB8B9"></path><path opacity="0.5" d="M4.72717 17.4685C4.5441 17.3514 4.41195 17.1696 4.35713 16.9593C4.30231 16.749 4.32885 16.5258 4.43145 16.3342L5.90574 13.6628C5.95622 13.5701 6.02472 13.4885 6.1072 13.4227C6.18969 13.3569 6.2845 13.3083 6.38606 13.2797C6.48762 13.251 6.59387 13.243 6.69857 13.2561C6.80327 13.2691 6.90431 13.303 6.99574 13.3556C7.38145 13.5914 7.49431 14.0885 7.29002 14.4899L5.81574 17.1614C5.5886 17.5628 5.11288 17.7042 4.72717 17.4685Z" fill="#C2C0C1"></path><path opacity="0.4" d="M1.38862 14.1002C1.27584 13.9027 1.24483 13.669 1.30223 13.449C1.35964 13.229 1.50089 13.0402 1.69576 12.923L4.36004 11.3316C4.76004 11.0873 5.25576 11.233 5.49147 11.6502C5.60393 11.8473 5.63491 12.0806 5.5778 12.3002C5.52069 12.5199 5.38 12.7085 5.18576 12.8259L2.52004 14.4173C2.12004 14.6373 1.60004 14.5159 1.38862 14.0987V14.1002Z" fill="#CBCBCB"></path><path d="M0 9.42835C0 9.01406 0.387143 8.66406 0.847143 8.66406H3.99429C4.45429 8.66406 4.84143 9.01263 4.84143 9.42835C4.84143 9.84263 4.45571 10.1926 3.99429 10.1926H0.847143C0.387143 10.1926 0 9.84406 0 9.42835Z" fill="#D2D2D2"></path><path opacity="0.2" d="M1.38852 4.72705C1.50561 4.54398 1.68746 4.41183 1.89774 4.35701C2.10803 4.30219 2.33125 4.32873 2.52281 4.43133L5.19424 5.90562C5.28689 5.9561 5.36851 6.0246 5.43431 6.10708C5.5001 6.18957 5.54874 6.28438 5.57735 6.38594C5.60597 6.48749 5.61399 6.59375 5.60094 6.69845C5.5879 6.80315 5.55405 6.90419 5.50138 6.99562C5.38407 7.17844 5.20212 7.31029 4.99186 7.36484C4.78159 7.4194 4.55849 7.39263 4.3671 7.2899L1.69567 5.81562C1.29424 5.58847 1.15281 5.11276 1.38852 4.72705Z" fill="#DADADA"></path><path d="M4.75719 1.38849C4.95463 1.27571 5.18837 1.24471 5.40838 1.30211C5.62838 1.35952 5.81718 1.50077 5.93434 1.69564L7.52577 4.35992C7.77005 4.75992 7.62434 5.25564 7.20719 5.49135C7.01006 5.60381 6.77679 5.63479 6.55714 5.57768C6.33749 5.52056 6.14886 5.37988 6.03148 5.18564L4.44005 2.51992C4.22005 2.11992 4.34148 1.59992 4.75862 1.38849H4.75719Z" fill="#E2E2E2"></path></svg></div></div><div class=" " style="position: relative; pointer-events: all; display: inline-block;"><div><div style="display: flex; align-items: center; flex-direction: row;"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: block; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg><div class="imt-fb-btn  right btn-animate " dir="ltr" style="transform: translateX(15px); opacity: 0.7;"><div><svg class="imt-fb-logo-img imt-fb-logo-img-big-bg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20"><path fill="none" d="M0 0h24v24H0z"></path><path d="M5 15v2a2 2 0 0 0 1.85 1.995L7 19h3v2H7a4 4 0 0 1-4-4v-2h2zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2zm-1 2.885L15.753 16h2.492L17 12.885zM8 2v2h4v7H8v3H6v-3H2V4h4V2h2zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3zM6 6H4v3h2V6zm4 0H8v3h2V6z" fill="rgba(255,255,255,1)"></path></svg><svg hidden="true" class="imt-float-ball-translated" width="11" height="11" viewBox="0 0 11 11" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="5.5" cy="5.5" r="5.5" fill="#60BB4C"></circle><path d="M1.40869 5.87858L2.24161 5.18962L4.15357 6.64214C4.15357 6.64214 6.33559 4.15566 9.0067 2.48145L9.32553 2.87514C9.32553 2.87514 6.28678 5.55844 4.71748 9.07881L1.40869 5.87858Z" fill="#EFF8ED"></path></svg></div></div><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg" style="display: none; opacity: 0;"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div></div><div style="position: relative; width: 100%; opacity: 0;"><div title="关闭悬浮球" class="imt-fb-close-button" style="transform: translateX(100%);"><svg width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2589_9951)"><path d="M7 14C5.14348 14 3.36301 13.2625 2.05025 11.9497C0.737498 10.637 0 8.85652 0 7C0 5.14348 0.737498 3.36301 2.05025 2.05025C3.36301 0.737498 5.14348 0 7 0C8.85652 0 10.637 0.737498 11.9497 2.05025C13.2625 3.36301 14 5.14348 14 7C14 8.85652 13.2625 10.637 11.9497 11.9497C10.637 13.2625 8.85652 14 7 14ZM4.183 5.064L6.118 7L4.183 8.936C4.12409 8.99361 4.07719 9.06234 4.04502 9.1382C4.01285 9.21406 3.99605 9.29554 3.99559 9.37794C3.99513 9.46034 4.01101 9.54201 4.04234 9.61823C4.07366 9.69444 4.11978 9.76369 4.17805 9.82195C4.23631 9.88022 4.30556 9.92634 4.38177 9.95766C4.45799 9.98898 4.53966 10.0049 4.62206 10.0044C4.70446 10.004 4.78594 9.98715 4.8618 9.95498C4.93766 9.92281 5.00639 9.87591 5.064 9.817L7 7.882L8.936 9.817C9.05327 9.93168 9.21104 9.99548 9.37506 9.99457C9.53908 9.99365 9.69612 9.92809 9.8121 9.8121C9.92809 9.69612 9.99365 9.53908 9.99457 9.37506C9.99548 9.21104 9.93168 9.05327 9.817 8.936L7.882 7L9.817 5.064C9.87591 5.00639 9.92281 4.93766 9.95498 4.8618C9.98715 4.78594 10.004 4.70446 10.0044 4.62206C10.0049 4.53966 9.98898 4.45799 9.95766 4.38177C9.92634 4.30556 9.88022 4.23631 9.82195 4.17805C9.76369 4.11978 9.69444 4.07366 9.61823 4.04234C9.54201 4.01101 9.46034 3.99513 9.37794 3.99559C9.29554 3.99605 9.21406 4.01285 9.1382 4.04502C9.06234 4.07719 8.99361 4.12409 8.936 4.183L7 6.118L5.064 4.183C4.94673 4.06832 4.78896 4.00452 4.62494 4.00543C4.46092 4.00635 4.30388 4.07191 4.1879 4.1879C4.07191 4.30388 4.00635 4.46092 4.00543 4.62494C4.00452 4.78896 4.06832 4.94673 4.183 5.064Z" fill="#B1B1B1" fill-opacity="0.32"></path></g><defs><clippath id="clip0_2589_9951"><rect width="14" height="14" fill="white"></rect></clippath></defs></svg></div></div><div class="imt-fb-more-buttons btn-animate" style="margin-top: 10px; transform: translateX(60px);"><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg" style="width: 22px; height: 22px;"><path d="M16 7.66699H10.375" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M11.625 14.333L6 14.333" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M14.125 16C15.1605 16 16 15.1605 16 14.125C16 13.0895 15.1605 12.25 14.125 12.25C13.0895 12.25 12.25 13.0895 12.25 14.125C12.25 15.1605 13.0895 16 14.125 16Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><path d="M7.875 9.75C8.91053 9.75 9.75 8.91053 9.75 7.875C9.75 6.83947 8.91053 6 7.875 6C6.83947 6 6 6.83947 6 7.875C6 8.91053 6.83947 9.75 7.875 9.75Z" stroke="currentColor" stroke-width="1.4" stroke-linecap="round" stroke-linejoin="round"></path><rect x="3" y="3" width="16" height="16" rx="1.66667" stroke="currentColor" stroke-width="1.4"></rect></svg></div></div></div><div class=" btn-animate" style="position: relative; pointer-events: all; display: inline-block;"><div><div class="imt-fb-more-button"><svg class="imt-fb-feedback imt-fb-icon" width="22" height="22" viewBox="0 0 22 22" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M11.0003 14.2749C11.213 14.2749 11.3895 14.2047 11.5299 14.0643C11.6705 13.9239 11.7408 13.7473 11.7408 13.5345C11.7408 13.3218 11.6705 13.1453 11.5299 13.0049C11.3895 12.8645 11.213 12.7943 11.0003 12.7943C10.7877 12.7943 10.6111 12.8645 10.4707 13.0049C10.3302 13.1453 10.2599 13.3218 10.2599 13.5345C10.2599 13.7473 10.3302 13.9239 10.4707 14.0643C10.6111 14.2047 10.7877 14.2749 11.0003 14.2749ZM11.0003 11.0842C11.1954 11.0842 11.3587 11.0185 11.4903 10.8869C11.622 10.7552 11.6878 10.5918 11.6878 10.3967V6.23645C11.6878 6.04135 11.622 5.87803 11.4903 5.74649C11.3587 5.6148 11.1954 5.54895 11.0003 5.54895C10.8052 5.54895 10.6419 5.6148 10.5104 5.74649C10.3787 5.87803 10.3128 6.04135 10.3128 6.23645V10.3967C10.3128 10.5918 10.3787 10.7552 10.5104 10.8869C10.6419 11.0185 10.8052 11.0842 11.0003 11.0842ZM5.53562 16.8311L3.70045 18.666C3.43966 18.9269 3.13968 18.9861 2.80051 18.8434C2.4615 18.7005 2.29199 18.4434 2.29199 18.072V4.73816C2.29199 4.27509 2.45241 3.88314 2.77324 3.5623C3.09408 3.24147 3.48603 3.08105 3.9491 3.08105H18.0516C18.5146 3.08105 18.9066 3.24147 19.2274 3.5623C19.5482 3.88314 19.7087 4.27509 19.7087 4.73816V15.174C19.7087 15.637 19.5482 16.029 19.2274 16.3498C18.9066 16.6706 18.5146 16.8311 18.0516 16.8311H5.53562ZM4.95033 15.4561H18.0516C18.1221 15.4561 18.1868 15.4266 18.2454 15.3678C18.3042 15.3092 18.3337 15.2445 18.3337 15.174V4.73816C18.3337 4.66758 18.3042 4.60295 18.2454 4.54428C18.1868 4.48546 18.1221 4.45605 18.0516 4.45605H3.9491C3.87851 4.45605 3.81389 4.48546 3.75522 4.54428C3.6964 4.60295 3.66699 4.66758 3.66699 4.73816V16.7254L4.95033 15.4561Z" fill="currentColor"></path></svg></div></div></div></div><div hidden="" id="immersive-translate-popup-overlay" class="immersive-translate-popup-overlay"><div class="immersive-translate-popup-wrapper" style="position: fixed; bottom: 30px; right: 65px;"></div></div></div></div></template></div></html>